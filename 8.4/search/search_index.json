{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Percona Server for MySQL 8.4 - Documentation","text":"<p>This documentation is for the latest release: Percona Server for MySQL 8.4.0-1 (Release Notes).</p> <p>Percona Server for MySQL is a freely available, fully compatible, enhanced, and open source drop-in replacement for any MySQL database. It provides superior and optimized performance, greater scalability, and availability, enhanced backups, increased visibility and instrumentation.</p> <p>Percona Server for MySQL is trusted by thousands of enterprises to provide better performance and concurrency for their most demanding workloads.</p>"},{"location":"index.html#for-monitoring-and-management","title":"For Monitoring and Management","text":"<p>Percona Monitoring and Management (PMM )monitors and provides actionable performance data for MySQL variants, including Percona Server for MySQL, Percona XtraDB Cluster, Oracle MySQL Community Edition, Oracle MySQL Enterprise Edition, and MariaDB. PMM captures metrics and data for the InnoDB, XtraDB, and MyRocks storage engines, and has specialized dashboards for specific engine details.</p> <p>Install PMM and connect your MySQL instances to it.</p> <p></p>"},{"location":"index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"adaptive-network-buffers.html","title":"Adaptive network buffers","text":"<p>To find the buffer size of the current connection, use the <code>network_buffer_length</code> status variable. Add <code>SHOW GLOBAL</code> to review the cumulative buffer sizes for all connections. This variable can help to estimate the maximum size of the network buffer\u2019s overhead.</p> <p>Network buffers grow towards the max_allowed_packet size and do not shrink until the connection is terminated. For example, if the connections are selected at random from the pool, an occasional big query eventually increases the buffers of all connections. The combination of max_allowed packet set to a value between 64MB to 128MB and the connection number between 256 to 1024 can create a large memory overhead.</p> <p>Percona Server for MySQL implemented the net_buffer_shrink_interval variable to solve this issue. The default value is 0 (zero). If you set the value higher than 0, Percona Server records the network buffer\u2019s maximum use size for the number of seconds set by net_buffer_shrink_interval. When the next interval starts, the network buffer is set to the recorded size. This action removes spikes in the buffer size.</p> <p>You can achieve similar results by disconnecting and reconnecting the TCP connections, but this solution is a heavier process. This process disconnects and reconnects connections with small buffers.</p>"},{"location":"adaptive-network-buffers.html#net_buffer_shrink_interval","title":"<code>net_buffer_shrink_interval</code>","text":"Option Description Command-line: \u2013net-buffer-shrink-interval=# Scope: Global Dynamic: Yes Data type: integer Default value: 0 <p>The interval is measured in seconds. The default value is 0, which disables the functionality. The minimum value is 0, and the maximum value is 31536000.</p> <p></p>"},{"location":"adaptive-network-buffers.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"additional-selinux-tools.html","title":"Additional SELinux tools and management","text":""},{"location":"additional-selinux-tools.html#installing-selinux-management-tools","title":"Installing SELinux management tools","text":"<p>To install SELinux management tools on Red Hat Enterprise Linux 8 or later, run the following command as root:</p> <pre><code>$ yum -y install policycoreutils-python-utils\n</code></pre> <p>Ensure you have root privileges to execute these commands.</p>"},{"location":"additional-selinux-tools.html#switching-selinux-mode","title":"Switching SELinux mode","text":"<p>SELinux can operate in three modes: Disabled, Permissive, and Enforcing. </p> <p>To switch SELinux mode until the next reboot, use either of the following commands as root:</p> <p><pre><code>$ setenforce Enforcing\n</code></pre> or <pre><code>$ setenforce 1\n</code></pre></p> <p>To view the current SELinux mode, use either of the following commands:</p> <p><pre><code>$ getenforce\n</code></pre> or <pre><code>$ sestatus | grep -i mode\n</code></pre></p>"},{"location":"additional-selinux-tools.html#managing-selinux-policies","title":"Managing SELinux policies","text":""},{"location":"additional-selinux-tools.html#using-the-semanage-command","title":"Using the semanage command","text":"<p>To add a service to the permissive domain, execute the following as root:</p> <pre><code>$ semanage permissive -a &lt;service_name&gt;\n</code></pre> <p>To delete a service from the permissive domain, run:</p> <pre><code>$ semanage permissive -d &lt;service_name&gt;\n</code></pre>"},{"location":"additional-selinux-tools.html#list-the-current-permissive-domains","title":"List the current Permissive domains","text":"<p>To list the current permissive domains, use the following command:</p> <pre><code>$ semanage permissive -l\n</code></pre> <p></p>"},{"location":"additional-selinux-tools.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"advisors.html","title":"Use Percona Monitoring and Management (PMM) Advisors","text":"<p>Percona Monitoring and Management (PMM) provides several categories of Advisors. Each Advisor contains a set of automated checks. These checks investigate your database settings for a specific range of possible issues.</p> <p>The Percona Platform hosts the Advisors. </p> <p>The PMM Server automatically downloads the Advisors if the <code>Advisors</code> and <code>Telemetry</code> options are enabled in <code>Configuration &gt; Settings &gt; Advanced Settings</code>. Both options are enabled by default.</p> <p>See also</p> <p>PMM documentation - Advisor checks</p> <p></p>"},{"location":"advisors.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"ai-docs.html","title":"How we use artificial intelligence","text":"<p>The technical writer oversees the integration of AI-driven tools and platforms into the documentation workflow, ensuring that AI-generated text meets the standards for clarity, coherence, and accuracy. While AI assists in tasks such as content generation, language enhancement, and formatting optimization, the technical writer is responsible for validating and refining the output to ensure its suitability for the intended audience.</p> <p>Throughout the documentation process, the technical writer reviews the quality and relevance of AI-generated content in detail and with critical judgment. By leveraging their expertise in language, communication, and subject matter knowledge, the technical writer collaborates with AI systems to refine and tailor the documentation to meet the specific needs and preferences of the audience.</p> <p>While AI accelerates the documentation process and enhances productivity, the technical writer verifies the information\u2019s accuracy and maintains consistency in terminology, style, and tone. The technical writer ensures that the final document reflects the company\u2019s commitment to excellence.</p> <p></p>"},{"location":"ai-docs.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"aio-page-requests.html","title":"Multiple page asynchronous I/O requests","text":"<p>The I/O unit size in InnoDB is only one page, even if the server doing read ahead. A 16KB I/O unit size is too small for sequential reads, and less efficient than a larger I/O unit size. InnoDB uses Linux asynchronous I/O (<code>aio</code>) by default. By submitting multiple, consecutive 16KB read requests at the same time, Linux internally merges the requests and reads more efficiently. </p> <p>This feature is able to submit multiple page I/O requests and works in the background. You can manage the feature with the linear read-ahead technique. This technique adds pages to the buffer pool based on the buffer pool pages being accessed sequentially. The [<code>innodb_read_ahead_threshold</code>] configuration parameter controls this operation.</p> <p>On a HDD RAID 1+0 environment, more than 1000MB/s disk reads can be achieved by submitting 64 consecutive pages requests at once, while only 160MB/s disk reads is shown by submitting single page request.</p>"},{"location":"aio-page-requests.html#status-variables","title":"Status variables","text":""},{"location":"aio-page-requests.html#innodb_buffered_aio_submitted","title":"<code>Innodb_buffered_aio_submitted</code>","text":"Option Description Scope: Global Data type: Numeric <p>This variable shows the number of submitted buffered asynchronous I/O requests.</p>"},{"location":"aio-page-requests.html#other-reading","title":"Other reading","text":"<ul> <li> <p>Making full table scan 10x faster in InnoDB</p> </li> <li> <p>Bug #68659  InnoDB Linux native aio should submit more i/o requests at once</p> </li> </ul> <p></p>"},{"location":"aio-page-requests.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apparmor-profiles.html","title":"AppArmor profile modes","text":"<p>AppArmor profile modes determine how applications interact with system resources. You can mix enforce mode profiles and complain mode profiles in your server. </p> Mode Description Enforce Restricts MySQL processes according to the rules defined in the profile. Any action violating these rules is denied. Complain Allows MySQL processes to take restricted actions, but logs these actions for review. Disabled Turns off profile restrictions entirely, allowing MySQL processes to take any action without logging. <p>Understanding these modes helps MySQL developers ensure that their applications can access necessary resources while maintaining system security.</p>"},{"location":"apparmor-profiles.html#benefits","title":"Benefits","text":"Benefit Description Enhanced Security AppArmor profile modes, such as Enforce and Complain, help enforce security policies to prevent unauthorized access. Easy Troubleshooting Profile modes provide flexibility in troubleshooting access issues by allowing developers to switch between modes."},{"location":"apparmor-profiles.html#disadvantages","title":"Disadvantages","text":"Disadvantage Description Limited Flexibility Profile modes may restrict certain actions or access, potentially limiting the functionality of MySQL applications. Complexity Understanding and managing different profile modes can be complex for beginner developers, leading to errors. Debugging Challenges Troubleshooting issues related to profile modes, such as DENIED entries in logs, may require additional expertise."},{"location":"apparmor-profiles.html#apparmor-links","title":"AppArmor links:","text":"<p>AppArmor Manage AppArmor Profiles Disable AppArmor Configure AppArmor Troubleshoot AppArmor</p> <p></p>"},{"location":"apparmor-profiles.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apparmor.html","title":"Secure Percona Server for MySQL with AppArmor","text":"<p>The operating system has a Discretionary Access Controls (DAC) system. AppArmor supplements the DAC with a Mandatory Access Control (MAC) system. AppArmor is the default security module for Ubuntu or Debian systems and uses profiles to define how programs access resources.</p> <p>AppArmor is path-based and restricts processes by using profiles. Each profile contains a set of policy rules. Some applications may install their profile along with the application. If an installation does not also install a profile, that application is not part of the AppArmor subsystem. You can also create profiles since they are simple text files stored in the <code>/etc/apparmor.d</code> directory.</p> <p>AppArmor enhances system security by enforcing strict access controls and protecting against unauthorized access and potential threats. It achieves this by defining profiles that specify how programs interact with system resources. These profiles act as a set of rules dictating a program\u2019s actions and the resources it can access. By confining each program to its designated profile, AppArmor limits the damage in case of a compromise and prevents unauthorized escalation of privileges. Additionally, AppArmor provides fine-grained control over program behavior, allowing administrators to tailor security policies to specific application requirements and minimize the attack surface. Overall, AppArmor is crucial in bolstering system security for MySQL developers, maintaining system integrity, and mitigating the risks associated with security breaches.</p>"},{"location":"apparmor.html#apparmor-links","title":"AppArmor links:","text":"<p>AppArmor Profiles Manage AppArmor Profiles Disable AppArmor Configure AppArmor Troubleshoot AppArmor</p> <p></p>"},{"location":"apparmor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-download-deb.html","title":"Install Percona Server for MySQL 8.4 using downloaded DEB packages","text":"<p>Download the packages from Percona Product Downloads. If needed, Instructions for the Percona Product Download are available.</p> <p>The following example downloads Percona Server for MySQL 8.4.0-1 release packages for Ubuntu 22.04:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-8.4/Percona-Server-8.4.0-1/binary/debian/jammy/x86_64/Percona-Server-8.4.0-1-r238b3c02-jammy-x86_64-bundle.tar\n</code></pre> <p>Unpack the download to get the packages:</p> <pre><code>$ tar xvf Percona-Server-8.4.0-1-r71449379-buster-x86_64-bundle.tar\n</code></pre> Expected output <pre><code>libperconaserverclient21_8.4.0-1-1.buster_amd64.deb\nlibperconaserverclient21-dev_8.4.0-1-1.buster_amd64.deb\npercona-mysql-router_8.4.0-1-1.buster_amd64.deb\npercona-server-client_8.4.0-1-1.buster_amd64.deb\npercona-server-common_8.4.0-1-1.buster_amd64.deb\npercona-server-dbg_8.4.0-1-1.buster_amd64.deb\npercona-server-rocksdb_8.4.0-1-1.buster_amd64.deb\npercona-server-server_8.4.0-1-1.buster_amd64.deb\npercona-server-source_8.4.0-1-1.buster_amd64.deb\npercona-server-test_8.4.0-1-1.buster_amd64.deb\n</code></pre> <p>Install Percona Server for MySQL using <code>dpkg</code>. Run this command as root or use the sudo command:</p> <pre><code>$ sudo dpkg -i *.deb\n</code></pre> <p>Warning</p> <p>When installing packages manually like this, you\u2019ll need to resolve all the dependencies and install missing packages yourself. The following packages will need to be installed before you can manually install Percona Server: <code>mysql-common</code>, <code>libjemalloc1</code>, <code>libaio1</code>, and <code>libmecab2</code>.</p> <p></p>"},{"location":"apt-download-deb.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-files.html","title":"Files in the DEB package built for Percona Server for MySQL 8.4","text":"Package Contains percona-server-server The database server itself, the mysqld binary and associated files. percona-server-common The files common to the server and client. percona-server-client The command line client. percona-server-dbg Debug symbols for the server. percona-server-test The database test suite. percona-server-source The server source. libperconaserverclient21-dev Header files needed to compile software to use the client library. libperconaserverclient21 The client-shared library. The version is incremented when there is an ABI change that requires software using the client library to be recompiled or its source code modified."},{"location":"apt-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-pinning.html","title":"Apt pinning the Percona Server for MySQL 8.4 packages","text":"<p>Pinning allows you to stay on a release and get packages from a different version. In some cases, you can pin selected packages and avoid accidentally upgrading all the packages. </p> <p>The pinning takes place in the <code>preference</code> file. To pin a package, set the <code>Pin-Priority</code> to higher numbers. </p> <p>Make a new file <code>/etc/apt/preferences.d/00percona.pref</code>. For example, add the following to the <code>preference</code> file:</p> <pre><code>Package: \nPin: release o=Percona Development Team\nPin-Priority: 1001\n</code></pre> <p>For more information about the pinning, you can check the official debian wiki.</p> <p></p>"},{"location":"apt-pinning.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-repo.html","title":"Use an APT repository to install Percona Server for MySQL 8.4","text":"<p>Ready-to-use packages are available from the Percona Server for MySQL software repositories and the Percona downloads page.</p> <p>Specific information on the supported platforms, products, and versions is described in Percona Software and Platform Lifecycle.</p> <p>We gather Telemetry data in the Percona packages and Docker images.</p>"},{"location":"apt-repo.html#arm-support","title":"ARM support","text":"<p>The DEB builds for Ubuntu 20.04, Ubuntu 22.04, Ubuntu 24.04, DEBIAN 11, and DEBIAN 12 contain ARM packages with the <code>aarch64.rpm</code> extension. This means that Percona Server for MySQL is available for users on ARM-based systems.</p>"},{"location":"apt-repo.html#install-percona-server-for-mysql-using-apt","title":"Install Percona Server for MySQL using APT","text":"<p>To install Percona Server for MySQL using APT, do the following steps:</p> <ol> <li> <p>Update the package repositories:</p> <pre><code>$ sudo apt update\n</code></pre> </li> <li> <p>Install the <code>curl</code> download utility if needed:</p> <pre><code>$ sudo apt install curl\n</code></pre> </li> <li> <p>Download the <code>percona-release</code> repository package:</p> <pre><code>$ curl -O https://repo.percona.com/apt/percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Install the downloaded package with <code>apt</code> as root or with sudo:</p> <pre><code>$ sudo apt install gnupg2 lsb-release ./percona-release_latest.generic_all.deb\n</code></pre> </li> <li> <p>Refresh the local cache to update the package information:</p> <pre><code>$ sudo apt update\n</code></pre> </li> <li> <p>Use <code>percona-release</code> to set up the repository for the Percona Server for MySQL 8.4 version:</p> <pre><code>$ sudo percona-release enable-only ps-84-lts release\n$ sudo percona-release enable tools release\n</code></pre> </li> <li> <p>You can check the repository setup for the Percona original release list in <code>/etc/apt/sources.list.d/percona-original-release.list</code>. </p> </li> <li> <p>Install the server package with the <code>percona-release</code> command:</p> <pre><code>$ sudo apt install percona-server-server\n</code></pre> </li> </ol> <p>See Configuring Percona repositories with <code>percona-release</code> for more information.</p> <p>Percona Server for MySQL 8.4.x comes with the MyRocks storage engine. This storage engine is installed as a plugin. For information on installing and configuring MyRocks, refer to the Percona MyRocks Installation Guide.</p> <p>Percona Server for MySQL contains user-defined functions from Percona Toolkit. These user-defined functions, <code>fnv_64</code>, <code>fnv1a_64</code>, <code>murmur_hash</code>, provide faster checksums. For more details on the user-defined functions, see Percona Toolkit UDF functions.</p> <p>After the installation completes, run the following command to create these functions:</p> <pre><code>mysql -e \"INSTALL COMPONENT 'file://component_percona_udf'\"\n</code></pre>"},{"location":"apt-repo.html#install-the-percona-testing-repository-using-apt","title":"Install the Percona Testing repository using APT","text":"<p>Percona offers pre-release builds from the testing repository. To enable it, run percona-release with the <code>testing</code> argument. Run the following command as root or use the sudo command:</p> <pre><code>$ sudo percona-release enable ps-84-lts testing\n</code></pre> <p>These builds should not be run in production. This build may not contain all of the features available in the final release. The features may change without notice.</p> <p></p>"},{"location":"apt-repo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-run.html","title":"Run Percona Server for MySQL 8.4 after APT repository installation","text":"<p>Percona Server for MySQL stores the data files in <code>/var/lib/mysql/</code> by default. You can find the configuration file that is used to manage Percona Server for MySQL in <code>/etc/mysql/my.cnf</code>.</p> <p>Note</p> <p>Debian and Ubuntu installation doesn\u2019t automatically create a special <code>debian-sys-maint</code> user which can be used by the control scripts to control the Percona Server for MySQL <code>mysqld</code> and <code>mysqld_safe</code> services which was the case with previous Percona Server for MySQL versions. If you still require this user you\u2019ll need to create it manually.</p> <p>Run the following commands as root or by using the sudo command</p> <ol> <li> <p>Starting the service</p> <p>Percona Server for MySQL is started automatically after it gets installed unless it encounters errors during the installation process. You can also manually start it by running: <code>service mysql start</code></p> </li> <li> <p>Confirming that service is running. You can check the service status by     running: <code>service mysql status</code></p> </li> <li> <p>Stopping the service</p> <p>You can stop the service by running: <code>service mysql stop</code></p> </li> <li> <p>Restarting the service. <code>service mysql restart</code></p> </li> </ol> <p>Note</p> <p>Debian 9.0 (stretch) and Ubuntu 18.04 LTS (bionic) come with systemd as the default system and service manager. You can invoke all the above commands with <code>systemctl</code> instead of <code>service</code>. Currently, both are supported.</p>"},{"location":"apt-run.html#working-with-apparmor","title":"Working with AppArmor","text":"<p>For information on AppArmor, see Working with AppArmor.</p> <p></p>"},{"location":"apt-run.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"apt-uninstall-server.html","title":"Uninstall Percona Server for MySQL 8.4 using the APT package manager","text":"<p>To uninstall Percona Server for MySQL you\u2019ll need to remove all the installed packages. Removing packages with apt remove does not remove the configuration and data files. Removing the packages with apt purge does remove the packages with configuration files and data files (all the databases). Depending on your needs you can choose which command better suits you.</p> <ol> <li> <p>Stop the Percona Server for MySQL service: <code>service mysql stop</code></p> </li> <li> <p>Remove the packages</p> <ol> <li> <p>Remove the packages. This will leave the data files (databases, tables, logs, configuration, etc.) behind. In case you don\u2019t need them you\u2019ll need to remove them manually: <code>apt remove percona-server\\</code></p> </li> <li> <p>Purge the packages. This command removes all the packages and deletes all the data files (databases, tables, logs, and so on.): <code>apt purge percona-server\\</code></p> </li> </ol> </li> </ol> <p></p>"},{"location":"apt-uninstall-server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-compression-encryption.html","title":"Audit Log Filter compression and encryption","text":""},{"location":"audit-log-filter-compression-encryption.html#compression","title":"Compression","text":"<p>You can enable compression for any format by setting the <code>audit_log_filter.compression</code> system variable when the server starts.</p> <p>The <code>audit_log_filter.compression</code> variable can be either of the following:</p> <ul> <li>NONE (no compression) - the default value</li> <li>GZIP - uses the GNU Zip compression</li> </ul> <p>If compression and encryption are enabled, the component applies compression before encryption. If you must manually recover a file with both settings, first decrypt the file and then uncompress the file.</p>"},{"location":"audit-log-filter-compression-encryption.html#encryption","title":"Encryption","text":"<p>You can encrypt any audit log filter file in any format. The audit log filter component generates the initial password, but you can use user-defined passwords after that. The component stores the passwords in the keyring, so that feature must be enabled.</p> <p>Set the <code>audit_log_filter.encryption</code> system variable with the server starts. The allowed values are the following:</p> <ul> <li>NONE - no encryption, the default value</li> <li>AES - AES-256-CBC (Cipher Block Chaining) encryption</li> </ul> <p>The AES uses the 256-bit key size.</p> <p>The following audit log filter functions are used with encryption:</p> Function name Description audit_log_encryption_password_set() Stores the password in the keyring. If encryption is enabled, the function also rotates the log file by renaming the current log file and creating a log file encrypted with the password. audit_log_encryption_password_get() Invoking this function without an argument returns the current encryption password. An argument that specifies the keyring ID of an archived password or current password returns that password by ID. <p>The <code>audit_log_filter.password_history_keep_days</code> variable is used with encryption. If the variable is not zero (0), invoking <code>audit_log_encryption_password_set()</code> causes the expiration of archived audit log passwords.</p> <p>When the component starts with encryption enabled, the component checks if the keyring has an audit log filter encryption password. If no password is found, the component generates a random password and stores this password in the keyring. Use <code>audit_log_encryption_password_get()</code> to review this password.</p> <p>If compression and encryption are enabled, the component applies compression before encryption. If you must manually recover a file with both settings, first decrypt the file and then uncompress the file.</p>"},{"location":"audit-log-filter-compression-encryption.html#manually-uncompressing-and-decrypting-audit-log-filter-files","title":"Manually uncompressing and decrypting audit log filter files","text":"<p>To decrypt an encrypted log file, use the openssl command. For example:</p> <pre><code>openssl enc -d -aes-256-cbc -pass pass:password\n    -iter iterations -md sha256\n    -in audit.timestamp.log.pwd_id.enc\n    -out audit.timestamp.log\n</code></pre> <p>To execute that command, you must obtain a password and iterations. To do this, use <code>audit_log_encryption_password_get()</code>. </p> <p>This function gets the encryption password, and the iterations count and returns this data as a JSON-encoded string. For example, if the audit log file name is <code>audit.20190415T151322.log.20190414T223342-2.enc</code>, the password ID is <code>{randomly-generated-alphanumeric-string}</code> and the keyring ID is <code>audit-log-20190414T223342-2</code>. </p> <p>Get the keyring password:</p> <pre><code>mysql&gt; SELECT audit_log_encryption_password_get('audit-log-20190414T223342-2');\n</code></pre> <p>The return value of this function may look like the following:</p> Expected output <pre><code>{\"password\":\"{randomly-generated-alphanumeric-string}\",\"iterations\":568977}\n</code></pre> <p></p>"},{"location":"audit-log-filter-compression-encryption.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-formats.html","title":"Audit Log Filter file format overview","text":"<p>When an auditable event occurs, the component writes a record to the log file.</p> <p>After the component starts, the first record lists the description of the server and the options at startup. After the first record, the auditable events are connections, disconnections, SQL statements executed, and so on. Statements within stored procedures or triggers are not logged, only the top-level statements.</p> <p>If files are referenced by <code>LOAD_DATA</code>, the contents are not logged.</p> <p>Set with the <code>audit_log_filter.format</code> system variable at startup. The available format types are the following;</p> Format Type Command Description XML (new style) <code>audit_log_filter.format=NEW</code> The default format XML (old style) <code>audit_log_filter.format=OLD</code> The original version of the XML format JSON <code>audit_log_filter.format=JSON</code> Files written as a JSON array <p>By default, the file contents in the new-style XML format are not compressed or encrypted.</p> <p>Changing the <code>audit_log_filter.format</code>, you should also change  the <code>audit_log_filter.file</code> name. For example, changing the <code>audit_log_filter.format</code>  to JSON, change the <code>audit_log_filter.file</code> to <code>audit.json</code>. If you don\u2019t change  the <code>audit_log_filter.file</code> name, then all audit log filter files have the same  base name and you won\u2019t be able to easily find when the format changed.</p> <p></p>"},{"location":"audit-log-filter-formats.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-json.html","title":"Audit Log Filter format - JSON","text":"<p>The JSON format has one top-level JSON array, which contain JSON objects with key-value pairs. These objects represent an event in the audit. Some pairs are listed in every audit record. The audit record type determines if other key-value pairs are listed. The order of the pairs within an audit record is not guaranteed. The value description may be truncated.</p> <p>Certain statistics, such as query time and size, are only available in the JSON format and help detect activity outliers when analyzed. </p> <p><pre><code>[\n  {\n    \"timestamp\": \"2023-03-29 11:17:03\",\n    \"id\": 0,\n    \"class\": \"audit\",\n    \"server_id\": 1\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 1,\n    \"class\": \"command\",\n    \"event\": \"command_start\",\n    \"connection_id\": 1,\n    \"command_data\": {\n      \"name\": \"command_start\",\n      \"status\": 0,\n      \"command\": \"query\"}\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 2,\n    \"class\": \"general\",\n    \"event\": \"log\",\n    \"connection_id\": 11,\n    \"account\": { \"user\": \"root[root] @ localhost []\", \"host\": \"localhost\" },\n    \"login\": { \"user\": \"root[root] @ localhost []\", \"os\": \"\", \"ip\": \"\", \"proxy\": \"\" },\n    \"general_data\": {\n      \"command\": \"Query\",\n      \"sql_command\": \"create_table\",\n      \"query\": \"CREATE TABLE t1 (c1 INT)\",\n      \"status\": 0}\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 3,\n    \"class\": \"query\",\n    \"event\": \"query_start\",\n    \"connection_id\": 11,\n    \"query_data\": {\n      \"query\": \"CREATE TABLE t1 (c1 INT)\",\n      \"status\": 0,\n      \"sql_command\": \"create_table\"}\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 4,\n    \"class\": \"query\",\n    \"event\": \"query_status_end\",\n    \"connection_id\": 11,\n    \"query_data\": {\n      \"query\": \"CREATE TABLE t1 (c1 INT)\",\n      \"status\": 0,\n      \"sql_command\": \"create_table\"}\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 5,\n    \"class\": \"general\",\n    \"event\": \"status\",\n    \"connection_id\": 11,\n    \"account\": { \"user\": \"root[root] @ localhost []\", \"host\": \"localhost\" },\n    \"login\": { \"user\": \"root[root] @ localhost []\", \"os\": \"\", \"ip\": \"\", \"proxy\": \"\" },\n    \"general_data\": {\n      \"command\": \"Query\",\n      \"sql_command\": \"create_table\",\n      \"query\": \"CREATE TABLE t1 (c1 INT)\",\n      \"status\": 0}\n  },\n  {\n    \"timestamp\": \"2023-03-29 11:17:05\",\n    \"id\": 6,\n    \"class\": \"command\",\n    \"event\": \"command_end\",\n    \"connection_id\": 1,\n    \"command_data\": {\n      \"name\": \"command_end\",\n      \"status\": 0,\n      \"command\": \"query\"}\n  }\n]\n</code></pre> The order of the attributes within the JSON object can vary. Certain attributes are in every element. Other attributes are optional and depend on the type of event and the filter settings or component settings.</p> <p>The following fields are contained in each object:</p> <ul> <li><code>timestamp</code></li> <li><code>id</code></li> <li><code>class</code></li> <li><code>event</code></li> </ul> <p>The possible attributes in a JSON object are the following:</p> Name Description <code>class</code> Defines the type of event <code>account</code> Defines the MySQL account associated with the event. <code>connection_data</code> Defines the client connection. <code>connection_id</code> Defines the client connection identifier <code>event</code> Defines a subclass of the <code>event</code> class <code>general_data</code> Defines the executed statement or command when the audit record has a class value of <code>general</code>. <code>id</code> Defines the event ID <code>login</code> Defines how the client connected to the server <code>query_statistics</code> Defines optional query statistics and is used for outlier detection <code>shutdown_data</code> Defines the audit log filter termination <code>startup_data</code> Defines the initialization of the audit log filter component <code>table_access_data</code> Defines access to a table <code>time</code> Defines an integer that represents a UNIX timestamp <code>timestamp</code> Defines a UTC value in the <code>YYYY-MM_DD hh:mm:ss</code> format <p></p>"},{"location":"audit-log-filter-json.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-naming.html","title":"Audit Log Filter file naming conventions","text":""},{"location":"audit-log-filter-naming.html#name-qualities","title":"Name qualities","text":"<p>The audit log filter file name has the following qualities:</p> <ul> <li>Optional directory name</li> <li>Base name</li> <li>Optional suffix</li> </ul> <p>Using either compression or encryption adds the following suffixes:</p> <ul> <li>Compression adds the <code>.gz</code> suffix</li> <li>Encryption adds the <code>pwd_id.enc</code> suffix</li> </ul> <p>The <code>pwd_id</code> represents the password used for encrypting the log files. The audit log filter component stores passwords in the keyring.</p> <p>You can combine compression and encryption, which adds both suffixes to the <code>audit_filter.log</code> name.</p> <p>The following table displays the possible ways a file can be named:</p> Default name Enabled feature audit.log No compression or encryption audit.log.gz Compression audit.log.pwd_id.enc Encryption audit.log.gz.pwd_id.enc Compression, encryption"},{"location":"audit-log-filter-naming.html#encryption-id-format","title":"Encryption ID format","text":"<p>The format for <code>pwd_id</code> is the following:</p> <ul> <li>A UTC value in <code>YYYYMMDDThhmmss</code> format that represents when the password was created</li> <li>A sequence number that starts at <code>1</code> and increases if passwords have the same timestamp value</li> </ul> <p>The following are examples of pwd_id values:</p> <pre><code>20230417T082215-1\n20230301T061400-1\n20230301T061400-2\n</code></pre> <p>The following example is a list of the audit log filter files with the <code>pwd_id</code>:</p> <pre><code>audit_filter.log.20230417T082215-1.enc\naudit_filter.log.20230301T061400-1.enc\naudit_filter.log.20230301T061400-2.enc\n</code></pre> <p>The current password has the largest sequence number.</p>"},{"location":"audit-log-filter-naming.html#renaming-operations","title":"Renaming operations","text":"<p>During initialization, the component checks if a file with that name exists.  If it does, the component renames the file. The component writes to an empty file.</p> <p>During termination, the component renames the file.</p> <p></p>"},{"location":"audit-log-filter-naming.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-new.html","title":"Audit Log Filter format - XML (new style)","text":"<p>The filter writes the audit log filter file in XML. The XML file uses  UTF-8.</p> <p>The  is the root element and this element contains   elements. Each  element contains specific  information about an event that is audited.  <p>For each new file, the Audit Log Filter component writes the XML  declaration and the root element tag. The component writes the closing   root element when closing the file. If the file is open, this  closing element is not available.</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;AUDIT&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Audit&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;0_2023-03-29T11:11:43&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:43&lt;/TIMESTAMP&gt;\n        &lt;SERVER_ID&gt;1&lt;/SERVER_ID&gt;\n    &lt;/AUDIT_RECORD&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Command Start&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;1_2023-03-29T11:11:45&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:45&lt;/TIMESTAMP&gt;\n        &lt;STATUS&gt;0&lt;/STATUS&gt;\n        &lt;CONNECTION_ID&gt;1&lt;/CONNECTION_ID&gt;\n        &lt;COMMAND_CLASS&gt;query&lt;/COMMAND_CLASS&gt;\n    &lt;/AUDIT_RECORD&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Query&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;2_2023-03-29T11:11:45&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:45&lt;/TIMESTAMP&gt;\n        &lt;COMMAND_CLASS&gt;create_table&lt;/COMMAND_CLASS&gt;\n        &lt;CONNECTION_ID&gt;11&lt;/CONNECTION_ID&gt;\n        &lt;HOST&gt;localhost&lt;/HOST&gt;\n        &lt;IP&gt;&lt;/IP&gt;\n        &lt;USER&gt;root[root] @ localhost []&lt;/USER&gt;\n        &lt;OS_LOGIN&gt;&lt;/OS_LOGIN&gt;\n        &lt;SQLTEXT&gt;CREATE TABLE t1 (c1 INT)&lt;/SQLTEXT&gt;\n        &lt;STATUS&gt;0&lt;/STATUS&gt;\n    &lt;/AUDIT_RECORD&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Query Start&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;3_2023-03-29T11:11:45&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:45&lt;/TIMESTAMP&gt;\n        &lt;STATUS&gt;0&lt;/STATUS&gt;\n        &lt;CONNECTION_ID&gt;11&lt;/CONNECTION_ID&gt;\n        &lt;COMMAND_CLASS&gt;create_table&lt;/COMMAND_CLASS&gt;\n        &lt;SQLTEXT&gt;CREATE TABLE t1 (c1 INT)&lt;/SQLTEXT&gt;\n    &lt;/AUDIT_RECORD&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Query&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;4_2023-03-29T11:11:45&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:45&lt;/TIMESTAMP&gt;\n        &lt;COMMAND_CLASS&gt;create_table&lt;/COMMAND_CLASS&gt;\n        &lt;CONNECTION_ID&gt;11&lt;/CONNECTION_ID&gt;\n        &lt;HOST&gt;localhost&lt;/HOST&gt;\n        &lt;IP&gt;&lt;/IP&gt;\n        &lt;USER&gt;root[root] @ localhost []&lt;/USER&gt;\n        &lt;OS_LOGIN&gt;&lt;/OS_LOGIN&gt;\n        &lt;SQLTEXT&gt;CREATE TABLE t1 (c1 INT)&lt;/SQLTEXT&gt;\n        &lt;STATUS&gt;0&lt;/STATUS&gt;\n    &lt;/AUDIT_RECORD&gt;\n    &lt;AUDIT_RECORD&gt;\n        &lt;NAME&gt;Command End&lt;/NAME&gt;\n        &lt;RECORD_ID&gt;5_2023-03-29T11:11:45&lt;/RECORD_ID&gt;\n        &lt;TIMESTAMP&gt;2023-03-29T11:11:45&lt;/TIMESTAMP&gt;\n        &lt;STATUS&gt;0&lt;/STATUS&gt;\n        &lt;CONNECTION_ID&gt;1&lt;/CONNECTION_ID&gt;\n        &lt;COMMAND_CLASS&gt;query&lt;/COMMAND_CLASS&gt;\n    &lt;/AUDIT_RECORD&gt;\n&lt;/AUDIT&gt;\n</code></pre> <p>The order of the attributes within an  can vary. Certain attributes are in every element. Other attributes are optional and depend on the type of audit record. <p>The attributes in every element are the following:</p> Attribute Name Description <code>&lt;NAME&gt;</code> The action that generated the audit record. <code>&lt;RECORD_ID&gt;</code> The <code>&lt;RECORD_ID&gt;</code> consists of a sequence number and a timestamp value. The sequence number is initialized when the component opens the audit log filter file. <code>&lt;TIMESTAMP&gt;</code> Displays the date and time when the audit event happened. <p>The optional attributes are the following:</p> Attribute Name Description <code>&lt;COMMAND_CLASS&gt;</code> Contains the type of performed action. <code>&lt;CONNECTION_ID&gt;</code> Contains the client connection identifier. <code>&lt;CONNECTION_ATTRIBUTES&gt;</code> Contains the client connection attributes. Each attribute has a <code>&lt;NAME&gt;</code> and <code>&lt;VALUE&gt;</code> pair. <code>&lt;CONNECTION_TYPE&gt;</code> Contains the type of connection security. <code>&lt;DB&gt;</code> Contains the database name. <code>&lt;HOST&gt;</code> Contains the client\u2019s hostname. <code>&lt;IP&gt;</code> Contains the client\u2019s IP address. <code>&lt;MYSQL_VERSION&gt;</code> Contains the MySQL server version. <code>&lt;OS_LOGIN&gt;</code> Contains the user name used during an external authentication, for example, if the user is authenticated through an LDAP component. If the authentication component does not set a value or the user is authenticated using MySQL authentication, this value is empty. <code>&lt;OS_VERSION&gt;</code> Contains the server\u2019s operating system. <code>&lt;PRIV_USER&gt;</code> Contains the user name used by the server when checking privileges. This name may be different than <code>&lt;USER&gt;</code>. <code>&lt;PROXY_USER&gt;</code> Contains the proxy user. If a proxy is not used, the value is empty. <code>&lt;SERVER_ID&gt;</code> Contains the server ID. <code>&lt;SQLTEXT&gt;</code> Contains the text of the SQL statement. <code>&lt;STARTUP_OPTIONS&gt;</code> Contains the startup options. These options may be provided by the command line or files. <code>&lt;STATUS&gt;</code> Contains the status of a command. A 0 (zero) is a success. A nonzero value is an error. <code>&lt;STATUS_CODE&gt;</code> Contains the status of a command, which either succeeds (0) or an error occurred (1). <code>&lt;TABLE&gt;</code> Contains the table name. <code>&lt;USER&gt;</code> Contains the user name from the client. This name may be different than <code>&lt;PRIV_USER&gt;</code>. <code>&lt;VERSION&gt;</code> Contains the audit log filter format. <p></p>"},{"location":"audit-log-filter-new.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-old.html","title":"Audit Log Filter format - XML (old style)","text":"<p>The old style XML format uses <code>&lt;AUDIT&gt;</code> tag as the root element and adds the <code>&lt;/AUDIT&gt;</code> tag when the file closes. Each audited event is contained in an  element.  <p>The order of the attributes within an  can vary. Certain attributes are in every element. Other attributes are optional and depend on the type of audit record. <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;AUDIT&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Audit\"\n    RECORD_ID=\"0_2023-03-29T11:15:52\"\n    TIMESTAMP=\"2023-03-29T11:15:52\"\n    SERVER_ID=\"1\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Command Start\"\n    RECORD_ID=\"1_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    STATUS=\"0\"\n    CONNECTION_ID=\"1\"\n    COMMAND_CLASS=\"query\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Query\"\n    RECORD_ID=\"2_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    COMMAND_CLASS=\"create_table\"\n    CONNECTION_ID=\"11\"\n    HOST=\"localhost\"\n    IP=\"\"\n    USER=\"root[root] @ localhost []\"\n    OS_LOGIN=\"\"\n    SQLTEXT=\"CREATE TABLE t1 (c1 INT)\"\n    STATUS=\"0\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Query Start\"\n    RECORD_ID=\"3_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    STATUS=\"0\"\n    CONNECTION_ID=\"11\"\n    COMMAND_CLASS=\"create_table\"\n    SQLTEXT=\"CREATE TABLE t1 (c1 INT)\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Query Status End\"\n    RECORD_ID=\"4_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    STATUS=\"0\"\n    CONNECTION_ID=\"11\"\n    COMMAND_CLASS=\"create_table\"\n    SQLTEXT=\"CREATE TABLE t1 (c1 INT)\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Query\"\n    RECORD_ID=\"5_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    COMMAND_CLASS=\"create_table\"\n    CONNECTION_ID=\"11\"\n    HOST=\"localhost\"\n    IP=\"\"\n    USER=\"root[root] @ localhost []\"\n    OS_LOGIN=\"\"\n    SQLTEXT=\"CREATE TABLE t1 (c1 INT)\"\n    STATUS=\"0\"/&gt;\n  &lt;AUDIT_RECORD\n    NAME=\"Command End\"\n    RECORD_ID=\"6_2023-03-29T11:15:53\"\n    TIMESTAMP=\"2023-03-29T11:15:53\"\n    STATUS=\"0\"\n    CONNECTION_ID=\"1\"\n    COMMAND_CLASS=\"query\"/&gt;\n&lt;/AUDIT&gt;\n</code></pre> <p>The required attributes are the following:</p> HTML Table Generator Attribute Name Description \u00a0NAME \u00a0The action that generated the audit record. \u00a0RECORD_ID \u00a0The RECORD_ID consists of a sequence number and a timestamp value. The sequence number is initialized when the component opens the audit log filter file. \u00a0TIMESTAMP \u00a0Displays the date and time when the audit event happened. <p>The optional attributes are the following:</p> HTML Table Generator Attribute Name Description COMMAND_CLASS Type of action performed CONNECTION_ID Client connection identifier CONNECTION_TYPE Connection security type DB Database name HOST Client's hostname IP Client's IP address MYSQL_VERSION Server version OS_LOGIN The user name used during an external authentication, for example, if the user is authenticated through an LDAP component. If the authentication component does not set a value or the user is authenticated using MySQL authentication, this value is empty. OS_VERSION Server's operating system PRIV_USER The user name used by the server when checking privileges. This name may be different than USER. PROXY_USER The proxy user. If a proxy is not used, the value is empty. SERVER_ID Server Identifier SQLTEXT SQL statement text STARTUP_OPTIONS Server startup options, either command line or config files STATUS Command's status - a 0 (zero) is a success, a non-zero is an error STATUS_CODE A 0 (zero) is a success, a non-zero is an error TABLE Table name USER \u00a0Client's user name - this name may be different than PRIV_USER. VERSION Format of audit log filter <p></p>"},{"location":"audit-log-filter-old.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-overview.html","title":"Audit Log Filter overview","text":"<p>The Audit Log Filter component allows you to monitor, log, and block a connection or query actively executed on the selected server. </p> <p>Enabling the component produces a log file that contains a record of server activity. The log file has information on connections and databases accessed by that connection. </p> <p>The component uses the <code>mysql</code> system database to store filter and user account data. Set the <code>audit_log_filter.database</code> variable at server startup to select a different database.</p> <p>The <code>AUDIT_ADMIN</code> privilege is required to enable users to manage the Audit Log Filter component.</p>"},{"location":"audit-log-filter-overview.html#privileges","title":"Privileges","text":"<p>Define the privilege at runtime at the startup of the server. The associated Audit Log Filter privilege can be unavailable if the component is not enabled.</p>"},{"location":"audit-log-filter-overview.html#audit_admin","title":"<code>AUDIT_ADMIN</code>","text":"<p>This privilege is defined by the server and enables the user to configure the component.</p>"},{"location":"audit-log-filter-overview.html#audit_abort_exempt","title":"<code>AUDIT_ABORT_EXEMPT</code>","text":"<p>This privilege allows queries from a user account to always be executed. An <code>abort</code> item does not block them. This ability lets the user account regain access to a system if an audit is misconfigured. The query is logged due to the privilege. User accounts with the <code>SYSTEM_USER</code> privilege have the <code>AUDIT_ABORT_EXEMPT</code> privilege.</p>"},{"location":"audit-log-filter-overview.html#audit-log-filter-tables","title":"Audit Log Filter tables","text":"<p>The Audit Log Filter component uses <code>mysql</code> system database tables in the <code>InnoDB</code> storage engine. These tables store user account data and filter data. When you start the server, change the component\u2019s database with the <code>audit_log_filter.database</code> variable.</p> <p>The <code>audit_log_filter</code> table stores the definitions of the filters and has the following column definitions:</p> HTML Table Generator Column name Description \u00a0NAME \u00a0Name of the filter \u00a0FILTER \u00a0Definition of the filter linked to the name as a JSON value <p>The <code>audit_log_user</code> table stores account data and has the following column definitions:</p> HTML Table Generator Column name Description \u00a0USER \u00a0The account name of the user \u00a0HOST \u00a0The account name of the host \u00a0FILTERNAME \u00a0The account filter name <p></p>"},{"location":"audit-log-filter-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-restrictions.html","title":"Audit Log Filter restrictions","text":""},{"location":"audit-log-filter-restrictions.html#general-restrictions","title":"General restrictions","text":"<p>The Audit Log Filter has the following general restrictions:</p> <ul> <li> <p>Logs only SQL statements. Statements made by NoSQL APIs, such as the Memcached API, are not logged.</p> </li> <li> <p>Logs only the top-level statement. Statements within a stored procedure or a trigger are not logged. Does not log the file contents for statements like <code>LOAD_DATA</code>.</p> </li> <li> <p>If used with a cluster, the component must be installed on each server used to execute SQL on the cluster.</p> </li> <li> <p>If used with a cluster, the application or user is responsible for aggregating all the data of each server used in the cluster.</p> </li> </ul> <p></p>"},{"location":"audit-log-filter-restrictions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-security.html","title":"Audit Log Filter security","text":"<p>The Audit Log Filter component generates audit log filter files. The directory  that contains these files should be accessible only to the following:</p> <ul> <li> <p>Users who must be able to view the log</p> </li> <li> <p>Server must be able to write to the directory</p> </li> </ul> <p>The files are not encrypted by default and may contain sensitive information.</p> <p>The default name for the file in the data directory is <code>audit_filter.log</code>. If needed, use the <code>audit_log_filter.file</code> system variable at server startup to change the location. Due to the log rotation, multiple audit log files may exist.</p> <p></p>"},{"location":"audit-log-filter-security.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"audit-log-filter-variables.html","title":"Audit log filter functions, options, and variables","text":"<p>The following sections describe the functions, options, and variables available in the audit log filter component.</p>"},{"location":"audit-log-filter-variables.html#audit-log-filter-functions","title":"Audit log filter functions","text":"<p>The following audit log filter functions are available.</p> Function name audit_log_encryption_password_get(keyring_id) audit_log_encryption_password_set(new_password) audit_log_filter_flush() audit_log_read() audit_log_read_bookmark() audit_log_session_filter_id() audit_log_filter_remove_filter(filter_name) audit_log_filter_remove_user(user_name) audit_log_rotate() audit_log_filter_set_filter(filter_name, definition) audit_log_filter_set_user(user_name, filter_name)"},{"location":"audit-log-filter-variables.html#audit_log_encryption_password_getkeyring_id","title":"audit_log_encryption_password_get(keyring_id)","text":"<p>This function returns the encryption password. Any keyring component or keyring component can be used, but the component or component must be enabled. If the component or component is not enabled, an error occurs.</p>"},{"location":"audit-log-filter-variables.html#parameters","title":"Parameters","text":"<p><code>keyring_id</code> - If the function does not contain a keyring_id, the function returns the current encryption password. You can also request a specific encryption password with the keyring ID of either the current password or an archived password.</p>"},{"location":"audit-log-filter-variables.html#returns","title":"Returns","text":"<p>This function returns a JSON object containing the password, iterations count used by the password.</p>"},{"location":"audit-log-filter-variables.html#example","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_encryption_password_get();\n</code></pre> Expected output <pre><code>+---------------------------------------------+\n| audit_log_encryption_password_get()         |\n+---------------------------------------------+\n| {\"password\":\"passw0rd\",\"iterations\":5689}   |\n+---------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_encryption_password_setnew_password","title":"audit_log_encryption_password_set(new_password)","text":"<p>This function sets the encryption password and stores the new password in the keyring. </p>"},{"location":"audit-log-filter-variables.html#parameters_1","title":"Parameters","text":"<p><code>password</code> - the password as a string. The maximum length is 766 bytes.</p>"},{"location":"audit-log-filter-variables.html#returns_1","title":"Returns","text":"<p>This function returns a string. An <code>OK</code> indicates a success. <code>ERROR</code> indicates a failure.</p>"},{"location":"audit-log-filter-variables.html#example_1","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_encryption_password_set(passw0rd);\n</code></pre> Expected output <pre><code>+-----------------------------------------------------+\n| audit_log_encryption_password_set(passw0rd)         |\n+-----------------------------------------------------+\n| OK                                                  |\n+-----------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_filter_flush","title":"audit_log_filter_flush()","text":"<p>This function updates the audit log filter tables and makes any changes operational. </p> <p>Modifying the audit log filter tables directly with <code>INSERT</code>, <code>UPDATE</code>, or <code>DELETE</code> does not implement the modifications immediately. The tables must be flushed to have those changes take effect. </p> <p>This function forces reloading all filters and should only be used if someone has modified the tables directly. </p> <p>Important</p> <p>Avoid using this function. This function performs an operation that is similar to uninstalling and reinstalling the component. Filters are detached from all current sessions. To restart logging, the current sessions must either disconnect and reconnect or do a change-user operation. </p>"},{"location":"audit-log-filter-variables.html#parameters_2","title":"Parameters","text":"<p>None.</p>"},{"location":"audit-log-filter-variables.html#returns_2","title":"Returns","text":"<p>This function returns either an <code>OK</code> for success or an error message for failure.</p>"},{"location":"audit-log-filter-variables.html#example_2","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_filter_flush();\n</code></pre> Expected output <pre><code>+--------------------------+\n| audit_log_filter_flush() |\n+--------------------------+\n| OK                       |\n+--------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_read","title":"audit_log_read()","text":"<p>If the audit log filter format is JSON, this function reads the audit log and returns an array of the audit events as a JSON string. Generates an error if the format is not JSON.</p>"},{"location":"audit-log-filter-variables.html#parameters_3","title":"Parameters","text":"<p>None. If the start position is not provided, the read continues from the current position. </p> <p>Optional: You can specify a starting position for the read with <code>start</code> or a <code>timestamp</code> and an <code>id</code>, both items are considered a bookmark and can be used to identify an event. You must include both (<code>timestamp</code> and <code>id</code>) or an error is generated. If the <code>timestamp</code> does not include a <code>time</code> section, the function assumes  the time is <code>00:00</code>.</p> <p>You can also provide a <code>max_array_length</code> to limit the number of log events.</p> <p>Call<code>audit_log_read_bookmark()</code> to return the most recently written event.</p>"},{"location":"audit-log-filter-variables.html#returns_3","title":"Returns","text":"<p>This function returns a string of a JSON array of the audit events or a JSON NULL value. Returns <code>NULL</code> and generates an error if the call fails.</p>"},{"location":"audit-log-filter-variables.html#example_3","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_read(audit_log_read_bookmark());\n</code></pre> Expected output <pre><code>+------------------------------------------------------------------------------+\n| audit_log_read(audit_log_read_bookmark())                                   |\n+------------------------------------------------------------------------------+\n| [{\"timestamp\" : \"2023-06-02 09:43:25\", \"id\": 10,\"class\":\"connection\",]       |\n+------------------------------------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_read_bookmark","title":"audit_log_read_bookmark()","text":"<p>This function provides a bookmark for the most recently written audit log event as a JSON string. Generates an error if the format is not JSON.</p> <p>If this function is used with [<code>audit_log_read()](#audit_log_read), the</code>audit_log_read()` function starts reading at that position.</p>"},{"location":"audit-log-filter-variables.html#parameters_4","title":"Parameters","text":"<p>None.</p>"},{"location":"audit-log-filter-variables.html#returns_4","title":"Returns","text":"<p>This function returns a <code>JSON</code> string containing a bookmark for success or  <code>NULL</code> and an error for failure.</p>"},{"location":"audit-log-filter-variables.html#example_4","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_read_bookmark();\n</code></pre> Expected output <pre><code>+----------------------------------------------------+\n| audit_log_read_bookmark()                          |\n+----------------------------------------------------+\n| {\"timestamp\" : \"2023-06-02 09:43:25\", \"id\": 10 }   |\n+----------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_session_filter_id","title":"<code>audit_log_session_filter_id()</code>","text":"<p>This function returns the internal ID of the audit log filter in the current session.</p> <p>Returns 0 (zero) if the session has no assigned filter.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filter_remove_filterfilter_name","title":"audit_log_filter_remove_filter(filter_name)","text":"<p>This function removes the selected filter from the current set of filters.</p> <p>If user accounts are assigned the selected filter, the user accounts are no longer filtered. The user accounts are removed from <code>audit_log_user</code>. If the user accounts are in a current session, they are detached from the selected filter and no longer logged.</p>"},{"location":"audit-log-filter-variables.html#parameters_5","title":"Parameters","text":"<p><code>filter_name</code> - a selected filter name as a string.</p>"},{"location":"audit-log-filter-variables.html#returns_5","title":"Returns","text":"<p>This function returns either an <code>OK</code> for success or an error message for failure.</p> <p>If the filter name does not exist, no error is generated. </p>"},{"location":"audit-log-filter-variables.html#example_5","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_filter_remove_filter('filter-name');\n</code></pre> Expected output <pre><code>+------------------------------------------------+\n| audit_log_filter_remove_filter('filter-name')  |\n+------------------------------------------------+\n| OK                                             |\n+------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_filter_remove_useruser_name","title":"audit_log_filter_remove_user(user_name)","text":"<p>This function removes the assignment of a filter from the selected user account.</p> <p>If the user account is in a current session, they are not affected. New sessions for this user account use the default account filter or are not logged.</p> <p>If the user name is <code>%</code>, the default account filter is removed.</p>"},{"location":"audit-log-filter-variables.html#parameters_6","title":"Parameters","text":"<p><code>user_name</code> - a selected user name in either the <code>user_name</code>@<code>host_name</code> format or <code>%</code>.</p>"},{"location":"audit-log-filter-variables.html#returns_6","title":"Returns","text":"<p>This function returns either an <code>OK</code> for success or an error message for failure.</p> <p>If the user_name has no filter assigned, no error is generated. </p>"},{"location":"audit-log-filter-variables.html#example_6","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_filter_remove_user('user-name@localhost');\n</code></pre> Expected output <pre><code>+------------------------------------------------------+\n| audit_log_filter_remove_user('user-name@localhost')  |\n+------------------------------------------------------+\n| OK                                                   |\n+------------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_rotate","title":"audit_log_rotate()","text":""},{"location":"audit-log-filter-variables.html#parameters_7","title":"Parameters","text":"<p>None.</p>"},{"location":"audit-log-filter-variables.html#returns_7","title":"Returns","text":"<p>This function returns the renamed file name.</p>"},{"location":"audit-log-filter-variables.html#example_7","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_rotate();\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_filter_set_filterfilter_name-definition","title":"audit_log_filter_set_filter(filter_name, definition)","text":"<p>This function, when provided with a filter name and definition, adds the filter. </p> <p>The new filter has a different filter ID. Generates an error if the filter name exists.</p>"},{"location":"audit-log-filter-variables.html#parameters_8","title":"Parameters","text":"<ul> <li> <p><code>filter_name</code> - a selected filter name as a string.</p> </li> <li> <p><code>definition</code> - Defines the definition as a JSON value.</p> </li> </ul>"},{"location":"audit-log-filter-variables.html#returns_8","title":"Returns","text":"<p>This function returns either an <code>OK</code> for success or an error message for failure.</p>"},{"location":"audit-log-filter-variables.html#example_8","title":"Example","text":"<pre><code>mysql&gt; SET @filter = '{ \"filter_name\": { \"log\": true }}'\nmysql&gt; SET audit_log_filter_set_filter('filter-name', @filter);\n</code></pre> Expected output <pre><code>+-------------------------------------------------------------+\n| audit_log_filter_set_filter('filter-name', @filter)  |\n+-------------------------------------------------------------+\n| OK                                                          |\n+-------------------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit_log_filter_set_useruser_name-filter_name","title":"audit_log_filter_set_user(user_name, filter_name)","text":"<p>This function assigns the filter to the selected user account.</p> <p>A user account can only have one filter. If the user account already has a filter, this function replaces the current filter. If the user account is in a current session, nothing happens. When the user account connects again the new filter is used.</p> <p>The user name, <code>%</code>, is the default account. The filter assigned to <code>%</code> is used by any user account without a defined filter.</p>"},{"location":"audit-log-filter-variables.html#parameters_9","title":"Parameters","text":"<ul> <li> <p><code>user_name</code> - a selected user name in either the <code>user_name</code>@<code>host_name</code> format or <code>%</code>.</p> </li> <li> <p><code>filter_name</code> - a selected filter name as a string.</p> </li> </ul>"},{"location":"audit-log-filter-variables.html#returns_9","title":"Returns","text":"<p>This function returns either an <code>OK</code> for success or an error message for failure.</p>"},{"location":"audit-log-filter-variables.html#example_9","title":"Example","text":"<pre><code>mysql&gt; SELECT audit_log_filter_set_user('user-name@localhost', 'filter-name');\n</code></pre> Expected output <pre><code>+-------------------------------------------------------------------+\n| audit_log_filter_set_user('user-name@localhost', 'filter-name')  |\n+-------------------------------------------------------------------+\n| OK                                                                |\n+-------------------------------------------------------------------+\n</code></pre>"},{"location":"audit-log-filter-variables.html#audit-log-filter-options-and-variables","title":"Audit log filter options and variables","text":"Name <code>audit-log-filter</code> <code>audit_log_filter.buffer_size</code> <code>audit_log_filter.compression</code> <code>audit_log_filter.database</code> <code>audit_log_filter.disable</code> <code>audit_log_filter.encryption</code> <code>audit_log_filter.file</code> <code>audit_log_filter.format</code> <code>audit_log_filter.format_unix_timestamp</code> <code>audit_log_filter.handler</code> <code>audit_log_filter.key_derivation_iterations_count_mean</code> <code>audit_log_filter.max_size</code> <code>audit_log_filter.keep_password_history_keep_days</code> <code>audit_log_filter.prune_seconds</code> <code>audit_log_filter.read_buffer_size</code> <code>audit_log_filter.rotate_on_size</code> <code>audit_log_filter.strategy</code> <code>audit_log_filter.syslog_tag</code> <code>audit_log_filter.syslog_priority</code>"},{"location":"audit-log-filter-variables.html#audit-log-filter","title":"<code>audit-log-filter</code>","text":"Option Description Command-line \u2013audit-log-filter[=value] Dynamic No Scope Data type Enumeration Default ON <p>This option determines how, at startup, the server loads the <code>audit_log_filter</code> component. The component must be registered. </p> <p>The valid values are the following:</p> <ul> <li>ON</li> <li>OFF</li> <li>FORCE</li> <li>FORCE_PLUS_PERMANENT</li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterbuffer_size","title":"<code>audit_log_filter.buffer_size</code>","text":"Option name Description Command-line \u2013audit-log-filter.buffer-size Dynamic No Scope Global Data type Integer Default 1048576 Minimum value 4096 Maximum value 18446744073709547520 Units byes Block size 4096 <p>This variable defines the buffer size in multiples of 4096 when logging is asynchronous. The contents for events are stored in a buffer. The contents are stored until the contents are written.</p> <p>The component initializes a single buffer and removes the buffer when the component terminates.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filtercompression","title":"<code>audit_log_filter.compression</code>","text":"Option name Description Command-line \u2013audit-log-filter.compression Dynamic Yes Scope Global Data type Enumeration Default NONE Valid values NONE or GZIP <p>This variable defines the compression type for the audit log filter file. The values can be either <code>NONE</code>, the default value and file has no compression, or <code>GZIP</code>.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterdatabase","title":"<code>audit_log_filter.database</code>","text":"Option name Description Command-line \u2013audit-log-filter.database Dynamic No Scope Global Data type String Default mysql <p>This variable defines the audit_log_filter database. This read-only variable stores the necessary tables. Set this option at system startup. The database name cannot exceed 64 characters or be <code>NULL</code>.</p> <p>An invalid database name prevents the use of the audit log filter component.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterdisable","title":"<code>audit_log_filter.disable</code>","text":"Option name Description Command-line \u2013audit-log-filter.disable Dynamic Yes Scope Global Data type Boolean Default OFF <p>This variable disables the component logging for all connections and any sessions. </p> <p>This variable requires the user account to have <code>SYSTEM_VARIABLES_ADMIN</code> and <code>AUDIT_ADMIN</code> privileges.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterencryption","title":"<code>audit_log_filter.encryption</code>","text":"Option name Description Command-line \u2013audit-log-filter.encryption Dynamic No Scope Global Data type Enumeration Default NONE Valid values NONE or AES <p>This variable defines the encryption type for the audit log filter file. The values can be either of the following:</p> <ul> <li><code>NONE</code> - the default value, no encryption</li> <li><code>AES</code> </li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterfile","title":"<code>audit_log_filter.file</code>","text":"Option name Description Command-line \u2013audit-log-filter.file Dynamic No Scope Global Data type String Default audit_filter.log <p>This variable defines the name and suffix of the audit log filter file. The component writes events to this file.</p> <p>The file name and suffix can be either of the following:</p> <ul> <li>a relative path name - the component looks for this file in the data directory</li> <li>a full path name - the component uses the given value</li> </ul> <p>If you use a full path name, ensure the directory is accessible only to users who need to view the log and the server.</p> <p>For more information, see Naming conventions</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterformat","title":"<code>audit_log_filter.format</code>","text":"Option name Description Command-line \u2013audit-log-filter.format Dynamic No Scope Global Data type Enumeration Default NEW Available values OLD, NEW, JSON <p>This variable defines the audit log filter file format. </p> <p>The available values are the following: </p> <ul> <li>OLD (old-style XML)</li> <li>NEW (new-style XML) and </li> <li>JSON.</li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterformat_unix_timestamp","title":"<code>audit_log_filter.format_unix_timestamp</code>","text":"Option name Description Command-line \u2013audit-log-filter.format-unix-timestamp Dynamic Yes Scope Global Data type Boolean Default OFF <p>This option is only supported for JSON-format files.</p> <p>Enabling this option adds a <code>time</code> field to JSON-format files. The integer represents the UNIX timestamp value and indicates the date and time when the audit event was generated. Changing the value causes a file rotation because all records must either have or do not have the <code>time</code> field. This option requires the <code>AUDIT_ADMIN</code> and <code>SYSTEM_VARIABLES_ADMIN</code> privileges.</p> <p>This option does nothing when used with other format types.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterhandler","title":"<code>audit_log_filter.handler</code>","text":"Option name Description Command-line \u2013audit-log-filter.handler Dynamic No Scope Global Data type String Default FILE <p>Defines where the component writes the audit log filter file. The following values are available:</p> <ul> <li><code>FILE</code> - component writes the log to a location specified in <code>audit_log_filter.file</code></li> <li><code>SYSLOG</code> - component writes to the syslog</li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterkey_derivation_iterations_count_mean","title":"<code>audit_log_filter.key_derivation_iterations_count_mean</code>","text":"Option name Description Command-line \u2013audit-log-filter.key-derivation-iterations-count-mean Dynamic Yes Scope Global Data type Integer Default 60000 Minimum value 1000 Maximum value 1000000 <p>Defines the mean value of iterations used by the password-based derivation routine while calculating the encryption key and iv values. A random number represents the actual iteration count and deviates no more than 10% from this value.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filtermax_size","title":"<code>audit_log_filter.max_size</code>","text":"Option name Description Command-line \u2013audit-log-filter.max-size Dynamic Yes Scope Global Data type Integer Default 1GB Minimum value 0 Maximum value 18446744073709551615 Unit bytes Block size 4096 <p>Defines pruning based on the combined size of the files:</p> <p>The default value is 1GB. </p> <p>A value of 0 (zero) disables pruning based on size.</p> <p>A value greater than 0 (zero) enables pruning based on size and defines the combined size limit. When the files exceed this limit, they can be pruned.</p> <p>The value is based on 4096 (block size). A value is truncated to the nearest multiple of the block size. If the value is less than 4096, the value is treated as 0 (zero).</p> <p>If the values for <code>audit_log_filter.rotate_on_size</code> and <code>audit_log_filter.max_size</code> are greater than 0, we recommend that <code>audit_log_filter.max_size</code> value should be at least seven times the <code>audit_log_filter.rotate_on_size</code> value.</p> <p>Pruning requires the following options:</p> <ul> <li><code>audit_log_filter.max_size</code></li> <li><code>audit_log_filter.rotate_on_size</code></li> <li><code>audit_log_filter.prune_seconds</code></li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterpassword_history_keep_days","title":"<code>audit_log_filter.password_history_keep_days</code>","text":"Option name Description Command-line \u2013audit-log-filter.password-history-keep-days Dynamic Yes Scope Global Data type Integer Default 0 <p>Defines when passwords may be removed and measured in days.</p> <p>Encrypted log files have passwords stored in the keyring. The component also stores a password history. A password does not expire, despite being past the value, in case the password is used for rotated audit logs. The operation of creating a password also archives the previous password.</p> <p>The default value is 0 (zero). This value disables the expiration of passwords. Passwords are retained forever. </p> <p>If the component starts and encryption is enabled, the component checks for an audit log filter encryption password. If a password is not found, the component generates a random password.</p> <p>Call <code>audit_log_filter_encryption_set()</code> to set a specific password.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterprune_seconds","title":"<code>audit_log_filter.prune_seconds</code>","text":"Option name Description Command-line \u2013audit-log-filter.prune-seconds Dynamic Yes Scope Global Data type Integer Default 0 Minimum value 0 Maximum value 1844674073709551615 Unit seconds <p>Defines when the audit log filter file is pruned. This pruning is based on the age of the file. The value is measured in seconds. </p> <p>A value of 0 (zero) is the default and disables pruning. The maximum value is 18446744073709551615.</p> <p>A value greater than 0 enables pruning. An audit log filter file can be pruned after this value.</p> <p>To enable log pruning, you must set one of the following:</p> <ul> <li>Enable log rotation by setting <code>audit_log_filter.rotate_on_size</code></li> <li>Add a value greater than 0 (zero) for either <code>audit_log_filter.max_size</code> or <code>audit_log_filter.prune_seconds</code></li> </ul>"},{"location":"audit-log-filter-variables.html#audit_log_filterread_buffer_size","title":"<code>audit_log_filter.read_buffer_size</code>","text":"Option name Description Command-line \u2013audit-log-filter.read-buffer-size Dynamic Yes Scope Global Data type Integer Unit Bytes Default 32768 <p>This option is only supported for JSON-format files.</p> <p>The size of the buffer for reading from the audit log filter file. The <code>audit_log_filter_read()</code> reads only from this buffer size.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterrotate_on_size","title":"<code>audit_log_filter.rotate_on_size</code>","text":"Option name Description Command-line \u2013audit-log-filter.rotate-on-size Dynamic Yes Scope Global Data type Integer Default 1GB <p>Performs an automatic log file rotation based on the size. The default value is 1GB. If the value is greater than 0, when the log file size exceeds the value, the component renames the current file and opens a new log file using the original name.</p> <p>If you set the value to less than 4096, the component does not automatically rotate the log files. You can rotate the log files manually using <code>audit_log_rotate()</code>. If the value is not a multiple of 4096, the component truncates the value to the nearest multiple.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filterstrategy","title":"<code>audit_log_filter.strategy</code>","text":"Option name Description Command-line \u2013audit-log-filter.strategy Dynamic No Scope Global Data type Enumeration Default ASYNCHRONOUS <p>Defines the Audit Log filter component\u2019s logging method. The valid values are the following:</p> Values Description ASYNCHRONOUS Waits until there is outer buffer space PERFORMANCE If the outer buffer does not have enough space, drops requests SEMISYNCHRONOUS Operating system permits caching SYNCHRONOUS Each request calls <code>sync()</code>"},{"location":"audit-log-filter-variables.html#audit_log_filtersyslog_tag","title":"<code>audit_log_filter.syslog_tag</code>","text":"Option Description Command-line \u2013audit-log-filter.syslog-tag= Dynamic No Scope Global Data type String Default audit-filter"},{"location":"audit-log-filter-variables.html#audit_log_filtersyslog_facility","title":"<code>audit_log_filter.syslog_facility</code>","text":"Option name Description Command-line \u2013audit-log-filter.syslog-facility Dynamic No Scope Global Data type String Default LOG_USER <p>Specifies the syslog <code>facility</code> value. The option has the same meaning as the appropriate parameter described in the syslog(3) manual.</p>"},{"location":"audit-log-filter-variables.html#audit_log_filtersyslog_priority","title":"<code>audit_log_filter.syslog_priority</code>","text":"Option name Description Command-line \u2013audit-log-filter.syslog-priority Dynamic No Scope Global Data type String Default LOG_INFO <p>Defines the <code>priority</code> value for the syslog. The option has the same meaning as the appropriate parameter described in the syslog(3) manual.</p>"},{"location":"audit-log-filter-variables.html#audit-log-filter-status-variables","title":"Audit log filter status variables","text":"<p>The audit log filter component exposes status variables. These variables provide information on the operations.</p> Name Description <code>audit_log_filter_current_size</code> The current size of the audit log filter file. If the log is rotated, the size is reset to 0. <code>audit_log_filter_direct_writes</code> Identifies when the <code>log_strategy_type</code> = ASYNCHRONOUS and messages bypass the write buffer and are written directly to the log file <code>audit_log_filter_max_drop_size</code> In the performance logging mode, the size of the largest dropped event. <code>audit_log_filter_events</code> The number of audit log filter events <code>audit_log_filter_events_filtered</code> The number of filtered audit log filter component events <code>audit_log_filter_events_lost</code> If the event is larger than the available audit log filter buffer space, the event is lost <code>audit_log_filter_events_written</code> The number of audit log filter events written <code>audit_log_filter_total_size</code> The total size of the events written to all audit log filter files. The number increases even when a log is rotated <code>audit_log_filter_write_waits</code> In the asynchronous logging mode, the number of times an event waited for space in the audit log filter buffer <p></p>"},{"location":"audit-log-filter-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup-locks.html","title":"Backup locks","text":"<p>Percona Server for MySQL offers the <code>LOCK TABLES FOR BACKUP</code> statement as a lightweight alternative to <code>FLUSH TABLES WITH READ LOCK</code> for both physical and logical backups.</p>"},{"location":"backup-locks.html#flust-tables-with-read-lock","title":"FLUST TABLES WITH READ LOCK","text":"<p>The FLUSH TABLES WITH READ LOCK statement performs two main actions:</p> <ul> <li> <p>Flushes any changes to the tables currently in memory but have not yet been written to disk. This operation ensures that the data on the disk is up-to-date with the most recent changes.</p> </li> <li> <p>Acquires a read lock on all tables. This means that other sessions can continue to read from the tables but cannot execute any write operations (like INSERT, UPDATE, or DELETE) until the lock is released. This action is beneficial when creating a consistent data snapshot for backup purposes.</p> </li> </ul> <p>Please note that FLUSH TABLES WITH READ LOCK applies to all databases unless you specify tables individually. Also, this statement causes an implicit commit.</p> <p>The following command connects to the server and executes the <code>FLUSH TABLES WITH READ LOCK</code> statement. After running this command, no write operations can be performed until the lock is released.</p> <pre><code>mysql --user=\"user\" --password=\"password\" --host=\"host\" --execute=\"FLUSH TABLES WITH READ LOCK\"\n</code></pre>"},{"location":"backup-locks.html#lock-tables-for-backup","title":"LOCK TABLES FOR BACKUP","text":"<p><code>LOCK TABLES FOR BACKUP</code> uses a new MDL lock type to block updates to non-transactional tables and DDL statements for all tables. If there is an active <code>LOCK TABLES FOR BACKUP</code> lock then all DDL statements and all updates to MyISAM, CSV, MEMORY, ARCHIVE, and MyRocks tables will be blocked in the <code>Waiting for backup lock</code> status, visible in <code>PERFORMANCE_SCHEMA</code> or <code>PROCESSLIST</code>.</p> <p><code>LOCK TABLES FOR BACKUP</code> does not affect <code>SELECT</code> queries for all mentioned storage engines. Against InnoDB, MyRocks, Blackhole and Federated tables, the <code>LOCK TABLES FOR BACKUP</code> does not apply to the <code>INSERT</code>, <code>REPLACE</code>, <code>UPDATE</code>, <code>DELETE</code> statements: Blackhole tables have no relevance to backups and Federated tables are ignored by both logical and physical backup tools.</p> <p>Unlike <code>FLUSH TABLES WITH READ LOCK</code>, <code>LOCK TABLES FOR BACKUP</code> does not flush tables, i.e. storage engines are not forced to close tables, and tables are not expelled from the table cache. As a result, <code>LOCK TABLES FOR BACKUP</code> only waits for conflicting statements to complete (i.e. DDL and updates to non-transactional tables). It never waits for SELECTs, or UPDATEs to InnoDB or MyRocks tables to complete, for example.</p> <p>If an \u201cunsafe\u201d statement is executed in the same connection that is holding a <code>LOCK TABLES FOR BACKUP</code> lock, the statement fails with the following error:</p> Expected output <pre><code>ERROR 1880 (HY000): Can't execute the query because you have a conflicting backup lock\n\nUNLOCK TABLES releases the lock acquired by LOCK TABLES FOR BACKUP.\n</code></pre> <p>The intended use case for Percona XtraBackup is:</p> <pre><code>LOCK TABLES FOR BACKUP\n... copy .frm, MyISAM, CSV, etc. ...\nUNLOCK TABLES\n... get binlog coordinates ...\n... wait for redo log copying to finish ...\n</code></pre>"},{"location":"backup-locks.html#privileges","title":"Privileges","text":"<p>The <code>LOCK TABLES FOR BACKUP</code> requires the <code>BACKUP_ADMIN</code> privilege.</p>"},{"location":"backup-locks.html#interaction-with-other-global-locks","title":"Interaction with other global locks","text":"<p>The <code>LOCK TABLES FOR BACKUP</code> has no effect if the current connection already owns a <code>FLUSH TABLES WITH READ LOCK</code> lock, as that lock is more restrictive. If <code>FLUSH TABLES WITH READ LOCK</code> is executed in a connection that has acquired <code>LOCK TABLES FOR BACKUP</code>, <code>FLUSH TABLES WITH READ LOCK</code> fails with an error.</p> <p>If the server is operating in the read-only mode (for example, read_only set to <code>1</code>), statements that are unsafe for backups will be either blocked or fail with an error, depending on whether they are executed in the same connection that owns a <code>LOCK TABLES FOR BACKUP</code> lock or other connections.</p>"},{"location":"backup-locks.html#myisam-index-and-data-buffering","title":"MyISAM index and data buffering","text":"<p>MyISAM key buffering is normally write-through, i.e. by the time each update to a MyISAM table is completed, all index updates are written to disk. The only exception is the delayed key writing feature which is disabled by default.</p> <p>When the global system variable delay_key_write is set to <code>ALL</code>, key buffers for all MyISAM tables are not flushed between updates, so a physical backup of those tables may result in broken MyISAM indexes. To prevent this, <code>LOCK TABLES FOR BACKUP</code> will fail with an error if delay_key_write is set to <code>ALL</code>. An attempt to set delay_key_write to <code>ALL</code> when there\u2019s an active backup lock will also fail with an error.</p> <p>Another option to involve delayed key writing is to create MyISAM tables with the DELAY_KEY_WRITE option and set the delay_key_write variable to <code>ON</code> (which is the default). In this case, <code>LOCK TABLES FOR BACKUP</code> will not be able to prevent stale index files from appearing in the backup. Users are encouraged to set delay_key_writes to <code>OFF</code> in the configuration file, <code>my.cnf</code>, or repair MyISAM indexes after restoring from a physical backup created with backup locks.</p> <p>MyISAM may also cache data for bulk inserts, e.g. when executing multi-row INSERTs or <code>LOAD DATA</code> statements. Those caches, however, are flushed between statements, so do not affect physical backups as long as all statements updating MyISAM tables are blocked.</p>"},{"location":"backup-locks.html#the-mysqldump-command","title":"The mysqldump Command","text":"<p>The <code>mysqldump</code> tool has also been extended with a new option, lock-for-backup (disabled by default). When used together with the <code>--single-transaction</code> option, the option makes <code>mysqldump</code> issue a <code>LOCK TABLES FOR BACKUP</code> before starting the dump operation to prevent unsafe statements that would normally result in an inconsistent backup.</p> <p>When used without the <code>--single-transaction</code> option, lock-for-backup is automatically converted to lock-all-tables.</p> <p>The option lock-for-backup is mutually exclusive with lock-all-tables, i.e. specifying both on the command line will lead to an error.</p> <p>If the backup locks feature is not supported by the target server, but lock-for-backup is specified on the command line, <code>mysqldump</code> aborts with an error.</p>"},{"location":"backup-locks.html#system-variables","title":"System Variables","text":""},{"location":"backup-locks.html#have_backup_locks","title":"<code>have_backup_locks</code>","text":"Option Description Command Line: Yes Config file No Scope: Global Dynamic: No Data type Boolean Default value YES <p>This is a server variable implemented to help other utilities decide what locking strategy can be implemented for a server. When available, the backup locks feature is supported by the server and the variable value is always <code>YES</code>.</p>"},{"location":"backup-locks.html#status-variables","title":"Status variables","text":""},{"location":"backup-locks.html#com_lock_tables_for_backup","title":"<code>Com_lock_tables_for_backup</code>","text":"Option Description Scope: Global/Session Data type Numeric <p>This status variable indicates the number of times the corresponding statements have been executed.</p>"},{"location":"backup-locks.html#client-command-line-parameter","title":"Client command line parameter","text":""},{"location":"backup-locks.html#lock-for-backup","title":"<code>lock-for-backup</code>","text":"Option Description Command Line: Yes Scope: Global Dynamic: No Data type String Default value Off <p>When used together with the \u2013-single-transaction option, the option makes <code>mysqldump</code> issue <code>LOCK TABLES FOR BACKUP</code> before starting the dump operation to prevent unsafe statements that would normally result in an inconsistent backup.</p> <p></p>"},{"location":"backup-locks.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"backup-restore-overview.html","title":"Backup and restore overview","text":"<p>Backups are data snapshots that are taken at a specific time and are stored in a common location in a common  format. A backup is only useful for a defined time. </p> <p>The following scenarios require a backup to recover:</p> Reason Description Hardware or host failure Issues with disks, such as stalls or broken disks. With cloud services, the instance can be unaccessible or broken. Corrupted data This issue can be caused by power outages, the database failed to write correctly and close the file. User mistake Deleting data or an update overwriting good data with bad data Natural disaster or data center failure Power outage, flooding, or internet issues Compliance Required to comply with regulations and standards"},{"location":"backup-restore-overview.html#strategies","title":"Strategies","text":"<p>Define a backup and restore strategy for each of your databases. The strategies should have the following practices:</p> Practice Description Retention How long should you keep the backups. This decision should be based on the organization\u2019s data governance policies and the expense of storing the backups. The schedule for backups should match the retention schedule. Document Document the strategy and any related policies. The documents should include information about the process and any tools used during backup or restore. Encrypt Encrypt the backup and secure the storage locations Test Test the backups on a timely basis. <p>The backup strategy defines type and the backup frequency, the hardware required, how the backups are verified, and storing the backups, which also  includes the backup security. The strategy uses the following metrics:</p> Metric Description Recovery Time Objective (RTO) How long can the system be down? Recovery Point Objective (RPO) How much data can the organization lose? <p>The restore strategy defines which user account has the restore responsibility and how and frequency  of testing the restore process.</p> <p>These strategies require planning, implementation, and rigorous testing. You must test your restore process with each type of backup used to validate the backup and measure the recovery time. Automate this testing as much as possible. You should also document the process. In case of disaster, you can follow the procedures in the document without wasting time.</p> <p>If you are using replication, consider using a dedicated replica for backups because the operation can cause a high CPU load.</p>"},{"location":"backup-restore-overview.html#physical-backup-or-logical-backup","title":"Physical backup or logical backup","text":"<p>A backup can be either a physical backup or a logical backup.</p>"},{"location":"backup-restore-overview.html#physical-backups","title":"Physical backups","text":"<p>A physical backup copies the files needed to store and recover the database. They can be data files, configuration files, logs, and other types of files. The physical database can be stored in the cloud, in offline storage, on disc, or tape.</p> <p>Percona XtraBackup takes a physical backup. You can also  use RDS/LVM Snapshots or the MySQL Enterprise Backup. </p> <p>If the server is stopped or down, you can copy the datadir with the <code>cp</code> command or the <code>rsync</code> command.</p>"},{"location":"backup-restore-overview.html#logical-backups","title":"Logical backups","text":"<p>A logical backup contains the structural details. This type of backup contains tables, views, procedures, and functions. </p> <p>Tools like [<code>mysqldump</code>],  [<code>mydumper</code>],  [<code>mysqlpump</code>], and  [<code>mysql shell</code>] take a logical backup.</p>"},{"location":"backup-restore-overview.html#comparison","title":"Comparison","text":"Comparison Physical backup Logical backup Content The physical database files The tables, users, procedures, and functions Restore speed Restore can be quick Restore can be slower and does not include file information. Storage Can take more space Based on what is selected, the backup can be smaller"},{"location":"backup-restore-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binary-tarball-install.html","title":"Install Percona Server for MySQL 8.4 from a binary tarball","text":"<p>A binary tarball contains a group of files, including the source code, bundled together into one file using the <code>tar</code> command and compressed using <code>gzip</code>. </p> <p>See the list of the binary tarball available based on the Percona Server for MySQL version to select the right tarball for your environment.</p> <p>You can download the binary tarballs from the <code>Linux - Generic</code> section on the download page.</p> <p>Fetch and extract the correct binary tarball. For example for Ubuntu 22.04:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-innovative-release/Percona-Server-8.4.0-1/binary/tarball/Percona-Server-8.4.0-1-Linux.x86_64.glibc2.35.tar.gz\n</code></pre> <p></p>"},{"location":"binary-tarball-install.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binary-tarball-names.html","title":"Binary tarball file names available based on the Percona Server for MySQL version","text":"<p>For later of Percona Server for MySQL, the tar files are organized by the <code>glibc2</code> version. You can find this version on your operating system with the following command:</p> <pre><code>$ ldd --version\n</code></pre> Expected output <pre><code>ldd (Ubuntu GLIBC 2.35-0ubuntu3.1) 2.35\nCopyright (C) 2022 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\nWritten by Roland McGrath and Ulrich Drepper.\n</code></pre> <p>If the <code>glibc2</code> version from your operating system is not listed, then this Percona Server for MySQL version does not support that operating system.</p>"},{"location":"binary-tarball-names.html#binary-tarball-file-name-organization","title":"Binary tarball file name organization","text":"<p>The following lists the platform and the associated full binary file name used by Percona Server for MySQL tar files 8.4.0-1.</p> Platform Percona Server for MySQL tarball name glibc2 version Ubuntu 22.04 Percona-Server-8.4.0-1-Linux.x86_64.glibc2.35.tar.gz glibc2.35 Ubuntu 20.04 Percona-Server-8.4.0-1-Linux.x86_64.glibc2.31.tar.gz glibc2.31 Red Hat Enterprise 9 Percona-Server-8.4.0-1-Linux.x86_64.glibc2.34.tar.gz glibc2.34 Red Hat Enterprise 8 Percona-Server-8.4.0-1-Linux.x86_64.glibc2.28.tar.gz glibc2.28 Red Hat Enterprise 7 Percona-Server-8.4.0-1-Linux.x86_64.glibc2.17.tar.gz glibc2.17 <p>The types of files are as follows:</p> Type Name Description Full Percona-Server-&lt;version-number&gt;-Linux.x86_64.&lt;glibc2-version&gt;.tar.gz Contains all files available Minimal Percona-Server-&lt;version-number&gt;-Linux.x86_64.&lt;glibc2-version&gt;.minimal.tar.gz Contains binaries and libraries Debug Percona-Server-&lt;version-number&gt;-Linux.x86_64.&lt;glibc2-version&gt;.debug.tar.gz Contains the minimal build files and test files, and debug symbols <p></p>"},{"location":"binary-tarball-names.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binlog-space.html","title":"Managing binary log disk space","text":"<p>It is a challenge to control how much disk space is used by the binary logs. The size of a binary log can vary because a single transaction must be written to a single binary log and cannot be split between multiple binary log files.</p>"},{"location":"binlog-space.html#binlog_space_limit","title":"binlog_space_limit","text":"Attribute Description Uses the command line Yes Uses the configuration file Yes Scope Global Dynamic No Variable type ULONG_MAX Default value 0 (unlimited) Maximum value - 64-bit platform 18446744073709547520 <p>This variable places an upper limit on the total size in bytes of all binary logs. When the limit is reached, the oldest binary logs are purged until the total size is under the limit or only the active log remains.</p> <p>The default value of <code>0</code> disables the feature. No limit is set on the log space. The binary logs accumulate indefinitely until the disk space is full.</p>"},{"location":"binlog-space.html#example","title":"Example","text":"<p>Set the <code>binlog_space_limit</code> to 50 GB in the <code>my.cnf</code> file:</p> <pre><code>[mysqld]\n...\nbinlog_space_limit = 50G\n...\n</code></pre> <p></p>"},{"location":"binlog-space.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"binlogging-replication-improvements.html","title":"Binary logs and replication improvements","text":"<p>Due to continuous development, Percona Server for MySQL incorporated a number of improvements related to replication and binary logs handling. This resulted in replication specifics, which distinguishes it from MySQL.</p>"},{"location":"binlogging-replication-improvements.html#safety-of-statements-with-a-limit-clause","title":"Safety of statements with a <code>LIMIT</code> clause","text":""},{"location":"binlogging-replication-improvements.html#summary-of-the-fix","title":"Summary of the fix","text":"<p>MySQL considers all <code>UPDATE/DELETE/INSERT ... SELECT</code> statements with <code>LIMIT</code> clause to be unsafe, no matter wether they are really producing non-deterministic result or not, and switches from statement-based logging to row-based one. Percona Server for MySQL is more accurate, it acknowledges such instructions as safe when they include <code>ORDER BY PK</code> or <code>WHERE</code> condition. This fix has been ported from the upstream bug report #42415 (#44).</p>"},{"location":"binlogging-replication-improvements.html#performance-improvement-on-relay-log-position-update","title":"Performance improvement on relay log position update","text":""},{"location":"binlogging-replication-improvements.html#relay-log-position-fix","title":"Relay log position fix","text":"<p>MySQL always updated relay log position in multi-source replications setups regardless of whether the committed transaction has already been executed or not. Percona Server omits relay log position updates for the already logged GTIDs.</p>"},{"location":"binlogging-replication-improvements.html#relay-log-position-details","title":"Relay log position details","text":"<p>Particularly, such unconditional relay log position updates caused additional fsync operations in case of <code>relay-log-info-repository=TABLE</code>, and with the higher number of channels transmitting such duplicate (already executed) transactions the situation became proportionally worse. Bug fixed #1786, (upstream #85141).</p>"},{"location":"binlogging-replication-improvements.html#performance-improvement-on-source-and-connection-status-updates","title":"Performance improvement on source and connection status updates","text":""},{"location":"binlogging-replication-improvements.html#source-and-connection-status-update-fix","title":"Source and connection status update fix","text":"<p>Replica nodes configured to update source status and connection information only on log file rotation did not experience the expected reduction in load. MySQL was additionally updating this information in case of multi-source replication when replica had to skip the already executed GTID event.</p>"},{"location":"binlogging-replication-improvements.html#write-flush-commands-to-the-binary-log","title":"Write <code>FLUSH</code> commands to the binary log","text":"<p><code>FLUSH</code> commands, such as <code>FLUSH SLOW LOGS</code>, are not written to the binary log if the system variable binlog_skip_flush_commands is set to ON.</p> <p>In addition, the following changes were implemented in the behavior of <code>read_only</code> and super_read_only modes:</p> <ul> <li> <p>When <code>read_only</code> is set to ON, any <code>FLUSH ...</code> command executed by a normal user (without the <code>SUPER</code> privilege) are not written to the binary log regardless of the value of the binlog_skip_flush_command variable.</p> </li> <li> <p>When super_read_only is set to ON, any <code>FLUSH ...</code> command executed by any user (even by those with the <code>SUPER</code> privilege) are not written to the binary log regardless of the value of the binlog_skip_flush_commands variable.</p> </li> </ul> <p>An attempt to run a <code>FLUSH</code> command without either <code>SUPER</code> or <code>RELOAD</code> privileges results in the <code>ER_SPECIFIC_ACCESS_DENIED_ERROR</code> exception regardless of the value of the binlog_skip_flush_commands variable.</p>"},{"location":"binlogging-replication-improvements.html#binlog_skip_flush_commands","title":"binlog_skip_flush_commands","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Default OFF <p>When binlog_skip_flush_commands is set to ON, <code>FLUSH ...</code> commands are not written to the binary log. See Writing FLUSH Commands to the Binary Log for more information about what else affects the writing of <code>FLUSH</code> commands to the binary log.</p> <p>Note</p> <p><code>FLUSH LOGS</code>, <code>FLUSH BINARY LOGS</code>, <code>FLUSH TABLES WITH READ LOCK</code>, and <code>FLUSH TABLES ... FOR EXPORT</code> are not written to the binary log no matter what value the binlog_skip_flush_commands variable contains. The <code>FLUSH</code> command is not recorded to the binary log and the value of binlog_skip_flush_commands is ignored if the <code>FLUSH</code> command is run with the <code>NO_WRITE_TO_BINLOG</code> keyword (or its alias <code>LOCAL</code>).</p>"},{"location":"binlogging-replication-improvements.html#maintaining-comments-with-drop-table","title":"Maintaining comments with DROP TABLE","text":"<p>When you issue a <code>DROP TABLE</code> command, the binary log stores the command but removes comments and encloses the table name in quotation marks. If you require the binary log to maintain the comments and not add quotation marks, enable <code>binlog_ddl_skip_rewrite</code>.</p>"},{"location":"binlogging-replication-improvements.html#binlog_ddl_skip_rewrite","title":"binlog_ddl_skip_rewrite","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Default OFF <p>If the variable is enabled, single table <code>DROP TABLE</code> DDL statements are logged in the binary log with comments. Multi-table <code>DROP TABLE</code> DDL statements are not supported and return an error.</p> <pre><code>SET binlog_ddl_skip_rewrite = ON;\n/*comment at start*/DROP TABLE t /*comment at end*/;\n</code></pre>"},{"location":"binlogging-replication-improvements.html#binary-log-user-defined-functions","title":"Binary log user defined functions","text":"<p>To implement Point in Time recovery, we have added the <code>binlog_utils_udf</code>. The following user-defined functions are included:</p> Name Returns Description get_binlog_by_gtid() Binlog file name as STRING Returns the binlog file name that contains the specified GTID get_last_gtid_from_binlog() GTID as STRING Returns the last GTID found in the specified binlog get_gtid_set_by_binlog() GTID set as STRING Returns all GTIDs found in the specified binlog get_binlog_by_gtid_set() Binlog file name as STRING Returns the file name of the binlog which contains at least one GTID from the specified set. get_first_record_timestamp_by_binlog() Timestamp as INTEGER Returns the timestamp of the first event in the specified binlog get_last_record_timestamp_by_binlog() Timestamp as INTEGER Returns the timestamp of the last event in the specified binlog <p>Note</p> <p>All functions returning timestamps return their values as microsecond precision UNIX time. In other words, they represent the number of microseconds since 1-JAN-1970.</p> <p>All functions accepting a binlog name as the parameter accepts only short names, without a path component. If the path separator (\u2018/\u2019) is found in the input, an error is returned. This serves the purpose of restricting the locations from where binlogs can be read. They are always read from the current binlog directory (@@log_bin_basename system variable).</p> <p>All functions returning binlog file names return the name in short form, without a path component.</p> <p>The basic syntax for <code>get_binlog_by_gtid()</code> is the following:</p> <pre><code>* get_binlog_by_gtid(string) [AS] alias\n</code></pre> <p>Usage: SELECT get_binlog_by_gtid(string) [AS] alias</p> <p>Example:</p> <pre><code>CREATE FUNCTION get_binlog_by_gtid RETURNS STRING SONAME 'binlog_utils_udf.so';\nSELECT get_binlog_by_gtid(\"F6F54186-8495-47B3-8D9F-011DDB1B65B3:1\") AS result;\n</code></pre> Expected output <pre><code>+--------------+\n| result       |\n+==============+\n| binlog.00001 |\n+--------------+\n</code></pre> <pre><code>DROP FUNCTION get_binlog_by_gtid;\n</code></pre> <p>The basic syntax for <code>get_last_gtid_from_binlog()</code> is the following:</p> <pre><code>* get_last_gtid_from_binlog(string) [AS] alias\n</code></pre> <p>Usage: SELECT get_last_gtid_from_binlog(string) [AS] alias</p> <p>For example:</p> <pre><code>CREATE FUNCTION get_last_gtid_from_binlog RETURNS STRING SONAME 'binlog_utils_udf.so';\nSELECT get_last_gtid_from_binlog(\"binlog.00001\") AS result;\n</code></pre> Expected output <pre><code>+-----------------------------------------+\n| result                                  |\n+=========================================+\n| F6F54186-8495-47B3-8D9F-011DDB1B65B3:10 |\n+-----------------------------------------+\n</code></pre> <pre><code>DROP FUNCTION get_last_gtid_from_binlog;\n</code></pre> <p>The basic syntax for <code>get_gtid_set_by_binlog()</code> is the following:</p> <pre><code>* get_gtid_set_by_binlog(string) [AS] alias\n</code></pre> <p>Usage: SELECT get_gtid_set_by_binlog(string) [AS] alias</p> <p>For example:</p> <pre><code>CREATE FUNCTION get_gtid_set_by_binlog RETURNS STRING SONAME 'binlog_utils_udf.so';\nSELECT get_gtid_set_by_binlog(\"binlog.00001\") AS result;\n</code></pre> Expected output <pre><code>+-------------------------+\n| result                  |\n+=========================+\n| 11ea-b9a7:7,11ea-b9a7:8 |\n+-------------------------+\n</code></pre> <pre><code>DROP FUNCTION get_gtid_set_by_binlog;\n</code></pre> <p>The basic syntax for <code>get_binlog_by_gtid_set()</code> is the following:</p> <ul> <li>get_binlog_by_gtid_set(string) [AS] alias</li> </ul> <p>Usage: SELECT get_binlog_by_gtid_set(string) [AS] alias</p> <p>Example:</p> <pre><code>CREATE FUNCTION get_binlog_by_gtid_set RETURNS STRING SONAME 'binlog_utils_udf.so';\nSELECT get_binlog_by_gtid_set(\"11ea-b9a7:7,11ea-b9a7:8\") AS result;\n</code></pre> Expected output <pre><code>+---------------------------------------------------------------+\n| result                                                        |\n+===============================================================+\n| bin.000003                                                    |\n+---------------------------------------------------------------+\n</code></pre> <pre><code>DROP FUNCTION get_binlog_by_gtid_set;\n</code></pre> <p>The basic syntax for <code>get_first_record_timestamp_by_binlog()</code> is the following:</p> <pre><code>* get_first_record_timestamp_by_binlog(TIMESTAMP) [AS] alias\n</code></pre> <p>Usage: SELECT get_first_record_timestamp_by_binlog(TIMESTAMP) [AS] alias</p> <p>For example:</p> <pre><code>CREATE FUNCTION get_first_record_timestamp_by_binlog RETURNS INTEGER SONAME 'binlog_utils_udf.so';\nSELECT FROM_UNIXTIME(get_first_record_timestamp_by_binlog(\"bin.00003\") DIV 1000000) AS result;\n</code></pre> Expected output <pre><code>+---------------------+\n| result              |\n+=====================+\n| 2020-12-03 09:10:40 |\n+---------------------+\n</code></pre> <pre><code>DROP FUNCTION get_first_record_timestamp_by_binlog;\n</code></pre> <p>The basic syntax for <code>get_last_record_timestamp_by_binlog()</code> is the following:</p> <pre><code>* get_last_record_timestamp_by_binlog(TIMESTAMP) [AS] alias\n</code></pre> <p>Usage: SELECT get_last_record_timestamp_by_binlog(TIMESTAMP) [AS] alias</p> <p>For example:</p> <pre><code>CREATE FUNCTION get_last_record_timestamp_by_binlog RETURNS INTEGER SONAME 'binlog_utils_udf.so';\nSELECT FROM_UNIXTIME(get_last_record_timestamp_by_binlog(\"bin.00003\") DIV 1000000) AS result;\n</code></pre> Expected output <pre><code>+---------------------+\n| result              |\n+=====================+\n| 2020-12-04 04:18:56 |\n+---------------------+\n</code></pre> <pre><code>DROP FUNCTION get_last_record_timestamp_by_binlog;\n</code></pre>"},{"location":"binlogging-replication-improvements.html#limitations","title":"Limitations","text":"<p>For the following variables, do not define values with one or more dot (.) characters:</p> <ul> <li> <p>log_bin</p> </li> <li> <p>log_bin_index</p> </li> </ul> <p>A value defined with these characters is handled differently in MySQL and Percona XtraBackup and can cause unpredictable behavior.</p> <p></p>"},{"location":"binlogging-replication-improvements.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"build-apt-packages.html","title":"Build APT packages","text":"<p>If you wish to build your own Debian/Ubuntu (dpkg) packages of Percona Server for MySQL, you first need to start with a source tarball, either from the Percona website or by generating your own by following the instructions above (Installing Percona Server for MySQL from the Git Source Tree).</p> <p>Extract the source tarball:</p> <pre><code>$ tar xfz Percona-Server-8.4.0-1-Linux.x86_64.ssl102.tar.gz\n$ cd Percona-Server-8.4.0-1\n</code></pre> <p>Copy the Debian packaging in the directory that Debian expects it to be in:</p> <pre><code>$ cp -ap build-ps/debian debian\n</code></pre> <p>Update the changelog for your distribution (here we update for the unstable distribution - sid), setting the version number appropriately. The trailing one in the version number is the revision of the Debian packaging.</p> <pre><code>$ dch -D unstable --force-distribution -v \"8.0.13-3-1\" \"Update to 8.0.13-3\"\n</code></pre> <p>Build the Debian source package:</p> <pre><code>$ dpkg-buildpackage -S\n</code></pre> <p>Use sbuild to build the binary package in a chroot:</p> <pre><code>$ sbuild -d sid percona-server-8.4_8.4.0-1.dsc\n</code></pre> <p>You can give different distribution options to <code>dch</code> and <code>sbuild</code> to build binary packages for all Debian and Ubuntu releases.</p> <p>Note</p> <p>PAM Authentication Plugin is not built with the server by default. In order to build the Percona Server for MySQL with PAM plugin, an additional option <code>-DWITH_PAM=ON</code> should be used.</p> <p></p>"},{"location":"build-apt-packages.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"clone-plugin.html","title":"MySQL Clone plugin","text":"<p>The MySQL Clone plugin lets you clone data from either a local server or from a remote server. The plugin creates a physical snapshot of the data stored in InnoDB, which includes schemas, tables, tablespaces, and data dictionary metadata. The cloned data is a functional data directory and can be used for provisioning a server .</p> <p>The following table lists the cloning operation types:</p> Cloning operation type Description Local Clones the data from the server where the operation is initiated to either a directory on the same server or a server node. Remote Clones the data from the donor to the joiner over the network. <p>When replicating a large number of transactions, the Clone plugin may be a more efficient solution. </p>"},{"location":"clone-plugin.html#install-the-clone-plugin","title":"Install the Clone plugin","text":"<p>The Clone plugin must be installed on both the donor and the joiner servers at either server startup or at runtime. To install the plugin at runtime, run the following command:</p> <pre><code>mysql&gt; INSTALL PLUGIN clone SONAME 'mysql_clone.so';\n</code></pre> <p>Review the INFORMATION_SCHEMA.PLUGINS table or run the <code>SHOW PLUGINS</code> command to verify the installation. The following is an example of querying the PLUGINS table.</p> <pre><code>mysql&gt; SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME='clone';\n</code></pre> <p>The result lists the Clone plugin and the status.</p>"},{"location":"clone-plugin.html#clone-data","title":"Clone data","text":"<p>The SQL statement used to clone data depends on if the operation is local or remote. The following code is an example of cloning data from a remote server:</p> <pre><code>mysql&gt; CLONE INSTANCE FROM `root@remote.server:13336` IDENTIFIED BY `user`;\n</code></pre> <p>Replace the user name, host name, and port number with the settings from the donor server.</p> <p></p>"},{"location":"clone-plugin.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"common-sql.html","title":"Common SQL commands","text":"<p>SQL commands used by MySQL can be categorized into different types based on their purposes: Data Definition Language (DDL), Data Manipulation Language (DML), Data Control Language (DCL), and Transaction Control Language (TCL).</p>"},{"location":"common-sql.html#data-manipulation-language-dml","title":"Data Manipulation Language (DML)","text":"<p>DML commands manage data within database tables.</p> <p>Common DML commands include:</p> <ul> <li> <p>SELECT: This command retrieves data from one or more tables in the database.</p> <pre><code>mysql&gt; SELECT * FROM customers;\n</code></pre> </li> <li> <p>INSERT: This command adds new records to a table.</p> <pre><code>mysql&gt; INSERT INTO customers (name, email) VALUES ('John Doe', 'john@example.com');\n</code></pre> </li> <li> <p>UPDATE: This command modifies existing records in a table.</p> <pre><code>mysql&gt; UPDATE customers SET email = 'newemail@example.com' WHERE id = 1;\n</code></pre> </li> <li> <p>DELETE: This command removes records from a table.</p> <pre><code>mysql&gt; DELETE FROM customers WHERE id = 1;\n</code></pre> </li> </ul>"},{"location":"common-sql.html#data-definition-language-ddl","title":"Data Definition Language (DDL)","text":"<p>DDL commands define, modify, and remove database objects such as tables, indexes, and views.</p> <p>Common DDL commands include:</p> <ul> <li> <p>CREATE: This command creates new database objects like tables, indexes, and views.</p> <pre><code>mysql&gt; CREATE TABLE employees (id INT, name VARCHAR(50));\n</code></pre> </li> <li> <p>ALTER: This command modifies the structure of existing database objects.</p> <pre><code>mysql&gt; ALTER TABLE employees ADD COLUMN email VARCHAR(100);\n</code></pre> </li> <li> <p>DROP: This command removes database objects from the database.</p> <pre><code>mysql&gt; DROP TABLE employees;\n</code></pre> </li> </ul>"},{"location":"common-sql.html#data-control-language-dcl","title":"Data Control Language (DCL)","text":"<p>DCL commands control access to database objects and define privileges.</p> <p>Common DCL commands include:</p> <ul> <li> <p>GRANT: This command grants specific privileges to database users.</p> <pre><code>mysql&gt; GRANT SELECT, INSERT ON employees TO 'user1'@'localhost';\n</code></pre> </li> <li> <p>REVOKE: This command revokes privileges from database users.</p> <pre><code>mysql&gt; REVOKE INSERT ON employees FROM 'user2'@'localhost';\n</code></pre> </li> </ul>"},{"location":"common-sql.html#transaction-control-language-tcl","title":"Transaction Control Language (TCL)","text":"<p>TCL commands manage transactions within a database.</p> <p>Common TCL commands include:</p> <ul> <li> <p>COMMIT: This command saves changes made during the current transaction to the database.</p> <pre><code>mysql&gt; COMMIT;\n</code></pre> </li> <li> <p>ROLLBACK: This command undoes changes made during the current transaction and restores the database to its previous state.</p> <pre><code>mysql&gt; ROLLBACK;\n</code></pre> </li> </ul> <p>Fundamental SQL links:</p> <ul> <li>SQL Basics</li> <li>SELECT</li> <li>INSERT</li> <li>DELETE</li> <li>UPDATE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"common-sql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"compile-percona-server.html","title":"Compile Percona Server for MySQL from source","text":"<p>The following instructions install Percona Server for MySQL 8.4.</p>"},{"location":"compile-percona-server.html#install-percona-server-for-mysql-from-the-git-source-tree","title":"Install Percona Server for MySQL from the Git Source Tree","text":"<p>Percona uses the Github revision control system for development. To build the latest Percona Server for MySQL from the source tree, you will need <code>git</code> installed on your system.</p> <p>You can now fetch the latest Percona Server for MySQL 8.4 sources.</p> <pre><code>$ git clone https://github.com/percona/percona-server.git\n$ cd percona-server\n$ git checkout 8.4\n$ git submodule init\n$ git submodule update\n</code></pre> <p>If you are going to be making changes to Percona Server for MySQL 8.4 and wanting to distribute the resulting work, you can generate a new source tarball (exactly the same way as we do for release):</p> <pre><code>$ cmake .\n$ make dist\n</code></pre> <p>After either fetching the source repository or extracting a source tarball (from Percona or one you generated yourself), you will now need to configure and build Percona Server for MySQL.</p> <p>First, run CMake to configure the build. Here you can specify all the normal build options as you do for a normal MySQL build. Depending on what options you wish to compile Percona Server for MySQL with, you may need other libraries installed on your system. Here is an example using a configure line similar to the options that Percona uses to produce binaries:</p> <pre><code>$ cmake . -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_CONFIG=mysql_release -DFEATURE_SET=community\n</code></pre>"},{"location":"compile-percona-server.html#compile-from-source","title":"Compile from source","text":"<p>Now, compile using make:</p> <pre><code>$ make\n</code></pre> <p>Install:</p> <pre><code>$ make install\n</code></pre> <p>Percona Server for MySQL 8.4 is installed on your system.</p> <p></p>"},{"location":"compile-percona-server.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"compressed-columns.html","title":"Compressed columns with dictionaries","text":"<p>The <code>per-column compression</code> feature is a data type modifier, independent from user-level SQL and InnoDB data compression, that causes the data stored in the column to be compressed on writing to storage and decompressed on reading. For all other purposes, the data type is identical to the one without the modifier, i.e. no new data types are created. Compression is done by using the <code>zlib</code> library.</p> <p>Additionally, it is possible to pre-define a set of strings for each compressed column to achieve a better compression ratio on relatively small individual data items.</p> <p>This feature provides:</p> <ul> <li> <p>a better compression ratio for text data which consists of a large number of predefined words (e.g. JSON or XML) using compression methods with static dictionaries</p> </li> <li> <p>a way to select columns in the table to compress (in contrast to the InnoDB row compression method). This feature is based on a patch provided by Weixiang Zhai.</p> </li> </ul>"},{"location":"compressed-columns.html#specifications","title":"Specifications","text":"<p>The feature is limited to InnoDB/XtraDB storage engine and to columns of the following data types:</p> <ul> <li> <p><code>BLOB</code> (including <code>TINYBLOB</code>, <code>MEDIUMBLOB</code>, <code>LONGBLOG</code>)</p> </li> <li> <p><code>TEXT</code> (including <code>TINYTEXT</code>, <code>MEDUUMTEXT</code>, <code>LONGTEXT</code>)</p> </li> <li> <p><code>VARCHAR</code> (including <code>NATIONAL VARCHAR</code>)</p> </li> <li> <p><code>VARBINARY</code></p> </li> <li> <p><code>JSON</code></p> </li> </ul> <p>A compressed column is declared by using the syntax that extends the existing <code>COLUMN_FORMAT</code> modifier: <code>COLUMN_FORMAT COMPRESSED</code>. If this modifier is applied to an unsupported column type or storage engine, an error is returned.</p> <p>The compression can be specified:</p> <ul> <li> <p>when creating a table: <code>CREATE TABLE ... (..., foo BLOB COLUMN_FORMAT COMPRESSED, ...);</code></p> </li> <li> <p>when altering a table and modifying a column to the compressed format: <code>ALTER TABLE ... MODIFY [COLUMN] ... COLUMN_FORMAT COMPRESSED</code>, or <code>ALTER TABLE ... CHANGE [COLUMN] ... COLUMN_FORMAT COMPRESSED</code>.</p> </li> </ul> <p>Unlike Oracle MySQL, compression is applicable to generated stored columns. Use this syntax extension as follows:</p> <pre><code>mysql&gt; CREATE TABLE t1(\n       id INT,\n       a BLOB,\n       b JSON COLUMN_FORMAT COMPRESSED,\n       g BLOB GENERATED ALWAYS AS (a) STORED COLUMN_FORMAT COMPRESSED WITH COMPRESSION_DICTIONARY numbers\n     ) ENGINE=InnoDB;\n</code></pre> <p>To decompress a column, specify a value other than <code>COMPRESSED</code> to <code>COLUMN_FORMAT</code>: <code>FIXED</code>, <code>DYNAMIC</code>, or <code>DEFAULT</code>. If there is a column compression/decompression request in an <code>ALTER TABLE</code>, it is forced to the <code>COPY</code> algorithm.</p> <p>Two new variables: innodb_compressed_columns_zip_level and innodb_compressed_columns_threshold have been implemented.</p>"},{"location":"compressed-columns.html#compression-dictionary-support","title":"Compression dictionary support","text":"<p>To achieve a better compression ratio on relatively small individual data items, it is possible to predefine a compression dictionary, which is a set of strings for each compressed column.</p> <p>Compression dictionaries can be represented as a list of words in the form of a string (a comma or any other character can be used as a delimiter although not required). In other words, <code>a, bb, ccc</code>, <code>a bb ccc</code>, and <code>abbccc</code> will have the same effect. However, the latter is more compact. The Quote symbol quoting is handled by regular SQL quoting. The maximum supported dictionary length is 32506 bytes (<code>zlib</code> limitation).</p> <p>The compression dictionary is stored in a new system InnoDB table.  As this table is of the data dictionary kind, concurrent reads are allowed, but writes are serialized, and reads are blocked by writes. Table read through old read views are not supported, similar to InnoDB internal DDL transactions.</p>"},{"location":"compressed-columns.html#interaction-with-innodb_force_recovery-variable","title":"Interaction with innodb_force_recovery variable","text":"<p>Compression dictionary operations are treated like DDL operations with the exception when innodb_force_value is set to <code>3</code>: with values less than <code>3</code>, compression dictionary operations are allowed, and with values &gt;= <code>3</code>, they are forbidden.</p>"},{"location":"compressed-columns.html#example","title":"Example","text":"<p>In order to use the compression dictionary, you need to create it. This can be done by running:</p> <pre><code>mysql&gt; SET @dictionary_data = 'one' 'two' 'three' 'four';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.00 sec)\n</code></pre> <pre><code>mysql&gt; CREATE COMPRESSION_DICTIONARY numbers (@dictionary_data);\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.00 sec)\n</code></pre> <p>To create a table that has both compression and compressed dictionary support you should run:</p> <pre><code>mysql&gt; CREATE TABLE t1(\n        id INT,\n        a BLOB COLUMN_FORMAT COMPRESSED,\n        b BLOB COLUMN_FORMAT COMPRESSED WITH COMPRESSION_DICTIONARY numbers\n      ) ENGINE=InnoDB;\n</code></pre> <p>The following example shows how to insert a sample of JSON data into the table:</p> <pre><code>SET @json_value =\n'[\\n'\n' {\\n'\n' \"one\" = 0,\\n'\n' \"two\" = 0,\\n'\n' \"three\" = 0,\\n'\n' \"four\" = 0\\n'\n' },\\n'\n' {\\n'\n' \"one\" = 0,\\n'\n' \"two\" = 0,\\n'\n' \"three\" = 0,\\n'\n' \"four\" = 0\\n'\n' },\\n'\n' {\\n'\n' \"one\" = 0,\\n'\n' \"two\" = 0,\\n'\n' \"three\" = 0,\\n'\n' \"four\" = 0\\n'\n' },\\n'\n' {\\n'\n' \"one\" = 0,\\n'\n' \"two\" = 0,\\n'\n' \"three\" = 0,\\n'\n' \"four\" = 0\\n'\n' }\\n'\n']\\n'\n;\n</code></pre> <pre><code>mysql&gt; INSERT INTO t1 VALUES(0, @json_value, @json_value);\nQuery OK, 1 row affected (0.01 sec)\n</code></pre>"},{"location":"compressed-columns.html#information_schema-tables","title":"INFORMATION_SCHEMA Tables","text":"<p>This feature implements two new <code>INFORMATION_SCHEMA</code> tables.</p>"},{"location":"compressed-columns.html#information_schemacompression_dictionary","title":"<code>INFORMATION_SCHEMA.COMPRESSION_DICTIONARY</code>","text":"Column Name Description \u2018BIGINT(21)_UNSIGNED dict_version\u2019 \u2018dictionary version\u2019 \u2018VARCHAR(64) dict_name\u2019 \u2018dictionary name\u2019 \u2018BLOB dict_data\u2019 \u2018compression dictionary string\u2019 <p>This table provides a view of the internal compression dictionary. The <code>SUPER</code> privilege is required to query it.</p>"},{"location":"compressed-columns.html#information_schemacompression_dictionary_tables","title":"<code>INFORMATION_SCHEMA.COMPRESSION_DICTIONARY_TABLES</code>","text":"Column Name Description \u2018BIGINT(21)_UNSIGNED table_schema\u2019 \u2018table schema\u2019 \u2018BIGINT(21)_UNSIGNED table_name\u2019 \u2018table ID from INFORMATION_SCHEMA.INNODB_SYS_TABLES\u2019 \u2018BIGINT(21)_UNSIGNED column_name\u2019 \u2018column position (starts from 0 as in INFORMATION_SCHEMA.INNODB_SYS_COLUMNS)\u2019 \u2018BIGINT(21)_UNSIGNED dict_name\u2019 \u2018dictionary ID\u2019 <p>This table provides a view over the internal table that stores the mapping between the compression dictionaries and the columns using them. The <code>SUPER</code> privilege is require to query it.</p>"},{"location":"compressed-columns.html#limitations","title":"Limitations","text":"<p>Compressed columns cannot be used in indices (neither on their own nor as parts of composite keys).</p> <p>Note</p> <p><code>CREATE TABLE t2 AS SELECT \\* FROM t1</code> will create a new table with a compressed column, whereas <code>CREATE TABLE t2 AS SELECT CONCAT(a,'') AS a FROM t1</code> will not create compressed columns.</p> <p>At the same time, after executing the <code>CREATE TABLE t2 LIKE t1</code> statement, <code>t2.a</code> will have the <code>COMPRESSED</code> attribute.</p> <p><code>ALTER TABLE ... DISCARD/IMPORT TABLESPACE</code> is not supported for tables with compressed columns. To export and import tablespaces with compressed columns, you uncompress them first with: <code>ALTER TABLE ... MODIFY ... COLUMN_FORMAT DEFAULT</code>.</p>"},{"location":"compressed-columns.html#mysqldump-command-line-parameters","title":"mysqldump command line parameters","text":"<p>By default, with no additional options, <code>mysqldump</code> will generate a MySQL compatible SQL output.</p> <p>All <code>/\\*!50633 COLUMN_FORMAT COMPRESSED \\*/</code> and <code>/\\*!50633 COLUMN_FORMAT COMPRESSED WITH COMPRESSION_DICTIONARY &lt;dictionary&gt; \\*/</code> won\u2019t be in the dump.</p> <p>When a new option enable-compressed-columns is specified, all <code>/\\*!50633 COLUMN_FORMAT COMPRESSED \\*/</code> will be left intact and all <code>/\\*!50633 COLUMN_FORMAT COMPRESSED WITH COMPRESSION_DICTIONARY &lt;dictionary&gt; \\*/</code> will be transformed into <code>/\\*!50633 COLUMN_FORMAT COMPRESSED \\*/</code>. In this mode, the dump will contain the necessary SQL statements to create compressed columns, but without dictionaries.</p> <p>When a new enable-compressed-columns-with-dictionaries option is specified, dump will contain all compressed column attributes and compression dictionary.</p> <p>Moreover, the following dictionary creation fragments will be added before <code>CREATE TABLE</code> statements which are going to use these dictionaries for the first time.</p> <pre><code>/*!50633 DROP COMPRESSION_DICTIONARY IF EXISTS &lt;dictionary&gt;; */\n/*!50633 CREATE COMPRESSION_DICTIONARY &lt;dictionary&gt;(...); */\n</code></pre> <p>Two new options add-drop-compression-dictionary and skip-add-drop-compression-dictionary will control if <code>/\\*!50633 DROP COMPRESSION_DICTIONARY IF EXISTS &lt;dictionary&gt; \\*/</code> part from previous paragraph will be skipped or not. By default, add-drop-compression-dictionary the mode will be used.</p> <p>When both enable-compressed-columns-with-dictionaries and <code>--tab=&lt;dir&gt;</code> (separate file for each table) options are specified, necessary compression dictionaries will be created in each output file using the following fragment (regardless of the values of add-drop-compression-dictionary and skip-add-drop-compression-dictionary options).</p> <pre><code>/*!50633 CREATE COMPRESSION_DICTIONARY IF NOT EXISTS &lt;dictionary&gt;(...); */\n</code></pre>"},{"location":"compressed-columns.html#system-variables","title":"System variables","text":""},{"location":"compressed-columns.html#innodb_compressed_columns_zip_level","title":"<code>innodb_compressed_columns_zip_level</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type Numeric Default 6 Range 0-9 <p>This variable is used to specify the compression level used for compressed columns. Specifying <code>0</code> will use no compression, <code>1</code> the fastest, and <code>9</code> the best compression. The default value is <code>6</code>.</p>"},{"location":"compressed-columns.html#innodb_compressed_columns_threshold","title":"<code>innodb_compressed_columns_threshold</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type Numeric Default 96 Range 1 - 2^64-1 (or 2^32-1 for 32-bit release) <p>By default, a value being inserted will be compressed if its length exceeds innodb_compressed_columns_threshold bytes. Otherwise, it will be stored in the raw (uncompressed) form.</p> <p>Please also note that because of the nature of some data, the compressed representation can be longer than the original value. In this case, it does not make sense to store such values in compressed form as Percona Server for MySQL would have to waste both memory space and CPU resources for unnecessary decompression. Therefore, even if the length of such non-compressible values exceeds innodb_compressed_columns_threshold, they will be stored in an uncompressed form (however, an attempt to compress them will still be made).</p> <p>This parameter can be tuned to skip unnecessary attempts of data compression for values that are known in advance by the user to have a bad compression ratio of their first N bytes.</p> <p></p>"},{"location":"compressed-columns.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"configure-apparmor.html","title":"Configure AppArmor","text":""},{"location":"configure-apparmor.html#edit-profile","title":"Edit profile","text":"<p>Only edit <code>/etc/apparmor.d/local/usr.sbin.mysql</code>. </p> <p>You should [switch the profile] to <code>Complain</code> mode before editing the file. Edit the file in any text editor. When finished, reload the profile and switch it to <code>Enforce</code> mode.</p>"},{"location":"configure-apparmor.html#configure-data-directory-location","title":"Configure data directory location","text":"<p>You can change the data directory to a non-default location, like /var/lib/mysqlcustom. You should enable audit mode to capture all actions and edit the profile to allow access to the custom location.</p> <pre><code>$ cat /etc/mysql/mysql.conf.d/mysqld.cnf\n</code></pre> Expected output <pre><code>The Percona Server 8.4 configuration file.\n\nFor explanations see\nhttps://dev.mysql.com/doc/mysql/en/server-system-variables.html\n\n[mysqld]\npid-file    = /var/run/mysqld/mysqld.pid\nsocket        = /var/run/mysqld/mysqld.sock\n*datadir    = /var/lib/mysqlcustom*\nlog-error    = /var/log/mysql/error.log\n</code></pre> <p>Enable audit mode for mysqld. In this mode, the security policy is enforced and all access is logged.</p> <pre><code>$ aa-audit mysqld\n</code></pre> <p>Restart Percona Server for MySQL.</p> <pre><code>$ sudo systemctl mysql restart\n</code></pre> <p>The restart fails because AppArmor has blocked access to the custom data directory location. To diagnose the issue, check the logs for the following:</p> <ul> <li> <p>ALLOWED - A log event when the profile is in complain mode and the action violates a policy.</p> </li> <li> <p>DENIED - A log event when the profile is in enforce mode and the action is blocked.</p> </li> </ul> <p>For example, the following log entries show <code>DENIED</code>:</p> Expected output <pre><code>...\nDec 07 12:17:08 ubuntu-s-4vcpu-8gb-nyc1-01-aa-ps audit[16013]: AVC apparmor=\"DENIED\" operation=\"mknod\" profile=\"/usr/sbin/mysqld\" name=\"/var/lib/mysqlcustom/binlog.index\" pid=16013 comm=\"mysqld\" requested_mask=\"c\" denied_mask=\"c\" fsuid=111 ouid=111\nDec 07 12:17:08 ubuntu-s-4vcpu-8gb-nyc1-01-aa-ps kernel: audit: type=1400 audit(1607343428.022:36): apparmor=\"DENIED\" operation=\"mknod\" profile=\"/usr/sbin/mysqld\" name=\"/var/lib/mysqlcustom/mysqld_tmp_file_case_insensitive_test.lower-test\" pid=16013 comm=\"mysqld\" requested_mask=\"c\" denied_mask=\"c\" fsuid=111 ouid=111\n...\n</code></pre> <p>Open <code>/etc/apparmor.d/local/usr.sbin.mysqld</code> in a text editor and edit the following entries in the <code>Allow data dir access</code> section.</p> <pre><code>Allow data dir access\n/var/lib/mysqlcustom/ r,\n/var/lib/mysqlcustom/** rwk,\n</code></pre> <p>In <code>etc/apparmor.d/local/usr.sbin.mysqld</code>, comment out, using the # symbol, the current entries in the Allow data dir access section. This step is optional. If you skip this step, mysqld continues to access the default data directory location.</p> <p>Note</p> <p>Edit the local version of the file instead of the main profile. Separating the changes makes maintenance easier.</p> <p>Reload the profile:</p> <pre><code>$ apparmor_parser -r -T /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> <p>Restart mysql:</p> <pre><code>$ systemctl restart mysqld\n</code></pre>"},{"location":"configure-apparmor.html#set-up-a-custom-log-location","title":"Set up a custom log location","text":"<p>To move your logs to a custom location, you must edit the my.cnf configuration file and then edit the local profile to allow access:</p> <pre><code>cat /etc/mysql/mysql.conf.d/mysqld.cnf\n</code></pre> Expected output <pre><code>The Percona Server 8.4 configuration file.\n\nFor explanations see\nhttps://dev.mysql.com/doc/mysql/en/server-system-variables.html\n\n[mysqld]\npid-file    = /var/run/mysqld/mysqld.pid\nsocket        = /var/run/mysqld/mysqld.sock\ndatadir    = /var/lib/mysql\nlog-error    = /*custom-log-dir*/mysql/error.log\n</code></pre> <p>Verify the custom directory exists.</p> <pre><code>$ ls -la /custom-log-dir/\n</code></pre> Expected output <pre><code>total 12\ndrwxrwxrwx  3 root root 4096 Dec  7 13:09 .\ndrwxr-xr-x 24 root root 4096 Dec  7 13:07 ..\ndrwxrwxrwx  2 root root 4096 Dec  7 13:09 mysql\n</code></pre> <p>Restart Percona Server.</p> <pre><code>$ service mysql start\n</code></pre> Expected output <pre><code>Job for mysql.service failed because the control process exited with error code.\nSee \"systemctl status mysql.service\" and \"journalctl -xe\" for details.\n</code></pre> <pre><code>$ journalctl -xe\n</code></pre> Expected output <pre><code>...\nAVC apparmor=\"DENIED\" operation=\"mknod\" profile=\"/usr/sbin/mysqld\" name=\"/custom-log-dir/mysql/error.log\"\n...\n</code></pre> <p>The access has been denied by AppArmor. Edit the local profile in the <code>Allow log file access</code> section to allow access to the custom log location.</p> <pre><code>$ cat /etc/apparmor.d/local/usr.sbin.mysqld\n</code></pre> Expected output <pre><code> Site-specific additions and overrides for usr.sbin.mysqld..\n For more details, please see /etc/apparmor.d/local/README.\n\n Allow log file access\n /custom-log-dir/mysql/ r,\n /custom-log-dir/mysql/** rw,\n</code></pre> <p>Reload the profile:</p> <pre><code>$ apparmor_parser -r -T /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> <p>Restart Percona Server:</p> <pre><code>$ systemctl restart mysqld\n</code></pre>"},{"location":"configure-apparmor.html#set-secure_file_priv-directory-location","title":"Set <code>secure_file_priv</code> directory location","text":"<p>By default, secure_file_priv points to the following location:</p> <pre><code>mysql&gt; mysqlshow variables like 'secure_file_priv';\n</code></pre> Expected output <pre><code>+------------------+-----------------------+\n| Variable_name    | Value                 |\n+------------------+-----------------------+\n| secure_file_priv | /var/lib/mysql-files/ |\n+------------------+-----------------------+\n</code></pre> <p>To allow access to another location, in a text editor, open the local profile. Review the settings in the <code>Allow data dir access</code> section:</p> <pre><code>Allow data dir access\n/var/lib/mysql/ r,\n/var/lib/mysql/** rwk,\n</code></pre> <p>Edit the local profile in a text editor to allow access to the custom location.</p> <pre><code>$ cat /etc/apparmor.d/local/usr.sbin.mysqld\n</code></pre> Expected output <pre><code>Site-specific additions and overrides for usr.sbin.mysqld..\nFor more details, please see /etc/apparmor.d/local/README.\n\nAllow data dir access\n/var/lib/mysqlcustom/ r,\n/var/lib/mysqlcustom/** rwk,\n</code></pre> <p>Reload the profile:</p> <pre><code>$ apparmor_parser -r -T /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> <p>Restart Percona Server for MySQL:</p> <pre><code>$ systemctl restart mysqld\n</code></pre>"},{"location":"configure-apparmor.html#apparmor-links","title":"AppArmor links:","text":"<p>AppArmor AppArmor Profiles Manage AppArmor Profiles Disable AppArmor Troubleshoot AppArmor</p> <p></p>"},{"location":"configure-apparmor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"copyright-and-licensing-information.html","title":"Copyright and licensing information","text":""},{"location":"copyright-and-licensing-information.html#documentation-licensing","title":"Documentation licensing","text":"<p>Percona Server for MySQL documentation is (C)2009-2023 Percona LLC and/or its affiliates and is distributed under the Creative Commons Attribution 4.0 International License.</p>"},{"location":"copyright-and-licensing-information.html#software-license","title":"Software license","text":"<p>Percona Server for MySQL is built upon MySQL from Oracle. Along with making our own modifications, we merge in changes from other sources such as community contributions and changes from MariaDB.</p> <p>The original SHOW USER/TABLE/INDEX statistics code came from Google.</p> <p>Percona does not require copyright assignment.</p> <p>See the COPYING files accompanying the software distribution.</p> <p></p>"},{"location":"copyright-and-licensing-information.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"create-table.html","title":"Create a table","text":"<p>Creating a table is essential to organizing and storing your data effectively when working with a database. Here\u2019s a step-by-step guide on how to create a table in such a database:</p>"},{"location":"create-table.html#permissions-required","title":"Permissions Required","text":"<p>To create a table in a database, you need appropriate permissions. Typically, you\u2019ll need the <code>CREATE TABLE</code> privilege, which allows you to create new tables within a database. This privilege is usually granted to database users by database administrators or through predefined user roles. If you do not have the necessary permissions, you\u2019ll need to contact your database administrator to grant them.</p>"},{"location":"create-table.html#define-the-table-structure","title":"Define the table structure","text":"<p>Now, define the structure of your table by specifying its columns along with their data types and any additional properties. Each column represents a different attribute of your data.</p> <p>Here\u2019s the syntax for creating a table:</p> <pre><code>CREATE TABLE table_name (\n    column1_name data_type constraints,\n    column2_name data_type constraints,\n    ...\n);\n</code></pre> <p>Replace <code>table_name</code> with the desired name for your table. For each column, provide a name, data type, and constraints such as <code>NOT NULL</code>, <code>PRIMARY KEY</code>, <code>AUTO_INCREMENT</code>.</p>"},{"location":"create-table.html#create-the-table","title":"Create the table","text":"<p>Execute the <code>CREATE TABLE</code> command to create the table in the database. For example, to create a table named <code>employees</code> with columns for <code>id</code>, <code>name</code>, and <code>salary</code>, you would run the following SQL command:</p> <pre><code>CREATE TABLE employees (\n    id INT PRIMARY KEY AUTO_INCREMENT,\n    name VARCHAR(50) NOT NULL,\n    salary DECIMAL(10, 2)\n);\n</code></pre> <p>This command creates a table named <code>employees</code> with three columns: <code>id</code>, <code>name</code>, and <code>salary</code>. The <code>id</code> column is an integer type and serves as the primary key with auto-increment functionality. The <code>name</code> column is a variable-length string, and the <code>salary</code> column is a decimal number with a precision of 10 digits and a scale of 2.</p>"},{"location":"create-table.html#verify-table-creation","title":"Verify Table Creation","text":"<p>After executing the <code>CREATE TABLE</code> command, verify that the table has been successfully created. You can use various SQL commands such as <code>SHOW TABLES</code> or <code>DESCRIBE table_name</code> to check the existence and structure of the newly created table.</p> <pre><code>mysql&gt; SHOW TABLES;\nmysql&gt; DESCRIBE employees;\n</code></pre>"},{"location":"create-table.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Tables</li> <li>Isolation Levels</li> <li>Transaction Management</li> <li>Views</li> </ul>"},{"location":"create-table.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"data-at-rest-encryption.html","title":"Data at Rest Encryption","text":"<p>Data security is a concern for institutions and organizations. <code>Transparent Data Encryption (TDE)</code> or <code>Data at Rest Encryption</code> encrypts data files. Data at rest is any data that is not accessed or changed frequently, stored on different types of storage devices. Encryption ensures that if an unauthorized user accesses the data files from the file system, the user cannot read the contents.</p> <p>If the user uses master key encryption, the MySQL keyring plugin stores the InnoDB master key, used for the master key encryption implemented by MySQL. The master key is also used to encrypt redo logs, and undo logs, along with the tablespaces.</p> <p>The InnoDB tablespace encryption has the following components:</p> <ul> <li> <p>The database instance has a master key for tablespaces and a master key for binary log encryption.</p> </li> <li> <p>Each tablespace has a tablespace key. The key is used to encrypt the Tablespace data pages. Encrypted tablespace keys are written on the tablespace header. In the master key implementation, the tablespace key cannot be changed unless you rebuild the table.</p> </li> </ul> <p>Two separate keys allow the master key to be rotated in a minimal operation. When the master key is rotated, each tablespace key is decrypted and re-encrypted with the new master key. The key rotation only reads and writes to the first page of each tablespace file (.ibd).</p> <p>An InnoDB tablespace file is comprised of multiple logical and physical pages. Page 0 is the tablespace header page and keeps the metadata for the tablespace. The encryption information is stored on page 0 and the tablespace key is encrypted.</p> <p>An encrypted page is decrypted at the I/O layer, added to the buffer pool, and used to access the data. A buffer pool page is not encrypted. The page is encrypted by the I/O layer before the page is flushed to disk.</p>"},{"location":"data-at-rest-encryption.html#percona-xtrabackup-support","title":"Percona XtraBackup support","text":"<p>Percona XtraBackup version 8.4 supports the backup of encrypted general tablespaces. </p> <p>Percona XtraBackup only supports features that are Generally Available (GA) in Percona Server for MySQL. Due to time constraints, a GA feature may be supported in a later Percona XtraBackup release. Review the Percona XtraBackup release notes for more information.</p> <p></p>"},{"location":"data-at-rest-encryption.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"data-masking-function-list.html","title":"Data masking component functions","text":"<p>The feature is in tech preview.</p> Name Usage <code>gen_blocklist(str, from_dictionary_name, to_dictionary_name)</code> Replace a term from a dictionary <code>gen_dictionary(dictionary_name)</code> Returns a random term from a dictionary <code>gen_range(lower, upper)</code> Returns a number from a range <code>gen_rnd_canada_sin()</code> Generates a Canadian Social Insurance number <code>gen_rnd_email([name_size, surname_size, domain])</code> Generates an email address <code>gen_rnd_iban([country, size])</code> Generates an International Bank Account number <code>gen_rnd_pan()</code> Generates a Primary account number for a payment card <code>gen_rnd_ssn()</code> Generates a US Social Security number <code>gen_rnd_uk_nin()</code> Generates a United Kingdom National Insurance number <code>gen_rnd_us_phone()</code> Generates a US phone number <code>gen_rnd_uuid()</code> Generates a Universally Unique Identifier <code>mask_canada_sin(str [,mask_char])</code> Masks the Canadian Social Insurance number <code>mask_iban(str [,mask_char])</code> Masks the International Bank Account number <code>mask_inner(str, margin1, margin2 [,mask_char])</code> Masks the inner part of a string <code>mask_outer(str, margin1, margin2 [,mask_char])</code> Masks the outer part of the string <code>mask_pan(str [,mask_char])</code> Masks the Primary Account number for a payment card <code>mask_pan_relaxed(str [,mask_char])</code> Partially masks the Primary Account number for a payment card <code>mask_ssn(str [,mask_char])</code> Masks the US Social Security number <code>mask_uk_nin(str [,mask_char])</code> Masks the United Kingdom National Insurance number <code>mask_uuid(str [,mask_char])</code> Masks the Universally Unique Identifier <code>masking_dictionary_remove(dictionary_name)</code> Removes the dictionary <code>masking_dictionary_term_add(dictionary_name, term_name)</code> Adds a term to the masking dictionary <code>masking_dictionary_term_remove(dictionary_name, term_name)</code> Removes a term from the masking dictionary"},{"location":"data-masking-function-list.html#gen_blockliststr-from_dictionary_name-to_dictionary_name","title":"gen_blocklist(str, from_dictionary_name, to_dictionary_name)","text":"<p>Replaces one term in a dictionary with a term, selected at random, in another dictionary.</p>"},{"location":"data-masking-function-list.html#parameters","title":"Parameters","text":"Parameter Optional Description Type <code>term</code> No The term to replace String <code>from_dictionary_name</code> No The dictionary that stores the term. String <code>to_dictionary_name</code> No The dictionary that stores the replacement term String"},{"location":"data-masking-function-list.html#returns","title":"Returns","text":"<p>A term, selected at random, from the dictionary listed in <code>to_dictionary_name</code> that replaces the selected term. If the selected <code>term</code> is not listed in the <code>from_dictionary_name</code> or a dictionary is missing, then the <code>term</code> is returned. If the <code>to_dictionary_name</code> does not exist, then returns NULL. The character set of the returned string is the same character set of the <code>term</code> parameter.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_blocklist('apple', 'fruit', 'nut');\n</code></pre> Expected output <pre><code>+-----------------------------------------+\n| gen_blocklist('apple', 'fruit', 'nut')  |\n+-----------------------------------------+\n| walnut                                  |\n+-----------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_dictionarydictionary_name","title":"gen_dictionary(dictionary_name)","text":"<p>Returns a term from a dictionary selected at random.</p>"},{"location":"data-masking-function-list.html#parameters_1","title":"Parameters","text":"Parameter Optional Description Type <code>dictionary_name</code> No Select the random term from this dictionary String"},{"location":"data-masking-function-list.html#returns_1","title":"Returns","text":"<p>A random term from the dictionary listed in <code>dictionary_name</code> in the <code>utf8mb4</code> character set. Returns NULL if the <code>dictionary_name</code> does not exist.</p>"},{"location":"data-masking-function-list.html#example_1","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_dictionary('trees');\n</code></pre> Expected output <pre><code>+--------------------------------------------------+\n| gen_dictionary('trees')                          |\n+--------------------------------------------------+\n| Norway spruce                                    |\n+--------------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rangelower-upper","title":"gen_range(lower, upper)","text":"<p>Returns a number from a defined range.</p>"},{"location":"data-masking-function-list.html#parameters_2","title":"Parameters","text":"Parameter Optional Description Type <code>lower</code> No The lower boundary of the range Integer <code>upper</code> No The upper boundary of the range Integer <p>The <code>upper</code> parameter value must be an integer either greater than or equal to the <code>lower</code> parameter value.</p>"},{"location":"data-masking-function-list.html#returns_2","title":"Returns","text":"<p>An integer, selected at random, from an inclusive range defined by the <code>lower</code> parameter value and the <code>upper</code> parameter value, or NULL if the <code>upper</code> boundary is less than the <code>lower</code> boundary.</p>"},{"location":"data-masking-function-list.html#example_2","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_range(10, 100);\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| gen_range(10,100)                    |\n+--------------------------------------+\n| 56                                   |\n+--------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_canada_sin","title":"gen_rnd_canada_sin()","text":"<p>Generates a Canada Social Insurance Number (SIN).</p> <p>Important</p> <p>Only use this function for testing because the result could be a legitimate SIN. Use <code>mask_canada_sin</code> to disguise the result if you must publish the result.</p>"},{"location":"data-masking-function-list.html#parameters_3","title":"Parameters","text":"<p>None.</p>"},{"location":"data-masking-function-list.html#returns_3","title":"Returns","text":"<p>Returns a Canada SIN formatted in three groups of three digits (for example, 123-456-789) in the <code>utf8mb4</code> character set. To ensure the number is consistent, the number is verified with the Luhn algorithm.</p>"},{"location":"data-masking-function-list.html#example_3","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_canada_sin();\n</code></pre> Expected output <pre><code>+-------------------------+\n| gen_rnd_canada_sin()    |\n+-------------------------+\n| 506-948-819             |\n+-------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_emailname_size-surname_size-domain","title":"gen_rnd_email([name_size, surname_size, domain])","text":"<p>Generates a random email address in the <code>name.surname@domain</code> format.</p>"},{"location":"data-masking-function-list.html#parameters_4","title":"Parameters","text":"Parameter Optional Description Type <code>name_size</code> Yes Specifies the number of characters in the name part. The default number is five. The minimum number is one. The maximum number is 1024. Integer <code>surname_size</code> Yes Specifies the number of characters in the surname part. The default number is seven. The minimum number is one. The maximum number is 1024. Integer <code>domain</code> Yes Specifies the domain name used. The default value is <code>example.com</code>. Integer"},{"location":"data-masking-function-list.html#returns_4","title":"Returns","text":"<p>A generated email address as a string in the same character set as <code>domain</code>. If the <code>domain</code> value is not specified, then the string is in the <code>utf8mb4</code> character set. The <code>name</code> and <code>surname</code> are random lower-case letters (a - z).</p>"},{"location":"data-masking-function-list.html#example_4","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_email(name_size=4, surname_size=5, domain='mydomain.edu');\n</code></pre> Expected output <pre><code>+-------------------------------------+\n| gen_rnd_email(4, 5, 'mydomain.edu') |\n+-------------------------------------+\n| qwer.asdfg@mydomain.edu             |\n+-------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_ibancountry-size","title":"gen_rnd_iban([country, size])","text":"<p>Generates an Internal Bank Account Number (IBAN).</p> <p>Important</p> <p>Generating an IBAN with a valid country code should only be used for testing. The function does not check if the generated value is a legitimate bank account. If you must publish the result, consider using <code>mask_iban</code> to disguise the result. The function does not perform a checksum on the bank account number.</p>"},{"location":"data-masking-function-list.html#parameters_5","title":"Parameters","text":"Parameter Optional Description Type <code>country</code> Yes A two-character country code String <code>size</code> Yes Number of characters Integer <p>If the <code>country</code> is not specified, the default value is <code>ZZ</code>. The value must be two upper-case characters (A-Z) or an error is returned.</p> <p>The default value for <code>size</code> is 16. The minimum value is 15. The maximum value is 34.</p>"},{"location":"data-masking-function-list.html#returns_5","title":"Returns","text":"<p>The function returns a string that is the length of the <code>size</code> value. The string consists of <code>country</code> (two characters) followed by the (size - 2) random digits.</p> <p>The character set is the same as the <code>country</code> parameter or if that parameter is not specified, the character set is <code>utf8mb4</code>.</p>"},{"location":"data-masking-function-list.html#example_5","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_iban();\n</code></pre> Expected output <pre><code>+-------------------+\n| gen_rnd_iban()    |\n+-------------------+\n|ZZ78959120078536   |\n+-------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_pan","title":"gen_rnd_pan()","text":"<p>Generates a Primary Account Number (PAN) for a payment card that passes basic checksum validation.</p> <p>The generated PAN can be one of the following:</p> <ul> <li> <p>American Express</p> </li> <li> <p>Visa</p> </li> <li> <p>Mastercard</p> </li> <li> <p>Discover</p> </li> </ul> <p>Important</p> <p>Generating the PAN should only be used for testing. The function does not check if the generated value is a legitimate primary account number. If you must publish the result, consider using <code>mask_pan</code> or <code>mask_pan_relaxed()</code> to disguise the result.</p>"},{"location":"data-masking-function-list.html#parameters_6","title":"Parameters","text":"<p>None</p>"},{"location":"data-masking-function-list.html#returns_6","title":"Returns","text":"<p>A random PAN string in <code>utf8mb4</code> character set.</p>"},{"location":"data-masking-function-list.html#example_6","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_pan();\n</code></pre> Expected output <pre><code>+-------------------+\n| gen_rnd_pan()     |\n+-------------------+\n| 1234567898765432  |\n+-------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_ssn","title":"gen_rnd_ssn()","text":"<p>Generates a United States Social Security Account Number (SSN).</p>"},{"location":"data-masking-function-list.html#parameters_7","title":"Parameters","text":"<p>None</p>"},{"location":"data-masking-function-list.html#returns_7","title":"Returns","text":"<p>A SSN string in a nine-digit number format \u201cAAA-GG-SSSS\u201d in the <code>utf8mb4</code> character set. The number has three parts, the first three digits are the area number, the group number, and the serial number. The generated SSN uses \u2018900\u2019 or greater numbers for the area number. These numbers are not legitimate because they are outside the approved range.</p>"},{"location":"data-masking-function-list.html#example_7","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_ssn();\n</code></pre> Expected output <pre><code>+----------------+\n| gen_rnd_ssn()  |\n+----------------+\n| 970-03-0370    |\n-----------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_uk_nin","title":"gen_rnd_uk_nin()","text":"<p>Generates a United Kingdom National Insurance Number (NIN).</p> <p>Important</p> <p>This function should only be used for testing. The function does not check if the generated value is a legitimate United Kingdom National Insurance number. If you must publish the result, consider masking the result with <code>mask_uk_nin</code>.</p>"},{"location":"data-masking-function-list.html#parameters_8","title":"Parameters","text":"<p>None.</p>"},{"location":"data-masking-function-list.html#returns_8","title":"Returns","text":"<p>A NIN string in the <code>utf8mb4</code> character set. The string is nine (9) characters in length, always starts with \u2018AA\u2019 and ends with \u2018C\u2019.</p>"},{"location":"data-masking-function-list.html#example_8","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_uk_nin();\n</code></pre> Expected output <pre><code>+----------------------+\n| gen_rnd_uk_nin()     |\n+----------------------+\n| AA123456C            |\n+----------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_us_phone","title":"gen_rnd_us_phone()","text":"<p>Generates a United States phone number with the <code>555</code> area code. The \u2018555\u2019 area code represents fictional numbers.</p>"},{"location":"data-masking-function-list.html#parameters_9","title":"Parameters","text":"<p>None</p>"},{"location":"data-masking-function-list.html#returns_9","title":"Returns","text":"<p>Returns a United States phone number in the <code>utf8mb4</code> character set.</p>"},{"location":"data-masking-function-list.html#example_9","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_us_phone();\n</code></pre> Expected output <pre><code>+--------------------+\n| gen_rnd_us_phone() |\n+--------------------+\n| 1-555-249-2029     |\n+--------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#gen_rnd_uuid","title":"gen_rnd_uuid()","text":"<p>Generates a version 4 Universally Unique Identifier (UUID).</p>"},{"location":"data-masking-function-list.html#parameters_10","title":"Parameters","text":"<p>None.</p>"},{"location":"data-masking-function-list.html#returns_10","title":"Returns","text":"<p>Returns a UUID as a string in the <code>utf8mb4</code> character set.</p>"},{"location":"data-masking-function-list.html#example_10","title":"Example","text":"<pre><code>mysql&gt; SELECT gen_rnd_uuid();\n</code></pre> Expected output <pre><code>+------------------------------------+\n| gen_rnd_uuid()                     |\n+------------------------------------+\n|9a3b642c-06c6-11ee-be56-0242ac120002|\n+------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_canada_sinstr-mask_char","title":"mask_canada_sin(str [,mask_char])","text":"<p>Masks a Canada Social Insurance Number (SIN).</p>"},{"location":"data-masking-function-list.html#parameters_11","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The masking character String <p>The <code>str</code> accepts an alphanumeric string.</p> <p>If you do not specify a <code>mask_char</code>, the default character is <code>X</code>. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_11","title":"Returns","text":"<p>A string with the selected characters masked by a specified <code>mask_char</code> or the default value for that parameter. The function supports multibyte characters in any character set. The character set of the return value is the same as <code>str</code>.</p> <p>An error is reported if  <code>str</code> length is an incorrect length.</p> <p>Returns a NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_11","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_canada_sin('555-555-555');\n</code></pre> Expected output <pre><code>+--------------------------------+\n| mask_canada_sin('555-555-555') |\n+--------------------------------+\n| XXX-XXX-XXX                    |\n+--------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_ibanstr-mask_char","title":"mask_iban(str [,mask_char])","text":"<p>Masks an Internal Bank Account Number (IBAN).</p>"},{"location":"data-masking-function-list.html#parameters_12","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes Character used for masking String <p>The <code>str</code> accepts either of the following:</p> <ul> <li> <p>No separator symbol</p> </li> <li> <p>Groups of four characters. These groups can be separated by a space or any separator character.</p> </li> </ul> <p>The default value for <code>mask_char</code> is <code>*</code>. The value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_12","title":"Returns","text":"<p>Returns the masked string. The character set of the result is the same as the character set of <code>str</code>.</p> <p>An error is reported if the <code>str</code> length is incorrect.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_12","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_iban('DE27 1002 02003 77495 4156');\n</code></pre> Expected output <pre><code>+---------------------------------------------+\n| mask_iban('DE27 1002 02003 77495 4156')     |\n+---------------------------------------------+\n| DE** **** **** **** ****                    |\n+---------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_innerstr-margin1-margin2-mask_char","title":"mask_inner(str, margin1, margin2 [,mask_char])","text":"<p>Returns the string where a selected inner portion is masked with a substitute character.</p>"},{"location":"data-masking-function-list.html#parameters_13","title":"Parameters","text":"Parameter Optional Description Type <code>string</code> No The string to be masked String <code>margin1</code> No The number of characters on the left end of the string to remain unmasked Integer <code>margin2</code> No The number of characters on the right end of the string to remain unmasked Integer <code>mask_char</code> Yes The masking character String <p>The <code>margin1</code> value cannot be a negative number. A value of <code>0</code> (zero) masks all characters.</p> <p>The <code>margin2</code> value cannot be a negative number. A value of <code>0</code> (zero) masks all characters.</p> <p>If the sum of <code>margin1</code> and <code>margin2</code> is greater than or equal to the string length, no masking occurs.</p> <p>If the <code>mask_char</code> is not specified, the default is \u2018X\u2019. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_13","title":"Returns","text":"<p>A string with the selected characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value in the character set of the <code>string</code> parameter.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_13","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_inner('123456789', 1, 2);\n</code></pre> Expected output <pre><code>+-----------------------------------+\n| mask_inner('123456789', 1, 2)     |\n+-----------------------------------+\n| 1XXXXXX89                          |\n+-----------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_outerstr-margin1-margin2-mask_char","title":"mask_outer(str, margin1, margin2 [,mask_char])","text":"<p>Returns the string where a selected outer portion is masked with a substitute character.</p>"},{"location":"data-masking-function-list.html#parameters_14","title":"Parameters","text":"Parameter Optional Description Type <code>string</code> No The string to be masked String <code>margin1</code> No On the left end of the string, mask this designated number of characters Integer <code>margin2</code> No On the right end of the string, mask this designated number of characters Integer <code>mask_char</code> Yes The masking character String <p>The <code>margin1</code> cannot be a negative number. A value of <code>0</code> (zero) does not mask any characters.</p> <p>The <code>margin2</code> cannot be a negative number. A value of <code>0</code> (zero) does not mask any characters.</p> <p>If the sum of <code>margin1</code> and <code>margin2</code> is greater than or equal to the string length, the string is masked.</p> <p>If the <code>mask_char</code> is not specified, the default is \u2018X\u2019. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_14","title":"Returns","text":"<p>A string with the selected characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value in the same character set as <code>string</code>.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_14","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_outer('123456789', 2, 2); \n</code></pre> Expected output <pre><code>+------------------------------------+\n| mask_outer('123456789', 2, 2).     |\n+------------------------------------+\n| XX34567XX                          |\n+------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_panstr-mask_char","title":"mask_pan(str [,mask_char])","text":"<p>Returns a masked payment card Primary Account Number (PAN). The mask replaces the PAN number with the specified character except for the last four digits.</p>"},{"location":"data-masking-function-list.html#parameters_15","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The masking character String <p>The <code>str</code> contains a minimum of 14 or a maximum of 19 alphanumeric characters. </p> <p>If the <code>mask_char</code> is not specified, the default value is \u2018X\u2019. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_15","title":"Returns","text":"<p>A string with the selected characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value. The character set of the result is the same character set as <code>str</code>.</p> <p>An error occurs if the <code>str</code> parameter is not the correct length.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_15","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_pan (gen_rnd_pan());\n</code></pre> Expected output <pre><code>+------------------------------------+\n| mask_pan(gen_rnd_pan())            |\n+------------------------------------+\n| XXXXXXXXXXX2345                    |\n+------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_pan_relaxedstr-mask_char","title":"mask_pan_relaxed(str [,mask_char])","text":"<p>Returns a masked payment card Primary Account Number (PAN). The first six numbers and the last four numbers and the rest of the string masked by specified character or <code>X</code>.</p>"},{"location":"data-masking-function-list.html#parameters_16","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The specified character for masking String <p>The <code>str</code> must contain a minimum of 14 or a maximum of 19 alphanumeric characters. </p> <p>If the <code>mask_char</code> is not specified, the default value is \u2018X\u2019.</p>"},{"location":"data-masking-function-list.html#returns_16","title":"Returns","text":"<p>A string with the first six numbers and the last four numbers and the rest of the string masked by a specified <code>mask_char</code> or that parameter\u2019s default value (<code>X</code>). The character set of the result is the same character set as <code>str</code>.</p> <p>The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p> <p>Reports an error is the <code>str</code> parameter is not the correct length.</p> <p>Returns NULL if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_16","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_pan_relaxed(gen_rnd_pan());\n</code></pre> Expected output <pre><code>+------------------------------------------+\n| mask_pan_relaxed(gen_rnd_pan())          |\n+------------------------------------------+\n| 520754XXXXXX4848                         |\n+------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_ssnstr-mask_char","title":"mask_ssn(str [,mask_char])","text":"<p>Returns a masked United States Social Security Number(SSN). The mask replaces the SSN number with the specified character except for the last four digits.</p>"},{"location":"data-masking-function-list.html#parameters_17","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The masking character String <p>The <code>str</code> accepts either of the following:</p> <ul> <li>Nine integers, no separator symbol</li> <li>Nine integers in the <code>AAA-GG-SSS</code> pattern. The <code>-</code> (dash symbol) is the separator character.</li> </ul> <p>If the <code>mask_char</code> is not specified, the default value is <code>*</code>. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_17","title":"Returns","text":"<p>A string with the selected characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value in the same character set of <code>str</code>. </p> <p>Reports an error if the value of the <code>str</code> is an incorrect length.</p> <p>Returns a NULL value if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_17","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_ssn('555-55-5555', 'X');\n</code></pre> Expected output <pre><code>+-----------------------------+\n| mask_ssn('555-55-5555','X') |\n+-----------------------------+\n| XXX-XX-5555                 |\n+-----------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_uk_ninstr-mask_char","title":"mask_uk_nin(str [,mask_char])","text":"<p>Returns a masked a United Kingdom National Insurance Number (NIN). The mask replaces the NIN number with the specified character except for the first two digits.</p>"},{"location":"data-masking-function-list.html#parameters_18","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The masking character String <p>The <code>str</code> accepts an alpha-numeric string and does not check format and the <code>str</code> can use any separator character.</p> <p>If the <code>mask_char</code> is not specified, the default value is <code>*</code>. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_18","title":"Returns","text":"<p>Returns a string with the selected characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value in the same character set as <code>str</code>.</p> <p>An error occurs if the <code>str</code> parameter is not the correct length. </p> <p>Returns a NULL value if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_18","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_uk_nin ('CT 26 46 83 D');\n</code></pre> Expected output <pre><code>+------------------------------------+\n| mask_uk_nin('CT 26 46 83 D')       |\n+------------------------------------+\n| CT ** ** ** *                      |\n+------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#mask_uuidstr-mask_char","title":"mask_uuid(str [,mask_char])","text":"<p>Masks a Universally Unique Identifier (UUID).</p>"},{"location":"data-masking-function-list.html#parameters_19","title":"Parameters","text":"Parameter Optional Description Type <code>str</code> No The string to be masked String <code>mask_char</code> Yes The masking character String <p>The <code>str</code> format is <code>********-****-****-****-************</code>.</p> <p>If the <code>mask_char</code> is not specified, the default value is \u2018*\u2019. The <code>mask_char</code> value can be a multibyte character in any character set and may not be same character set as <code>str</code>.</p>"},{"location":"data-masking-function-list.html#returns_19","title":"Returns","text":"<p>A string with the characters masked by a specified <code>mask_char</code> or that parameter\u2019s default value in the same character set as <code>str</code>.</p> <p>Returns an error if the length of <code>str</code> is incorrect.</p> <p>Returns <code>NULL</code> if you invoke this function with NULL as the primary argument.</p>"},{"location":"data-masking-function-list.html#example_19","title":"Example","text":"<pre><code>mysql&gt; SELECT mask_uuid('9a3b642c-06c6-11ee-be56-0242ac120002');\n</code></pre> Expected output <pre><code>+-------------------------------------------------------+\n| mask_uuid('9a3b642c-06c6-11ee-be56-0242ac120002')     |\n+-------------------------------------------------------+\n|********_****_****_****_************                   |\n+-------------------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#masking_dictionary_removedictionary_name","title":"masking_dictionary_remove(dictionary_name)","text":"<p>Removes all of the terms and then removes the dictionary. </p> <p>Requires the <code>MASKING_DICTIONARIES_ADMIN</code> privilege.</p>"},{"location":"data-masking-function-list.html#parameters_20","title":"Parameters","text":"Parameter Optional Description Type <code>dictionary_name</code> No The dictionary to be removed String"},{"location":"data-masking-function-list.html#returns_20","title":"Returns","text":"<p>Returns a string value of <code>1</code> (one) in the <code>utf8mb4</code> character set if the operation is successful or <code>NULL</code> if the operation could not find the <code>dictionary_name</code>.</p>"},{"location":"data-masking-function-list.html#example_20","title":"Example","text":"<pre><code>mysql&gt; SELECT masking_dictionary_remove('trees');\n</code></pre> Expected output <pre><code>+------------------------------------------+\n| masking_dictionary_remove('trees')       |\n+------------------------------------------+\n|                                        1 |\n+------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#masking_dictionary_term_adddictionary_name-term_name","title":"masking_dictionary_term_add(dictionary_name, term_name)","text":"<p>Adds a term to the dictionary and requires the <code>MASKING_DICTIONARIES_ADMIN</code> privilege.</p>"},{"location":"data-masking-function-list.html#parameters_21","title":"Parameters","text":"Parameter Optional Description Type <code>dictionary_name</code> No The dictionary where the term is added String <code>term_name</code> No The term added to the selected dictionary String"},{"location":"data-masking-function-list.html#returns_21","title":"Returns","text":"<p>Returns a string value of <code>1</code> (one) in the <code>utf8mb4</code> character set if the operation is successful. If the <code>dictionary_name</code> does not exist, the operation creates the dictionary.</p> <p>Returns <code>NULL</code> if the operation fails. An operation can fail if the <code>term_name</code> is already available in the dictionary specified by <code>dictionary_name</code>.</p> <p>The operation uses <code>INSERT IGNORE</code> and can have the following outcomes:</p> <ul> <li> <p>The <code>term_name</code> is truncated if the <code>term_name</code> length is greater than maximum length of the <code>Term</code> field in the <code>mysql.masking_dictionaries</code> table.</p> </li> <li> <p>The character of the <code>dictionary_name</code> is not supported by the <code>Dictionary</code> field in <code>mysql.masking_dictionaries</code> table, the character is implicitly  converted to \u2018?\u2019. </p> </li> <li> <p>If the character of the <code>term_name</code> is not supported by the <code>Term</code> field in the <code>mysql.masking_dictionaries</code> table, the character is implicitly converted to \u2018?\u2019.</p> </li> </ul> <p>The following command returns the table information:</p> <pre><code>mysql&gt; DESCRIBE mysql.masking_dictionaries;\n</code></pre> <p>The result returns the table structure.</p> Expected output <pre><code>+------------+--------------+------+-----+---------+-------+\n| Field      | Type         | Null | Key | Default | Extra |\n+------------+--------------+------+-----+---------+-------+\n| Dictionary | varchar(256) | NO   | PRI | NULL    |       |\n| Term       | varchar(256) | NO   | PRI | NULL    |       |\n+------------+--------------+------+-----+---------+-------+\n2 rows in set (0.02 sec)\n</code></pre> <p>Modify the table with an <code>ALTER TABLE</code> statement, if needed.</p>"},{"location":"data-masking-function-list.html#example_21","title":"Example","text":"<pre><code>mysql&gt; SELECT masking_dictionary_term_add('trees','pine');\n</code></pre> Expected output <pre><code>+-----------------------------------------------+\n| masking_dictionary_term_add('trees', 'pine')  |\n+-----------------------------------------------+\n|                                             1 |\n+-----------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#masking_dictionary_term_removedictionary_name-term_name","title":"masking_dictionary_term_remove(dictionary_name, term_name)","text":"<p>Removes the selected term from the dictionary. </p> <p>Requires the <code>MASKING_DICTIONARIES_ADMIN</code> privilege.</p>"},{"location":"data-masking-function-list.html#parameters_22","title":"Parameters","text":"Parameter Optional Description Type <code>dictionary_name</code> No The dictionary that contains the <code>term_name</code> String <code>term_name</code> No The term to be removed String"},{"location":"data-masking-function-list.html#returns_22","title":"Returns","text":"<p>Returns a string value of <code>1</code> (one) in the <code>utf8mb4</code> character set if the operation is successful.</p> <p>Returns <code>NULL</code> if the operation fails. An operation can fail if the following occurs:</p> <ul> <li>The <code>term_name</code> is not available in the dictionary specified by <code>dictionary_name</code></li> <li>The <code>dictionary_name</code> could not be found</li> </ul>"},{"location":"data-masking-function-list.html#parameters_23","title":"Parameters","text":"Parameter Optional Description Type <code>dictionary_name</code> No The dictionary for the term String <code>term_name</code> No The term to be added String"},{"location":"data-masking-function-list.html#example_22","title":"Example","text":"<pre><code>mysql&gt; SELECT masking_dictionary_term_remove('trees','pine');\n</code></pre> Expected output <pre><code>+-------------------------------------------------------+\n| masking_dictionary_term_remove('trees', 'pine')       |\n+-------------------------------------------------------+\n|                                                     1 |\n+-------------------------------------------------------+\n</code></pre>"},{"location":"data-masking-function-list.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"data-masking-overview.html","title":"Data masking overview","text":"<p>Data masking helps to limit the exposure of sensitive data by preventing access to non-authorized users. Masking provides a way to create a version of the data in situations, such as a presentation, sales demo, or software testing, when the real data should not be used. Data masking changes the data values while using the same format and cannot be reverse engineered. Masking reduces an organization\u2019s risk by making the data useless to an outside party.</p>"},{"location":"data-masking-overview.html#data-masking-techniques","title":"Data masking techniques","text":"<p>The common data masking techniques are the following:</p> Technique Description Custom string Replaces sensitive data with a specific string, such as a phone number with XXX-XXX-XXXX Data substitution Replaces sensitive data with realistic alternative values, such as city name with another name from a dictionary <p></p>"},{"location":"data-masking-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"data-types-basic.html","title":"Common data types","text":"<p>Choosing the correct data type for each column ensures data accuracy, efficiency, and reliability within the database. The following describes the purpose of a data type in Percona Server for MySQL:</p> <ul> <li> <p>Purpose:</p> </li> <li> <p>Data types define the kind of data that can be stored in a column of a table.</p> </li> <li> <p>They enforce constraints on the values that can be inserted into the column, ensuring data integrity.</p> </li> <li> <p>Data types determine how the data is stored in memory and on disk, optimizing storage space and performance.</p> </li> <li> <p>They provide a way to specify the format and range of acceptable values for numeric, string, date, and other types of data.</p> </li> <li> <p>Data types facilitate efficient sorting, indexing, and searching of data within the database.</p> </li> <li> <p>Importance:</p> </li> <li> <p>Choosing the appropriate data type for each column is crucial for efficient database design and performance.</p> </li> <li> <p>Data types help prevent data corruption and inconsistency by enforcing strict rules for data storage and manipulation.</p> </li> <li> <p>They enable database administrators and developers to define the structure of the database accurately and ensure compatibility with application requirements.</p> </li> <li> <p>Understanding data types allows for effective data modeling and schema design, leading to well-organized and scalable databases.</p> </li> </ul> <p>The following is a description of common data types:</p>"},{"location":"data-types-basic.html#integer-types","title":"Integer Types","text":"<p>Integers are whole numbers without any fractional part. Percona Server for MySQL offers different sizes of integer types to accommodate various ranges of values.</p> Data Type name Description <code>TINYINT</code> A very small integer that can hold values from -128 to 127 (signed) or 0 to 255 (unsigned). <code>SMALLINT</code> A small integer that can hold values from -32768 to 32767 (signed) or 0 to 65535 (unsigned). <code>MEDIUMINT</code> A medium-sized integer that can hold values from -8388608 to 8388607 (signed) or 0 to 16777215 (unsigned). <code>INT</code> or <code>INTEGER</code> A standard-sized integer that can hold values from -2147483648 to 2147483647 (signed) or 0 to 4294967295 (unsigned). <code>BIGINT</code> A large integer that can hold values from -9223372036854775808 to 9223372036854775807 (signed) or 0 to 18446744073709551615 (unsigned)."},{"location":"data-types-basic.html#floating-point-types","title":"Floating-Point Types","text":"<p>Floating-point types are used to represent numbers with a fractional part.</p> Data Type name Description <code>FLOAT</code> A single-precision floating-point number that can hold up to 7 decimal digits of precision. <code>DOUBLE</code> or <code>REAL</code> A double-precision floating-point number that can hold up to 15 decimal digits of precision."},{"location":"data-types-basic.html#fixed-point-types","title":"Fixed-Point Types","text":"<p>Fixed-point types are used to represent exact numeric values.</p> <ul> <li><code>DECIMAL</code> or <code>NUMERIC</code>: A fixed-point number with user-defined precision and scale.</li> </ul>"},{"location":"data-types-basic.html#string-types","title":"String Types","text":"<p>String types are used to store text data.</p> Data Type name Description <code>CHAR</code> A fixed-length string that can hold up to 255 characters. <code>VARCHAR</code> A variable-length string that can hold up to 65535 characters. <code>TEXT</code> A string with a maximum length of 65535 characters. <code>BLOB</code> A binary large object that can hold up to 65535 bytes."},{"location":"data-types-basic.html#date-and-time-types","title":"Date and Time Types","text":"<p>Date and time types are used to store date and time information.</p> Data Type name Description <code>DATE</code> A date value in the format YYYY-MM-DD. <code>TIME</code> A time value in the format HH:MM:SS. <code>DATETIME</code> A combination of date and time values in the format YYYY-MM-DD HH:MM:SS. <code>TIMESTAMP</code> A timestamp value representing the number of seconds since the Unix epoch (January 1, 1970)."},{"location":"data-types-basic.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"data-types-basic.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"database.html","title":"Introduction to Databases and SQL","text":""},{"location":"database.html#introduction-to-databases","title":"Introduction to databases","text":"<p>A database in the server is a structured collection of data. It helps store, organize, and manage various types of information like customer details, product inventories, financial records, and more. Using a database allows you to store data in an organized manner, making it easy to retrieve, update, and manipulate as needed.</p>"},{"location":"database.html#advantages","title":"Advantages","text":"<p>Using a database in servers has several benefits. The table below lists these advantages:</p> Advantages Description Efficient Storage Databases store data in an organized way, making it easy to manage large volumes of information. Quick Retrieval You can quickly find and retrieve specific data using SQL queries. Data Integrity Databases ensure data accuracy and consistency through constraints and relationships. Scalability Databases can handle growing amounts of data and users efficiently. Security Databases provide robust security features to protect sensitive data."},{"location":"database.html#disadvantages","title":"Disadvantages","text":"<p>While databases offer many advantages, there are also some drawbacks to consider. The table below outlines these disadvantages:</p> Disadvantages Description Complex Setup Setting up and configuring a database can be complex and time-consuming. Maintenance Databases require regular maintenance and updates to function optimally. Resource Intensive Databases can consume significant server resources, impacting performance. Backup and Recovery Proper backup and recovery processes are necessary to prevent data loss. Cost Licensing and operational costs for databases can be high, especially for large-scale deployments."},{"location":"database.html#permissions-required","title":"Permissions required","text":"<p>To create a database on a server, a user must have the <code>CREATE</code> privilege. This privilege allows the user to create new databases and tables within those databases.</p>"},{"location":"database.html#using-sql-commands-with-a-database","title":"Using SQL Commands with a database","text":""},{"location":"database.html#create-a-database","title":"Create a database","text":"<p>You use the <code>CREATE DATABASE</code> command to create a new database in the server. This command tells the server to create a new database with the specified name. For example, to create a database named <code>my_database</code>, you execute the following command:</p> <pre><code>mysql&gt; CREATE DATABASE my_database;\n</code></pre> <p>This command creates a new, empty database called <code>my_database</code>. You can then start adding tables and data to this database.</p>"},{"location":"database.html#select-a-database","title":"Select a database","text":"<p>After creating a database, you need to select it to start working with it. Use the <code>USE</code> command to specify which database you want to use for your SQL statements. For example, to select the <code>my_database</code> database, you execute the following command:</p> <pre><code>mysql&gt; USE my_database;\n</code></pre> <p>This command tells the server to use <code>my_database</code> for all subsequent SQL commands. Now, any SQL operations you perform will apply to <code>my_database</code>.</p>"},{"location":"database.html#database-management","title":"Database management","text":"<ul> <li>Modify Tables</li> <li>Isolation Levels</li> <li>Transaction Management</li> <li>Views</li> </ul>"},{"location":"database.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"delete.html","title":"DELETE statement","text":"<p>The DELETE statement removes one or more rows from a table based on specified conditions. It allows developers to selectively delete data from a table, providing a way to manage and maintain the database by removing unnecessary or outdated records.</p>"},{"location":"delete.html#advantages-and-disadvantages-of-using-delete-statement","title":"Advantages and Disadvantages of Using DELETE Statement","text":"Trade-offs Description Advantages Allows selective removal of specific rows from a table, helping to maintain data integrity and manage database resources efficiently. Can be combined with WHERE clause to delete rows that meet certain conditions, providing flexibility in data manipulation. Provides a straightforward way to remove unwanted data without affecting the structure of the table or other related tables. Disadvantages Deleting large amounts of data can impact performance and may require careful consideration to avoid unintended consequences. Deletes are permanent and irreversible, so it\u2019s crucial to double-check conditions and backup data before executing DELETE queries."},{"location":"delete.html#syntax-of-delete-statement","title":"Syntax of DELETE Statement","text":"<p>The statement has the following options:</p> Option Description <code>DELETE FROM table_name</code> This clause specifies the table from which you want to delete rows. <code>WHERE condition</code> (Optional) This clause filters the rows to be deleted based on a specific condition. If omitted, all rows in the table will be deleted. <p>The syntax of the DELETE statement is as follows:</p> <pre><code>DELETE FROM table_name\n[WHERE condition];\n</code></pre>"},{"location":"delete.html#example-of-delete-statement","title":"Example of DELETE Statement","text":"<p>This example deletes all rows from the <code>orders</code> table where the <code>order_date</code> is before January 1, 2023.</p> <pre><code>DELETE FROM orders\nWHERE order_date &lt; '2023-01-01';\n</code></pre> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SQL Basics</li> <li>SELECT</li> <li>INSERT</li> <li>UPDATE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"delete.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"development.html","title":"Development of Percona Server for MySQL","text":"<p>Percona Server for MySQL is an open source project to produce a distribution of the MySQL Server with improved performance, scalability and diagnostics.</p>"},{"location":"development.html#submit-changes","title":"Submit changes","text":"<p>We keep the trunk in a constant state of stability to allow for a release at any time and to minimize wasted time by developers due to broken code.</p>"},{"location":"development.html#overview","title":"Overview","text":"<p>At Percona we use Git for source control, GitHub for code hosting, and Jira for release management.</p> <p>We change our software to implement new features and/or to fix bugs. Refactoring could be classed either as a new feature or a bug depending on the scope of work.</p> <p>New features and bugs are targeted to specific releases. A release is part of a series. For example, 2.4 is a series in Percona XtraBackup and 2.4.15, 2.4.16, and 2.4.17 are releases in this series.</p> <p>Code is proposed for merging in the form of pull requests on GitHub.</p> <p>For Percona Server for MySQL, we have several Git branches on which development occurs: 5.5, 5.6, 5.7, and 8.0. As Percona Server for MySQL is not a traditional project, instead of being a set of patches against an existing product, these branches are not related. In other words, we do not merge from one release branch to another. To have your changes in several branches, you must propose branches to each release branch.</p>"},{"location":"development.html#making-a-change-to-a-project","title":"Making a change to a project","text":"<p>In this case, we are going to use <code>percona-xtrabackup</code> as an example. The workflow is similar for Percona Server for MySQL, but the patch will need to be modified in all release branches of Percona Server for MySQL.</p> <ul> <li> <p><code>git branch https://github.com/percona/percona-xtrabackup/featureX</code> (where \u2018featureX\u2019 is a sensible name for the task at hand)</p> </li> <li> <p>(developer makes changes in featureX, testing locally)</p> </li> <li> <p>The Developer pushes to <code>https://github.com/percona/username/percona-xtrabackup/featureX</code></p> </li> <li> <p>The developer can submit a pull request to https://github.com/percona/percona-xtrabackup,</p> </li> <li> <p>Code undergoes a review</p> </li> <li> <p>Once code is accepted, it can be merged</p> </li> </ul> <p>If the change also applies to a stable release (e.g. 2.4) then changes should be made on a branch of 2.4 and merged to a branch of the trunk. In this case, there should be two branches run through the param build and two merge proposals (one for the stable release and one with the changes merged to the trunk). This prevents somebody else from having to guess how to merge your changes.</p>"},{"location":"development.html#percona-server-for-mysql","title":"Percona Server for MySQL","text":"<p>The same process for Percona Server for MySQL, but we have several different branches (and merge requests).</p> <p></p>"},{"location":"development.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"disable-apparmor.html","title":"Disable AppArmor","text":""},{"location":"disable-apparmor.html#disable-apparmor-risks","title":"Disable AppArmor Risks","text":"<p>Using AppArmor might seem like an extra step, but if you disable it, your server could face security risks.</p> <p>Do not disable AppArmor in production environments. Instead, use AppArmor\u2019s security features and configure it to fit your needs.</p>"},{"location":"disable-apparmor.html#risks","title":"Risks","text":"Risk Description Increased Attack Surface Disabling AppArmor removes security restrictions, potentially allowing unauthorized access to Percona Server for MySQL\u2019s files and functionalities. This creates an attractive target for attackers seeking to exploit vulnerabilities or gain control of your database. Unforeseen Security Holes AppArmor can help mitigate even unknown vulnerabilities by restricting unexpected behaviors. Disabling it leaves your system more susceptible to these hidden security holes. Accidental Misconfigurations Even with good intentions, manual configuration of access controls can be error-prone. AppArmor provides a pre-defined security layer, reducing the risk of human error in managing permissions."},{"location":"disable-apparmor.html#disable-procedure","title":"Disable procedure","text":"<p>If AppArmor must be disabled, run the following commands:</p> <ol> <li> <p>Check the status.</p> <pre><code>$ sudo apparmor_status\n</code></pre> </li> <li> <p>Stop and disable AppArmor.</p> <pre><code>$ sudo systemctl stop apparmor\n$ sudo systemctl disable apparmor\n</code></pre> </li> </ol>"},{"location":"disable-apparmor.html#apparmor-links","title":"AppArmor links","text":"<p>AppArmor AppArmor Profiles Manage AppArmor Profiles Configure AppArmor Troubleshoot AppArmor</p> <p></p>"},{"location":"disable-apparmor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"disable-audit-log-filter.html","title":"Disable Audit Log Filter logging","text":"<p>The <code>audit_log_filter.disable</code> system variable lets you disable or enable logging for all connections.</p> <p>You can set the variable in the following ways:</p> <ul> <li>Option file</li> <li>Command-line startup string</li> <li>SET statement during runtime</li> </ul> <pre><code>mysql&gt; SET GLOBAL audit_log_filter.disable = true;\n</code></pre> <p>Setting <code>audit_log_filter.disable</code> has the following effect:</p> Value Actions true Generates a warning. Audit log function calls and changes in variables generate session warnings. Disables the component. false Re-enables the component and generates a warning. This is the default value."},{"location":"disable-audit-log-filter.html#privileges-required","title":"Privileges required","text":"<p>Setting the value of <code>audit_log_filter.disable</code> at runtime requires the following:</p> <ul> <li><code>AUDIT_ADMIN</code> privilege</li> <li><code>SYSTEM_VARIABLES_ADMIN</code> privilege</li> </ul> <p></p>"},{"location":"disable-audit-log-filter.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"docker-config.html","title":"Docker environment variables","text":"<p>When running a Docker container with Percona Server, you can adjust the configuration of the instance Add one or more environment variables to the <code>docker run</code> command.</p> <p>These variables will not affect you if you start the container with a data directory that already contains a database. Any pre-existing database remains untouched on the container startup.</p> <p>The variables are optional, but you must specify at least one of the following:</p> <ul> <li> <p><code>MYSQL_DATABASE</code> - the database schema name that is created when the container starts</p> </li> <li> <p><code>MYSQL_USER</code> - create a user account when the container starts</p> </li> <li> <p><code>MYSQL_PASSWORD</code> - used with <code>MYSQL_USER</code> to create a password for that user account.</p> </li> <li> <p><code>MYSQL_ALLOW_EMPTY_PASSWORD</code> - creates a root user with an empty password. This option is insecure and only should be used for testing or proof of concept when the database can be removed afterward. Anyone can connect as <code>root</code>.</p> </li> <li> <p><code>MYSQL_ROOT_PASSWORD</code> - this password is used for the <code>root</code> user account. This option is not recommended for production.</p> </li> <li> <p><code>MYSQL_RANDOM_ROOT_PASSWORD</code> - set this variable instead of <code>MYSQL_ROOT_PASSWORD</code> when you want Percona Server to generate a password for you. The generated password is available in the container\u2019s logs only during the first start of the container. Use <code>docker logs</code>. You cannot retrieve the password after the first start.</p> </li> </ul> <p>To further secure your instance, use the <code>MYSQL_ONETIME_PASSWORD</code> variable.</p> <p>These variables are visible to anyone able to run <code>Docker inspect</code>. </p> <pre><code>$ docker inspect ps\n</code></pre> Expected output <pre><code>...\n \"Env\": [\n                \"MYSQL_ROOT_PASSWORD=root\",\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"PS_VERSION=8.4.0-1\",\n                \"OS_VER=el8\",\n                \"FULL_PERCONA_VERSION=8.4.0-1.el8\"\n               ]\n...\n</code></pre> <p>You should use <code>Docker secrets</code> or volumes instead. </p> <p>Percona Server for MySQL also allows adding the <code>_FILE</code> suffix to a variable name. This suffix lets you add the value in a path so that the value cannot be inspected from outside the container.</p> <p></p>"},{"location":"docker-config.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"docker.html","title":"Running Percona Server for MySQL in a Docker Container","text":"<p>Percona Server for MySQL has an official Docker image hosted on Docker Hub. Download a specific version by adding the Docker tag filter for the 8.4 versions. </p> <p>We gather Telemetry data in the Percona packages and Docker images.</p> <p>Make sure that you are using the latest version of Docker. The <code>APT</code> version or the <code>YUM</code> version may be outdated and cause errors.</p>"},{"location":"docker.html#starting-a-detached-container","title":"Starting a detached container","text":"<p>Start a container with the <code>--detached</code> or <code>-d</code> option, which runs the container in the background. In <code>detached</code> mode, when the root process used to run the container exits, the container exits.</p> <p>The following example starts a container named <code>ps</code> with the latest version of Percona Server for MySQL 8.4. This action also creates the <code>root</code> user and uses <code>root</code> as the password. Please note that <code>root</code> is not a secure password. </p> <pre><code>$ docker run -d \\\n  --name ps \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  percona/percona-server:8.4\n</code></pre> Expected output <pre><code>Unable to find image 'percona/percona-server:8.4' locally\n8.4: Pulling from percona/percona-server\n</code></pre> <p>By default, Docker pulls the image from Docker Hub if it is not available locally.</p> <p>To view the container\u2019s logs, use the following command:</p> <pre><code>$ docker logs ps --follow\n</code></pre> Expected output <pre><code>Initializing database\n2022-09-07T15:20:03.158128Z 0 [System] [MY-013169] [Server] /usr/sbin/mysqld (mysqld 8.4.0-1) initializing of server in progress as process 15\n2022-09-07T15:20:03.167764Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.\n2022-09-07T15:20:03.530600Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.\n2022-09-07T15:20:04.367600Z 0 [Warning] [MY-013829] [Server] Missing data directory for ICU regular expressions: /usr/lib64/mysql/private/.\n...\n2022-09-07T15:20:13.706090Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Bind-address: '::' port: 33060, socket: /var/lib/mysql/mysqlx.sock\n2022-09-07T15:20:13.706136Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.4.0-1'  socket: '/var/lib/mysql/mysql.sock'  port: 3306  Percona Server (GPL), Release 21, Revision c59f87d2854.\n</code></pre> <p>You can access the server when you see the <code>ready for connections</code> information in the log.</p>"},{"location":"docker.html#passing-options","title":"Passing Options","text":"<p>You can pass options with the <code>docker run</code> command. For example, the following command uses UTF-8 as the default setting for character set and collation for all databases:</p> <pre><code>$ docker run -d \\\n --name ps \\\n -e MYSQL_ROOT_PASSWORD=root \\\n percona/percona-server:8.4 \\\n --character-set-server=utf8 \\\n --collation-server=utf8_general_ci\n</code></pre>"},{"location":"docker.html#accessing-the-percona-server-container","title":"Accessing the Percona Server Container","text":"<p>The <code>docker exec</code> command lets you have a shell inside the container. This command uses <code>it</code> which forwards your input stream as an interactive TTY. </p> <p>An example of accessing the detached container:</p> <pre><code>$ docker exec -it ps /bin/bash\n</code></pre> <p>If you need to troubleshoot, the error log is found in <code>/var/log/</code> or <code>/var/log/mysql/</code>. The file name may be error.log or mysqld.log. </p>"},{"location":"docker.html#troubleshooting","title":"Troubleshooting","text":"<p>You can view the error log with the following command:</p> <pre><code>[mysql@ps] $ more /var/log/mysql/error.log\n</code></pre> Expected output <pre><code>...\n2017-08-29T04:20:22.190474Z 0 [Warning] 'NO_ZERO_DATE', 'NO_ZERO_IN_DATE' and 'ERROR_FOR_DIVISION_BY_ZERO' sql modes should be used with strict mode. They will be merged with strict mode in a future release.\n2017-08-29T04:20:22.190520Z 0 [Warning] 'NO_AUTO_CREATE_USER' sql mode was not set.\n...\n</code></pre>"},{"location":"docker.html#accessing-the-database","title":"Accessing the database","text":"<p>You can access the database either with <code>Docker exec</code> or using the <code>mysql</code> command in the container\u2019s shell.</p> <p>An example of using <code>Docker exec</code> to access the database:</p> <pre><code>$ docker exec -ti ps mysql -uroot -proot\n</code></pre> Expected output <pre><code>mysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 9\n...\n</code></pre> <p>Exiting Percona Server also exits the container.</p> <p>You can also run the MySQL command-line client within the container\u2019s shell to access the database:</p> <pre><code>[mysql@ps] $ mysql -uroot -proot\n</code></pre> Expected output <pre><code>mysql: [Warning] Using a password on the command line interface can be insecure.\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 8\nServer version: 8.4.0-1 Percona Server (GPL), Release 21, Revision c59f87d2854\n\nCopyright (c) 2009-2022 Percona LLC and/or its affiliates\nCopyright (c) 2000, 2022, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n</code></pre>"},{"location":"docker.html#accessing-the-server-from-an-application-in-another-container","title":"Accessing the server from an application in another container","text":"<p>The image exposes the standard MySQL port 3306, so container linking makes the Percona Server instance available from other containers. To link a container running your application (in this case, from an image named <code>app/image</code>) with the Percona Server container, run it with the following command:</p> <pre><code>$ docker run -d \\\n  --name app \\\n  --link ps \\\n  app/image:latest\n</code></pre> <p>This application container will be able to access the Percona Server container via port 3306.</p>"},{"location":"docker.html#storing-data","title":"Storing data","text":"<p>There are two ways to store data used by applications that run in Docker containers:</p> <ul> <li> <p>Let Docker manage the storage of your data by writing the database files to disk on the host system using its internal volume management.</p> </li> <li> <p>Create a data directory on the host system on high-performance storage and mount it to a directory visible from the container. This method places the database files in a known location on the host system, and makes it easy for tools and applications on the host system to access the files. The user should ensure that the directory exists, that the user accounts have required permissions, and that any other security mechanisms on the host system are set up correctly.</p> </li> </ul> <p>For example, if you create a data directory on a suitable volume on your host system named <code>/local/datadir</code>, you run the container with the following command:</p> <pre><code>$ docker run -d \\\n  --name ps \\\n  -e MYSQL_ROOT_PASSWORD=root \\\n  -v /local/datadir:/var/lib/mysql \\\n  percona/percona-server:8.4\n</code></pre> <p>The <code>-v /local/datadir:/var/lib/mysql</code> option mounts the <code>/local/datadir</code> directory on the host to <code>/var/lib/mysql</code> in the container, which is the default data directory used by Percona Server for MySQL.</p> <p>Do not add MYSQL_ROOT_PASSWORD to the <code>docker run</code> command if the data directory contains subdirectories, files, or data.</p> <p>Note</p> <p>If you have SELinux enabled, assign the relevant policy type to the new data directory so that the container will be allowed to access it:</p> <pre><code>$ chcon -Rt svirt_sandbox_file_t /local/datadir\n</code></pre>"},{"location":"docker.html#port-forwarding","title":"Port forwarding","text":"<p>Docker allows mapping ports on the container to ports on the host system using the <code>-p</code> option. If you run the container with this option, you can connect to the database by connecting your client to a port on the host machine. This ability simplifies consolidating instances to a single host.</p> <p>To map the standard MySQL port 3306 to port 6603 on the host:</p> <pre><code>$ docker run -d \\\n --name ps \\\n -e MYSQL_ROOT_PASSWORD=root \\\n -p 6603:3306 \\\n percona/percona-server:8.4\n</code></pre>"},{"location":"docker.html#exiting-the-container","title":"Exiting the container","text":"<p>If you are in the interactive shell, use CTRL-D or exit to exit the session.</p> <p>If you have a non-shell process running, interrupt the process with <code>CTRL-C</code> before using either <code>CTRL-D</code> or <code>exit.</code></p>"},{"location":"docker.html#stopping-the-container","title":"Stopping the container","text":"<p>The docker stop container command sends a TERM signal, then waits 10 seconds and sends a KILL signal. The following example stops the <code>ps</code> container:</p> <pre><code>$ docker stop ps\n</code></pre> <p>The default length of time before stopping a container is 10 seconds. A very large instance cannot dump the data from memory to disk within that time. With this type of instance, add the <code>--time</code> or the <code>-t</code> option to docker stop:</p> <pre><code>$ docker stop ps -t 600\n</code></pre>"},{"location":"docker.html#removing-the-container","title":"Removing the container","text":"<p>To remove a stopped container, use the <code>docker rm</code> command.</p> <pre><code>$ docker rm ps\n</code></pre>"},{"location":"docker.html#for-more-information","title":"For more information","text":"<p>Review the Docker Docs</p> <p></p>"},{"location":"docker.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"downgrade.html","title":"Downgrade Percona Server for MySQL","text":"<p>Downgrading to a 5.7 or earlier series is not supported.</p> <p>The following table lists the downgrade paths:</p> Path Examples Methods Within a bugfix release series or an LTS release 8.0.35 to 8.0.34 in-place downgrade, logical downgrade, asynchronous replication, MySQL Clone plugin A bugfix or LTS release to the last bugfix or LTS release series 8.4.x to 8.0.x logical downgrade, asynchronous replication A bugfix or LTS release to an innovation release after the last LTS series 8.4.x to 8.3.0 logical downgrade, asynchronous replication An innovation release to another innovation release after the last LTS series 8.3.0 to 8.2.0 logical downgrade, asynchronous replication <p>We don\u2019t support downgrades with any 8.0.x release below 8.0.34. A releases in the range above 8.0.34 can be downgraded to any release within that range, including 8.0.34.</p>"},{"location":"downgrade.html#downgrading-risks","title":"Downgrading risks","text":"<p>Downgrading has the following risks:</p> Risk Description Data loss If the downgrade process has issues, you may lose your data. It is crucial that you back up your data before attempting to downgrade. Incompatibility If you use any feature or improvement in the latest version, downgrading could result in incompatibility issues. Performance Downgrading may result in a loss of performance Security Newer versions have security updates that are not available in the older versions, which could lead to exposure. <p></p>"},{"location":"downgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"download-instructions.html","title":"Percona Product Download Instructions","text":""},{"location":"download-instructions.html#select-the-software","title":"Select the software","text":"<p>Do the following steps to select the software:</p> <ol> <li>Open Percona Software Downloads</li> <li>Locate the Percona Software, for example, Percona Server for MySQL</li> <li>In <code>Select Product</code>, select the which product, for example, Percona Server 8.4</li> <li>In <code>Select Product Version</code>, select the version, for example, PERCONA-SERVER-8.4.0-1</li> <li>In <code>Select Software</code>, select the operating system, for example, DEBIAN GNU/LINUX 12.0 (\u201cBOOKWORM\u201d).</li> </ol> <p>The easiest method is to download all packages. </p> <p>The <code>Package Download Options</code> may mix <code>AMD64</code> and <code>ARM64</code> packages. Select the correct CPU architecture for your system.</p>"},{"location":"download-instructions.html#download-to-a-local-computer","title":"Download to a local computer","text":"<p>In <code>Package Download Options</code>, select a specific package or select the <code>DOWNLOAD ALL PACKAGES</code> button.</p> <p>The selected packages are downloaded to the local computer.</p>"},{"location":"download-instructions.html#download-to-another-computer","title":"Download to another computer","text":"<p>In <code>Package Download Options</code>, select a specific package or select the <code>DOWNLOAD ALL PACKAGES</code> button, and hover your cursor over the <code>DOWNLOAD</code> arrow. Right-click and in the drop-down menu, select <code>Copy Link</code>.</p> <p>Paste the link in your terminal to download the selected package.</p> <p></p>"},{"location":"download-instructions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-binary-relay-log-files.html","title":"Encrypt binary log files and relay log files","text":"<p>Encrypt the binary log files and the relay log files to protect them from unauthorized viewing. The encryption uses the Advanced Encryption Standard (AES) symmetric block cipher algorithm. Instead of bits, this algorithm works on bytes.</p> <p>Any supported encryption keyring plugin or component must be installed and configured to use encryption.</p> <p>Enabling binary log encryption at system start, the server generates a binary log encryption key before iniatializing the binary log and relay logs. The key encrypts a file password for each binary log, if binary logging is enabled, and relay log. Keys generated from the file passwords encrypt the data in the files.</p> <p>When used by the server, the binary log encryption key is called the binary log master key. This key can be rotated as needed and only the file password for each file is re-encrypted. </p> <p>The binary log index file and relay log index file is never encrypted. Relay log files are encrypted for all channels.</p> <p>To review if a binary log file is encrypted or not, use the <code>SHOW BINARY LOGS</code> statement.</p> <p>If the server is running, the <code>BINLOG_ENCRYPTION_ADMIN</code> privilege is required to enable or disable encryption.</p>"},{"location":"encrypt-binary-relay-log-files.html#binlog_encryption","title":"<code>binlog_encryption</code>","text":"Option Description Command-line <code>--binlog-encryption[= {ON \\| OFF}]</code> Scope Global Dynamic Yes Data type Boolean Default OFF <p>This system variable enables binary log file encryption and relay log file encryption on the server. The default value is <code>OFF</code>. You can enable encryption for relay log files on a replica without a binary log.</p> <p>If you set the <code>binlog_encryption</code> to <code>OFF</code>, the server immediately rotates the binary log file and relay log files and all logging is not encrypted. For any previously encrypted files, the server can still read them and they are not decrypted. </p> <p></p>"},{"location":"encrypt-binary-relay-log-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-doublewrite-file-pages.html","title":"Encrypt doublewrite file pages","text":"<p>InnoDB encrypts doublewrite file pages associated with encrypted tablespaces automatically. Doublewrite files can contain the following page types:</p> <ul> <li>Unencrypted</li> <li>Uncompressed</li> <li>Encrypted</li> <li>Compressed</li> </ul> <p></p>"},{"location":"encrypt-doublewrite-file-pages.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-file-per-table-tablespace.html","title":"Encrypt File-Per-Table Tablespace","text":"<p>The file_per_table tablespace inherits the default schema encryption setting. Use the <code>ENCRYPTION</code> clause in the  in <code>CREATE TABLE</code> statement to explicitly set the encryption.</p> <p><pre><code>mysql&gt; CREATE TABLE ... ENCRYPTION='Y';\n</code></pre> To change the encryption setting for an existing file_per_table tablespace, add the <code>ENCRYPTION</code> clause. The <code>ALTER TABLE</code> statement without the <code>ENCRYPTION</code> clause does not change the encryption state.</p> <pre><code>mysql&gt; ALTER TABLE ... ENCRYPTION='Y';\n</code></pre> <p>If the <code>table_encryption_privilege_check</code> is enabled, the <code>TABLE_ENCRYPTION_ADMIN</code> privilige is required to change the file_per_table encryption setting from the default schema encryption. </p> <p></p>"},{"location":"encrypt-file-per-table-tablespace.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-logs.html","title":"Log encryption","text":"<p>Describes the redo log encryption and the undo log encryption.</p>"},{"location":"encrypt-logs.html#redo-log-encryption","title":"Redo Log encryption","text":"<p>Use the <code>innodb_redo_log_encrypt</code> option to enable or disable redo log data encryption. By default, the encryption of the redo log is disabled.</p> <p>InnoDB uses the tablespace encryption key to encrypt the redo log data. If the encryption is enabled, when the server encrypts and writes the redo log data to the disk. When the server reads the redo log data from disk, the data is decrypted.</p> <p>Changing the encryption does not change existing redo log pages. Setting the option to <code>ON</code>, any existing redo log pages remain unencrypted; writing new pages to disk encrypts them. Setting the option to <code>OFF</code>, any existing encrypted pages remain encrypted; writing new pages to disk are unencrypted.</p> <p>The metadata for the redo log encryption includes the tablespace encryption key and is stored the in redo log file header. Removing the encryption metadata disables the redo log encryption.</p> <p>Without the keyring component or the encryption key, a normal restart is not possible. InnoDB scans the redo log pages during startup. If the encryption options are not available, InnoDB cannot scan these pages. A forced startup without the redo logs is possible.</p>"},{"location":"encrypt-logs.html#option","title":"Option","text":""},{"location":"encrypt-logs.html#innodb_redo_log_encrypt","title":"<code>innodb_redo_log_encrypt</code>","text":"Variable Description Command-line <code>--innodb-redo-log-encrypt[= {ON \\| OFF}]</code> Dynamic Yes Scope Global Data type Boolean Default OFF Option Description ON This option is a compatibility alias for the master_key. Any existing redo log pages remain unencrypted; new pages are encrypted when written to disk. OFF Any existing encrypted pages remain encrypted; new pages are unencrypted. <p>Determines the encryption for the table redo log data. The default option for the variable is <code>OFF</code>.</p>"},{"location":"encrypt-logs.html#undo-log-encryption","title":"Undo Log encryption","text":"<p>Use the <code>innodb_undo_log_encrypt</code> option to enable or disable undo log data encryption. By default, the option to encrypt the undo log data is disabled.</p> <p>InnoDB uses the tablespace encryption key to encrypt the undo log data. If the encryption is enabled, when the server encrypts and writes the undo log data to the disk. When the server reads the undo log data from disk, the data is decrypted.</p> <p>Changing the encryption does not change existing undo log pages. Setting the option to <code>ON</code>, any existing pages remain unencrypted; writing new pages to disk encrypts them. Setting the option to <code>OFF</code>, any existing encrypted pages remain encrypted; writing new pages to disk are unencrypted.</p> <p>The metadata for the redo log encryption includes the tablespace encryption key and is stored the in undo log file header.</p> <p>The server requires the keyring component used to encrypt log data until that data is truncated, even if the current option setting is <code>OFF</code>. When the undo tablespace is truncated, the encryption header is removed.</p>"},{"location":"encrypt-logs.html#innodb_undo_log_encrypt","title":"<code>innodb_undo_log_encrypt</code>","text":"Option Description Command-line <code>--innodb-undo-log-encrypt[= {ON \\| OFF}]</code> Scope Global Dynamic Yes Data type Boolean Default OFF <p>This system variable defines the encryption status for the undo log data. The default setting is <code>OFF</code>, which disables the encryption.</p> <p></p>"},{"location":"encrypt-logs.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-system-tablespace.html","title":"Encrypt system tablespace","text":"<p>By default, the system tablespace, which contains the system database and the data dictionary tables, is unencrypted. To change the encryption requires the <code>CREATE TABLESPACE</code> privilege on all tables in the instance.</p> <p>In an <code>ALTER TABLESPCE</code> statement, add the <code>ENCRYPTION</code> option with the tablespace name to enable encryption.</p> <p><pre><code>mysql&gt; ALTER TABLESPACE mysql ENCRYPTION='Y';\n</code></pre> Disable encryption by setting the <code>ENCRYPTION</code> option to \u2018N\u201d.</p> <pre><code>mysql&gt; ALTER TABLESPACE mysql ENCRYPTION='N';\n</code></pre> <p></p>"},{"location":"encrypt-system-tablespace.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-tablespaces.html","title":"Encrypt schema or general tablespace","text":"<p>Percona Server for MySQL uses the same encryption architecture as MySQL, a two-tier system consisting of a master key and tablespace keys. The master key can be changed, or rotated in the keyring, as needed. Each tablespace key, when decrypted, remains the same.</p> <p>The feature requires the keyring plugin.</p>"},{"location":"encrypt-tablespaces.html#set-the-default-for-schemas-and-general-tablespace-encryption","title":"Set the default for schemas and general tablespace encryption","text":"<p>The tables in a general tablespace are either all encrypted or all unencrypted. A tablespace cannot contain a mixture of encrypted tables and unencrypted tables.</p> <p>The encryption of a schema or a general tablespace is determined by the <code>default_table_encryption</code> variable unless you specify the ENCRYPTION clause in the CREATE SCHEMA or CREATE TABLESPACE statement.</p> <p>You can set the <code>default_table_encryption</code> variable in an individual connection.</p> <pre><code>mysql&gt; SET default_table_encryption=ON;\n</code></pre>"},{"location":"encrypt-tablespaces.html#default_table_encryption","title":"<code>default_table_encryption</code>","text":"Option Description Command-line default-table-encryption Scope Session Dynamic Yes Data type Text Default OFF <p>Defines the default encryption setting for schemas and general tablespaces. The variable allows you to create or alter schemas or tablespaces without specifying the ENCRYPTION clause. The default encryption setting applies only to schemas and general tablespaces and is not applied to the MySQL system tablespace.</p> <p>The variable has the following possible options:</p> Value Description <code>ON</code> New tables are encrypted. Add <code>ENCRYPTION=\"N\"</code> to the <code>CREATE TABLE</code> or <code>ALTER TABLE</code> statement to create unencrypted tables. <code>OFF</code> By default, new tables are unencrypted. Add <code>ENCRYPTION=\"Y\"</code> to the <code>CREATE TABLE</code> or <code>ALTER TABLE</code> statement to create encrypted tables. <p>Note</p> <p>The <code>ALTER TABLE</code> statement changes the current encryption mode only if you use the <code>ENCRYPTION</code> clause.</p>"},{"location":"encrypt-tablespaces.html#innodb_encrypt_online_alter_logs","title":"<code>innodb_encrypt_online_alter_logs</code>","text":"Option Description Command-line \u2013innodb-encrypt-online-alter-logs Scope Global Dynamic Yes Data type Boolean Default OFF <p>This variable simultaneously turns on the encryption of files used by InnoDB for full-text search using parallel sorting, building indexes using merge sort, and online DDL logs created by InnoDB for online DDL. Encryption is available for file merges used in queries and backend processes.</p>"},{"location":"encrypt-tablespaces.html#use-encryption","title":"Use ENCRYPTION","text":"<p>If you do not set the default encryption setting, you can create general tablespaces with the <code>ENCRYPTION</code> setting.</p> <pre><code>mysql&gt; CREATE TABLESPACE tablespace_name ENCRYPTION='Y';\n</code></pre> <p>All tables contained in the tablespace are either encrypted or not encrypted. You cannot encrypt only some of the tables in a general tablespace. This feature extends the  CREATE TABLESPACE statement to accept the <code>ENCRYPTION='Y/N'</code> option.</p> <p>The option is a tablespace attribute and is not allowed with the <code>CREATE TABLE</code> or <code>SHOW CREATE TABLE</code> statement except with file-per-table tablespaces.</p> <p>In an encrypted general tablespace, an attempt to create an unencrypted table generates the following error:</p> <pre><code>mysql&gt; CREATE TABLE t3 (a INT, b TEXT) TABLESPACE foo ENCRYPTION='N';\n</code></pre> Expected output <pre><code>ERROR 1478 (HY0000): InnoDB: Tablespace 'foo' can contain only ENCRYPTED tables.\n</code></pre> <p>The server diagnoses an attempt to create or move tables, including partitioned ones, to a general tablespace with an incompatible encryption setting and aborts the process.</p> <p>If you must move tables between incompatible tablespaces, create tables with the same structure in another tablespace and run <code>INSERT INTO SELECT</code> from each of the source tables into the destination tables.</p>"},{"location":"encrypt-tablespaces.html#export-an-encrypted-general-tablespace","title":"Export an encrypted general tablespace","text":"<p>You can only export encrypted file-per-table tablespaces</p> <p></p>"},{"location":"encrypt-tablespaces.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encrypt-temporary-files.html","title":"Encrypt temporary files","text":"<p>For InnoDB user-created temporary tables are created in a temporary tablespace file and use the <code>innodb_temp_tablespace_encrypt</code> variable.</p> <p>The <code>CREATE TEMPORARY TABLE</code> does not support the <code>ENCRYPTION</code> clause. The <code>TABLESPACE</code> clause cannot be set to <code>innodb_temporary</code>.</p> <p>The global temporary tablespace datafile <code>ibtmp1</code> contains the temporary table undo logs while intrinsic temporary tables and user-created temporary tables are located in the encrypted session temporary tablespace.</p> <p>To create new temporary tablespaces unencrypted, the following variables must be set to <code>OFF</code> at runtime:</p> <ul> <li> <p><code>innodb_temp_tablespace_encrypt</code></p> </li> <li> <p><code>default_table_encryption</code></p> </li> </ul> <p>Any existing encrypted user-created temporary files and intrinsic temporary tables remain in an encrypted session.</p> <p>Temporary tables are only destroyed when the session is disconnected.</p> <p>The <code>default_table_encryption</code> setting in my.cnf determines if a temporary table is encrypted.</p> <p>If the <code>innodb_temp_tablespace_encrypt</code> = \u201cOFF\u201d and the <code>default_table_encryption</code> =\u201dON\u201d, the user-created temporary tables are encrypted. The temporary tablespace data file <code>ibtmp1</code>, which contains undo logs, is not encrypted.</p> <p>If the <code>innodb_temp_tablespace_encrypt</code> is \u201cON\u201d for the system tablespace, InnoDB generates an encryption key and encrypts the system\u2019s temporary tablespace.  If you reset the encryption to \u201cOFF\u201d, all subsequent pages are written to an unencrypted tablespace. Any generated keys are not erased to allow encrypted tables and undo data to be decrypted.</p> <p>For each temporary file, an encryption key has the following attributes:</p> <ul> <li> <p>Generated locally</p> </li> <li> <p>Maintained in memory for the lifetime of the temporary file</p> </li> <li> <p>Discarded with the temporary file</p> </li> </ul>"},{"location":"encrypt-temporary-files.html#encrypt_tmp_files","title":"<code>encrypt_tmp_files</code>","text":"Option Description Command-line \u2013encrypt_tmp_files Scope Global Dynamic No Data type Boolean Default OFF <p>This variable turns \u201cON\u201d the encryption of temporary files created by the Percona Server for MySQL. The default value is <code>OFF</code>.</p>"},{"location":"encrypt-temporary-files.html#innodb_temp_tablespace_encrypt","title":"<code>innodb_temp_tablespace_encrypt</code>","text":"Option Description Command-line innodb-temp-tablespace-encrypt Scope Global Dynamic Yes Data type Boolean Default OFF <p>When this variable is set to <code>ON</code>, the server encrypts the global temporary tablespace and has the .ibtmp1 file extension and the session temporary tablespace and has the .ibt file extension. </p> <p>The variable does not enforce the encryption of currently open temporary files and does not rebuild the system\u2019s temporary tablespace to encrypt data that has already been written.</p> <p></p>"},{"location":"encrypt-temporary-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"encryption-functions.html","title":"Encryption functions","text":"<p>Percona Server for MySQL adds encryption functions and variables to manage the encryption range. The functions may take an algorithm argument. Encryption converts plaintext into ciphertext using a key and an encryption algorithm.</p> <p>You can also use the user-defined functions with the PEM format keys generated externally by the OpenSSL utility.</p> <p>A digest uses plaintext and generates a hash value. This hash value can verify if the plaintext is unmodified. You can also sign or verify on digests to ensure that the original plaintext was not modified. You cannot decrypt the original text from the hash value.</p> <p>When choosing key lengths, consider the following:</p> <ul> <li> <p>Encryption strength increases with the key size and, also, the key generation time.</p> </li> <li> <p>If performance is important and the functions are frequently used, use symmetric encryption. Symmetric encryption functions are faster than asymmetric encryption functions. Moreover, asymmetric encryption has restrictions on the maximum length of a message being encrypted. For example, for RSA the algorithm maximum message size is the key length in bytes (key length in bits / 8) minus 11.</p> </li> </ul> <p>The following table and sections describe the functions. For examples, see function examples.</p> Function Name asymmetric_decrypt(algorithm, crypt_str, key_str) asymmetric_derive(pub_key_str, priv_key_str) asymmetric_encrypt(algorithm, str, key_str) asymmetric_sign(algorithm, digest_str, priv_key_str, digest_type) asymmetric_verify(algorithm, digest_str, sig_str, pub_key_str, digest_type) create_asymmetric_priv_key(algorithm, (key_len | dh_parameters)) create_asymmetric_pub_key(algorithm, priv_key_str) create_dh_parameters(key_len) create_digest(digest_type, str) <p>The following table describes the Encryption threshold variables which can be used to set the maximum value for a key length based on the type of encryption.</p> Variable Name encryption_udf.dh_bits_threshold encryption_udf.dsa_bits_threshold encryption_udf.rsa_bits_threshold"},{"location":"encryption-functions.html#install-component_encryption_udf","title":"Install component_encryption_udf","text":"<p>Use the Install Component Statement to add the component_encryption_udf component. The functions and variables are available. The user-defined functions and the Encryption threshold variables are auto-registered. There is no requirement to invoke <code>CREATE FUNCTION ... SONAME ...</code>.</p> <p>The <code>INSERT</code> privilege on the <code>mysql.component</code> system table is required to run the <code>INSTALL COMPONENT</code> statement. To register the component, the operation adds a row to this table.</p> <p>The following is an example of the installation command:</p> <pre><code>mysql&gt; INSTALL COMPONENT 'file://component_encryption_udf';\n</code></pre> <p>Note</p> <p>If you are Compiling Percona Server for MySQL from Source, the Encryption UDF component is built by default when Percona Server for MySQL is built. Specify the <code>-DWITH_ENCRYPTION_UDF=OFF</code> cmake option to exclude it.</p>"},{"location":"encryption-functions.html#user-defined-functions-described","title":"User-defined functions described","text":""},{"location":"encryption-functions.html#asymmetric_decryptalgorithm-crypt_str-key_str","title":"asymmetric_decrypt(algorithm, crypt_str, key_str)","text":"<p>Decrypts an encrypted string using the algorithm and a key string.</p>"},{"location":"encryption-functions.html#returns","title":"Returns","text":"<p>A plaintext as a string.</p>"},{"location":"encryption-functions.html#parameters","title":"Parameters","text":"<p>The following are the function\u2019s parameters:</p> <ul> <li> <p>algorithm - the encryption algorithm supports RSA to decrypt the string.</p> </li> <li> <p>key_str - a string in the PEM format. The key string must have the following attributes:</p> </li> <li> <p>Valid</p> </li> <li> <p>Public or private key string that corresponds with the private or public key string used with the asymmetric_encrypt function.</p> </li> </ul>"},{"location":"encryption-functions.html#asymmetric_derivepub_key_str-priv_key_str","title":"asymmetric_derive(pub_key_str, priv_key_str)","text":"<p>Derives a symmetric key using a public key generated on one side and a private key generated on another.</p>"},{"location":"encryption-functions.html#asymmetric_derive-output","title":"asymmetric_derive output","text":"<p>A key as a binary string.</p>"},{"location":"encryption-functions.html#asymmetric_derive-parameters","title":"asymmetric_derive parameters","text":"<p>The <code>pub_key_str</code> must be a public key in the PEM format and generated using the Diffie-Hellman (DH) algorithm.</p> <p>The <code>priv_key_str</code> must be a private key in the PEM format and generated using the Diffie-Hellman (DH) algorithm.</p>"},{"location":"encryption-functions.html#asymmetric_encryptalgorithm-str-key_str","title":"asymmetric_encrypt(algorithm, str, key_str)","text":"<p>Encrypts a string using the algorithm and a key string.</p>"},{"location":"encryption-functions.html#asymmetric_encrypt-output","title":"asymmetric_encrypt output","text":"<p>A ciphertext as a binary string.</p>"},{"location":"encryption-functions.html#asymmetric_encrypt-parameters","title":"asymmetric_encrypt parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>algorithm - the encryption algorithm supports RSA to encrypt the string.</p> </li> <li> <p>str - measured in bytes. The length of the string must not be greater than the key_str modulus length in bytes - 11 (additional bytes used for PKCS1 padding)</p> </li> <li> <p>key_str - a key (either private or public) in the PEM format</p> </li> </ul>"},{"location":"encryption-functions.html#asymmetric_signalgorithm-digest_str-priv_key_str-digest_type","title":"asymmetric_sign(algorithm, digest_str, priv_key_str, digest_type)","text":"<p>Signs a digest string using a private key string.</p>"},{"location":"encryption-functions.html#asymmetric_sign-output","title":"asymmetric_sign output","text":"<p>A signature is a binary string.</p>"},{"location":"encryption-functions.html#asymmetric_sign-parameters","title":"asymmetric_sign parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>algorithm - the encryption algorithm supports either RSA or DSA to encrypt the string.</p> </li> <li> <p>digest_str - the digest binary string that is signed. Invoking create_digest generates the digest.</p> </li> <li> <p>priv_key_str - the private key used to sign the digest string. The key must be in the PEM format.</p> </li> <li> <p>digest_type - the OpenSSL version installed on your system determines the available hash functions. The following table lists these functions:</p> OpenSSL 1.0.2 OpenSSL 1.1.0 OpenSSL 1.1.1 OpenSSL 3.0.x md5 md5 md5 md5 sha1 sha1 sha1 sha1 sha224 sha224 sha224 sha224 sha384 sha384 sha384 sha384 sha512 sha512 sha512 sha512 md4 md4 md4 md4 sha md5-sha1 md5-sha1 md5-sha1 ripemd160 ripemd160 ripemd160 sha512-224 whirlpool whirlpool sha512-224 sha512-256 blake2b512 sha512-256 sha3-224 blake2s256 whirlpool sha3-256 sm3 sha3-384 blake2b512 sha3-512 blake2s256 sha3-224 sha3-384 sha3-512 shake128 shake256 </li> </ul>"},{"location":"encryption-functions.html#asymmetric_verifyalgorithm-digest_str-sig_str-pub_key_str-digest_type","title":"asymmetric_verify(algorithm, digest_str, sig_str, pub_key_str, digest_type)","text":"<p>Verifies whether the signature string matches the digest string.</p>"},{"location":"encryption-functions.html#asymmetric_verify-output","title":"asymmetric_verify output","text":"<p>A <code>1</code> (success) or a <code>0</code> (failure).</p>"},{"location":"encryption-functions.html#asymmetric_verify-parameters","title":"asymmetric_verify parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>algorithm - supports either \u2018RSA\u2019 or \u2018DSA\u2019.</p> </li> <li> <p>digest_str - invoking create_digest generates this digest binary string.</p> </li> <li> <p>sig_str - the signature binary string. Invoking asymmetric_sign generates this string.</p> </li> <li> <p>pub_key_str - the signer\u2019s public key string. This string must correspond to the private key passed to asymmetric_sign to generate the signature string. The string must be in the PEM format.</p> </li> <li> <p>digest_type - the supported values are listed in the digest type table of create_digest</p> </li> </ul>"},{"location":"encryption-functions.html#create_asymmetric_priv_keyalgorithm-key_len-dh_parameters","title":"create_asymmetric_priv_key(algorithm, (key_len | dh_parameters))","text":"<p>Generates a private key using the given algorithm and key length for RSA or DSA or Diffie-Hellman parameters for DH. For RSA or DSA, if needed, execute <code>KILL [QUERY|CONNECTION] &lt;id&gt;</code> to terminate a long-lasting key generation. The DH key generation from existing parameters is a quick operation. Therefore, it does not make sense to terminate that operation with <code>KILL</code>.</p>"},{"location":"encryption-functions.html#create_asymmetric_priv_key-output","title":"create_asymmetric_priv_key output","text":"<p>The key as a string in the PEM format.</p>"},{"location":"encryption-functions.html#create_asymmetric_priv_key-parameters","title":"create_asymmetric_priv_key parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>algorithm - the supported values are \u2018RSA\u2019, \u2018DSA\u2019, or \u2018DH\u2019.</p> </li> <li> <p>key_len - the supported key length values are the following:</p> <ul> <li> <p>RSA - the minimum length is 1,024. The maximum length is 16,384.</p> </li> <li> <p>DSA - the minimum length is 1,024. The maximum length is 9,984.</p> </li> </ul> <p>Note</p> <p>The key length limits are defined by OpenSSL. To change the maximum key length, use either encryption_udf.rsa_bits_threshold or encryption_udf.dsa_bits_threshold.</p> </li> <li> <p>dh_parameters - Diffie-Hellman (DH) parameters. Invoking create_dh_parameter creates the DH parameters.</p> </li> </ul>"},{"location":"encryption-functions.html#create_asymmetric_pub_keyalgorithm-priv_key_str","title":"create_asymmetric_pub_key(algorithm, priv_key_str)","text":"<p>Derives a public key from the given private key using the given algorithm.</p>"},{"location":"encryption-functions.html#create_asymmetric_pub_key-output","title":"create_asymmetric_pub_key output","text":"<p>The key as a string in the PEM format.</p>"},{"location":"encryption-functions.html#create_asymmetric_pub_key-parameters","title":"create_asymmetric_pub_key parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>algorithm - the supported values are \u2018RSA\u2019, \u2018DSA\u2019, or \u2018DH\u2019.</p> </li> <li> <p>priv_key_str - must be a valid key string in the PEM format.</p> </li> </ul>"},{"location":"encryption-functions.html#create_dh_parameterskey_len","title":"create_dh_parameters(key_len)","text":"<p>Creates parameters for generating a Diffie-Hellman (DH) private/public key pair. If needed, execute <code>KILL [QUERY|CONNECTION] &lt;id&gt;</code> to terminate the generation of long-lasting parameters.</p> <p>Generating the DH parameters can take more time than generating the RSA keys or the DSA keys. OpenSSL defines the parameter length limits. To change the maximum parameter length, use encryption_udf.dh_bits_threshold.</p>"},{"location":"encryption-functions.html#create_dh_parameters-output","title":"create_dh_parameters output","text":"<p>A string in the PEM format and can be passed to create_asymmetric_private_key.</p>"},{"location":"encryption-functions.html#create_dh_parameters-parameters","title":"create_dh_parameters parameters","text":"<p>The parameters are the following:</p> <ul> <li>key_len - the range for the key length is from 1024 to 10,000. The default value is 10,000.</li> </ul>"},{"location":"encryption-functions.html#create_digestdigest_type-str","title":"create_digest(digest_type, str)","text":"<p>Creates a digest from the given string using the given digest type. The digest string can be used with asymmetric_sign and asymmetric_verify.</p>"},{"location":"encryption-functions.html#create_digest-output","title":"create_digest output","text":"<p>The digest of the given string as a binary string</p>"},{"location":"encryption-functions.html#create_digest-parameters","title":"create_digest parameters","text":"<p>The parameters are the following:</p> <ul> <li> <p>digest_type - the OpenSSL version installed on your system determines the available hash functions. The following table lists these functions:</p> OpenSSL 1.0.2 OpenSSL 1.1.0 OpenSSL 1.1.1 OpenSSL 3.0.x md5 md5 md5 md5 sha1 sha1 sha1 sha1 sha224 sha224 sha224 sha224 sha384 sha384 sha384 sha384 sha512 sha512 sha512 sha512 md4 md4 md4 md4 sha md5-sha1 md5-sha1 md5-sha1 ripemd160 ripemd160 ripemd160 sha512-224 whirlpool whirlpool sha512-224 sha512-256 blake2b512 sha512-256 sha3-224 blake2s256 whirlpool sha3-256 sm3 sha3-384 blake2b512 sha3-512 blake2s256 sm3 sha3-224 blake2b512 sha3-384 blake2s256 sha3-512 blake2b512 shake128 blake2s256 shake256 </li> <li> <p>str - String used to generate the digest string.</p> </li> </ul>"},{"location":"encryption-functions.html#encryption-threshold-variables","title":"Encryption threshold variables","text":"<p>The maximum key length limits are defined by OpenSSL. Server administrators can limit the maximum key length using the encryption threshold variables.</p> <p>The variables are automatically registered when component_encryption_udf is installed.</p> Variable Name encryption_udf.dh_bits_threshold"},{"location":"encryption-functions.html#encryption_udfdh_bits_threshold","title":"<code>encryption_udf.dh_bits_threshold</code>","text":"<p>The variable sets the maximum limit for the create_dh_parameters user-defined function and takes precedence over the OpenSSL maximum length value.</p> Option Description command-line Yes scope Global data type unsigned integer default 10000 <p>The range for this variable is from 1024 to 10,000. The default value is 10,000.</p>"},{"location":"encryption-functions.html#encryption_udfdsa_bits_threshold","title":"encryption_udf.dsa_bits_threshold","text":"<p>The variable sets the threshold limits for create_asymmetric_priv_key user-defined function when the function is invoked with the DSA parameter and takes precedence over the OpenSSL maximum length value.</p> Option Description command-line Yes scope Global data type unsigned integer default 9984 <p>The range for this variable is from 1,024 to 9,984. The default value is 9,984.</p>"},{"location":"encryption-functions.html#encryption_udfrsa_bits_threshold","title":"encryption_udf.rsa_bits_threshold","text":"<p>The variable sets the threshold limits for the create_asymmetric_priv_key user-defined function when the function is invoked with the RSA parameter and takes precedence over the OpenSSL maximum length value.</p> Option Description command-line Yes scope Global data type unsigned integer default 16384 <p>The range for this variable is from 1,024 to 16,384. The default value is 16,384.</p>"},{"location":"encryption-functions.html#examples","title":"Examples","text":"<p>Code examples for the following operations:</p> <ul> <li> <p>set the threshold variables</p> </li> <li> <p>create a private key</p> </li> <li> <p>create a public key</p> </li> <li> <p>encrypt data</p> </li> <li> <p>decrypt data</p> </li> </ul> <pre><code>-- Set Global variable\nmysql&gt; SET GLOBAL encryption_udf.dh_bits_threshold = 4096;\n\n-- Set Global variable\nmysql&gt; SET GLOBAL encryption_udf.rsa_bits_threshold = 4096;\n</code></pre> <pre><code>-- Create private key\nmysql&gt; SET @private_key = create_asymmetric_priv_key('RSA', 3072);\n\n-- Create public key\nmysql&gt; SET @public_key = create_asymmetric_pub_key('RSA', @private_key);\n\n-- Encrypt data using the private key (you can also use the public key)\nmysql&gt; SET @ciphertext = asymmetric_encrypt('RSA', 'This text is secret', @private_key);\n\n-- Decrypt data using the public key (you can also use the private key)\n-- The decrypted value @plaintext should be identical to the original 'This text is secret'\nmysql&gt; SET @plaintext = asymmetric_decrypt('RSA', @ciphertext, @public_key);\n</code></pre> <p>Code examples for the following operations:</p> <ul> <li> <p>generate a digest string</p> </li> <li> <p>generate a digest signature</p> </li> <li> <p>verify the signature against the digest</p> </li> </ul> <pre><code>-- Generate a digest string\nmysql&gt; SET @digest = create_digest('SHA256', 'This is the text for digest');\n\n-- Generate a digest signature\nmysql&gt; SET @signature = asymmetric_sign('RSA', @digest, @private_key, 'SHA256');\n\n-- Verify the signature against the digest\n-- The @verify_signature must be equal to 1\nmysql&gt; SET @verify_signature = asymmetric_verify('RSA', @digest, @signature, @public_key, 'SHA256');\n</code></pre> <p>Code examples for the following operations:</p> <ul> <li> <p>generate a DH parameter</p> </li> <li> <p>generates two DH key pairs</p> </li> <li> <p>generate a symmetric key using the public_1 and the private_2</p> </li> <li> <p>generate a symmetric key using the public_2 and the private_1</p> </li> </ul> <pre><code> -- Generate a DH parameter\n mysql&gt; SET @dh_parameter = create_dh_parameters(3072);\n\n -- Generate DH key pairs\n mysql&gt; SET @private_1 = create_asymmetric_priv_key('DH', @dh_parameter);\n mysql&gt; SET @public_1 = create_asymmetric_pub_key('DH', @private_1);\n mysql&gt; SET @private_2 = create_asymmetric_priv_key('DH', @dh_parameter);\n mysql&gt; SET @public_2 = create_asymmetric_pub_key('DH', @private_2);\n\n-- Generate a symmetric key using the public_1 and private_2\n-- The @symmetric_1 must be identical to @symmetric_2\nmysql&gt; SET symmetric_1 = asymmetric_derive(@public_1, @private_2);\n\n-- Generate a symmetric key using the public_2 and private_1\n-- The @symmetric_2 must be identical to @symmetric_1\nmysql&gt; SET symmetric_2 = asymmetric_derive(@public_2, @private_1);\n</code></pre> <p>Code examples for the following operations:</p> <ul> <li> <p>create a private key using a <code>SET</code> statement</p> </li> <li> <p>create a private key using a  <code>SELECT</code> statement</p> </li> <li> <p>create a private key using an <code>INSERT</code> statement</p> </li> </ul> <pre><code>mysql&gt; SET @private_key1 = create_asymmetric_priv_key('RSA', 3072);\nmysql&gt; SELECT create_asymmetric_priv_key('RSA', 3072) INTO @private_key2;\nmysql&gt; INSERT INTO key_table VALUES(create_asymmetric_priv_key('RSA', 3072));\n</code></pre>"},{"location":"encryption-functions.html#uninstall-component_encryption_udf","title":"Uninstall component_encryption_udf","text":"<p>You can deactivate and uninstall the component using the Uninstall Component statement.</p> <pre><code>mysql&gt; UNINSTALL COMPONENT 'file://component_encryption_udf';\n</code></pre> <p></p>"},{"location":"encryption-functions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"enforce-engine.html","title":"Enforcing storage engine","text":"<p>Percona Server for MySQL implements a variable to enforce the use of a specific storage engine.</p> <p>When this variable is specified and a user tries to create a table using an explicit storage engine that is not the specified enforced engine, the user will get either an error if the <code>NO_ENGINE_SUBSTITUTION</code> SQL mode is enabled or a warning if <code>NO_ENGINE_SUBSTITUTION</code> is disabled and the table will be created anyway using the enforced engine (this is consistent with the default MySQL way of creating the default storage engine if other engines are not available unless <code>NO_ENGINE_SUBSTITUTION</code> is set).</p> <p>In case user tries to enable enforce_storage_engine with engine that isn\u2019t available, system will not start.</p> <p>Note</p> <p>If you\u2019re using enforce_storage_engine, you must either disable it before doing <code>mysql_upgrade</code> or perform <code>mysql_upgrade</code> with server started with <code>--skip-grants-tables</code>.</p>"},{"location":"enforce-engine.html#system-variables","title":"System variables","text":""},{"location":"enforce-engine.html#enforce_storage_engine","title":"<code>enforce_storage_engine</code>","text":"Option Description Command Line: Yes Config file Yes Scope: Global Dynamic: No Data type String Default value NULL <p>This variable is not case sensitive.</p>"},{"location":"enforce-engine.html#example","title":"Example","text":"<p>Adding following option to my.cnf will start the server with InnoDB as enforced storage engine.</p> <pre><code>enforce_storage_engine=InnoDB\n</code></pre> <p></p>"},{"location":"enforce-engine.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"extended-mysqldump.html","title":"Extended mysqldump","text":""},{"location":"extended-mysqldump.html#backup-locks-support","title":"Backup locks support","text":"<p>When used together with the <code>\u2013single-transaction</code> option, the lock-for-backup option makes <code>mysqldump</code> issue <code>LOCK TABLES FOR BACKUP</code> before starting the dump operation to prevent unsafe statements that would normally result in an inconsistent backup.</p> <p>More information can be found in Backup Locks.</p>"},{"location":"extended-mysqldump.html#compressed-columns-support","title":"Compressed columns support","text":"<p>mysqldump supports the Compressed columns with dictionaries feature. </p> <p>More information can be found in Compressed columns with dictionaries.</p>"},{"location":"extended-mysqldump.html#taking-backup-by-descending-primary-key-order","title":"Taking backup by descending primary key order","text":"<p>\u2013order-by-primary-desc tells <code>mysqldump</code> to take the backup by descending primary key order (<code>PRIMARY KEY DESC</code>) which can be useful if the storage engine is using the reverse order column for a primary key.</p>"},{"location":"extended-mysqldump.html#rocksdb-support","title":"RocksDB support","text":"<p>mysqldump detects when MyRocks is installed and available. If there is a session variable named <code>rocksdb_skip_fill_cache</code>, mysqldump sets the variable to 1.</p> <p>mysqldump automatically enables <code>rocksdb_bulk_load</code> if the the target server supports the variable.</p> <p></p>"},{"location":"extended-mysqldump.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"extended-select-into-outfile.html","title":"Extended SELECT INTO OUTFILE/DUMPFILE","text":"<p>Percona Server for MySQL extends the <code>SELECT INTO ... OUTFILE</code> and <code>SELECT INTO DUMPFILE</code> commands to add support for UNIX sockets and named pipes. Before this was implemented the database would return an error for such files.</p> <p>This feature allows using <code>LOAD DATA LOCAL INFILE</code> in combination with <code>SELECT INTO OUTFILE</code> to quickly load multiple partitions across the network or in other setups, without having to use an intermediate file that wastes space and I/O.</p> <p></p>"},{"location":"extended-select-into-outfile.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"extended-set-var.html","title":"Extended SET VAR optimizer hint","text":"<p>Percona Server for MySQL extends the <code>SET_VAR</code> introduced in MySQL 8.4 effectively replacing the <code>SET STATEMENT ... FOR</code> statement. <code>SET_VAR</code> is an optimizer hint that can be applied to session variables.</p> <p>Percona Server for MySQL 8.4 extends the <code>SET_VAR</code> hint to support the following:</p> <ul> <li> <p>The <code>OPTIMIZE TABLE</code> statement</p> </li> <li> <p>MyISAM session variables</p> </li> <li> <p>Plugin or Storage Engine variables</p> </li> <li> <p>InnoDB Session variables</p> </li> <li> <p>The <code>ALTER TABLE</code> statement</p> </li> <li> <p><code>CALL stored_proc()</code> statement</p> </li> <li> <p>The <code>ANALYZE TABLE</code> statement</p> </li> <li> <p>The <code>CHECK TABLE</code> statement</p> </li> <li> <p>The <code>LOAD INDEX</code> statement (used for MyISAM)</p> </li> <li> <p>The <code>CREATE TABLE</code> statement</p> </li> </ul> <p>Percona Server for MySQL also supports setting the following variables by using <code>SET_VAR</code>:</p> <p></p>"},{"location":"extended-set-var.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"extended-show-grants.html","title":"Extended SHOW GRANTS","text":"<p>In Oracle MySQL <code>SHOW GRANTS</code> displays only the privileges granted explicitly to the named account. Other privileges might be available to the account, but they are not displayed. For example, if an anonymous account exists, the named account might be able to use its privileges, but <code>SHOW GRANTS</code> will not display them. Percona Server for MySQL offers the <code>SHOW EFFECTIVE GRANTS</code> command to display all the effectively available privileges to the account, including those granted to a different account.</p>"},{"location":"extended-show-grants.html#example","title":"Example","text":"<p>If we create the following users:</p> <pre><code>mysql&gt; CREATE USER grantee@localhost IDENTIFIED BY 'grantee1';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.50 sec)\n</code></pre> <pre><code>mysql&gt; CREATE USER grantee IDENTIFIED BY 'grantee2';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.09 sec)\n</code></pre> <pre><code>mysql&gt; CREATE DATABASE db2;\n</code></pre> Expected output <pre><code>Query OK, 1 row affected (0.20 sec)\n</code></pre> <pre><code>mysql&gt; GRANT ALL PRIVILEGES ON db2.* TO grantee WITH GRANT OPTION;\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.12 sec)\n</code></pre> <ul> <li><code>SHOW EFFECTIVE GRANTS</code> output before the change:</li> </ul> <pre><code>mysql&gt; SHOW EFFECTIVE GRANTS;\n</code></pre> Expected output <pre><code>+----------------------------------------------------------------------------------------------------------------+\n| Grants for grantee@localhost                                                                                   |\n+----------------------------------------------------------------------------------------------------------------+\n| GRANT USAGE ON *.* TO 'grantee'@'localhost' IDENTIFIED BY PASSWORD '*9823FF338D44DAF02422CF24DD1F879FB4F6B232' |\n+----------------------------------------------------------------------------------------------------------------+\n1 row in set (0.04 sec)\n</code></pre> <p>Although the grant for the <code>db2</code> database isn\u2019t shown, <code>grantee</code> user has enough privileges to create the table in that database:</p> <pre><code>user@trusty:~$ mysql -ugrantee -pgrantee1 -h localhost\n</code></pre> <pre><code>mysql&gt; CREATE TABLE db2.t1(a int);\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (1.21 sec)\n</code></pre> <ul> <li>The output of <code>SHOW EFFECTIVE GRANTS</code> after the change shows all the privileges for the <code>grantee</code> user:</li> </ul> <pre><code>mysql&gt; SHOW EFFECTIVE GRANTS;\n</code></pre> Expected output <pre><code>+-------------------------------------------------------------------+\n| Grants for grantee@localhost                                      |\n+-------------------------------------------------------------------+\n| GRANT USAGE ON *.* TO 'grantee'@'localhost' IDENTIFIED BY PASSWORD|\n| '*9823FF338D44DAF02422CF24DD1F879FB4F6B232'                       |\n| GRANT ALL PRIVILEGES ON `db2`.* TO 'grantee'@'%' WITH GRANT OPTION|\n+-------------------------------------------------------------------+\n2 rows in set (0.00 sec)\n</code></pre>"},{"location":"extended-show-grants.html#other-reading","title":"Other reading","text":"<ul> <li>#53645 - <code>SHOW GRANTS</code> not displaying all the applicable grants</li> </ul>"},{"location":"extended-show-grants.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"faq.html","title":"Frequently asked questions","text":""},{"location":"faq.html#q-will-percona-server-for-mysql-with-xtradb-invalidate-our-mysql-support","title":"Q: Will Percona Server for MySQL with XtraDB invalidate our MySQL support?","text":"<p>A: We don\u2019t know the details of your support contract. You should check with your Oracle representative. We have heard anecdotal stories from MySQL Support team members that they have customers who use Percona Server for MySQL with XtraDB, but you should not base your decision on that.</p>"},{"location":"faq.html#q-will-we-have-to-gpl-our-whole-application-if-we-use-percona-server-for-mysql-with-xtradb","title":"Q: Will we have to GPL our whole application if we use Percona Server for MySQL with XtraDB?","text":"<p>A: This is a common misconception about the GPL. We suggest reading the Free Software Foundation \u2018s excellent reference material on the GPL Version 2, which is the license that applies to MySQL and therefore to Percona Server for MySQL with XtraDB. That document contains links to many other documents which should answer your questions. Percona is unable to give legal advice about the GPL.</p>"},{"location":"faq.html#q-do-i-need-to-install-percona-client-libraries","title":"Q: Do I need to install Percona client libraries?","text":"<p>A: No, you don\u2019t need to change anything on the clients. Percona Server for MySQL is 100% compatible with all existing client libraries and connectors.</p>"},{"location":"faq.html#q-when-using-the-percona-xtrabackup-to-set-up-a-replication-replica-on-debian-based-systems-im-getting-error-1045-28000-access-denied-for-user-debian-sys-maintlocalhost-using-password-yes","title":"Q: When using the Percona XtraBackup to set up a replication replica on Debian-based systems I\u2019m getting: \u201cERROR 1045 (28000): Access denied for user \u2018debian-sys-maint\u2019@\u2019localhost\u2019 (using password: YES)\u201d","text":"<p>A: In case you\u2019re using the init script on Debian-based system to start <code>mysqld</code>, be sure that the password for <code>debian-sys-maint</code> user has been updated and it\u2019s the same as that user\u2019s password from the server that the backup has been taken from. The password can be seen and updated in <code>/etc/mysql/debian.cnf</code>. For more information on how to set up a replication replica using Percona XtraBackup see this how-to.</p> <p></p>"},{"location":"faq.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"feature-comparison.html","title":"Feature comparison","text":""},{"location":"feature-comparison.html#percona-server-for-mysql-feature-comparison","title":"Percona Server for MySQL feature comparison","text":"<p>Percona Server for MySQL is a free, fully compatible, enhanced, and open source drop-in replacement for any MySQL database. It provides superior performance, scalability, and instrumentation.</p> <p>Percona Server for MySQL is trusted by thousands of enterprises to provide better performance and concurrency for their most demanding workloads. It delivers higher value to MySQL server users with optimized performance, greater performance scalability and availability, enhanced backups, and increased visibility.</p> <p>We provide these benefits by significantly enhancing Percona Server for MySQL as compared to the standard MySQL database server:</p> Features Percona Server for MySQL 8.4 MySQL 8.4 Open Source Yes Yes ACID Compliance Yes Yes Multi-Version Concurrency Control Yes Yes Row-Level Locking Yes Yes Automatic Crash Recovery Yes Yes Table Partitioning Yes Yes Views Yes Yes Subqueries Yes Yes Triggers Yes Yes Stored Procedures Yes Yes Foreign Keys Yes Yes Window Functions Yes Yes Common Table Expressions Yes Yes Geospatial Features (GIS, SRS) Yes Yes GTID Replication Yes Yes Group Replication Yes Yes MyRocks Storage Engine Yes No Improvements for Developers Percona Server for MySQL 8.4 MySQL 8.4 NoSQL Socket-Level Interface Yes Yes X API Support Yes Yes JSON Functions Yes Yes InnoDB Full-Text Search Improvements Yes No Extra Hash/Digest Functions Yes No Instrumentation and Troubleshooting Features Percona Server for MySQL 8.4 MySQL 8.4 INFORMATION_SCHEMA Tables 95 65 Global Performance and Status Counters 853 434 Optimizer Histograms Yes Yes Per-Table Performance Counters Yes No Per-Index Performance Counters Yes No Per-User Performance Counters Yes No Per-Client Performance Counters Yes No Per-Thread Performance Counters Yes No Global Query Response Time Statistics Yes No Enhanced SHOW INNODB ENGINE STATUS Yes No Undo Segment Information Yes No Temporary Tables Information Yes No Extended Slow Query Logging Yes No User Statistics Yes No Performance and Scalability Features Percona Server for MySQL 8.4 MySQL 8.4 InnoDB Resource Groups Yes Yes Configurable Page Sizes Yes Yes Contention-Aware Transaction Scheduling Yes Yes Improved Scalability By Splitting Mutexes Yes No Improved MEMORY Storage Engine Yes No Improved Flushing Yes No Parallel Doublewrite Buffer Yes Yes Configurable Fast Index Creation Yes No Per-Column Compression for VARCHAR/BLOB and JSON Yes No Compressed Columns with Dictionaries Yes No Security Features Percona Server for MySQL 8.4 MySQL 8.4 SQL Roles Yes Yes SHA-2 Based Password Hashing Yes Yes Password Rotation Policy Yes Yes PAM Authentication Plugin Yes Enterprise-Only Encryption Features Percona Server for MySQL 8.4 MySQL 8.4 Storing Keyring in a File Yes Yes Storing Keyring in Hashicorp Vault Yes Enterprise Only Encrypt InnoDB Data Yes Yes Encrypt InnoDB Logs Yes Yes Encrypt Built-In InnoDB Tablespaces (General, System, Undo, Temp) Yes Yes Encrypt Binary Logs Yes No Encrypt Temporary Files Yes No Enforce Encryption Yes No Operational Improvements Percona Server for MySQL 8.4 MySQL 8.4 Atomic DDL Yes Yes Transactional Data Dictionary Yes Yes Instant DDL Yes Yes SET PERSIST Yes Yes Invisible Indexes Yes Yes Threadpool Yes Enterprise-Only Backup Locks Yes No Extended SHOW GRANTS Yes No Improved Handling of Corrupted Tables Yes No Ability to Kill Idle Transactions Yes No Improvements to START TRANSACTION WITH CONSISTENT SNAPSHOT Yes No Features for Running Database as a Service (DBaaS) Percona Server for MySQL 8.4 MySQL 8.4 Enforce a Specific Storage Engine Yes Yes <p></p>"},{"location":"feature-comparison.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"fido-authentication-plugin.html","title":"FIDO authentication plugin","text":"<p>Percona Server for MySQL supports the Fast Identify Online (FIDO) authentication method that uses a plugin. The FIDO authentication provides a set of standards that reduces the reliance on passwords.</p> <p>The server-side fido authentication plugin enables authentication using external devices. If this plugin is the only authentication plugin used by the account, this plugin allows authentication without a password. Multi-factor authentication can use non-FIDO MySQL authentication methods, the FIDO authentication method, or a combination of both. </p> <p>All distributions include the client-side <code>authentication_fido_client</code> plugin. This plugin allows clients to connect to accounts that use <code>authentication_fido</code> and authenticate on a server that has that plugin loaded.</p>"},{"location":"fido-authentication-plugin.html#plugin-and-library-file-names","title":"Plugin and library file names","text":"<p>The plugin and library file names are listed in the following table. </p> Plugin or file name Plugin or library file name Server-side plugin <code>authentication_fido</code> Client-side plugin <code>authentication_fido_client</code> Library file authentication_fido.so"},{"location":"fido-authentication-plugin.html#install-the-fido-authentication-plugin","title":"Install the FIDO authentication plugin","text":"<p>The library file must be stored in the directory named by the [<code>plugin_dir</code>] variable. </p> At server startupEdit my.cnf and restart the serverLoad the plugin at runtime <p>At server startup, use the [<code>--plugin_load_add</code>] option with the library name. The option must be added each time the server starts.</p> <pre><code>[mysqld]\n...\nplugin-load-add=authentication_fido.so\n...\n</code></pre> <pre><code>mysql&gt; INSTALL PLUGIN authentication_fido SONAME `authentication_fido.so`;\n</code></pre>"},{"location":"fido-authentication-plugin.html#verify-installation","title":"Verify installation","text":"<p>Use the [<code>SHOW PLUGINS</code>] statement or query the <code>INFORMATION_SCHEMA.PLUGINS</code> table to verify that the plugin was loaded successfully and is active.</p> <p>Check the server error log if the plugin is not loaded.</p>"},{"location":"fido-authentication-plugin.html#fido-authentication-strategies","title":"FIDO authentication strategies","text":"<p>FIDO can be used with non-FIDO authentication. FIDO can be used to create 1FA accounts that do not require passwords.</p>"},{"location":"fido-authentication-plugin.html#use-fido-authentication-with-non-fido-authentication","title":"Use FIDO authentication with non-FIDO authentication","text":"<p>A FIDO device is associated with the account using FIDO authentication. The FIDO device must be registered before the account can be used in a one-time process. This device must be available and the user must perform whatever FIDO device action required, such as adding a thumbprint, or the registration fails.</p> <p>The registration can only be performed by the user named by the account. An error occurs if a user attempts the registration for another user. </p> <p>The device registration can be performed on the mysql client or MySQL Shell.  Use the <code>--fido-register-factor</code> option with the factor or factors for the device. For example, if you are using FIDO as a second authentication method, which is a common practice, the statement is <code>--fido-register-factor=2</code>. </p> <p>Any authentication factors that proceed the FIDO registration must succeed before the registration continues.</p> <p>The server checks the user account information to determine if the FIDO device requires registration. If the device must be registered, the server switches the client session to sandbox mode. The registration must be completed before any other activity. In this mode, only <code>ALTER USER</code> statements are permitted. If the session is started with <code>--fido-register-factor</code>, the client generates the statements required to register. After the registration is complete, the session is switched out of sandbox mode and the client can proceed as normal.</p> <p>After the device is registered, the server updates the <code>mysql.user</code> system table for that account with the device registration status and stores the public key and credential ID.</p> <p>The user must use the same FIDO device during registration and authentication. If the device is reset or the user attempts to use a different device, the authentication fails. To use a different device, the registered device must be unregistered and you must complete the registration process again.</p>"},{"location":"fido-authentication-plugin.html#use-fido-authentication-as-the-only-method","title":"Use FIDO authentication as the only method","text":"<p>If FIDO is used as the only method of authentication, the method does not use a password. The authentication uses a method such as a biometric scan or a security key.</p> <p>The user creates an account with the <code>PASSWORDLESS_USER_ADMIN</code> privilege and the <code>CREATE USER</code> privilege. </p> <p>The first element of the <code>authentication_policy</code> value must be an asterisk(*). Do not start with the plugin name. [Configuring the <code>authentication policy</code> value] has more information.</p> <p>You must include the <code>INITIAL AUTHENTICATION IDENTIFIED BY</code> clause in the <code>CREATE USER</code> statement. The server does accept the statement without the clause but the account is unusable because the user cannot connect to the server to register the device. </p> <p>The <code>CREATE USER</code> syntax is the following:</p> <pre><code>mysql&gt; CREATE USER &lt;username&gt;@&lt;hostname&gt; IDENTIFIED WITH authentication_fido INITIAL AUTHENTICATION IDENTIFIED BY '&lt;password&gt;';\n</code></pre> <p>During registration, the user must authenticate with the password. After the device is registered, the server deletes the password and modifies the account to make FIDO the only authentication method. </p>"},{"location":"fido-authentication-plugin.html#unregister-a-fido-device","title":"Unregister a FIDO device","text":"<p>If the FIDO device is replaced or lost, the following actions occur:</p> Action required Who can perform the action Unregister the previous device The account owner or any user with the <code>CREATE USER</code> privilege can unregister the device Register the new device The user planning to use the device must register the new device <p>Unregister a device with the following statement:</p> <pre><code>mysql&gt; ALTER USER `username`@`hostname` {2|3} FACTOR UNREGISTER;\n</code></pre> <p></p>"},{"location":"fido-authentication-plugin.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"filter-audit-log-filter-files.html","title":"Filter the Audit Log Filter logs","text":"<p>The audit filter log filtering is based on rules. The filter rule definition has the ability to include or exclude events based on the following attributes:</p> <ul> <li>User account</li> <li>Audit event class</li> <li>Audit event subclass</li> <li>Audit event fields (for example, <code>COMMAND_CLASS</code> or <code>STATUS</code>)</li> </ul> <p>You can define multiple filters and assign any filter to multiple accounts. You can also create a default filter for specific user accounts. The filters are defined using function calls. After the filter is defined, the filter is stored in <code>mysql</code> system tables. </p>"},{"location":"filter-audit-log-filter-files.html#audit-log-filter-functions","title":"Audit Log Filter functions","text":"<p>The Audit Log filter functions require <code>AUDIT_ADMIN</code> or <code>SUPER</code> privilege. </p> <p>The following functions are used for rule-based filtering:</p> Function Description Example audit_log_filter_flush() Manually flush the filter tables <code>SELECT audit_log_filter_flush()</code> audit_log_filter_set_filter() Defines a filter <code>SELECT audit_log_filter_set_filter('log_connections','{ \"filter\":{}}'</code>\u2019) audit_log_filter_remove_filter() Removes a filter audit_log_filter_set_user() Assigns a filter to a specific user account audit_log_filter_remove_user() Removes the filters from a specific user account <p>Using a SQL interface, you can define, display, or modify audit log filters. The filters are stored in the <code>mysql</code> system database.</p> <p>The <code>audit_log_session_filter_id()</code> function returns the internal ID of the audit log filter in the current session.</p> <p>Filter definitions are <code>JSON</code> values.</p> <p>The function, <code>audit_log_filter_flush()</code>, forces reloading all filters and should only be invoked when modifying the audit tables. This function affects all users. Users in current sessions must either execute change-user or disconnect and reconnect.</p>"},{"location":"filter-audit-log-filter-files.html#constraints","title":"Constraints","text":"<p>The <code>component_audit_log_filter</code> component must be enabled and the audit tables must exist to use the audit log filter functions. The user account must have the required privileges. </p>"},{"location":"filter-audit-log-filter-files.html#using-the-audit-log-filter-functions","title":"Using the audit log filter functions","text":"<p>With a new connection, the audit log filter component finds the user account name in the filter assignments. If a filter has been assigned, the component uses that filter. If no filter has been assigned, but there is a default account filter, the component uses that filter. If there is no filter assigned, and there is no default account filter, then the component does not process any event.</p> <p>The default account is represented by <code>%</code> as the account name.</p> <p>You can assign filters to a specific user account or disassociate a user account from a filter. To disassociate a user account, either unassign a filter or assign a different filter. If you remove a filter, that filter is unassigned from all users, including current users in current sessions.</p> <p></p>"},{"location":"filter-audit-log-filter-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"functions.html","title":"Functions","text":"<p>A function in MySQL is a reusable block of code that performs a specific task and returns a value. It allows users to encapsulate logic, modularize code, and perform complex calculations or data manipulations.</p>"},{"location":"functions.html#advantages-of-using-functions","title":"Advantages of Using Functions:","text":"Benefits Description Reusability Functions can be reused multiple times in different parts of a SQL statement or query, reducing code duplication and promoting code modularity and maintainability. Encapsulation Functions encapsulate logic and calculations, making it easier to understand and manage complex operations within the database. Performance Functions can improve query performance by reducing the amount of data transferred between the database server and the client application. Customization Functions allow users to create custom data transformations and calculations tailored to specific business requirements, enhancing the flexibility of the database."},{"location":"functions.html#disadvantages-of-using-functions","title":"Disadvantages of Using Functions:","text":"Disadvantages Description Performance Functions may introduce performance overhead, particularly if they involve complex computations or require access to large datasets. Maintenance Functions require maintenance to keep them synchronized with changes to the underlying data model or business logic. Changes may impact the behavior of dependent queries. Portability Functions written in MySQL may not be compatible with other database systems, limiting the portability of applications and databases. Security Improperly designed or implemented functions may pose security risks, such as SQL injection vulnerabilities or unauthorized access to sensitive data."},{"location":"functions.html#create-function","title":"Create function","text":"<pre><code>mysql&gt; CREATE FUNCTION calculate_discount (total_amount DECIMAL(10, 2)) RETURNS DECIMAL(10, 2)\n    -&gt; BEGIN\n    -&gt;     DECLARE discount DECIMAL(10, 2);\n    -&gt;     IF total_amount &gt; 100 THEN\n    -&gt;         SET discount = total_amount * 0.1;\n    -&gt;     ELSE\n    -&gt;         SET discount = 0;\n    -&gt;     END IF;\n    -&gt;     RETURN discount;\n    -&gt; END;\n</code></pre>"},{"location":"functions.html#call-function","title":"Call function","text":"<pre><code>mysql&gt; SELECT calculate_discount(120);\n</code></pre>"},{"location":"functions.html#drop-function","title":"Drop function","text":"<pre><code>mysql&gt; DROP FUNCTION IF EXISTS calculate_discount;\n</code></pre>"},{"location":"functions.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"functions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"glossary.html","title":"Glossary","text":""},{"location":"glossary.html#acid","title":"ACID","text":"<p>Set of properties that guarantee database transactions are processed reliably. Stands for Atomicity, Consistency, Isolation, Durability.</p>"},{"location":"glossary.html#atomicity","title":"Atomicity","text":"<p>Atomicity means that database operations are applied following a \u201call or nothing\u201d rule. A transaction is either fully applied or not at all.</p>"},{"location":"glossary.html#consistency","title":"Consistency","text":"<p>Consistency means that each transaction that modifies the database takes it from one consistent state to another.</p>"},{"location":"glossary.html#durability","title":"Durability","text":"<p>Once a transaction is committed, it will remain so.</p>"},{"location":"glossary.html#foreign-key","title":"Foreign Key","text":"<p>A referential constraint between two tables. Example: A purchase order in the purchase_orders table must have been made by a customer that exists in the customers table.</p>"},{"location":"glossary.html#general-availability-ga","title":"General Availability (GA)","text":"<p>A finalized version of the product which is made available to the general public. It is the final stage in the software release cycle.</p>"},{"location":"glossary.html#isolation","title":"Isolation","text":"<p>The Isolation requirement means that no transaction can interfere with another.</p>"},{"location":"glossary.html#innodb","title":"InnoDB","text":"<p>A Storage Engine for MySQL and derivatives (Percona Server, MariaDB) originally written by Innobase Oy, since acquired by Oracle. It provides ACID compliant storage engine with foreign key support. As of MySQL version 5.5, InnoDB became the default storage engine on all platforms.</p>"},{"location":"glossary.html#jenkins","title":"Jenkins","text":"<p>Jenkins is a continuous integration system that we use to help ensure the continued quality of the software we produce. It helps us achieve the aims of:</p> <ul> <li> <p>no failed tests in the trunk on any platform</p> </li> <li> <p>aid developers in ensuring merge requests build and test on all platform</p> </li> <li> <p>no known performance regressions (without a damn good explanation).</p> </li> </ul>"},{"location":"glossary.html#lsn","title":"LSN","text":"<p>The Log Sequence Number (LSN) is an 8-byte number. Every data change adds an entry to the redo log and generates an LSN. The server increments the LSN with every change.</p>"},{"location":"glossary.html#mariadb","title":"MariaDB","text":"<p>A fork of MySQL that is maintained primarily by Monty Program AB. It aims to add features, and fix bugs while maintaining 100% backward compatibility with MySQL.</p>"},{"location":"glossary.html#mycnf","title":"my.cnf","text":"<p>The file name of the default MySQL configuration file.</p>"},{"location":"glossary.html#myisam","title":"MyISAM","text":"<p>A MySQL Storage Engine that was the default until MySQL 5.5.</p>"},{"location":"glossary.html#mysql","title":"MySQL","text":"<p>An open source database that has spawned several distributions and forks. MySQL AB was the primary maintainer and distributor until bought by Sun Microsystems, which was then acquired by Oracle. As Oracle owns the MySQL trademark, the term MySQL is often used for the Oracle distribution of MySQL as distinct from the drop-in replacements such as MariaDB and Percona Server for MySQL.</p>"},{"location":"glossary.html#numa","title":"NUMA","text":"<p>Non-Uniform Memory Access (NUMA) is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to a processor. Under NUMA, a processor can access its own local memory faster than non-local memory, that is, memory local to another processor or memory shared between processors. The whole system may still operate as one unit, and all memory is basically accessible from everywhere but at a potentially higher latency and lower performance.</p>"},{"location":"glossary.html#percona-server-for-mysql","title":"Percona Server for MySQL","text":"<p>The Percona branch of MySQL with performance and management improvements.</p>"},{"location":"glossary.html#storage-engine","title":"Storage Engine","text":"<p>A storage engine is a piece of software that implements the details of data storage and retrieval for a database system. This term is primarily used within the MySQL ecosystem due to it being the first widely used relational database to have an abstraction layer around storage. It is analogous to a Virtual File System layer in an Operating System. A VFS layer allows an operating system to read and write multiple file systems (e.g. FAT, NTFS, XFS, ext3) and a Storage Engine layer allows a database server to access tables stored in different engines (for example, MyISAM or InnoDB).</p>"},{"location":"glossary.html#tech-preview","title":"Tech Preview","text":"<p>A tech preview item can be a feature, a variable, or a value within a variable. The term designates that the item is not yet ready for production use and is not included in support by SLA. A tech preview item is included in a release so that users can provide feedback. The item is either updated and released as general availability(GA) or removed if not useful. The item\u2019s functionality can change from tech preview to GA.</p>"},{"location":"glossary.html#xtradb","title":"XtraDB","text":"<p>The Percona improved version of InnoDB provides performance, features, and reliability above what is shipped by Oracle in InnoDB.</p> <p></p>"},{"location":"glossary.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"group-replication-flow-control.html","title":"Manage group replication flow control","text":"<p>In replication, flow control prevents one member from falling too far behind the cluster and avoids excessive buffering. A cluster is not required to keep members in sync together for replication. The pending transactions in the relay log only increase for the lagging replica. Each member sends statistics to the group.</p> <p>Flow control sets a threshold on the queue for transactions waiting in the certification queue or the transactions waiting in the applier queue. If the thresholds are exceeded, and during the duration that they are exceeded, flow control adjusts the writer members to the capacity of the delayed member. This action ensures that all members are in sync.</p> <p>Flow controls work asynchronously and depend on the following:</p> <ul> <li>Monitoring the throughput and queue sizes of each member</li> <li>Throttling members to avoid writing beyond the capacity available</li> </ul> <p>The following system variables set flow control behavior for Group Replication:</p> <ul> <li>group_replication_flow_control_mode</li> <li>group_replication_flow_control_certifier_threshold</li> <li>group_replication_flow_control_applier_threshold</li> </ul> <p>Flow control is enabled and disabled by selecting a value in the group_replication_flow_control_mode variable. Flow control can also be enabled on the certifier or applier level or both and sets the threshold level.</p> <p></p>"},{"location":"group-replication-flow-control.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"group-replication-system-variables.html","title":"Group replication system variables","text":"variable name group_replication_auto_evict_timeout group_replication_certification_loop_chunk_size group_replication_certification_loop_sleep_time group_replication_flow_control_mode"},{"location":"group-replication-system-variables.html#group_replication_auto_evict_timeout","title":"group_replication_auto_evict_timeout","text":"<p>The variable is in tech preview mode. Before using the variable in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> Option Description Command-line \u2013group-replication-auto-evict-timeout Dynamic Yes Scope Global Type Integer Default value 0 Maximum Value 65535 Unit seconds <p>The value can be changed while Group Replication is running. The change takes effect immediately. Every node in the group can have a different timeout value, but, to avoid unexpected exits, we recommend that all nodes have the same value.</p> <p>The variable specifies a period of time in seconds before a node is automatically evicted if the node exceeds the flow control threshold. The default value is 0, which disables the eviction. To set the timeout, change the value with a number higher than zero.</p> <p>In single-primary mode, the primary server ignores the timeout.</p>"},{"location":"group-replication-system-variables.html#group_replication_certification_loop_chunk_size","title":"group_replication_certification_loop_chunk_size","text":"Option Description Command-line \u2013group-replication-certification-loop-chunk-size Dynamic Yes Scope Global Data type ulong Default value 0 <p>Defines the size of the chunk that must be processed during the certifier garbage collection phase after which the client transactions are allowed to interleave. The default value is 0.</p> <p>The minimum value is 0. The maximum value is 4294967295.</p>"},{"location":"group-replication-system-variables.html#group_replication_certification_loop_sleep_time","title":"group_replication_certification_loop_sleep_time","text":"Option Description Command-line \u2013group-replication-certification-loop-sleep-time Dynamic Yes Scope Global Data type ulong Default value 0 <p>Defines the sleep time in microseconds that the certifier garbage collection loop allows client transactions to interleave. The default value is 0.</p> <p>The minimum value is 0. The maximum value is 1000000.</p>"},{"location":"group-replication-system-variables.html#group_replication_flow_control_mode","title":"group_replication_flow_control_mode","text":"Option Description Command-line \u2013group_replication_flow_control_mode Dynamic Yes Scope Global Data type Enumeration Default value Quota Valid values DISABLED  QUOTA  MAJORITY <p>The \u201cMAJORITY\u201d value is in tech preview mode. Before using the variable in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> <p>The variable specifies the mode use for flow control.</p> <p>Percona Server for MySQL adds the \u201cMAJORITY\u201d value to the group_replication_flow_control_mode variable. In \u201cMAJORITY\u201d mode, flow control is activated only if the majority, more than half the number of members, exceed the flow control threshold. The other values are not changed.</p> <p></p>"},{"location":"group-replication-system-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"improved-memory-engine.html","title":"Improved MEMORY storage engine","text":"<p>A Fixed Row Format (<code>FRF</code>) is used in the <code>MEMORY</code> storage engine. The fixed row format imposes restrictions on the type of columns as it assigns in advance a limited amount of memory per row. This renders a <code>VARCHAR</code> field in a <code>CHAR</code> field in practice and makes it impossible to have a <code>TEXT</code> or <code>BLOB</code> field with that engine implementation.</p> <p>To overcome this limitation, the Improved MEMORY Storage Engine is introduced in this release for supporting true <code>VARCHAR</code>, <code>VARBINARY</code>, <code>TEXT</code>, and <code>BLOB</code> fields in the <code>MEMORY</code> tables.</p> <p>This implementation is based on the Dynamic Row Format (<code>DFR</code>) introduced by the mysql-heap-dynamic-rows patch.</p> <p><code>DFR</code> is used to store column values in a variable-length form, thus helping to decrease the memory footprint of those columns and making possible <code>BLOB</code> and <code>TEXT</code> fields and real <code>VARCHAR</code> and <code>VARBINARY</code>.</p> <p>Unlike the fixed implementation, each column value in <code>DRF</code> uses only as much space as required. Variable-length values can use up to 4 bytes to store the actual value length, and only the necessary number of blocks is used to store the value.</p> <p>Rows in <code>DFR</code> are represented internally by multiple memory blocks, which means that a single row can consist of multiple blocks organized into one set. Each row occupies at least one block, there can not be multiple rows within a single block. Block size can be configured when creating a table (see below).</p> <p>This <code>DFR</code> implementation has two caveats regarding ordering and indexes.</p>"},{"location":"improved-memory-engine.html#caveats","title":"Caveats","text":""},{"location":"improved-memory-engine.html#ordering-of-rows","title":"Ordering of rows","text":"<p>In the absence of <code>ORDER BY</code>, records may be returned in a different order than the previous <code>MEMORY</code> implementation.</p> <p>This is not a bug. Any application relying on a specific order without an <code>ORDER BY</code> clause may deliver unexpected results. A specific order without <code>ORDER BY</code> is a side effect of a storage engine and query optimizer implementation which may and will change between minor MySQL releases.</p>"},{"location":"improved-memory-engine.html#indexing","title":"Indexing","text":"<p>It is currently impossible to use indexes on <code>BLOB</code> columns due to some limitations of the Dynamic Row Format. Trying to create such an index will fail with the following error:</p> Expected output <pre><code>BLOB column '&lt;name&gt;' can't be used in key specification with the used table type.\n</code></pre>"},{"location":"improved-memory-engine.html#restrictions","title":"Restrictions","text":"<p>For performance reasons, a mixed solution is implemented: the fixed format is used at the beginning of the row, while the dynamic one is used for the rest of it.</p> <p>The size of the fixed-format portion of the record is chosen automatically on <code>CREATE TABLE</code> and cannot be changed later. This, in particular, means that no indexes can be created later with <code>CREATE INDEX</code> or <code>ALTER TABLE</code> when the dynamic row format is used.</p> <p>All values for columns used in indexes are stored in fixed format at the first block of the row, then the following columns are handled with <code>DRF</code>.</p> <p>This sets two restrictions to tables:</p> <ul> <li> <p>the order of the fields and therefore,</p> </li> <li> <p>the minimum size of the block used in the table.</p> </li> </ul>"},{"location":"improved-memory-engine.html#ordering-of-columns","title":"Ordering of columns","text":"<p>The columns used in fixed format must be defined before the dynamic ones in the <code>CREATE TABLE</code> statement. If this requirement is not met, the engine will not be able to add blocks to the set for these fields and they will be treated as fixed.</p>"},{"location":"improved-memory-engine.html#minimum-block-size","title":"Minimum block size","text":"<p>The block size has to be big enough to store all fixed-length information in the first block. If not, the <code>CREATE TABLE</code> or <code>ALTER TABLE</code> statements will fail (see below).</p>"},{"location":"improved-memory-engine.html#limitations","title":"Limitations","text":"<p>MyISAM tables are still used for query optimizer internal temporary tables where the <code>MEMORY</code> tables could be used now instead: for temporary tables containing large <code>VARCHAR\\</code>`s, ``BLOB<code>, and</code>TEXT` columns.</p>"},{"location":"improved-memory-engine.html#setting-row-format","title":"Setting row format","text":"<p>Taking the restrictions into account, the Improved MEMORY Storage Engine will choose <code>DRF</code> over <code>FRF</code> at the moment of creating the table according to following criteria:</p> <ul> <li> <p>There is an implicit request of the user in the column types OR</p> </li> <li> <p>There is an explicit request of the user AND the overhead incurred by <code>DFR</code> is beneficial.</p> </li> </ul>"},{"location":"improved-memory-engine.html#implicit-request","title":"Implicit request","text":"<p>The implicit request by the user is taken when there is at least one <code>BLOB</code> or <code>TEXT</code> column in the table definition. If there are none of these columns and no relevant option is given, the engine will choose <code>FRF</code>.</p> <p>For example, this will yield the use of the dynamic format:</p> <pre><code>mysql&gt; CREATE TABLE t1 (f1 VARCHAR(32), f2 TEXT, PRIMARY KEY (f1)) ENGINE=HEAP;\n</code></pre> <p>While this will not:</p> <pre><code>mysql&gt; CREATE TABLE t1 (f1 VARCHAR(16), f2 VARCHAR(16), PRIMARY KEY (f1)) ENGINE=HEAP;\n</code></pre>"},{"location":"improved-memory-engine.html#explicit-request","title":"Explicit request","text":"<p>The explicit request is set with one of the following options in the <code>CREATE TABLE</code> statement:</p> <ul> <li> <p><code>KEY_BLOCK_SIZE = &lt;value&gt;</code></p> </li> <li> <p>Requests the DFR with the specified block size (in bytes)</p> </li> </ul> <p>Despite its name, the <code>KEY_BLOCK_SIZE</code> option refers to a block size used to store data rather then indexes. The reason for this is that an existing <code>CREATE TABLE</code> option is reused to avoid introducing new ones.</p> <p>The Improved MEMORY Engine checks whether the specified block size is large enough to keep all key column values. If it is too small, table creation will abort with an error.</p> <p>After <code>DRF</code> is requested explicitly and there are no <code>BLOB</code> or <code>TEXT</code> columns in the table definition, the Improved MEMORY Engine will check if using the dynamic format provides any space saving benefits as compared to the fixed one:</p> <ul> <li> <p>if the fixed row length is less than the dynamic block size (plus the dynamic row overhead - platform dependent) OR</p> </li> <li> <p>there isn\u2019t any variable-length columns in the table or <code>VARCHAR</code> fields are declared with length 31 or less,</p> </li> </ul> <p>the engine will revert to the fixed format as it is more space efficient in such case. The row format being used by the engine can be checked using <code>SHOW TABLE STATUS</code>.</p>"},{"location":"improved-memory-engine.html#examples","title":"Examples","text":"<p>On a 32-bit platform:</p> <pre><code>mysql&gt; CREATE TABLE t1 (f1 VARCHAR(32), f2 VARCHAR(32), f3 VARCHAR(32), f4 VARCHAR(32), PRIMARY KEY (f1)) KEY_BLOCK_SIZE=124 ENGINE=HEAP;\n\nmysql&gt; SHOW TABLE STATUS LIKE 't1'; \n</code></pre> Expected output <pre><code>Name  Engine  Version    Rows Avg_row_length  Data_length     Max_data_length Index_length    Data_free       Auto_increment  Create_time     Update_time     Check_time      Collation       Checksum        Create_options  Comment\nt1    MEMORY  10         X    0       X       0       0       NULL    NULL    NULL    NULL    latin1_swedish_ci       NULL    row_format=DYNAMIC KEY_BLOCK_SIZE=124\n</code></pre> <p>On a 64-bit platform:</p> <pre><code>mysqlCREATE TABLE t1 (f1 VARCHAR(32), f2 VARCHAR(32), f3 VARCHAR(32), f4 VARCHAR(32), PRIMARY KEY (f1)) KEY_BLOCK_SIZE=124 ENGINE=HEAP;\n</code></pre> <pre><code>mysqlSHOW TABLE STATUS LIKE 't1';\n</code></pre> Expected output <pre><code>Name  Engine  Version    Rows Avg_row_length  Data_length     Max_data_length Index_length    Data_free       Auto_increment  Create_time     Update_time     Check_time      Collation       Checksum        Create_options  Comment\nt1    MEMORY  10         X    0       X       0       0       NULL    NULL    NULL    NULL    latin1_swedish_ci       NULL    KEY_BLOCK_SIZE=124\n</code></pre>"},{"location":"improved-memory-engine.html#implementation-details","title":"Implementation details","text":"<p>MySQL MEMORY tables keep data in arrays of fixed-size chunks. These chunks are organized into two groups of <code>HP_BLOCK</code> structures:</p> <ul> <li> <p><code>group1</code> contains indexes, with one <code>HP_BLOCK</code> per key (part of <code>HP_KEYDEF</code>),</p> </li> <li> <p><code>group2</code> contains record data, with a single <code>HP_BLOCK</code> for all records.</p> </li> </ul> <p>While columns used in indexes are usually small, other columns in the table may need to accommodate larger data. Typically, larger data is placed into <code>VARCHAR</code> or <code>BLOB</code> columns.</p> <p>The Improved MEMORY Engine implements the concept of dataspace, <code>HP_DATASPACE</code>, which incorporates the <code>HP_BLOCK</code> structures for the record data, adding more information for managing variable-sized records.</p> <p>Variable-size records are stored in multiple \u201cchunks\u201d, which means that a single record of data (a database \u201crow\u201d) can consist of multiple chunks organized into one \u201cset\u201d, contained in <code>HP_BLOCK</code> structures.</p> <p>In variable-size format, one record is represented as one or many chunks depending on the actual data, while in fixed-size mode, one record is always represented as one chunk. The index structures would always point to the first chunk in the chunkset.</p> <p>Variable-size records are necessary only in the presence of variable-size columns. The Improved Memory Engine will be looking for <code>BLOB</code> or <code>VARCHAR</code> columns with a declared length of 32 or more. If no such columns are found, the table will be switched to the fixed-size format. You should always put such columns at the end of the table definition in order to use the variable-size format.</p> <p>Whenever data is being inserted or updated in the table, the Improved Memory Engine will calculate how many chunks are necessary.</p> <p>For <code>INSERT</code> operations, the engine only allocates new chunksets in the recordspace. For <code>UPDATE</code> operations it will modify the length of the existing chunkset if necessary, unlinking unnecessary chunks at the end, or allocating and adding more if a larger length is needed.</p> <p>When writing data to chunks or copying data back to a record, fixed-size columns are copied in their full format, while <code>VARCHAR</code> and <code>BLOB</code> columns are copied based on their actual length, skipping any <code>NULL</code> values.</p> <p>When allocating a new chunkset of N chunks, the engine will try to allocate chunks one-by-one, linking them as they become allocated. For allocating a single chunk, it will attempt to reuse a deleted (freed) chunk. If no free chunks are available, it will try to allocate a new area inside a <code>HP_BLOCK</code>.</p> <p>When freeing chunks, the engine will place them at the front of a free list in the dataspace, each one containing a reference to the previously freed chunk.</p> <p>The allocation and contents of the actual chunks varies between fixed and variable-size modes:</p> <ul> <li> <p>Format of a fixed-size chunk:</p> <ul> <li> <p><code>uchar[]</code> * With <code>sizeof=chunk_dataspace_length</code>, but at least <code>sizeof(uchar\\*)</code> bytes. It keeps actual data or pointer to the next deleted chunk, where <code>chunk_dataspace_length</code> equals to full record length</p> </li> <li> <p><code>uchar</code> * Status field (1 means \u201cin use\u201d, 0 means \u201cdeleted\u201d)</p> </li> </ul> </li> <li> <p>Format of a variable-size chunk:</p> <ul> <li> <p><code>uchar[]</code> * With <code>sizeof=chunk_dataspace_length</code>, but at least <code>sizeof(uchar\\*)</code> bytes. It keeps actual data or pointer to the next deleted chunk, where <code>chunk_dataspace_length</code> is set according to table\u2019s <code>key_block_size</code></p> </li> <li> <p><code>uchar\\*</code> * Pointer to the next chunk in this chunkset, or NULL for the last chunk</p> </li> <li> <p><code>uchar</code> * Status field (1 means \u201cfirst\u201d, 0 means \u201cdeleted\u201d, 2 means \u201clinked\u201d)</p> </li> </ul> </li> </ul> <p>Total chunk length is always aligned to the next <code>sizeof(uchar\\*)</code>.</p> <p>See also</p> <p>Dynamic row format for MEMORY tables</p> <p></p>"},{"location":"improved-memory-engine.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"index-info-schema-tables.html","title":"Index of INFORMATION_SCHEMA tables","text":"<p>This is a list of the <code>INFORMATION_SCHEMA TABLES</code> that exist in Percona Server for MySQL with XtraDB. The entry for each table points to the page in the documentation where it\u2019s described.</p> <ul> <li> <p>INFORMATION_SCHEMA.CLIENT_STATISTICS</p> </li> <li> <p>INFORMATION_SCHEMA.GLOBAL_TEMPORARY_TABLES</p> </li> <li> <p>[INFORMATION_SCHEMA.INDEX_STATISTICS]</p> </li> <li> <p>PROCFS</p> </li> <li> <p>INFORMATION_SCHEMA.QUERY_RESPONSE_TIME</p> </li> <li> <p>INFORMATION_SCHEMA.TABLE_STATISTICS</p> </li> <li> <p>INFORMATION_SCHEMA.TEMPORARY_TABLES</p> </li> <li> <p>THREAD_STATISTICS</p> </li> <li> <p>INFORMATION_SCHEMA.USER_STATISTICS</p> </li> <li> <p>XTRADB_INTERNAL_HASH_TABLES</p> </li> <li> <p>XTRADB_READ_VIEW</p> </li> <li> <p>INFORMATION_SCHEMA.XTRADB_RSEG</p> </li> <li> <p>INFORMATION_SCHEMA.XTRADB_ZIP_DICT</p> </li> <li> <p>INFORMATION_SCHEMA.XTRADB_ZIP_DICT_COLS</p> </li> </ul> <p></p>"},{"location":"index-info-schema-tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-corrupt-table-action.html","title":"Handle corrupted tables","text":"<p>When a server subsystem tries to access a corrupted table, the server may crash. If this outcome is not desirable when a corrupted table is encountered, set the new system innodb_corrupt_table_action variable to a value which allows the ongoing operation to continue without crashing the server.</p> <p>The server error log registers attempts to access corrupted table pages.</p>"},{"location":"innodb-corrupt-table-action.html#interacting-with-the-innodb_force_recovery-variable","title":"Interacting with the innodb_force_recovery variable","text":"<p>The innodb_corrupt_table_action variable may work in conjunction with the innodb_force_recovery variable which considerably reduces the effect of InnoDB subsystems running in the background.</p> <p>If the innodb_force_recovery option is &lt;4, corrupted pages are lost and the server may continue to run due to the innodb_corrupt_table_action variable having a non-default value.</p> <p>For more information about the innodb_force_recovery variable, see Forcing InnoDB Recovery from the MySQL Reference Manual.</p> <p>This feature adds a system variable.</p>"},{"location":"innodb-corrupt-table-action.html#system-variables","title":"System variables","text":""},{"location":"innodb-corrupt-table-action.html#innodb_corrupt_table_action","title":"<code>innodb_corrupt_table_action</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type ULONG Default assert Range assert, warn, salvage <ul> <li> <p>Enabling <code>innodb_file_per_table</code> and using the <code>assert</code> value creates an assertion failure which causes XtraDB to intentionally crash the server. This action is expected when detecting corrupted data in a single-table tablespace.</p> </li> <li> <p>Enabling <code>innodb_file_per_table</code> and using the <code>warn</code> value causes XtraDB to pass the table corruption as <code>corrupt table</code> instead of crashing the server. Detecting the file as corrupt also disables the file I/O for that data file, except for the deletion operation.</p> </li> <li> <p>Enabling <code>innodb_file_per_table</code> and using the <code>salvage</code> value causes XtraDB to allow read access to the corrupted tablespace but ignores any corrupted pages.</p> </li> </ul> <p></p>"},{"location":"innodb-corrupt-table-action.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-expanded-fast-index-creation.html","title":"Expanded fast index creation","text":"<p>Percona has implemented several changes related to MySQL\u2019s fast index creation feature. Fast index creation was implemented in MySQL as a way to speed up the process of adding or dropping indexes on tables with many rows.</p> <p>This feature implements a session variable that enables extended fast index creation. Besides optimizing DDL directly, expand_fast_index_creation may also optimize index access for subsequent DML statements because using it results in much less fragmented indexes.</p>"},{"location":"innodb-expanded-fast-index-creation.html#the-mysqldump-command","title":"The mysqldump command","text":"<p>A new option, <code>--innodb-optimize-keys</code>, was implemented in mysqldump. It changes the way InnoDB tables are dumped, so that secondary and foreign keys are created after loading the data, thus taking advantage of fast index creation. More specifically:</p> <ul> <li> <p><code>KEY</code>, <code>UNIQUE KEY</code>, and <code>CONSTRAINT</code> clauses are omitted from <code>CREATE TABLE</code> statements corresponding to InnoDB tables.</p> </li> <li> <p>An additional <code>ALTER TABLE</code> is issued after dumping the data, in order to create the previously omitted keys.</p> </li> </ul>"},{"location":"innodb-expanded-fast-index-creation.html#alter-table","title":"<code>ALTER TABLE</code>","text":"<p>When <code>ALTER TABLE</code> requires a table copy, secondary keys are now dropped and recreated later, after copying the data. The following restrictions apply:</p> <ul> <li> <p>Only non-unique keys can be involved in this optimization.</p> </li> <li> <p>If the table contains foreign keys, or a foreign key is being added as a part of the current <code>ALTER TABLE</code> statement, the optimization is disabled for all keys.</p> </li> </ul>"},{"location":"innodb-expanded-fast-index-creation.html#optimize-table","title":"<code>OPTIMIZE TABLE</code>","text":"<p>Internally, <code>OPTIMIZE TABLE</code> is mapped to <code>ALTER TABLE ... ENGINE=innodb</code> for InnoDB tables. As a consequence, it now also benefits from fast index creation, with the same restrictions as for <code>ALTER TABLE</code>.</p>"},{"location":"innodb-expanded-fast-index-creation.html#caveats","title":"Caveats","text":"<p>InnoDB fast index creation uses temporary files in tmpdir for all indexes being created. So make sure you have enough tmpdir space when using expand_fast_index_creation. It is a session variable, so you can temporarily switch it off if you are short on tmpdir space and/or don\u2019t want this optimization to be used for a specific table.</p> <p>There\u2019s also a number of cases when this optimization is not applicable:</p> <ul> <li> <p><code>UNIQUE</code> indexes in <code>ALTER TABLE</code> are ignored to enforce uniqueness where necessary when copying the data to a temporary table;</p> </li> <li> <p><code>ALTER TABLE</code> and <code>OPTIMIZE TABLE</code> always process tables containing foreign keys as if expand_fast_index_creation is OFF to avoid dropping keys that are part of a FOREIGN KEY constraint;</p> </li> <li> <p>mysqldump \u2013innodb-optimize-keys ignores foreign keys because InnoDB requires a full table rebuild on foreign key changes. So adding them back with a separate <code>ALTER TABLE</code> after restoring the data from a dump would actually make the restore slower;</p> </li> <li> <p>mysqldump \u2013innodb-optimize-keys ignores indexes on <code>AUTO_INCREMENT</code> columns, because they must be indexed, so it is impossible to temporarily drop the corresponding index;</p> </li> <li> <p>mysqldump \u2013innodb-optimize-keys ignores the first UNIQUE index on non-nullable columns when the table has no <code>PRIMARY KEY</code> defined, because in this case InnoDB picks such an index as the clustered one.</p> </li> </ul>"},{"location":"innodb-expanded-fast-index-creation.html#system-variables","title":"System variables","text":""},{"location":"innodb-expanded-fast-index-creation.html#expand_fast_index_creation","title":"<code>expand_fast_index_creation</code>","text":"Option Description Command Line: Yes Config file No Scope: Local/Global Dynamic: Yes Data type Boolean Default value ON/OFF <p>See also</p> <p>Improved InnoDB fast index creation</p> <p>Thinking about running OPTIMIZE on your InnoDB Table? Stop! </p> <p></p>"},{"location":"innodb-expanded-fast-index-creation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-fragmentation-count.html","title":"InnoDB page fragmentation counters","text":"<p>InnoDB page fragmentation is caused by random insertion or deletion from a secondary index. This means that the physical ordering of the index pages on the disk is not same as the index ordering of the records on the pages. As a consequence this means that some pages take a lot more space and that queries which require a full table scan can take a long time to finish.</p> <p>To provide more information about the InnoDB page fragmentation  Percona Server for MySQL now provides the following counters as status variables: Innodb_scan_pages_contiguous, Innodb_scan_pages_disjointed, Innodb_scan_data_size, Innodb_scan_deleted_recs_size, and Innodb_scan_pages_total_seek_distance.</p>"},{"location":"innodb-fragmentation-count.html#status-variables","title":"Status variables","text":""},{"location":"innodb-fragmentation-count.html#innodb_scan_pages_contiguous","title":"<code>Innodb_scan_pages_contiguous</code>","text":"Option Description Scope Session Data type Numeric <p>This variable shows the number of contiguous page reads inside a query.</p>"},{"location":"innodb-fragmentation-count.html#innodb_scan_pages_disjointed","title":"<code>Innodb_scan_pages_disjointed</code>","text":"Option Description Scope Session Data type Numeric <p>This variable shows the number of disjointed page reads inside a query.</p>"},{"location":"innodb-fragmentation-count.html#innodb_scan_data_size","title":"<code>Innodb_scan_data_size</code>","text":"Option Description Scope Session Data type Numeric <p>This variable shows the size of data in all InnoDB pages read inside a query (in bytes) - calculated as the sum of <code>page_get_data_size(page)</code> for every page scanned.</p>"},{"location":"innodb-fragmentation-count.html#innodb_scan_deleted_recs_size","title":"<code>Innodb_scan_deleted_recs_size</code>","text":"Option Description Scope Session Data type Numeric <p>This variable shows the size of deleted records (marked as <code>deleted</code> in <code>page_delete_rec_list_end()</code>) in all InnoDB pages read inside a query (in bytes) - calculated as the sum of <code>page_header_get_field(page, PAGE_GARBAGE)</code> for every page scanned.</p>"},{"location":"innodb-fragmentation-count.html#innodb_scan_pages_total_seek_distance","title":"<code>Innodb_scan_pages_total_seek_distance</code>","text":"Option Description Scope Session Data type Numeric <p>This variable shows the total seek distance when moving between pages.</p>"},{"location":"innodb-fragmentation-count.html#related-reading","title":"Related reading","text":"<ul> <li> <p>InnoDB: look after fragmentation</p> </li> <li> <p>Defragmenting a Table</p> </li> </ul> <p></p>"},{"location":"innodb-fragmentation-count.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-fts-improvements.html","title":"InnoDB full-text search improvements","text":""},{"location":"innodb-fts-improvements.html#ignoring-stopword-list","title":"Ignoring stopword list","text":"<p>By default, all Full-Text Search indexes check the stopwords list, to see if any indexed elements contain words on that list.</p> <p>Using this list for n-gram indexes isn\u2019t always suitable, for example, any item that contains <code>a</code> or <code>i</code> will be ignored. Another word that can\u2019t be searched is <code>east</code>, this one will find no matches because <code>a</code> is on the FTS stopword list.</p> <p>To resolve this issue, Percona Server for MySQL has the <code>innodb_ft_ignore_stopwords</code> variable to control whether InnoDB Full-Text Search should ignore the stopword list.</p> <p>Although this variable is introduced to resolve n-gram issues, it affects all Full-Text Search indexes as well.</p> <p>Being a stopword doesn\u2019t just mean being one of the predefined words from the list. Tokens shorter than innodb_ft_min_token_size or longer than innodb_ft_max_token_size are also considered stopwords. Therefore, when innodb_ft_ignore_stopwords is set to <code>ON</code> even for non-ngram FTS, <code>innodb_ft_min_token_size</code> / <code>innodb_ft_max_token_size</code> will be ignored meaning that in this case very short and very long words will also be indexed.</p>"},{"location":"innodb-fts-improvements.html#system-variables","title":"System variables","text":""},{"location":"innodb-fts-improvements.html#innodb_ft_ignore_stopwords","title":"<code>innodb_ft_ignore_stopwords</code>","text":"Option Description Command-line Yes Config file Yes Scope Session, Global Dynamic Yes Data type Boolean Default OFF <p>When enabled, this variable will instruct InnoDB Full Text Search parser to ignore the stopword list when building/updating an FTS index.</p> <p></p>"},{"location":"innodb-fts-improvements.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-io.html","title":"Improved InnoDB I/O scalability","text":"<p>Because InnoDB is a complex storage engine it must be configured properly in order to perform at its best. Some points are not configurable in standard InnoDB. The goal of this feature is to provide a more exhaustive set of options for XtraDB.</p>"},{"location":"innodb-io.html#system-variables","title":"System variables","text":""},{"location":"innodb-io.html#innodb_flush_method","title":"<code>innodb_flush_method</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic No Data type Enumeration Default NULL Allowed values fsync, O_DSYNC, O_DIRECT, O_DIRECT_NO_FSYNC, littlesync, nosync <p>The following values are allowed:</p> <ul> <li> <p><code>fdatasync</code>: use <code>fsync()</code> to flush data, log, and parallel doublewrite files.</p> </li> <li> <p><code>O_SYNC</code>: use <code>O_SYNC</code> to open and flush the log and parallel doublewrite files; use <code>fsync()</code> to flush the data files. Do not use <code>fsync()</code> to flush the parallel doublewrite file.</p> </li> <li> <p><code>O_DIRECT</code>: use O_DIRECT to open the data files and <code>fsync()</code> system call to flush data, log, and parallel doublewrite files.</p> </li> <li> <p><code>O_DIRECT_NO_FSYNC</code>: use O_DIRECT to open the data files and parallel doublewrite files, but does not use the <code>fsync()</code> system call to flush the data files, log files, and parallel doublewrite files. Do not use this option for the XFS file system.</p> </li> </ul> <p>Note</p> <p>On an ext4 filesystem, set <code>innodb_log_write_ahead_size</code> to match the filesystem\u2019s write-ahead block size. This variable avoids <code>unaligned AIO/DIO</code> warnings.</p>"},{"location":"innodb-io.html#status-variables","title":"Status variables","text":"<p>The following information has been added to <code>SHOW ENGINE INNODB STATUS</code> to confirm the checkpointing activity:</p> <pre><code>The current checkpoint age target\nThe current age of the oldest page modification which has not been flushed to disk yet.\nThe current age of the last checkpoint\n...\n---\nLOG\n---\nLog sequence number 0 1059494372\nLog flushed up to   0 1059494372\nLast checkpoint at  0 1055251010\nMax checkpoint age  162361775\nCheckpoint age target 104630090\nModified age        4092465\nCheckpoint age      4243362\n0 pending log writes, 0 pending chkp writes\n...\n</code></pre> <p></p>"},{"location":"innodb-io.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"innodb-show-status.html","title":"Extended show engine InnoDB status","text":"<p>This feature reorganizes the output of <code>SHOW ENGINE INNODB STATUS</code> to improve readability and to provide additional information. The variable innodb_show_locks_held controls the umber of locks held to print for each InnoDB transaction.</p> <p>This feature modified the <code>SHOW ENGINE INNODB STATUS</code> command as follows:</p> <ul> <li> <p>Added extended information about InnoDB internal hash table sizes (in bytes) in the <code>BUFFER POOL AND MEMORY</code> section; also added buffer pool size in bytes.</p> </li> <li> <p>Added additional LOG section information.</p> </li> </ul>"},{"location":"innodb-show-status.html#other-information","title":"Other information","text":"<ul> <li>Author / Origin: Baron Schwartz, https://lists.mysql.com/internals/35174</li> </ul>"},{"location":"innodb-show-status.html#system-variables","title":"System variables","text":""},{"location":"innodb-show-status.html#innodb_show_locks_held","title":"<code>innodb_show_locks_held</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type ULONG Default 10 Range 0 - 1000 <p>Specifies the number of locks held to print for each InnoDB transaction in <code>SHOW ENGINE INNODB STATUS</code>.</p>"},{"location":"innodb-show-status.html#innodb_print_lock_wait_timeout_info","title":"<code>innodb_print_lock_wait_timeout_info</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type Boolean Default OFF <p>Makes InnoDB to write information about all lock wait timeout errors into the log file.</p> <p>This allows to find out details about the failed transaction, and, most importantly, the blocking transaction. Query string can be obtained from EVENTS_STATEMENTS_CURRENT table, based on the <code>PROCESSLIST_ID</code> field, which corresponds to <code>thread_id</code> from the log output.</p> <p>Taking into account that blocking transaction is often a multiple statement one, following query can be used to obtain blocking thread statements history:</p> <pre><code>SELECT s.SQL_TEXT FROM performance_schema.events_statements_history s\nINNER JOIN performance_schema.threads t ON t.THREAD_ID = s.THREAD_ID\nWHERE t.PROCESSLIST_ID = %d\nUNION\nSELECT s.SQL_TEXT FROM performance_schema.events_statements_current s\nINNER JOIN performance_schema.threads t ON t.THREAD_ID = s.THREAD_ID\nWHERE t.PROCESSLIST_ID = %d;\n</code></pre> <p>The <code>PROCESSLIST_ID</code> in this example is exactly the thread id from error log output.</p>"},{"location":"innodb-show-status.html#status-variables","title":"Status variables","text":"<p>The status variables here contain information available in the output of <code>SHOW ENGINE INNODB STATUS</code>, organized by the sections <code>SHOW ENGINE INNODB STATUS</code> displays. If you are familiar with the output of <code>SHOW ENGINE INNODB STATUS</code>, you will probably already recognize the information these variables contain.</p>"},{"location":"innodb-show-status.html#background-thread","title":"BACKGROUND THREAD","text":"<p>The following variables contain information in the <code>BACKGROUND THREAD</code> section of the output from <code>SHOW ENGINE INNODB STATUS</code>. </p> Expected output <pre><code>-----------------\nBACKGROUND THREAD\n-----------------\nsrv_master_thread loops: 1 srv_active, 0 srv_shutdown, 11844 srv_idle\nsrv_master_thread log flush and writes: 11844\n</code></pre> <p>InnoDB has a source thread which performs background tasks depending on the server state, once per second. If the server is under workload, the source thread runs the following: performs background table drops; performs change buffer merge, adaptively; flushes the redo log to disk; evicts tables from the dictionary cache if needed to satisfy its size limit; makes a checkpoint. If the server is idle: performs background table drops, flushes and/or checkpoints the redo log if needed due to the checkpoint age; performs change buffer merge at full I/O capacity; evicts tables from the dictionary cache if needed; and makes a checkpoint.</p>"},{"location":"innodb-show-status.html#innodb_background_log_sync","title":"<code>Innodb_background_log_sync</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the number of times the InnoDB source thread has written and flushed the redo log.</p>"},{"location":"innodb-show-status.html#semaphores","title":"SEMAPHORES","text":"<p>The following variables contain information in the <code>SEMAPHORES</code> section of the output from <code>SHOW ENGINE INNODB STATUS</code>. An example of that output is:</p> Expected output <pre><code>----------\nSEMAPHORES\n----------\nOS WAIT ARRAY INFO: reservation count 9664, signal count 11182\nMutex spin waits 20599, rounds 223821, OS waits 4479\nRW-shared spins 5155, OS waits 1678; RW-excl spins 5632, OS waits 2592\nSpin rounds per wait: 10.87 mutex, 15.01 RW-shared, 27.19 RW-excl\n</code></pre>"},{"location":"innodb-show-status.html#insert-buffer-and-adaptive-hash-index","title":"INSERT BUFFER AND ADAPTIVE HASH INDEX","text":"<p>The following variables contain information in the <code>INSERT BUFFER AND ADAPTIVE HASH INDEX</code> section of the output from <code>SHOW ENGINE INNODB STATUS</code>. An example of that output is:</p> Expected output <pre><code>-------------------------------------\nINSERT BUFFER AND ADAPTIVE HASH INDEX\n-------------------------------------\nIbuf: size 1, free list len 6089, seg size 6091,\n44497 inserts, 44497 merged recs, 8734 merges\n0.00 hash searches/s, 0.00 non-hash searches/s\n</code></pre>"},{"location":"innodb-show-status.html#innodb_ibuf_free_list","title":"<code>Innodb_ibuf_free_list</code>","text":"Option Description Scope Global Data type Numeric"},{"location":"innodb-show-status.html#innodb_ibuf_segment_size","title":"<code>Innodb_ibuf_segment_size</code>","text":"Option Description Scope Global Data type Numeric"},{"location":"innodb-show-status.html#log","title":"LOG","text":"<p>The following variables contain information in the <code>LOG</code> section of the output from <code>SHOW ENGINE INNODB STATUS</code>. An example of that output is:</p> Expected output <pre><code>LOG\n---\nLog sequence number 10145937666\nLog flushed up to   10145937666\nPages flushed up to 10145937666\nLast checkpoint at  10145937666\nMax checkpoint age    80826164\nCheckpoint age target 78300347\nModified age          0\nCheckpoint age        0\n0 pending log writes, 0 pending chkp writes\n9 log i/o's done, 0.00 log i/o's/second\nLog tracking enabled\nLog tracked up to   10145937666\nMax tracked LSN age 80826164\n</code></pre>"},{"location":"innodb-show-status.html#innodb_lsn_current","title":"<code>Innodb_lsn_current</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the current log sequence number.</p>"},{"location":"innodb-show-status.html#innodb_lsn_flushed","title":"<code>Innodb_lsn_flushed</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the current maximum LSN that has been written and flushed to disk.</p>"},{"location":"innodb-show-status.html#innodb_lsn_last_checkpoint","title":"<code>Innodb_lsn_last_checkpoint</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the LSN of the latest completed checkpoint.</p>"},{"location":"innodb-show-status.html#innodb_checkpoint_age","title":"<code>Innodb_checkpoint_age</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the current InnoDB checkpoint age, i.e., the difference between the current LSN and the LSN of the last completed checkpoint.</p>"},{"location":"innodb-show-status.html#buffer-pool-and-memory","title":"BUFFER POOL AND MEMORY","text":"<p>The following variables contain information in the <code>BUFFER POOL AND MEMORY</code> section of the output from <code>SHOW ENGINE INNODB STATUS</code>. An example of that output is:</p> Expected output <pre><code>----------------------\nBUFFER POOL AND MEMORY\n----------------------\nTotal memory allocated 137363456; in additional pool allocated 0\nTotal memory allocated by read views 88\nInternal hash tables (constant factor + variable factor)\n    Adaptive hash index 2266736         (2213368 + 53368)\n    Page hash           139112 (buffer pool 0 only)\n    Dictionary cache    729463  (554768 + 174695)\n    File system         824800  (812272 + 12528)\n    Lock system         333248  (332872 + 376)\n    Recovery system     0       (0 + 0)\nDictionary memory allocated 174695\nBuffer pool size        8191\nBuffer pool size, bytes 134201344\nFree buffers            7481\nDatabase pages          707\nOld database pages      280\nModified db pages       0\nPending reads 0\nPending writes: LRU 0, flush list 0 single page 0\nPages made young 0, not young 0\n0.00 youngs/s, 0.00 non-youngs/s\nPages read 707, created 0, written 1\n0.00 reads/s, 0.00 creates/s, 0.00 writes/s\nNo buffer pool page gets since the last printout\nPages read ahead 0.00/s, evicted without access 0.00/s, Random read ahead 0.00/s\nLRU len: 707, unzip_LRU len: 0\n</code></pre>"},{"location":"innodb-show-status.html#innodb_mem_adaptive_hash","title":"<code>Innodb_mem_adaptive_hash</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the current size, in bytes, of the adaptive hash index.</p>"},{"location":"innodb-show-status.html#innodb_mem_dictionary","title":"<code>Innodb_mem_dictionary</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the current size, in bytes, of the InnoDB in-memory data dictionary info.</p>"},{"location":"innodb-show-status.html#innodb_mem_total","title":"<code>Innodb_mem_total</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the total amount of memory, in bytes, InnoDB has allocated in the process heap memory.</p>"},{"location":"innodb-show-status.html#innodb_buffer_pool_pages_lru_flushed","title":"<code>Innodb_buffer_pool_pages_LRU_flushed</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the total number of buffer pool pages which have been flushed from the LRU list, i.e., too old pages which had to be flushed in order to make buffer pool room to read in new data pages.</p>"},{"location":"innodb-show-status.html#innodb_buffer_pool_pages_made_not_young","title":"<code>Innodb_buffer_pool_pages_made_not_young</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the number of times a buffer pool page was not marked as accessed recently in the LRU list because of innodb_old_blocks_time variable setting.</p>"},{"location":"innodb-show-status.html#innodb_buffer_pool_pages_made_young","title":"<code>Innodb_buffer_pool_pages_made_young</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the number of times a buffer pool page was moved to the young end of the LRU list due to its access, to prevent its eviction from the buffer pool.</p>"},{"location":"innodb-show-status.html#innodb_buffer_pool_pages_old","title":"<code>Innodb_buffer_pool_pages_old</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the total number of buffer pool pages which are considered to be old according to the Making the Buffer Pool Scan Resistant manual page.</p>"},{"location":"innodb-show-status.html#transactions","title":"TRANSACTIONS","text":"<p>The following variables contain information in the <code>TRANSACTIONS</code> section of the output from <code>SHOW INNODB STATUS</code>. An example of that output is:</p> Expected output <pre><code>------------\nTRANSACTIONS\n------------\nTrx id counter F561FD\nPurge done for trx's n:o &lt; F561EB undo n:o &lt; 0\nHistory list length 19\nLIST OF TRANSACTIONS FOR EACH SESSION:\n---TRANSACTION 0, not started, process no 993, OS thread id 140213152634640\nmysql thread id 15933, query id 32109 localhost root\nshow innodb status\n---TRANSACTION F561FC, ACTIVE 29 sec, process no 993, OS thread id 140213152769808 updating or deleting\nmysql tables in use 1, locked 1\n</code></pre>"},{"location":"innodb-show-status.html#innodb_max_trx_id","title":"<code>Innodb_max_trx_id</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the next free transaction id number.</p>"},{"location":"innodb-show-status.html#innodb_oldest_view_low_limit_trx_id","title":"<code>Innodb_oldest_view_low_limit_trx_id</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the highest transaction id, above which the current oldest open read view does not see any transaction changes. Zero if there is no open view.</p>"},{"location":"innodb-show-status.html#innodb_purge_trx_id","title":"<code>Innodb_purge_trx_id</code>","text":"Option Description Scope Global Data type Numeric <p>This variable shows the oldest transaction id whose records have not been purged yet.</p>"},{"location":"innodb-show-status.html#innodb_purge_undo_no","title":"<code>Innodb_purge_undo_no</code>","text":"Option Description Scope Global Data type Numeric"},{"location":"innodb-show-status.html#information_schema-tables","title":"INFORMATION_SCHEMA Tables","text":"<p>The following table contains information about the oldest active transaction in the system.</p>"},{"location":"innodb-show-status.html#information_schemaxtradb_read_view","title":"<code>INFORMATION_SCHEMA.XTRADB_READ_VIEW</code>","text":"<p>The data type for the following columns is <code>BIGINT UNSIGNED</code>. The columns contain 64-bit integers.</p> Column Name Description \u2018READ_VIEW_LOW_LIMIT_TRX_NUMBER\u2019 This is the highest transactions number at the time the view was created. \u2018READ_VIEW_UPPER_LIMIT_TRX_ID\u2019 This is the highest transactions ID at the time the view was created. This means that it should not see newer transactions with IDs bigger than or equal to that value. \u2018READ_VIEW_LOW_LIMIT_TRX_ID\u2019 This is the latest committed transaction ID at the time the oldest view was created. This means that it should see all transactions with IDs smaller than or equal to that value. <p>The following table contains information about the memory usage for InnoDB/XtraDB hash tables.</p>"},{"location":"innodb-show-status.html#information_schemaxtradb_internal_hash_tables","title":"<code>INFORMATION_SCHEMA.XTRADB_INTERNAL_HASH_TABLES</code>","text":"Column Name Description \u2018INTERNAL_HASH_TABLE_NAME\u2019 Hash table name \u2018TOTAL_MEMORY\u2019 Total amount of memory \u2018CONSTANT_MEMORY\u2019 Constant memory \u2018VARIABLE_MEMORY\u2019 Variable memory"},{"location":"innodb-show-status.html#other-reading","title":"Other reading","text":"<ul> <li> <p>SHOW INNODB STATUS walk through</p> </li> <li> <p>Table locks in SHOW INNODB STATUS</p> </li> </ul> <p></p>"},{"location":"innodb-show-status.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"insert.html","title":"INSERT statement","text":"<p>In MySQL, the INSERT statement adds new rows of data to a table. It follows a simple syntax pattern that beginners can easily understand.</p> Trade-Offs Description Advantages - Allows for efficient addition of new data into the database. - Provides flexibility to insert data into specific columns or all columns of a table. - Supports inserting multiple rows with a single INSERT statement. - Can be used in conjunction with SELECT statements to insert data from one table into another. Disadvantages - May result in performance overhead, especially when inserting large volumes of data or when indexes need to be updated. - Requires proper error handling to deal with constraints, such as primary key or unique constraints, to prevent duplicate entries. - Limited functionality for bulk inserts compared to specialized tools or techniques like bulk loading utilities. <p>Syntax of the INSERT Statement:</p> Option Description INSERT INTO This keyword indicates that you are performing an insertion operation into a table. table_name This is the name of the table where you want to insert the data. column1, column2, \u2026 These are optional and specify the columns into which you want to insert data. If omitted, values must be provided for all columns in the table, in the same order as they are defined in the table. VALUES This keyword introduces the list of values to be inserted into the specified columns. Alternatively, you can use the SELECT statement to retrieve data from another table and insert it into the specified columns. value1, value2, \u2026 These are the values to be inserted into the corresponding columns. The number and order of values must match the number and order of columns specified in the INSERT INTO clause. <p>The number of values in the <code>VALUES</code> clause must always match the number of columns specified or the total number of columns in the table.</p> <p>To insert data into a table, you use the INSERT INTO statement followed by the table name and a list of column names (if specified) or the <code>VALUES</code> keyword, followed by the values you want to insert into the table.</p> <pre><code>INSERT INTO table_name (column1, column2, ...)\nVALUES (value1, value2, ...);\n</code></pre> <p>In this example, we are doing the following:</p> <ul> <li> <p>Inserting a new row into the \u201cemployees\u201d table.</p> </li> <li> <p>The values 1, \u2018John Doe\u2019, and 50000 are being inserted into the \u201cid\u201d, \u201cname\u201d, and \u201csalary\u201d columns, respectively.</p> </li> </ul> <pre><code>mysql&gt; INSERT INTO employees (id, name, salary)\n        VALUES (1, 'John Doe', 50000);\n</code></pre> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SQL Basics</li> <li>SELECT</li> <li>DELETE</li> <li>UPDATE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"insert.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-audit-log-filter.html","title":"Install the Audit Log Filter","text":"<p>The <code>plugin_dir</code> system variable defines the component library location. If needed, at server startup, set the <code>plugin_dir</code> variable.</p> <p>In the <code>share</code> directory, locate the <code>audit_log_filter_linux_install.sql</code>script.</p> <p>At the time you run the script, you can select the database used to store the JSON filter tables. </p> <ul> <li>If the component is loaded, the installation script takes the database name from the <code>audit_log_filter.database</code> variable</li> <li>If the component is not loaded, but passes the <code>-D db_name</code> to the mysql client when the installation script runs, uses the <code>db_name</code>.</li> <li>If the component is not loaded and the <code>-D</code> option is not provided, the installation script creates the required tables in the default database name <code>mysql</code>.</li> </ul> <p>You can also designate a different database with the <code>audit_log_filter.database</code> system variable. The database name cannot be NULL or exceed 64 characters. If the database name is invalid, the audit log filter tables are not found.</p> <p>To install the component, run the following command:</p> <pre><code>mysql&gt; INSTALL COMPONENT 'file://component_audit_log_filter';\n</code></pre> <p>Find more information in the INSTALL COMPONENT document.</p> <p>After the installation, you can use the <code>--audit_log_filter</code> option when restarting the server. To prevent the server from not running the plugin use <code>--audit_log_filter</code> with either the <code>FORCE</code> or the <code>FORCE_PLUS_PERMANENT</code> values.</p> <p>To upgrade from <code>audit_log_filter</code> plugin in Percona Server 8.0 to <code>component_audit_log_filter</code> component in Percona Server 8.4, do the manual upgrade.</p> <p></p>"},{"location":"install-audit-log-filter.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-component.html","title":"INSTALL COMPONENT","text":"<p>The <code>INSTALL COMPONENT</code> does the following:</p> <ul> <li>Installs the component</li> <li>Activates the component</li> </ul> <p>If an error, such as a misspelled component name, occurs, the statement fails and nothing happens.</p> <p>You can install multiple components at the same time. </p>"},{"location":"install-component.html#example","title":"Example","text":"<p>The following is an example of the <code>INSTALL COMPONENT</code> statement.</p> <pre><code>mysql&gt; INSTALL COMPONENT 'file://componentA';\n</code></pre> <p></p>"},{"location":"install-component.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-data-masking-component.html","title":"Install the data masking component","text":"<p>The component has the following parts:</p> <ul> <li>A database server system table used to store the terms and dictionaries</li> <li>A <code>component_masking_functions</code> component that contains the loadable functions</li> </ul> <p>The <code>MASKING_DICTIONARIES_ADMIN</code> privilege may be required by some functions.</p>"},{"location":"install-data-masking-component.html#install-the-component","title":"Install the component","text":"<p>The following steps install the component:</p> <ol> <li> <p>Create <code>masking_dictionaries</code>.</p> <pre><code>mysql&gt; CREATE TABLE IF NOT EXISTS\nmysql.masking_dictionaries(\n    Dictionary VARCHAR(256) NOT NULL,\n    Term VARCHAR(256) NOT NULL,\n    UNIQUE INDEX dictionary_term_idx (Dictionary, Term)\n) ENGINE = InnoDB DEFAULT CHARSET=utf8mb4;\n</code></pre> </li> <li> <p>Install the data masking components and the loadable functions.</p> <pre><code>mysql&gt; INSTALL COMPONENT 'file://component_masking_functions';\n</code></pre> </li> <li> <p>The <code>MASKING_DICTIONARIES_ADMIN</code> is required to use the the following functions:</p> <ul> <li> <p><code>masking_dictionary_term_add</code></p> </li> <li> <p><code>masking_dictionary_term_remove</code></p> </li> <li> <p><code>masking_dictionary_remove</code></p> <pre><code>mysql&gt; GRANT MASKING_DICTIONARIES_ADMIN ON *.* TO &lt;user&gt;;\n</code></pre> </li> </ul> </li> </ol>"},{"location":"install-data-masking-component.html#useful-links","title":"Useful links","text":"<p>Uninstall the data masking component</p> <p>Data masking component functions</p> <p></p>"},{"location":"install-data-masking-component.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"install-myrocks.html","title":"Percona MyRocks installation guide","text":"<p>Percona MyRocks is distributed as a separate package that can be enabled as a plugin for Percona Server for MySQL 8.4 and later versions.</p> <p>Note</p> <p>File formats across different MyRocks variants may not be compatible. Percona Server for MySQL supports only Percona MyRocks.  Migrating from one variant to another requires a logical data dump and reload.</p> <ul> <li> <p>Install Percona MyRocks</p> </li> <li> <p>Remove Percona MyRocks</p> </li> </ul>"},{"location":"install-myrocks.html#install-percona-myrocks","title":"Install Percona MyRocks","text":"<p>It is recommended to install Percona software from official repositories:</p> <ol> <li> <p>Configure Percona repositories as described in Percona Software Repositories Documentation.</p> </li> <li> <p>Install Percona MyRocks using the corresponding package manager:</p> <ul> <li>For Debian or Ubuntu:</li> </ul> <pre><code>$ sudo apt install percona-server-rocksdb\n</code></pre> <ul> <li>For RHEL or CentOS:</li> </ul> <pre><code>$ sudo yum install percona-server-rocksdb\n</code></pre> </li> </ol> <p>After installation, you should see the following output:</p> Expected output <pre><code>* This release of |Percona Server| is distributed with RocksDB storage engine.\n* Run the following script to enable the RocksDB storage engine in Percona Server:\n</code></pre> <pre><code>$ ps-admin --enable-rocksdb -u &lt;mysql_admin_user&gt; -p[mysql_admin_pass] [-S &lt;socket&gt;] [-h &lt;host&gt; -P &lt;port&gt;]\n</code></pre>"},{"location":"install-myrocks.html#enable-myrocks-with-ps-admin","title":"Enable MyRocks with ps-admin","text":"<p>Run the <code>ps-admin</code> script as system root user or with sudo and provide the MySQL root user credentials to properly enable the RocksDB (MyRocks) storage engine:</p> <pre><code>$ sudo ps-admin --enable-rocksdb -u root -pPassw0rd\n</code></pre> Expected output <pre><code>Checking if RocksDB plugin is available for installation ...\nINFO: ha_rocksdb.so library for RocksDB found at /usr/lib64/mysql/plugin/ha_rocksdb.so.\n\nChecking RocksDB engine plugin status...\nINFO: RocksDB engine plugin is not installed.\n\nInstalling RocksDB engine...\nINFO: Successfully installed RocksDB engine plugin.\n</code></pre> <p>Note</p> <p>When you use the <code>ps-admin</code> script to enable Percona MyRocks, it performs the following:</p> <ul> <li> <p>Disables Transparent huge pages</p> </li> <li> <p>Installs and enables the RocksDB plugin</p> </li> </ul> <p>If the script returns no errors, Percona MyRocks should be successfully enabled on the server. You can verify it as follows:</p> <pre><code>mysql&gt; SHOW ENGINES;\n</code></pre> Expected output <pre><code>+---------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n| Engine  | Support | Comment                                                                    | Transactions | XA   | Savepoints |\n+---------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n| ROCKSDB | YES     | RocksDB storage engine                                                     | YES          | YES  | YES        |\n...\n| InnoDB  | DEFAULT | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys | YES          | YES  | YES        |\n+---------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n10 rows in set (0.00 sec)\n</code></pre> <p>Note that the RocksDB engine is not set to be default, new tables will still be created using the InnoDB (XtraDB) storage engine. To make RocksDB storage engine default, set <code>default-storage-engine=rocksdb</code> in the <code>[mysqld]</code> section of <code>my.cnf</code> and restart Percona Server for MySQL.</p> <p>Alternatively, you can add <code>ENGINE=RocksDB</code> after the <code>CREATE TABLE</code> statement for every table that you create.</p>"},{"location":"install-myrocks.html#install-myrocks-plugins","title":"Install MyRocks plugins","text":"<p>You can install MyRocks manually with a series of INSTALL PLUGIN statements. You must have the <code>INSERT</code> privilege for the <code>mysql.plugin</code> system table.</p> <p>The following statements install MyRocks:</p> <pre><code>INSTALL PLUGIN ROCKSDB SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_CFSTATS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_DBSTATS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_PERF_CONTEXT SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_PERF_CONTEXT_GLOBAL SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_CF_OPTIONS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_GLOBAL_INFO SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_COMPACTION_HISTORY SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_COMPACTION_STATS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_ACTIVE_COMPACTION_STATS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_DDL SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_INDEX_FILE_MAP SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_LOCKS SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_TRX SONAME 'ha_rocksdb.so';\nINSTALL PLUGIN ROCKSDB_DEADLOCK SONAME 'ha_rocksdb.so';\n</code></pre>"},{"location":"install-myrocks.html#remove-percona-myrocks","title":"Remove Percona MyRocks","text":"<p>It will not be possible to access tables created using the RocksDB engine with another storage engine after you remove Percona MyRocks. If you need this data, alter the tables to another storage engine. For example, to alter the <code>City</code> table to InnoDB, run the following:</p> <pre><code>mysql&gt; ALTER TABLE City ENGINE=InnoDB;\n</code></pre> <p>To disable and uninstall the RocksDB engine plugins, use the <code>ps-admin</code> script as follows:</p> <pre><code>$ sudo ps-admin --disable-rocksdb -u root -pPassw0rd\n</code></pre> Expected output <pre><code>Checking RocksDB engine plugin status...\nINFO: RocksDB engine plugin is installed.\n\nUninstalling RocksDB engine plugin...\nINFO: Successfully uninstalled RocksDB engine plugin.\n</code></pre> <p>After the engine plugins have been uninstalled, remove the Percona MyRocks package:</p> <ul> <li> <p>For Debian or Ubuntu:</p> <pre><code>$ sudo apt remove percona-server-rocksdb-8.4\n</code></pre> </li> <li> <p>For RHEL or CentOS:</p> <pre><code>$ sudo yum remove percona-server-rocksdb-80.x86_64\n</code></pre> </li> </ul> <p>Finally, remove all the MyRocks Server Variables from the configuration file (<code>my.cnf</code>) and restart Percona Server for MySQL.</p>"},{"location":"install-myrocks.html#uninstall-myrocks-plugins","title":"Uninstall MyRocks plugins","text":"<p>You can uninstall the plugins for MyRocks. You must have the <code>DELETE</code> privilege for the <code>mysql.plugin</code> system table.</p> <p>The following statements remove the MyRocks plugins:</p> <pre><code>UNINSTALL PLUGIN ROCKSDB;\nUNINSTALL PLUGIN ROCKSDB_CFSTATS;\nUNINSTALL PLUGIN ROCKSDB_DBSTATS;\nUNINSTALL PLUGIN ROCKSDB_PERF_CONTEXT;\nUNINSTALL PLUGIN ROCKSDB_PERF_CONTEXT_GLOBAL;\nUNINSTALL PLUGIN ROCKSDB_CF_OPTIONS;\nUNINSTALL PLUGIN ROCKSDB_GLOBAL_INFO;\nUNINSTALL PLUGIN ROCKSDB_COMPACTION_HISTORY;\nUNINSTALL PLUGIN ROCKSDB_COMPACTION_STATS;\nUNINSTALL PLUGIN ROCKSDB_ACTIVE_COMPACTION_STATS;\nUNINSTALL PLUGIN ROCKSDB_DDL;\nUNINSTALL PLUGIN ROCKSDB_INDEX_FILE_MAP;\nUNINSTALL PLUGIN ROCKSDB_LOCKS;\nUNINSTALL PLUGIN ROCKSDB_TRX;\nUNINSTALL PLUGIN ROCKSDB_DEADLOCK;\n</code></pre> <p></p>"},{"location":"install-myrocks.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"installation.html","title":"Install Percona Server for MySQL","text":"<p>Before installing, read the Percona Server for MySQL 8.4 Release notes.</p> <p>We gather Telemetry data in the Percona packages and Docker images.</p>"},{"location":"installation.html#install-percona-server-for-mysql-from-repositories","title":"Install Percona Server for MySQL from Repositories","text":"<p>Percona provides repositories for yum (<code>RPM</code> packages for Red Hat, CentOS and Amazon Linux AMI) and apt (<code>.deb</code> packages for Ubuntu and Debian) for software such as Percona Server for MySQL, Percona XtraBackup, and Percona Toolkit. This makes it easy to install and update your software and its dependencies through your operating system\u2019s package manager. This is the recommended way of installing where possible.</p> <p>The following guides describe the installation process for using the official Percona repositories for the <code>.deb</code> and <code>.rpm</code> packages.</p> <p>Install Percona Server for MySQL on Debian and Ubuntu  Install Percona Server for MySQL on Red Hat Enterprise Linux and CentOS </p> <p></p>"},{"location":"installation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"isolation-levels.html","title":"Isolation levels","text":"<p>In databases, isolation levels define how transactions interact with each other and the data they access. They determine the level of concurrency and consistency in a multi-user database environment.</p> <p>In MySQL, there are four isolation levels available, each offering different trade-offs between concurrency and consistency:</p> <p>Each isolation level offers a different balance between concurrency and consistency, and the choice depends on the application\u2019s specific requirements. By selecting the appropriate isolation level, developers can ensure their MySQL database applications\u2019 desired data integrity and performance level.</p>"},{"location":"isolation-levels.html#read-uncommitted","title":"Read Uncommitted","text":"<p>In the Read Uncommitted isolation level, transactions can read data that has been modified by other transactions but not yet committed. This level allows for the highest concurrency but can lead to dirty reads.</p> <pre><code>SET TRANSACTION ISOLATION LEVEL READ UNCOMMITTED;\n\n-- Perform a SELECT query to read uncommitted data\nSELECT * FROM table_name;\n</code></pre>"},{"location":"isolation-levels.html#read-committed","title":"Read Committed","text":"<p>In Read Committed isolation level, transactions can only read data that has been committed by other transactions. This level prevents dirty reads but allows for non-repeatable reads and phantom reads.</p> <pre><code>SET TRANSACTION ISOLATION LEVEL READ COMMITTED;\n\n-- Perform a SELECT query to read committed data\nSELECT * FROM table_name;\n</code></pre>"},{"location":"isolation-levels.html#repeatable-read","title":"Repeatable Read","text":"<p>In Repeatable Read isolation level, transactions can only read data that has been committed by other transactions at the start of the transaction. This level prevents dirty reads and non-repeatable reads but allows for phantom reads.</p> <pre><code>SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;\n\n-- Perform a SELECT query to read data consistently within the transaction\nSELECT * FROM table_name;\n</code></pre>"},{"location":"isolation-levels.html#serializable","title":"Serializable","text":"<p>In Serializable isolation level, transactions are executed serially, preventing any concurrent access to the data. This level provides the highest level of isolation but can lead to reduced concurrency and potential deadlock situations.</p> <pre><code>SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n\n-- Perform a SELECT query within a serializable transaction\nSELECT * FROM table_name;\n</code></pre> <p>These examples demonstrate how to set and use different isolation levels in SQL transactions, each providing consistency and concurrency control.</p>"},{"location":"isolation-levels.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Modify Tables</li> <li>Transaction Management</li> <li>Views</li> </ul>"},{"location":"isolation-levels.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"jemalloc-profiling.html","title":"Jemalloc memory allocation profiling","text":"<p>Percona Server for MySQL can take advantage of the memory-profiling ability of the jemalloc allocator. This ability provides a method to investigate memory-related issues.</p>"},{"location":"jemalloc-profiling.html#requirements","title":"Requirements","text":"<p>This memory-profiling requires jemalloc_detected. This read-only variable returns <code>true</code> if jemalloc with the profiling-enabled option is being used by Percona Server for MySQL.</p> <p>As root, customize jemalloc with the following flags:</p> Option Description \u2013enable-stats Enables statistics-gathering ability \u2013enable-prof Enables heap profiling and the ability to detect leaks. <p>Using <code>LD_PRELOAD</code>. Build the library, configure the malloc configuration with the <code>prof:true</code> string, and then use <code>LD_PRELOAD</code> to  preload the <code>libjemalloc.so</code> library. The libprocess <code>MemoryProfiler</code> class detects the library automatically and enables the profiling support.</p> <p>The following is an example of the required commands:</p> <pre><code>./configure --enable-stats --enable-prof &amp;&amp; make &amp;&amp; make install\nMALLOC_CONF=prof:true\nLD_PRELOAD=/usr/lib/libjemalloc.so\n</code></pre>"},{"location":"jemalloc-profiling.html#use-percona-server-for-mysql-with-jemalloc-with-profiling-enabled","title":"Use Percona Server for MySQL with jemalloc with profiling enabled","text":"<p>To detect if jemalloc is set, run the following command:</p> <pre><code>SELECT @@jemalloc_detected;\n</code></pre> <p>To enable jemalloc profiling in a MySQL client, run the following command:</p> <pre><code>set global jemalloc_profiling=on;\n</code></pre> <p>The malloc_stats_totals table returns the statistics, in bytes, of the memory usage. The command takes no parameters and returns the results as a table.</p> <p>The following example commands display this result:</p> <pre><code>use performance_schema;\n</code></pre> <pre><code>SELECT * FROM malloc_stats_totals;\n</code></pre> Expected output <pre><code>+----+------------+------------+------------+-------------+------------+\n| id | ALLOCATION | MAPPED     | RESIDENT   | RETAINED    | METADATA   |\n+----+------------+------------+------------+-------------+------------+\n|  1 | 390977528  | 405291008  | 520167424  | 436813824   | 9933744    |\n+----+------------+------------+------------+-------------+------------+\n1 row in set (0.00 sec)\n</code></pre> <p>The malloc_stats table returns the cumulative totals, in bytes, of several statistics per type of arena. The command takes no parameters and returns the results as a table.</p> <p>The following example commands display this result:</p> <pre><code>use performance_schema;\n</code></pre> <pre><code>mysql&gt; SELECT * FROM malloc_stats ORDER BY TYPE DESC LIMIT 3;\n</code></pre> Expected output <pre><code>+--------+-------------+-------------+-------------+-------------+\n| TYPE   | ALLOCATED   | NMALLOC     | NDALLOC     | NRESQUESTS  |\n+--------+-------------+-------------+-------------+-------------+\n| small  | 23578872    | 586156      | 0           | 2649417     |\n| large  | 367382528   | 2218        | 0           | 6355        |\n| huge   | 0           | 0           | 0           | |\n+--------+-------------+-------------+-------------+-------------+\n3 rows in set (0.00 sec)\n</code></pre>"},{"location":"jemalloc-profiling.html#dumping-the-profile","title":"Dumping the profile","text":"<p>The profiling samples the <code>malloc()</code> calls and stores the sampled stack traces in a separate location in memory. These samples can be dumped into the filesystem. A dump returns a detailed view of the state of the memory.</p> <p>The process is global; therefore, only a single concurrent run is available and only the most recent runs are stored on disk.</p> <p>Use the following command to create a profile dump file:</p> <pre><code>flush memory profile;\n</code></pre> <p>The generated memory profile dumps are written to the /tmp directory.</p> <p>You can analyze the dump files with <code>jeprof</code> program, which must be installed on the host system in the appropriate path. This program is a perl script that post-processes the dump files in their raw format. The program has no connection to the <code>jemalloc</code> library and the version numbers are not required to match.</p> <p>To verify the dump, run the following command:</p> <pre><code>ls /tmp/jeprof_mysqld*\n/tmp/jeprof_mysqld.1.0.170013202213\njeprof --show_bytes /tmp/jeprof_mysqld.1.0.170013202213 jeprof.*.heap\n</code></pre> <p>You can also access the memory profile to plot a graph of the memory use. This ability requires that <code>jeprof</code> and <code>dot</code> are in the /tmp path. For the graph to display useful information, the binary file must contain symbol information.</p> <p>Run the following command:</p> <pre><code>jeprof --dot /usr/sbin/mysqld /tmp/jeprof_mysqld.1.0.170013202213 &gt; /tmp/jeprof1.dot\ndot --Tpng /tmp/jeprof1.dot &gt; /tmp/jeprof1.png\n</code></pre> <p>Note</p> <p>An example of allocation graph.</p>"},{"location":"jemalloc-profiling.html#performance_schema-tables","title":"PERFORMANCE_SCHEMA tables","text":"<p>The following tables are implemented to retrieve memory allocation statistics for a running instance or return the cumulative number of allocations requested or allocations returned for a running instance.</p> <p>More information about the stats that are returned can be found in jemalloc.</p>"},{"location":"jemalloc-profiling.html#malloc_stats_totals","title":"malloc_stats_totals","text":"<p>The current stats for allocations. All measurements are in bytes.</p> Column Name Description ALLOCATED The total amount the application allocated ACTIVE The total amount allocated by the application of active pages. A multiple of the page size and this value is greater than or equal to the stats.allocated value. The sum does not include allocator metadata pages and stats.arenas.&lt;i&gt;.pdirty or stats.arenas.&lt;i&gt;.pmuzzy. MAPPED The total amount in chunks that are mapped by the allocator in active extents. This value does not include inactive chunks. The value is at least as large as the stats.active and is a multiple of the chunk size. RESIDENT A maximum number the allocator has mapped in physically resident data pages. All allocator metadata pages and unused dirty pages are included in this value. Pages may not be physically resident if they correspond to demand-zeroed virtual memory that has not yet been touched. This value is a maximum rather than a precise value and is a multiple of the page size. The value is greater than the stats.active. RETAINED The amount retained by the virtual memory mappings of the operating system. This value does not include any returned mappings. This type of memory, usually de-committed, untouched, or purged. The value is associated with physical memory and is excluded from mapped memory statistics. METADATA The total amount dedicated to metadata. This value contains the base allocations which are used for bootstrap-sensitive allocator metadata structures. Transparent huge pages usage is not included."},{"location":"jemalloc-profiling.html#malloc_stats","title":"malloc_stats","text":"<p>The cumulative number of allocations requested or allocations returned for a running instance.</p> Column Name Description Type The type of object: small, large, and huge ALLOCATED The number of bytes that are currently allocated to the application. NMALLOC A cumulative number of times an allocation was requested from the arena\u2019s bins. The number includes times when the allocation satisfied an allocation request or filled a relevant tcache if opt.tcache is enabled. NDALLOC A cumulative number of times an allocation was returned to the arena\u2019s bins. The number includes times when the allocation was deallocated or flushed the relevant tcache if opt.tcache is enabled. NREQUESTS The cumulative number of allocation requests satisfied."},{"location":"jemalloc-profiling.html#system-variables","title":"System variables","text":"<p>The following variables have been added:</p>"},{"location":"jemalloc-profiling.html#jemalloc_detected","title":"jemalloc_detected","text":"<p>Description: This read-only variable returns <code>true</code> if jemalloc with profiling enabled is detected. The following options are required:</p> <ul> <li> <p>Jemalloc is installed and compiled with profiling enabled</p> </li> <li> <p>Percona Server for MySQL is configured to use jemalloc by using the environment variable <code>LD_PRELOAD</code>.</p> </li> <li> <p>The environment variable <code>MALLOC_CONF</code> is set to <code>prof:true</code>.</p> </li> </ul> <p>The following options are:</p> <ul> <li> <p>Scope: Global</p> </li> <li> <p>Variable Type: Boolean</p> </li> <li> <p>Default Value: false</p> </li> </ul>"},{"location":"jemalloc-profiling.html#jemalloc_profiling","title":"jemalloc_profiling","text":"<p>Description: Enables jemalloc profiling. The variable requires jemalloc_detected.</p> <ul> <li> <p>Command Line: \u2013jemalloc_profiling[=(OFF|ON)]</p> </li> <li> <p>Config File: Yes</p> </li> <li> <p>Scope: Global</p> </li> <li> <p>Dynamic: Yes</p> </li> <li> <p>Variable Type: Boolean</p> </li> <li> <p>Default Value: OFF</p> </li> </ul>"},{"location":"jemalloc-profiling.html#disable-profiling","title":"Disable profiling","text":"<p>To disable jemalloc profiling, in a MySQL client, run the following command:</p> <pre><code>set global jemalloc_profiling=off;\n</code></pre> <p></p>"},{"location":"jemalloc-profiling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"json-overview.html","title":"JSON in MySQL","text":"<p>JSON stands for JavaScript Object Notation. It is a lightweight data-interchange format that is easy for humans to read and write. It is also easy for machines to parse and generate. MySQL supports JSON data type, allowing you to store JSON documents in your database. </p>"},{"location":"json-overview.html#create-a-table-with-json-data-type","title":"Create a table with JSON Data Type","text":"<p>Create a table that includes a column with the JSON data type.</p> <pre><code>mysql&gt; CREATE TABLE users (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    info JSON\n);\n</code></pre> <p>The columns are the following:</p> <ul> <li> <p><code>id</code> is an auto-incremented primary key.</p> </li> <li> <p><code>name</code> is a column for storing the user\u2019s name.</p> </li> <li> <p><code>info</code> is a column for storing JSON data.</p> </li> </ul>"},{"location":"json-overview.html#insert-json-data","title":"Insert JSON Data","text":"<p>Insert the JSON data into the table using the <code>INSERT</code> statement. The <code>name</code> column stores the user\u2019s name. The <code>info</code> column stores JSON data using the <code>JSON_OBJECT</code> function. This function creates a JSON object with key-value pairs.</p> <pre><code>mysql&gt; INSERT INTO users (name, info) VALUES (\n    'John Doe',\n    JSON_OBJECT('age', 30, 'city', 'New York', 'email', 'john.doe@example.com')\n);\n</code></pre>"},{"location":"json-overview.html#query-json-data","title":"Query JSON Data","text":"<p>You can query JSON data using the <code>SELECT</code> statement. The <code>name</code> column retrieves the user\u2019s name. The <code>info-&gt;&gt;'$.age'</code> expression retrieves the value of the <code>age</code> key from the JSON object stored in the <code>info</code> column.</p> <pre><code>mysql&gt; SELECT name, info-&gt;&gt;'$.age' AS age FROM users;\n</code></pre>"},{"location":"json-overview.html#update-json-data","title":"Update JSON Data","text":"<p>You can update JSON data using the <code>UPDATE</code> statement. The <code>JSON_SET</code> function updates the value of the <code>age</code> key in the JSON object stored in the <code>info</code> column. The <code>WHERE</code> clause specifies that only the row with the name \u2018John Doe\u2019 should be updated.</p> <pre><code>mysql&gt; UPDATE users\nSET info = JSON_SET(info, '$.age', 31)\nWHERE name = 'John Doe';\n</code></pre>"},{"location":"json-overview.html#delete-json-data","title":"Delete JSON Data","text":"<p>You can delete JSON data using the <code>DELETE</code> statement. This statement removes rows from the <code>users</code> table where the <code>city</code> key in the JSON object stored in the <code>info</code> column has the value \u2018New York\u2019.</p> <pre><code>mysql&gt; DELETE FROM users WHERE info-&gt;&gt;'$.city' = 'New York';\n</code></pre>"},{"location":"json-overview.html#add-new-key-value-pairs-to-json-data","title":"Add New Key-Value Pairs to JSON Data","text":"<p>You can add new key-value pairs to existing JSON data using the <code>JSON_SET</code> function. The <code>JSON_SET</code> function adds a new key <code>phone</code> with the value \u2018123-456-7890\u2019 to the JSON object stored in the <code>info</code> column.</p> <pre><code>mysql&gt; UPDATE users\nSET info = JSON_SET(info, '$.phone', '123-456-7890')\nWHERE name = 'John Doe';\n</code></pre>"},{"location":"json-overview.html#remove-key-value-pairs-from-json-data","title":"Remove Key-Value Pairs from JSON Data","text":"<p>You can remove key-value pairs from existing JSON data using the <code>JSON_REMOVE</code> function. This function removes the <code>email</code> key from the JSON object stored in the <code>info</code> column.</p> <pre><code>mysql&gt; UPDATE users\nSET info = JSON_REMOVE(info, '$.email')\nWHERE name = 'John Doe';\n</code></pre>"},{"location":"json-overview.html#use-json-functions","title":"Use JSON Functions","text":"<p>MySQL provides several functions to work with JSON data.</p>"},{"location":"json-overview.html#json_extract","title":"<code>JSON_EXTRACT</code>","text":"<p>You can extract data from a JSON document using the <code>JSON_EXTRACT</code> function. This function extracts the value of the <code>city</code> key from the JSON object stored in the <code>info</code> column.</p> <pre><code>mysql&gt; SELECT JSON_EXTRACT(info, '$.city') AS city FROM users WHERE name = 'John Doe';\n</code></pre>"},{"location":"json-overview.html#json_array","title":"<code>JSON_ARRAY</code>","text":"<p>You can create a JSON array using the <code>JSON_ARRAY</code> function. This function creates a JSON array with the values \u2018apple\u2019, \u2018banana\u2019, and \u2018cherry\u2019.</p> <pre><code>mysql&gt; INSERT INTO users (name, info) VALUES (\n    'Jane Smith',\n    JSON_ARRAY('apple', 'banana', 'cherry')\n);\n</code></pre>"},{"location":"json-overview.html#json_contains","title":"<code>JSON_CONTAINS</code>","text":"<p>You can check if a JSON document contains a specific value using the <code>JSON_CONTAINS</code> function. This function checks if the <code>info</code> column contains the value \u2018New York\u2019 for the <code>city</code> key.</p> <pre><code>mysql&gt; SELECT name FROM users WHERE JSON_CONTAINS(info, '\"New York\"', '$.city');\n</code></pre> <p></p>"},{"location":"json-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"keyring-components-plugins-overview.html","title":"Keyring components overview","text":"<p>Percona Server supports a keyring that enables internal server components to store sensitive information securely for later retrieval.</p> <p>Warning</p> <p>Enable only one keyring component at a time for each server instance. Enabling multiple keyring components is not supported and may result in data loss.</p> <p>Percona Server supports the following keyring components:</p> <p>Use the keyring file component </p> <p>Use the keyring vault component </p> <p>Use the Key Management Interoperability Protocol (KMIP) </p> <p>Use the Amazon Key Management Service (AWS KMS) </p> <p></p>"},{"location":"keyring-components-plugins-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"kill-idle-trx.html","title":"Kill idle transactions","text":"<p>This feature limits the age of idle transactions, for all transactional storage engines. If a transaction is idle for more seconds than the threshold specified, it will be killed. This prevents users from blocking InnoDB purge by mistake.</p>"},{"location":"kill-idle-trx.html#system-variables","title":"System variables","text":""},{"location":"kill-idle-trx.html#kill_idle_transaction","title":"<code>kill_idle_transaction</code>","text":"Option Description Config file Yes Scope: Global Dynamic: Yes Data type Integer Default value 0 (disabled) Units Seconds <p>If non-zero, any idle transaction will be killed after being idle for this many seconds.</p> <p></p>"},{"location":"kill-idle-trx.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"ldap-authentication.html","title":"Using LDAP authentication plugins","text":"<p>LDAP (Lightweight Directory Access Protocol) provides an alternative method to access existing directory servers, which maintain information about individuals, groups, and organizations.</p> <p>Percona Server for MySQL supports the simple LDAP authentication. The Percona simple LDAP authentication plugin is a free and Open Source implementation of the MySQL Enterprise Simple LDAP authentication plugin. Percona Server for MySQL also supports an SASL-based LDAP authentication plugin. This plugin only supports the SCRAM-SHA-1 SASL mechanism. </p>"},{"location":"ldap-authentication.html#plugin-names-and-file-names","title":"Plugin names and file names","text":"<p>The following tables show the plugin names and the file name for simple LDAP authentication and SASL-based LDAP authentication.</p> Simple LDAP authentication plugin names and library nameSASL-based LDAP authentication plugin names and library names Plugin or file Plugin name or file name Server-side plugin authentication_ldap_simple client-side plugin mysql_clear_password library file authentication_ldap_simple.so Plugin or file Plugin name or file name Server-side plugin authentication_ldap_sasl client-side plugin authentication_ldap_sasl_client library files authentication_ldap_sasl.so  authentication_ldap_sasl_client.so"},{"location":"ldap-authentication.html#how-does-the-authentication-work","title":"How does the authentication work","text":"<p>The server-side LDAP plugins work only with the specific client-side plugin:</p> <ul> <li> <p>The <code>authentication_ldap_simple</code> plugin, on the server, performs the simple LDAP authentication. The client, using <code>mysql_clear_password</code>, connects to the server. The client plugin sends the password to the server as cleartext. For this method, use a secure connection between the client and server.</p> </li> <li> <p>The <code>authentication_ldap_sasl</code> plugin, on the server, performs the SASL-based LDAP authentication. The client must use the <code>authentication_ldap_sasl_client</code> plugin. The method does not send the password to the server in cleartext. The server-side and client-side plugins use Simple Authentication and Security Layer (SASL) to send secure messages within the LDAP protocol.</p> </li> </ul> <p>For either method, the database server rejects the connection if the client user name and the host name do not match a server account.</p> <p>If a database server LDAP authentication is successful, the LDAP server searches for an entry. The LDAP server matches the user and authenticates using the LDAP password. If the database server account names the LDAP user distinguished name (DN), added by the <code>IDENTIFIED WITH &lt;plugin-name&gt; BY '&lt;auth-string&gt;'</code> clause, the LDAP server uses that value and the LDAP password provided by the client. This method fails if the DN and password have incorrect values</p> <p>If the LDAP server finds multiple matches or no match, authentication fails.</p> <p>If the password is correct, and the LDAP server finds a match, then LDAP authentication succeeds. The LDAP server returns the LDAP entry and the authentication plugin determines the authenticated user\u2019s name based on the entry. If the LDAP entry has no group attribute, the plugin returns the client user name as the authenticated name. If the LDAP entry has a group attribute, the plugin returns the group value as the authenticated name.</p> <p>The database server compares the client user name to the authenticated user name. If these names are the same, the database server uses the client user name to check for privileges. If the name differs, then the database server looks for an account that matches the authenticated name.</p>"},{"location":"ldap-authentication.html#prerequisites-for-authentication","title":"Prerequisites for authentication","text":"<p>The LDAP authentication plugins required the following:</p> <ul> <li> <p>An available LDAP server</p> </li> <li> <p>The LDAP server must contain the LDAP user accounts to be authenticated</p> </li> <li> <p>The OpenLDAP client library must be available on the same system as the plugin</p> </li> </ul> <p>The SASL-based LDAP authentication additionally requires the following:</p> <ul> <li> <p>Configure the LDAP server to communicate with a SASL server</p> </li> <li> <p>Available SASL client library on the same system as the client plugin.</p> </li> <li> <p>Services are configured to use the supported SCRAM-SHA-1 SASL mechanism</p> </li> </ul>"},{"location":"ldap-authentication.html#install-the-plugins","title":"Install the plugins","text":"<p>You can use either of the following methods to install the plugins.</p>"},{"location":"ldap-authentication.html#load-the-plugins-at-server-start","title":"Load the plugins at server start","text":"<p>Use either of the following methods to load the plugin at server start.</p> Load the simple LDAP authenticationLoad the SASL_based LDAP authentication plugin <p>Add the following statements to your <code>my.cnf</code> file to load simple LDAP authentication:</p> <pre><code>[mysqld]\nplugin-load-add=authentication_ldap_simple.so\nauthentication_ldap_simple_server_host=127.0.0.1\nauthentication_ldap_simple_bind_base_dn='dc=percona, dc=com'\n</code></pre> <p>Restart the server for the changes to take effect.</p> <p>Add the following statements to your <code>my.cnf</code> file to load the SASL-based LDAP authentication:</p> <pre><code>[mysqld]\nplugin-load-add=authentication_ldap_sasl.so\nauthentication_ldap_sasl_server_host=127.0.0.1\nauthentication_ldap_sasl_bind_base_dn='dc=percona, dc=com'\n</code></pre>"},{"location":"ldap-authentication.html#load-the-plugins-at-runtime","title":"Load the plugins at runtime","text":"<p>Install the plugin with the following statements.</p> Load the simple LDAP authentication pluginLoad the SASL-based LDAP authentication plugin <pre><code>mysql&gt; INSTALL PLUGIN authentication_ldap_simple SONAME 'authentication_ldap_simple.so';\n</code></pre> <p>To set and persist values at runtime, use the following statements:</p> <pre><code>mysql&gt; SET PERSIST authentication_ldap_simple_server_host='127.0.0.1';\nmysql&gt; SET PERSIST authentication_ldap_simple_bind_base_dn='dc=percona, dc=com';\n</code></pre> <pre><code>mysql&gt; INSTALL PLUGIN authentication_ldap_sasl SONAME 'authentication_ldap_sasl.so';\n</code></pre> <p>To set and persist values at runtime, use the following statements:</p> <pre><code>mysql&gt; SET PERSIST authentication_ldap_sasl_server_host='127.0.0.1';\nmysql&gt; SET PERSIST authentication_ldap_sasl_bind_base_dn='dc=percona, dc=com';\n</code></pre>"},{"location":"ldap-authentication.html#create-a-user-using-simple-ldap-authentication","title":"Create a user using simple LDAP authentication","text":"<p>There are several methods to add or modify a user.</p> Use authentication_ldap_simple pluginUse the authentication string in simple LDAP <p>In the <code>CREATE USER</code> statement or the <code>ALTER USER</code> statement, for simple LDAP authentication, you can specify the <code>authentication_ldap_simple</code> plugin in the <code>IDENTIFIED WITH</code> clause:</p> <pre><code>mysql&gt; CREATE USER ... IDENTIFIED WITH authentication_ldap_simple;\n</code></pre> <p>Using the <code>IDENTIFIED WITH</code> clause, the database server assigns the specified plugin.</p> <p>If you provide the optional authentication string clause, \u2018cn,ou,dc,dc\u2019 in the example, the string is stored along with the password.</p> <pre><code>mysql&gt; CREATE USER ... IDENTIFIED WITH authentication_ldap_simple BY 'cn=[user name],ou=[organization unit],dc=[domain component],dc=com'\n</code></pre> <p>Unless the authentication_ldap_simple_group_role_mapping variable is used, creating a user with an authentication string does not use the following system variables:</p> <ul> <li> <p>authentication_ldap_simple_bind_base_dn</p> </li> <li> <p>authentication_ldap_simple_bind_root_dn</p> </li> <li> <p>authentication_ldap_simple_bind_root_pwd</p> </li> <li> <p>authentication_ldap_simple_user_search_attr</p> </li> <li> <p>authentication_ldap_simple_group_search_attr</p> </li> </ul> <p>Creating the user with <code>IDENTIFIED BY authentication_ldap_simple</code> uses the variables.</p> <p>Creating the user with the authentication_ldap_simple_group_role_mapping variable also adds the authentication_ldap_simple_bind_root_dn and authentication_ldap_simple_bind_root_pwd variables.</p>"},{"location":"ldap-authentication.html#create-a-user-using-sasl-based-ldap-authentication","title":"Create a user using SASL-based LDAP authentication","text":"<p>There are several methods to add or modify a user.</p> Use authentication_ldap_sasl pluginUse the authentication string in SASL-based LDAP <p>For SASL-based LDAP authentication, in the <code>CREATE USER</code> statement or the <code>ALTER USER</code> statement, you can specify the <code>authentication_ldap_sasl</code> plugin:</p> <pre><code>mysql&gt; CREATE USER ... IDENTIFIED WITH authentication_ldap_sasl;\n</code></pre> <p>If you provide the optional authentication string clause, \u2018cn,ou,dc,dc\u2019 in the example, the string is stored along with the password.</p> <pre><code>mysql&gt; CREATE USER ... IDENTIFIED WITH authentication_ldap_sasl BY 'cn=[user name],ou=[organization unit],dc=[domain component],dc=com'\n</code></pre> <p>Unless the authentication_ldap_sasl_group_role_mapping variable is used, creating a user with an authentication string does not use the following system variables:</p> <ul> <li> <p>authentication_ldap_sasl_bind_base_dn</p> </li> <li> <p>authentication_ldap_sasl_bind_root_dn</p> </li> <li> <p>authentication_ldap_sasl_bind_root_pwd</p> </li> <li> <p>authentication_ldap_sasl_user_search_attr</p> </li> <li> <p>authentication_ldap_sasl_group_search_attr</p> </li> </ul> <p>Creating the user with <code>IDENTIFIED BY authentication_ldap_sasl</code> uses the variables. </p> <p>Creating the user with the authentication_ldap_sasl_group_role_mapping variable also adds theauthentication_ldap_sasl_bind_root_dn and authentication_ldap_sasl_bind_root_pwd variables.</p>"},{"location":"ldap-authentication.html#examples","title":"Examples","text":"<p>The following sections are examples of using simple LDAP authentication and SASL-based LDAP authentication.</p> <p>For the purposes of this example, we use the following LDAP user:</p> <pre><code>uid=ldapuser,ou=testusers,dc=percona,dc=com\n</code></pre> Simple LDAP authenticationSASL-based LDAP authentication <p>The following example configures an LDAP user and connects to the database server.</p> <p>Create a database server account for <code>ldapuser</code> with the following statement:</p> <pre><code>mysql&gt; CREATE USER 'ldapuser'@'localhost' IDENTIFIED WITH authentication_ldap_simple BY 'uid=ldapuser,ou=testusers,dc=percona,dc=com';\n</code></pre> <p>The authentication string does not include the LDAP password. This password must be provided by the client user when they connect.</p> <pre><code>mysql&gt; mysql --user=ldapuser --password --enable-cleartext-plugin\n</code></pre> <p>The user enters the <code>ldapuser</code> password. The client sends the password as cleartext, which is necessary when using a server-side LDAP library without SASL. The following actions may minimize the risk:</p> <ul> <li>Require that the database server clients explicitly enable the <code>mysql_clear_password</code> plugin with <code>--enable-cleartext-plugin</code>. </li> <li>Require that the database server clients connect to the database server using an encrypted connection</li> </ul> <p>The following example configures an LDAP user and connect to the database server.</p> <p>Create a database server account for <code>ldapuser</code> with the following statement:</p> <pre><code>mysql&gt; CREATE USER 'ldapuser'@'localhost' IDENTIFIED WITH authentication_ldap_sasl AS 'uid=ldapuser,ou=testusers,dc=percona,dc=com';\n</code></pre> <p>The authentication string does not include the LDAP password. This password must be provided by the client user when they connect.</p> <p>Clients connect ot the database server by providing the database server user name and LDAP password:</p> <pre><code>mysql&gt; mysql --user=ldapuser --password\n</code></pre> <p>The authentication is similar to the authentication method used by simple LDAP authentication, except that the client and the database server SASL LDAP plugins use SASL messages. These messages are secure within the LDAP protocol.</p>"},{"location":"ldap-authentication.html#uninstall-the-plugins","title":"Uninstall the plugins","text":"<p>If you installed either plugin at server startup, remove those options from the <code>my.cnf</code> file, remove any startup options that set LDAP system variables, and restart the server.</p> Uninstall the simple LDAP authentication pluginUninstall the SASL-based LDAP authentication plugin <p>If you installed the plugins at runtime, run the following statements:</p> <pre><code>mysql&gt; UNINSTALL PLUGIN authentication_ldap_simple;\n</code></pre> <p>If you used <code>SET_PERSIST</code>, use <code>RESET PERSIST</code> to remove the settings.</p> <p>If you installed the plugins at runtime, run the following statements:</p> <pre><code>mysql&gt; UNINSTALL PLUGIN authentication_ldap_sasl;\n</code></pre> <p>If you used <code>SET_PERSIST</code>, use <code>RESET PERSIST</code> to remove the settings.</p> <p></p>"},{"location":"ldap-authentication.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"ldap-system-variables.html","title":"LDAP authentication plugin system variables","text":""},{"location":"ldap-system-variables.html#authentication-system-variables","title":"Authentication system variables","text":"<p>The installation adds the following variables:</p> Variable name Description authentication_ldap_sasl_bind_base_dn Base distinguished name authentication_ldap_sasl_bind_root_dn Root distinguished name authentication_ldap_sasl_bind_root_dn_pwd Password for the root distinguished name authentication_ldap_sasl_ca_path Absolute path of the certificate authority authentication_ldap_sasl_fallback_server_host If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server authentication_ldap_sasl_fallback_server_port The port number for the fallback server authentication_ldap_sasl_group_role_mapping A list of LDAP group names - MySQL role pairs authentication_ldap_sasl_group_search_attr Name of the attribute that specifies the group names in the LDAP directory entries authentication_ldap_sasl_group_search_filter Custom group search filter authentication_ldap_sasl_init_pool_size Initial size of the connection pool to the LDAP server authentication_ldap_sasl_log_status logging level authentication_ldap_sasl_max_pool_size Maximum size of the pool of connections to the LDAP server authentication_ldap_sasl_server_host LDAP server host authentication_ldap_sasl_server_port LDAP server TCP/IP port number authentication_ldap_sasl_ssl If plugin connections to the LDAP server use the SSL protocol (ldaps://) authentication_ldap_sasl_tls If plugin connections to the LDAP server are secured with STARTTLS (ldap://) authentication_ldap_sasl_user_search_attr Name of the attribute that specifies user names in the LDAP directory entries authentication_ldap_simple_bind_base_dn Base distinguished name authentication_ldap_simple_bind_root_dn Root distinguished name authentication_ldap_simple_bind_root_dn_pwd Password for the root distinguished name authentication_ldap_simple_ca_path Absolute path of the certificate authority authentication_ldap_simple_fallback_server_host If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server authentication_ldap_simple_fallback_server_port The port number for the fallback server authentication_ldap_simple_group_role_mapping A list of LDAP group names - MySQL role pairs authentication_ldap_simple_group_search_attr Name of the attribute that specifies the group names in the LDAP directory entries authentication_ldap_simple_group_search_filter Custom group search filter authentication_ldap_simple_init_pool_size Initial size of the connection pool to the LDAP server authentication_ldap_simple_log_status logging level authentication_ldap_simple_max_pool_size Maximum size of the pool of connections to the LDAP server authentication_ldap_simple_server_host LDAP server host authentication_ldap_simple_server_port LDAP server TCP/IP port number authentication_ldap_simple_ssl If plugin connections to the LDAP server use the SSL protocol (ldaps://) authentication_ldap_simple_tls If plugin connections to the LDAP server are secured with STARTTLS (ldap://) authentication_ldap_simple_user_search_attr Name of the attribute that specifies user names in the LDAP directory entries <p>The following variables are described in detail:</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_bind_base_dn","title":"<code>authentication_ldap_sasl_bind_base_dn</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-bind-base-dn=value Scope Global Dynamic Yes Data type String Default NULL <p>The base distinguished name (DN) for SASL-based LDAP authentication. You can limit the search scope by using the variable as the base of the search.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_bind_root_dn","title":"<code>authentication_ldap_sasl_bind_root_dn</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-bind-root-dn=value Scope Global Dynamic Yes Data type String Default NULL <p>The <code>root</code> distiguished name (DN) used to authenticate SASL-based LDAP. When performing a search, this variable is used with <code>authentication_ldap_sasl_bind_root_pwd</code> as the authenticating credentials to the LDAP server.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_bind_root_pwd","title":"<code>authentication_ldap_sasl_bind_root_pwd</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-bind-root-pwd=value Scope Global Dynamic Yes Data type String Default NULL <p>The <code>root</code> password used to authenticate against SASL-based LDAP server. This variable is used with <code>authentication_ldap_sasl_bind_root_dn</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_ca_path","title":"<code>authentication_ldap_sasl_ca_path</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-ca_path=value Scope Global Dynamic Yes Data type String Default NULL <p>The certificate authority\u2019s absolute path used to verify the LDAP certificate.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_fallback_server_host","title":"<code>authentication_ldap_sasl_fallback_server_host</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-fallback-server-host Scope Global Dynamic Yes Type Sting Default NULL <p>Use with <code>authentication_ldap_sasl_fallback_server_port</code>.</p> <p>If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server and authenticate using that server.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_fallback_server_port","title":"<code>authentication_ldap_sasl_fallback_server_port</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-fallback-server-port Scope Global Dynamic Yes Type Integer Default NULL <p>Use with <code>authentication_ldap_sasl_fallback_server_host</code>.</p> <p>If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server and authenticate using that server.</p> <p>If the fallback server host has a value, and the fallback port is 0, users can specify multiple fallback servers.</p> <p>Use this format to specify multiple fallback servers: <code>authentication_ldap_sasl_fallback_server_host=\"ldap(s)://host:port,ldap(s)://host2:port2</code>, for example.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_group_role_mapping","title":"<code>authentication_ldap_sasl_group_role_mapping</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-group-role-mapping=value Scope Global Dynamic Yes Data type String Default Null <p>When an LDAP user logs in, the server checks if the LDAP user is a member of the specified group. If the user is, then the server automatically grants the database server roles to the user.</p> <p>The variable has this format: <code>&lt;ldap_group&gt;=&lt;mysql_role&gt;,&lt;ldap_group2&gt;=&lt;mysql_role2&gt;,</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_group_search_attr","title":"<code>authentication_ldap_sasl_group_search_attr</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-group-search-attr=value Scope Global Dynamic Yes Data type String Default cn <p>The attribute name that specifies group names in the LDAP directory entries for SASL-based LDAP authentication.  </p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_group_search_filter","title":"<code>authentication_ldap_sasl_group_search_filter</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-group-search-filter=value Scope Global Dynamic Yes Data type String Default (|(&amp;(objectClass=posixGroup)(memberUid=%s))(&amp;(objectClass=group)(member=%s))) <p>The custom group search filter for SASL-based LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_init_pool_size","title":"<code>authentication_ldap_sasl_init_pool_size</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-init-pool-size=value Scope Global Dynamic Yes Data type Integer Default 10 Minimum value 0 Maximum value 32767 Unit connections <p>The initial size of the connection pool to the LDAP server for SASL-based LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_log_status","title":"<code>authentication_ldap_sasl_log_status</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-log-status=value Scope Global Dynamic Yes Data type Integer Default 1 Minimum value 1 Maximum value 6 <p>The logging level for messages written to the error log for SASL-based LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_max_pool_size","title":"<code>authentication_ldap_sasl_max_pool_size</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-max-pool-size=value Scope Global Dynamic Yes Data type Integer Default 1000 Minimum value 0 Maximum value 32767 Unit connections <p>The maximum connection pool size to the LDAP server in SASL-based LDAP authentication. The variable is used with <code>authentication_ldap_sasl_init_pool_size</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_server_host","title":"<code>authentication_ldap_sasl_server_host</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-server-host=value Scope Global Dynamic Yes Data type String Default NULL <p>The LDAP server host used for SASL-based LDAP authentication.  The LDAP server host can be an IP address or a host name.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_server_port","title":"<code>authentication_ldap_sasl_server_port</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-server-port=value Scope Global Dynamic Yes Data type Integer Default 389 Minimum value 1 Maximum value 32376 <p>The LDAP server TCP/IP port number used for SASL-based LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_ssl","title":"<code>authentication_ldap_sasl_ssl</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-ssl=value Scope Global Dynamic Yes Data type Boolean Default OFF <p>If this variable is enabled, the plugin connects to the server with SSL.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_tls","title":"<code>authentication_ldap_sasl_tls</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-tls=value Scope Global Dynamic Yes Data type Boolean Default OFF <p>If this variable is enabled, the plugin connects to the server with TLS.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_sasl_user_search_attr","title":"<code>authentication_ldap_sasl_user_search_attr</code>","text":"Option Description Command-line \u2013authentication-ldap-sasl-user-search-attr=value Scope Global Dynamic Yes Data type String Default uid <p>The attribute name that specifies the user names in LDAP directory entries in SASL-based LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_bind_base_dn","title":"<code>authentication_ldap_simple_bind_base_dn</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-bind-base-dn=value Scope Global Dynamic Yes Data type String Default NULL <p>The base distinguished name (DN) for simple LDAP authentication. You can limit the search scope by using the variable as the base of the search.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_bind_root_dn","title":"<code>authentication_ldap_simple_bind_root_dn</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-bind-root-dn=value Scope Global Dynamic Yes Data type String Default NULL <p>The <code>root</code> distinguished name (DN) used to authenticate simple LDAP. When performing a search, this variable is used with <code>authentication_ldap_simple_bind_root_pwd</code> as the authenticating credentials to the LDAP server.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_bind_root_pwd","title":"<code>authentication_ldap_simple_bind_root_pwd</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-bind-root-pwd=value Scope Global Dynamic Yes Data type String Default NULL <p>The <code>root</code> password used to authenticate against simple LDAP server. This variable is used with <code>authentication_ldap_simple_bind_root_dn</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_ca_path","title":"<code>authentication_ldap_simple_ca_path</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-ca_path=value Scope Global Dynamic Yes Data type String Default NULL <p>The certificate authority\u2019s absolute path used to verify the LDAP certificate.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_fallback_server_host","title":"<code>authentication_ldap_simple_fallback_server_host</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-fallback-server-host Scope Global Dynamic Yes Type Sting Default NULL <p>Use with <code>authentication_ldap_simple_fallback_server_port</code>.</p> <p>If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server and authenticate using that server.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_fallback_server_port","title":"<code>authentication_ldap_simple_fallback_server_port</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-fallback-server-port Scope Global Dynamic Yes Type Integer Default NULL <p>Use with <code>authentication_ldap_simple_fallback_server_host</code>.</p> <p>If the primary server is unavailable, the authentication plugin attempts to connect to the fallback server and authenticate using that server.</p> <p>If the fallback server host has a value, and the fallback port is 0, users can specify multiple fallback servers.</p> <p>Use this format to specify multiple fallback servers: <code>authentication_ldap_simple_fallback_server_host=\"ldap(s)://host:port,ldap(s)://host2:port2</code>, for example.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_group_role_mapping","title":"<code>authentication_ldap_simple_group_role_mapping</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-group-role-mapping=value Scope Global Dynamic Yes Data type String Default Null <p>When an LDAP user logs in, the server checks if the LDAP user is a member of the specified group. If the user is, then the server automatically grants the database server roles to the user.</p> <p>The variable has this format: <code>&lt;ldap_group&gt;=&lt;mysql_role&gt;,&lt;ldap_group2&gt;=&lt;mysql_role2&gt;,</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_group_search_attr","title":"<code>authentication_ldap_simple_group_search_attr</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-group-search-attr=value Scope Global Dynamic Yes Data type String Default cn <p>The attribute name that specifies group names in the LDAP directory entries for simple LDAP authentication.  </p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_group_search_filter","title":"<code>authentication_ldap_simple_group_search_filter</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-group-search-filter=value Scope Global Dynamic Yes Data type String Default (|(&amp;(objectClass=posixGroup)(memberUid=%s))(&amp;(objectClass=group)(member=%s))) <p>The custom group search filter for simple LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_init_pool_size","title":"<code>authentication_ldap_simple_init_pool_size</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-init-pool-size=value Scope Global Dynamic Yes Data type Integer Default 10 Minimum value 0 Maximum value 32767 Unit connections <p>The initial size of the connection pool to the LDAP server for simple LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_log_status","title":"<code>authentication_ldap_simple_log_status</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-log-status=value Scope Global Dynamic Yes Data type Integer Default 1 Minimum value 1 Maximum value 6 <p>The logging level for messages written to the error log for simple LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_max_pool_size","title":"<code>authentication_ldap_simple_max_pool_size</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-max-pool-size=value Scope Global Dynamic Yes Data type Integer Default 1000 Minimum value 0 Maximum value 32767 Unit connections <p>The maximum connection pool size to the LDAP server in simple LDAP authentication. The variable is used with <code>authentication_ldap_simple_init_pool_size</code>.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_server_host","title":"<code>authentication_ldap_simple_server_host</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-server-host=value Scope Global Dynamic Yes Data type String Default NULL <p>The LDAP server host used for simple LDAP authentication.  The LDAP server host can be an IP address or a host name.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_server_port","title":"<code>authentication_ldap_simple_server_port</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-server-port=value Scope Global Dynamic Yes Data type Integer Default 389 Minimum value 1 Maximum value 32376 <p>The LDAP server TCP/IP port number used for simple LDAP authentication.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_ssl","title":"<code>authentication_ldap_simple_ssl</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-ssl=value Scope Global Dynamic Yes Data type Boolean Default OFF <p>If this variable is enabled, the plugin connects to the server with SSL.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_tls","title":"<code>authentication_ldap_simple_tls</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-tls=value Scope Global Dynamic Yes Data type Boolean Default OFF <p>If this variable is enabled, the plugin connects to the server with TLS.</p>"},{"location":"ldap-system-variables.html#authentication_ldap_simple_user_search_attr","title":"<code>authentication_ldap_simple_user_search_attr</code>","text":"Option Description Command-line \u2013authentication-ldap-simple-user-search-attr=value Scope Global Dynamic Yes Data type String Default uid <p>The attribute name that specifies the user names in LDAP directory entries in simple LDAP authentication.</p> <p></p>"},{"location":"ldap-system-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"libcoredumper.html","title":"Libcoredumper","text":""},{"location":"libcoredumper.html#using-libcoredumper","title":"Using libcoredumper","text":"<p>A core dump file is the documented moment of a computer when either the computer or an application exits. Developers examine the dump as one of the tasks when searching for the cause of a failure.</p> <p>The <code>libcoredumper</code> is a free and Open Source fork of <code>google-coredumper</code>, enhanced to work on newer Linux versions, and GCC and CLANG.</p>"},{"location":"libcoredumper.html#enabling-the-libcoredumper","title":"Enabling the <code>libcoredumper</code>","text":"<p>Enable core dumps for troubleshooting purposes.</p> <p>To enable the <code>libcoredumper</code>, add the <code>coredumper</code> variable to the <code>mysqld</code> section of <code>my.cnf</code>. This variable is independent of the older <code>core-file</code> variable.</p> <p>The variable can have the following possible values:</p> Value Description Blank The core dump is saved under MySQL datadir and named core. A path ending with / The core dump is saved under the specified directory and named core. Full path with a filename The core dump is saved under the specified directory and filename <p>Restart the server.</p>"},{"location":"libcoredumper.html#verifying-the-libcoredumper-is-active","title":"Verifying the <code>libcoredumper</code> is active","text":"<p>MySQL writes to the log when generating a core file and delegates the core dump operation to the Linux kernel. </p> <pre><code>Writing a core file\n</code></pre> <p>MySQL using the <code>libcoredumper</code> to generate the file creates the following message in the log:</p> <pre><code>Writing a core file using lib coredumper\n</code></pre> <p>Every core file adds a crash timestamp instead of a PID for the following reasons:</p> <ul> <li>Correlates the core file with the crash. MySQL prints a UTC timestamp on the crash log.</li> </ul> <pre><code>10:02:09 UTC - mysqld got signal 11;\n</code></pre> <ul> <li>Stores multiple core files.</li> </ul> <p>Note</p> <p>For example, operators and containers run as the process id of PID 1. If the process ID is used to identify the core file, each container crash generates a core dump that overwrites the previous core file.</p>"},{"location":"libcoredumper.html#disabling-the-libcoredumper","title":"Disabling the libcoredumper","text":"<p>You can disable the libcoredumper. A core file may contain sensitive data and takes disk space.</p> <p>To disable the <code>libcoredumper</code> you must do the following:</p> <ol> <li> <p>In the <code>mysqld</code> section of my.cnf, remove the <code>libcoredumper</code> variable.</p> </li> <li> <p>Restart the server.</p> </li> </ol> <p></p>"},{"location":"libcoredumper.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"log-connection-error.html","title":"Too many connections warning","text":"<p>If the log_error_verbosity system variable is set to <code>2</code> or higher, this feature generates the <code>Too many connections</code> warning in the log.</p> <p></p>"},{"location":"log-connection-error.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"log-warnings-suppress.html","title":"Suppress warning messages","text":"<p>This feature is intended to provide a general mechanism (using <code>log_warnings_silence</code>) to disable certain warning messages to the log file. Currently, it is only implemented for disabling message #1592 warnings. This feature does not influence warnings delivered to a client. Please note that warning code needs to be a string:</p> <pre><code>mysql&gt; SET GLOBAL log_warnings_suppress = '1592';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.00 sec)\n</code></pre>"},{"location":"log-warnings-suppress.html#system-variables","title":"System variables","text":""},{"location":"log-warnings-suppress.html#log_warnings_suppress","title":"<code>log_warnings_suppress</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type SET Default (empty string) Range (empty string), 1592 <p>It is intended to provide a more general mechanism for disabling warnings than existed previously with variable suppress_log_warning_1592. When set to the empty string, no warnings are disabled. When set to <code>1592</code>, warning #1592 messages (unsafe statement for binary logging) are suppressed. In the future, the ability to optionally disable additional warnings may also be added.</p>"},{"location":"log-warnings-suppress.html#related-reading","title":"Related reading","text":"<ul> <li> <p>MySQL bug 42851</p> </li> <li> <p>MySQL InnoDB replication</p> </li> <li> <p>InnoDB Startup Options and System Variables</p> </li> <li> <p>InnoDB Error Handling</p> </li> </ul> <p></p>"},{"location":"log-warnings-suppress.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"manage-apparmor-profiles.html","title":"Managing AppArmor profiles","text":""},{"location":"manage-apparmor-profiles.html#understanding-apparmor-risks-in-mysql-development","title":"Understanding AppArmor Risks in MySQL Development","text":"<p>While AppArmor profiles help secure your MySQL server, misconfiguring them can lead to unexpected behavior and potential security vulnerabilities. Here\u2019s why careful review and testing are crucial when making changes:</p>"},{"location":"manage-apparmor-profiles.html#potential-risks-of-misconfigured-apparmor-profiles","title":"Potential risks of misconfigured AppArmor profiles","text":"Misconfiguration Description Overly restrictive profiles These profiles might prevent MySQL from accessing necessary files or resources, hindering its functionality and causing errors. Imagine a profile accidentally blocking MySQL from writing to its log files, rendering them useless for troubleshooting. Underly permissive profiles Profiles with insufficient restrictions could allow unauthorized access to MySQL\u2019s files or functionalities. This creates a security risk, as an attacker exploiting a vulnerability might leverage a permissive profile to gain more control over the server. Incorrect profile assignment Assigning the wrong profile to a process can lead to either of the issues mentioned above.  For instance, accidentally assigning a profile meant for a different service to MySQL could have unintended consequences."},{"location":"manage-apparmor-profiles.html#importance-of-careful-review-and-testing","title":"Importance of careful review and testing","text":"<p>By carefully reviewing and testing your AppArmor profile changes, you can minimize the risks associated with misconfigurations and ensure a secure and functional MySQL environment.</p> <ul> <li> <p>Review your changes thoroughly: Double-check your AppArmor profile modifications to ensure they grant MySQL the necessary permissions while maintaining security. </p> </li> <li> <p>Test your changes in a safe environment: Before deploying changes to a production server, test them in a staging environment that mimics your production setup. This test allows you to identify and fix any issues caused by the AppArmor profile adjustments without impacting your live MySQL instance.</p> </li> </ul>"},{"location":"manage-apparmor-profiles.html#install-the-utilities-used-to-control-apparmor","title":"Install the utilities used to control AppArmor","text":"<p>Install the <code>apparmor-utils</code> package to work with profiles. Use these utilities to create, update, enforce, switch to complain mode, and disable profiles, as needed:</p> <pre><code>$ sudo apt install apparmor-utils\n</code></pre> Expected output <pre><code>Reading package lists... Done\nBuilding dependency tree\n...\nThe following additional packages will be installed:\n    python3-apparmor python3-libapparmor\n...\n</code></pre>"},{"location":"manage-apparmor-profiles.html#add-the-mysqld-profile","title":"Add the mysqld profile","text":"<p>Add the mysqld profile with the following procedure:</p> <ol> <li> <p>Download the current version of the AppArmor:</p> <pre><code>$ wget https://raw.githubusercontent.com/percona/percona-server/release-8.4.0-1/build-ps/debian/percona-server-server.install\n</code></pre> Expected output <pre><code>...\nSaving to 'apparamor-profile`\n...\n</code></pre> </li> <li> <p>Move the file to /etc/apparmor.d/usr.sbin.mysqld</p> <pre><code>$ sudo mv apparmor-profile /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> </li> <li> <p>Create an empty file for editing:</p> <pre><code>$ sudo touch /etc/apparmor.d/local/usr.sbin.mysqld\n</code></pre> </li> <li> <p>Load the profile:</p> <pre><code>$ sudo apparmor_parser -r -T -W /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> </li> <li> <p>Restart Percona Server for MySQL:</p> <pre><code>$ sudo systemctl restart mysql\n</code></pre> </li> <li> <p>Verify the profile status:</p> <pre><code>$ sudo aa-status\n</code></pre> Expected output <pre><code>...\nprocesses are in enforce mode\n...\n/usr/sbin/mysqld (100840)\n...\n</code></pre> </li> </ol>"},{"location":"manage-apparmor-profiles.html#check-the-current-status","title":"Check the current status","text":"<p>As root or using <code>sudo</code>, you can check the AppArmor status:</p> <pre><code>$ sudo aa-status\n</code></pre> Expected output <pre><code>apparmor module is loaded.\n34 profiles are loaded.\n32 profiles in enforce mode.\n...\n    /usr/sbin/mysqld\n...\n2 profiles in complain mode.\n...\n3 profiles have profiles defined.\n...\n0 processes are in complain mode.\n0 processes are unconfined but have a profile defined.\n</code></pre>"},{"location":"manage-apparmor-profiles.html#switch-a-profile-to-complain-mode","title":"Switch a profile to complain mode","text":"<p>Switch a profile to complain mode when the program is in your path with this command:</p> <pre><code>$ sudo aa-complain &lt;program&gt;\n</code></pre> <p>If needed, specify the program\u2019s path in the command:</p> <pre><code>$ sudo aa-complain /sbin/&lt;program&gt;\n</code></pre> <p>If the profile is not stored in <code>/etc/apparmor.d/</code>, use the following command:</p> <pre><code>$ sudo aa-complain /path/to/profiles/&lt;program&gt;\n</code></pre>"},{"location":"manage-apparmor-profiles.html#switch-a-profile-to-enforce-mode","title":"Switch a profile to enforce mode","text":"<p>Switch a profile to the enforce mode when the program is in your path with this command:</p> <pre><code>$ sudo aa-enforce &lt;program&gt;\n</code></pre> <p>If needed, specify the program\u2019s path in the command:</p> <pre><code>$ sudo aa-enforce /sbin/&lt;program&gt;\n</code></pre> <p>If the profile is not stored in <code>/etc/apparmor.d/</code>, use the following command:</p> <pre><code>$ sudo aa-enforce /path/to/profile\n</code></pre>"},{"location":"manage-apparmor-profiles.html#disable-one-profile","title":"Disable one profile","text":"<p>You can disable a profile but it is recommended to Switch a Profile to Complain mode.</p> <p>Use either of the following methods to disable a profile:</p> <pre><code>$ sudo ln -s /etc/apparmor.d/usr.sbin.mysqld /etc/apparmor.d/disable/\n$ sudo apparmor_parser -R /etc/apparmor.d/usr.sbin.mysqld\n</code></pre> <p>or</p> <pre><code>$ aa-disable /etc/apparmor.d/usr.sbin.mysqld\n</code></pre>"},{"location":"manage-apparmor-profiles.html#reload-all-profiles","title":"Reload all profiles","text":"<p>Run either of the following commands to reload all profiles:</p> <pre><code>$ sudo service apparmor reload\n</code></pre> <p>or</p> <pre><code>$ sudo systemctl reload apparmor.service\n</code></pre>"},{"location":"manage-apparmor-profiles.html#reload-one-profile","title":"Reload one profile","text":"<p>To reload one profile, run the following: You may need to restart the program for some changes to take effect.</p>"},{"location":"manage-apparmor-profiles.html#useful-links","title":"Useful links:","text":"<p>AppArmor AppArmor Profiles Disable AppArmor Configure AppArmor Troubleshoot AppArmor</p> <p></p>"},{"location":"manage-apparmor-profiles.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"manage-audit-log-filter.html","title":"Manage the Audit Log Filter files","text":"<p>The Audit Log Filter files have the following potential results:</p> <ul> <li>Consume a large amount of disk space</li> <li>Grow large</li> </ul> <p>You can manage the space by using log file rotation. This operation renames and then rotates the current log file and then uses the original name on a new current log file. You can rotate the file either manually or automatically.</p> <p>If automatic rotation is enabled, you can prune the log file. This pruning operation can be based on either the log file age or combined log file size.</p>"},{"location":"manage-audit-log-filter.html#manual-log-rotation","title":"Manual log rotation","text":"<p>The default setting for <code>audit_log_filter.rotate_on_size</code> is 1GB. If this option is set to <code>0</code>, the audit log filter component does not do an automatic rotation of the log file. You must do the rotation manually with this setting.</p> <p>The <code>SELECT audit_log_rotate()</code> command renames the file and creates a new audit log filter file with the original name. You must have the <code>AUDIT_ADMIN</code> privilege. </p> <p>The files are pruned if either <code>audit_log_filter.max_size</code> or <code>audit_log_filter.prune_seconds</code> have a value greater than 0 (zero) and <code>audit_log_filter.rotate_on_size</code> &gt; 0.</p> <p>After the files have been renamed, you must manually remove any archived audit log filter files. The renamed audit log filter files can be read by <code>audit_log_read()</code>. The <code>audit_log_read()</code> does not find the logs if the name pattern differs from the current pattern.</p> <p></p>"},{"location":"manage-audit-log-filter.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"manage-selinux-modes.html","title":"Manage SELinux modes","text":"<p>SELinux, or Security-Enhanced Linux, is a security module that provides access control policies. It enhances the system\u2019s security by allowing administrators to define rules restricting how applications and users can access resources. SELinux operates in three different modes: Disabled, Permissive, and Enforcing.</p>"},{"location":"manage-selinux-modes.html#disabled-mode","title":"Disabled Mode","text":"<p>In Disabled mode, SELinux is completely turned off. The system does not enforce any SELinux policies, and there is no SELinux security checking. Applications and processes run without any restrictions imposed by SELinux. This mode is typically used for troubleshooting or when SELinux is not needed.</p> <p>To set SELinux to Disabled mode, you need to edit the SELinux configuration file. Open the file <code>/etc/selinux/config</code> with a text editor and set the <code>SELINUX</code> parameter to <code>disabled</code>:</p> <pre><code>$ SELINUX=disabled\n</code></pre> <p>Save the file and reboot the system for the change to take effect.</p>"},{"location":"manage-selinux-modes.html#permissive-mode","title":"Permissive Mode","text":"<p>In Permissive mode, SELinux policies are not enforced, but violations are logged. This mode is useful for troubleshooting and for understanding what SELinux would block without actually blocking anything. Applications and processes run as if SELinux is not enforcing policies, but administrators can see which actions would have been denied if SELinux were enforcing.</p> <p>To set SELinux to Permissive mode, you can edit the SELinux configuration file <code>/etc/selinux/config</code> and set the <code>SELINUX</code> parameter to <code>permissive</code>:</p> <pre><code>$ SELINUX=permissive\n</code></pre> <p>Save the file and reboot the system. Alternatively, you can change to Permissive mode temporarily without rebooting by running the following command as root:</p> <pre><code>$ setenforce 0\n</code></pre>"},{"location":"manage-selinux-modes.html#enforcing-mode","title":"Enforcing Mode","text":"<p>In Enforcing mode, SELinux enforces all policies and denies access based on the rules defined in the policy. This mode is the default and most secure mode. SELinux actively restricts actions of applications and processes based on the policies in place. Any violation of the rules results in access being denied and logged.</p> <p>To set SELinux to Enforcing mode, edit the SELinux configuration file <code>/etc/selinux/config</code> and set the <code>SELINUX</code> parameter to <code>enforcing</code>:</p> <pre><code>$ SELINUX=enforcing\n</code></pre> <p>Save the file and reboot the system. To change to Enforcing mode temporarily without rebooting, you can use the following command as root:</p> <pre><code>$ setenforce 1\n</code></pre>"},{"location":"manage-selinux-modes.html#how-to-check-the-selinux-mode","title":"How to check the SELinux mode","text":"<p>You can check which mode SELinux is currently running in by using a few terminal commands.</p>"},{"location":"manage-selinux-modes.html#use-the-sestatus-command","title":"Use the <code>sestatus</code> command","text":"<p>To check the current SELinux mode, you can use the <code>sestatus</code> command. This command shows the status of SELinux, including the mode it is operating in. Type the following command and press Enter:</p> <pre><code>$ sestatus\n</code></pre> Expected output <pre><code>SELinux status:                 enabled\nSELinuxfs mount:                /sys/fs/selinux\nSELinux root directory:         /etc/selinux\nLoaded policy name:             targeted\nCurrent mode:                   enforcing\nMode from config file:          enforcing\nPolicy MLS status:              enabled\nPolicy deny_unknown status:     allowed\nMax kernel policy version:      31\n</code></pre> Result Description Current mode This line shows the mode SELinux is currently operating in. It can be \u201cenforcing\u201d, \u201cpermissive\u201d, or \u201cdisabled\u201d. Enforcing SELinux is actively enforcing its policies and blocking any actions that are not allowed. Permissive SELinux is not blocking actions, but it logs any actions that would be blocked in enforcing mode. Disabled SELinux is completely turned off, and no policies are enforced or logged. Mode from config file This line shows the mode that SELinux is configured to use at boot time, which might be different from the current mode if changes were made without rebooting."},{"location":"manage-selinux-modes.html#use-the-getenforce-command","title":"Use the <code>getenforce</code> command","text":"<p>Another command to check the current SELinux mode is <code>getenforce</code>. Type the following command and press Enter:</p> <pre><code>$ getenforce\n</code></pre> Expected output <pre><code>Enforcing\n</code></pre>"},{"location":"manage-selinux-modes.html#check-the-configuration-file","title":"Check the configuration file","text":"<p>You can also check the SELinux configuration file to see what mode SELinux is set to use when the system boots. Open the configuration file located at <code>/etc/selinux/config</code> using a text editor. For example, you can use <code>cat</code> to view the file contents:</p> <pre><code>$ cat /etc/selinux/config\n</code></pre> Expected output <pre><code>SELINUX=enforcing\n</code></pre>"},{"location":"manage-selinux-modes.html#how-to-switch-the-selinux-mode","title":"How to switch the SELinux mode","text":"<p>Switching the SELinux mode changes how the Security-Enhanced Linux (SELinux) system controls access and enforces policies on your system.</p>"},{"location":"manage-selinux-modes.html#switch-selinux-mode-temporarily","title":"Switch SELinux mode temporarily","text":"<p>To switch SELinux mode temporarily, use the <code>setenforce</code> command. This change will last until the system is rebooted.</p> <pre><code>$ sudo setenforce 1\n</code></pre> <p>To check if the mode has changed, run <code>sestatus</code>.</p>"},{"location":"manage-selinux-modes.html#switch-selinux-mode-permanently","title":"Switch SELinux Mode permanently","text":"<p>To make the change permanent, you need to edit the SELinux configuration file. This file is usually located at <code>/etc/selinux/config</code>.</p> <ol> <li> <p>Open the configuration file with a text editor. For example, using <code>nano</code>:</p> <pre><code>$ sudo nano /etc/selinux/config\n</code></pre> </li> <li> <p>Look for the line that starts with <code>SELINUX=</code>. It will be followed by the current mode: <code>enforcing</code>, <code>permissive</code>, or <code>disabled</code>.</p> </li> <li> <p>Change the value to the desired mode.</p> </li> <li> <p>Save the file and exit the text editor.</p> </li> </ol> <p>To apply the permanent change, reboot the system. After the system restarts, check the SELinux mode with <code>sestatus</code> to ensure the change took effect.</p>"},{"location":"manage-selinux-modes.html#changing-selinux-mode-for-a-service","title":"Changing SELinux mode for a service","text":"<p>SELinux (Security-Enhanced Linux) controls access and permissions for processes and users on a Linux system. SELinux has different modes: Enforcing, Permissive, and Disabled. When you change the SELinux mode for a specific service, you can control how strictly SELinux policies apply to that service. This can be useful when you need to test or troubleshoot services without disabling SELinux entirely.</p>"},{"location":"manage-selinux-modes.html#step-1-identify-the-service","title":"Step 1: Identify the Service","text":"<p>First, identify the service for which you want to change the SELinux mode. For example, let\u2019s say you want to change the SELinux mode for the Apache web server (<code>httpd</code>).</p>"},{"location":"manage-selinux-modes.html#step-2-check-current-selinux-context","title":"Step 2: Check current SELinux context","text":"<p>Check the current SELinux context of the service to understand its current mode and permissions. You can use the <code>ps</code> command with <code>-Z</code> option to view the SELinux context of a running process.</p> <pre><code>$ ps -eZ | grep httpd\n</code></pre> <p>This command displays the SELinux context for all <code>httpd</code> processes.</p>"},{"location":"manage-selinux-modes.html#step-3-create-a-custom-selinux-policy-module","title":"Step 3: Create a Custom SELinux Policy Module","text":"<p>To change the SELinux mode for a specific service, you create a custom SELinux policy module. This module will move the service to a permissive domain while keeping the rest of the system in enforcing mode.</p> <p>Create a policy file, for example, <code>httpd_permissive.te</code>:</p> <pre><code>$ nano httpd_permissive.te\n</code></pre> <p>Add the following content to the file:</p> <pre><code>policy_module(httpd_permissive, 1.0)\n\ngen_permissive(httpd_t)\n</code></pre> <p>This policy module tells SELinux to make the <code>httpd_t</code> domain permissive.</p>"},{"location":"manage-selinux-modes.html#step-4-compile-and-install-the-policy-module","title":"Step 4: Compile and Install the Policy Module","text":"<p>Compile the policy module using the <code>checkmodule</code> and <code>semodule_package</code> commands:</p> <pre><code>$ checkmodule -M -m -o httpd_permissive.mod httpd_permissive.te\n$ semodule_package -o httpd_permissive.pp -m httpd_permissive.mod\n</code></pre> <p>Install the compiled policy module using the <code>semodule</code> command:</p> <pre><code>$ semodule -i httpd_permissive.pp\n</code></pre> <p>This installs the custom SELinux policy module, making the <code>httpd</code> service run in permissive mode.</p>"},{"location":"manage-selinux-modes.html#step-5-verify-the-changes","title":"Step 5: Verify the Changes","text":"<p>Restart the service to apply the changes:</p> <pre><code>$ systemctl restart httpd\n</code></pre> <p>Check the SELinux context again to ensure the <code>httpd</code> service is running in the permissive domain:</p> <pre><code>$ ps -eZ | grep httpd\n</code></pre> <p>You should see the <code>httpd</code> processes with a permissive context.</p>"},{"location":"manage-selinux-modes.html#step-6-monitor-logs-and-adjust-policies","title":"Step 6: Monitor Logs and Adjust Policies","text":"<p>While the service is in a permissive domain, SELinux logs any policy violations without enforcing them. Monitor the logs to identify and resolve issues. Use <code>audit2allow</code> to generate new policies if needed:</p> <pre><code>$ ausearch -m avc -c httpd | audit2allow -M httpd_custom\n$ semodule -i httpd_custom.pp\n</code></pre> <p>This command sequence helps you create and install new SELinux policies based on logged violations, refining your SELinux configuration.</p> <p></p>"},{"location":"manage-selinux-modes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"misc-info-schema-tables.html","title":"Misc. INFORMATION_SCHEMA tables","text":"<p>This page lists the <code>INFORMATION_SCHEMA</code> tables added to standard MySQL by Percona Server for MySQL that don\u2019t exist elsewhere in the documentation.</p>"},{"location":"misc-info-schema-tables.html#temporary-tables","title":"Temporary tables","text":"<p>Note</p> <p>This feature implementation is considered tech preview quality.</p> <p>Only the temporary tables that were explicitly created with CREATE TEMPORARY TABLE or ALTER TABLE are shown, and not the ones created to process complex queries.</p>"},{"location":"misc-info-schema-tables.html#information_schemaglobal_temporary_tables","title":"<code>INFORMATION_SCHEMA.GLOBAL_TEMPORARY_TABLES</code>","text":"Column Name Description \u2018SESSION_ID\u2019 \u2018MySQL connection id\u2019 \u2018TABLE_SCHEMA\u2019 \u2018Schema in which the temporary table is created\u2019 \u2018TABLE_NAME\u2019 \u2018Name of the temporary table\u2019 \u2018ENGINE\u2019 \u2018Engine of the temporary table\u2019 \u2018NAME\u2019 \u2018Internal name of the temporary table\u2019 \u2018TABLE_ROWS\u2019 \u2018Number of rows of the temporary table\u2019 \u2018AVG_ROW_LENGTH\u2019 \u2018Average row length of the temporary table\u2019 \u2018DATA_LENGTH\u2019 \u2018Size of the data (Bytes)\u2019 \u2018INDEX_LENGTH\u2019 \u2018Size of the indexes (Bytes)\u2019 \u2018CREATE_TIME\u2019 \u2018Date and time of creation of the temporary table\u2019 \u2018UPDATE_TIME\u2019 \u2018Date and time of the latest update of the temporary table\u2019 <p>This table holds information on the temporary tables that exist for all connections. You don\u2019t need the <code>SUPER</code> privilege to query this table.</p>"},{"location":"misc-info-schema-tables.html#information_schematemporary_tables","title":"<code>INFORMATION_SCHEMA.TEMPORARY_TABLES</code>","text":"Column Name Description \u2018SESSION_ID\u2019 \u2018MySQL connection id\u2019 \u2018TABLE_SCHEMA\u2019 \u2018Schema in which the temporary table is created\u2019 \u2018TABLE_NAME\u2019 \u2018Name of the temporary table\u2019 \u2018ENGINE\u2019 \u2018Engine of the temporary table\u2019 \u2018NAME\u2019 \u2018Internal name of the temporary table\u2019 \u2018TABLE_ROWS\u2019 \u2018Number of rows of the temporary table\u2019 \u2018AVG_ROW_LENGTH\u2019 \u2018Average row length of the temporary table\u2019 \u2018DATA_LENGTH\u2019 \u2018Size of the data (Bytes)\u2019 \u2018INDEX_LENGTH\u2019 \u2018Size of the indexes (Bytes)\u2019 \u2018CREATE_TIME\u2019 \u2018Date and time of creation of the temporary table\u2019 \u2018UPDATE_TIME\u2019 \u2018Date and time of the latest update of the temporary table\u2019 <p>This table holds information on the temporary tables existing for the running connection.</p> <p></p>"},{"location":"misc-info-schema-tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"modify-tables.html","title":"Modify a table","text":"<p>The <code>ALTER TABLE</code> command acts like a toolkit that allows you to change the structure of existing tables. You can add new sections (columns), remove old ones, or change how information is stored (data types). This command helps you adapt your database to new needs or improve efficiency.</p>"},{"location":"modify-tables.html#things-to-watch-out-for","title":"Things to Watch Out For","text":"<ul> <li> <p>Data loss: Be careful when modifying tables! Deleting a section (column) or changing its format might erase existing data in that section.</p> </li> <li> <p>Slowdowns: Altering large tables or making complex changes can slow down the database, especially during busy times. It might take longer for things to work while the changes are applied.</p> </li> <li> <p>Locks: MySQL might temporarily lock the tables you\u2019re working on when making changes. This operation means other users can\u2019t access or modify that data until the changes are complete, which can cause delays for others.</p> </li> </ul>"},{"location":"modify-tables.html#modify-table-example","title":"Modify table example","text":"<p>After a table has been created, you may need to modify its structure or properties. Percona Server for MySQL provides the <code>ALTER TABLE</code> command for making such modifications. You can add, modify, or drop columns, change data types, add constraints, and more using this command.</p> <p>The following is an example using an <code>ALTER TABLE</code> command:</p> <pre><code>mysql&gt; ALTER TABLE users\nADD COLUMN age INT,\nMODIFY COLUMN email VARCHAR(255),\nDROP COLUMN username;\n</code></pre>"},{"location":"modify-tables.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Tables</li> <li>Create table</li> <li>Isolation Levels</li> <li>Transaction Management</li> <li>Views</li> </ul>"},{"location":"modify-tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-added-features.html","title":"Updated supported features","text":"<p>The following is a list of the latest supported features:</p> <ul> <li> <p>Percona Server for MySQLsupports <code>SELECT FOR UPDATE SKIP LOCKED/NOWAIT</code>. The transaction isolation level must be <code>READ COMMITTED</code>.</p> </li> <li> <p>Percona Server for MySQL adds the ability to cancel ongoing manual compactions. The cancel methods are the following:</p> <ul> <li> <p>Using either Control+C (from a session) or KILL (from another session) for client sessions running manual compactions by <code>SET GLOBAL rocksdb_compact_cf (variable)</code>.</p> </li> <li> <p>Using a global variable <code>rocksdb_cancel_manual_compactions</code> to cancel all ongoing manual compactions.</p> </li> </ul> </li> <li> <p>Percona Server for MySQL adds supported for Generated Columns and index are supported.</p> </li> <li> <p>Percona Server for MySQL adds support for explicit DEFAULT value expressions. </p> </li> </ul> <p></p>"},{"location":"myrocks-added-features.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-column-families.html","title":"MyRocks column families","text":"<p>MyRocks stores all data in a single server instance as a collection of key-value pairs within the log structured merge tree data structure. This is a flat data structure that requires that keys be unique throughout the whole data structure. MyRocks incorporates table IDs and index IDs into the keys.</p> <p>Each key-value pair belongs to a column family. It is a data structure similar in concept to tablespaces. Each column family has distinct attributes, such as block size, compression, sort order, and MemTable. Utilizing these attributes, MyRocks effectively uses column families to store indexes.</p> <p>On system initialization, MyRocks creates two column families.  The <code>__system__</code> column family is reserved by MyRocks; no user created tables or indexes belong to this column family.  The <code>default</code> column family is the location for the indexes created by the user when you a column family is not explicitly specified.</p> <p>To be able to apply a custom block size, compression, or sort order you need to create an index in its own column family using the <code>COMMENT</code> clause.</p> <p>The following example demonstrates how to place the <code>PRIMARY KEY</code> into the cf1 column family and the index <code>kb</code> \u2014 into the cf2 column family.</p> <pre><code>CREATE TABLE t1 (a INT, b INT,\nPRIMARY KEY(a) COMMENT 'cfname=cf1',\nKEY kb(b) COMMENT 'cfname=cf2')\nENGINE=ROCKSDB;\n</code></pre> <p>The column family name is specified as the value of the cfname attribute at the beginning of the <code>COMMENT</code> clause. The name is case sensitive and may not contain leading or trailing whitespace characters.</p> <p>The <code>COMMENT</code> clause may contain other information following the semicolon character (;) after the column family name: \u2018cfname=foo; special column family\u2019. If the column family cannot be created, MyRocks uses the default column family.</p> <p>Warning</p> <p>The <code>cfname</code> attribute must be all lowercase. Place the equals sign (=) in front of the column family name without any whitespace on both sides of it.</p> <pre><code>COMMENT 'cfname=Foo; Creating the Foo family name'\n</code></pre> <p>See also</p> <p>Using <code>COMMENT</code> to Specify Column Family Names with Multiple Table Partitions https://github.com/facebook/mysql-5.6/wiki/Column-Families-on-Partitioned-Tables.</p>"},{"location":"myrocks-column-families.html#controlling-the-number-of-column-families-to-reduce-memory-consumption","title":"Controlling the number of column families to reduce memory consumption","text":"<p>Each column family has its own MemTable. It is an in-memory data structure where data are written to before they are flushed to SST files. The queries also use MemTables first. To reduce the overall memory consumption, the number of active column families should stay low.</p> <p>With the option <code>|opt.no-create-column-family|</code> set to true, the <code>COMMENT</code> clause will not treat cfname as a special token; it will not be possible to create column families using the <code>COMMENT</code> clause.</p>"},{"location":"myrocks-column-families.html#column-family-options","title":"Column family options","text":"<p>On startup, the server applies the <code>|opt.default-cf-options|</code> option to all existing column families. You may use the <code>|opt.override-cf-options|</code> option to override the value of any attribute of a chosen column family.</p> <p>Note that the options <code>|opt.dcfo|</code> and <code>|opt.ocfo|</code> are read-only at runtime.</p> <p>At runtime, use the the <code>|opt.update-cf-options|</code> option to update some column family attributes.</p> <p></p>"},{"location":"myrocks-column-families.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-data-loading.html","title":"Data loading","text":"<p>By default, MyRocks configurations are optimized for short transactions, and not for data loading. MyRocks has a couple of special session variables to speed up data loading dramatically.</p>"},{"location":"myrocks-data-loading.html#sorted-bulk-loading","title":"Sorted bulk loading","text":"<p>If your data is guaranteed to be loaded in primary key order, then this method is recommended. This method works by dropping any secondary keys first, loading data into your table in primary key order, and then restoring the secondary keys via Fast Secondary Index Creation.</p>"},{"location":"myrocks-data-loading.html#creating-secondary-indexes","title":"Creating secondary indexes","text":"<p>When loading data into empty tables, it is highly recommended to drop all secondary indexes first, then loading data, and adding all secondary indexes after finishing loading data. MyRocks has a feature called <code>Fast Secondary Index Creation</code>. Fast Secondary Index Creation is automatically used when executing <code>CREATE INDEX</code> or <code>ALTER TABLE ... ADD INDEX</code>. With Fast Secondary Index Creation, the secondary index entries are directly written to bottommost RocksDB levels and bypassing compaction. This significantly reduces total write volume and CPU time for decompressing and compressing data on higher levels.</p>"},{"location":"myrocks-data-loading.html#loading-data","title":"Loading data","text":"<p>As described above, loading data is highly recommended for tables with primary key only (no secondary keys), with all secondary indexes added after loading data.</p> <p>When loading data into MyRocks tables, there are two recommended session variables:</p> <pre><code>SET session sql_log_bin=0;\nSET session rocksdb_bulk_load=1;\n</code></pre> <p>When converting from large MyISAM/InnoDB tables, either by using the <code>ALTER</code> or <code>INSERT INTO SELECT</code> statements it\u2019s recommended that you create MyRocks tables as below (in case the table is sufficiently big it will cause the server to consume all the memory and then be terminated by the OOM killer):</p> <pre><code>SET session sql_log_bin=0;\nSET session rocksdb_bulk_load=1;\nALTER TABLE large_myisam_table ENGINE=RocksDB;\nSET session rocksdb_bulk_load=0;\n</code></pre> <p>Using <code>sql_log_bin=0</code> avoids writing to binary logs.</p> <p>With rocksdb_bulk_load set to <code>1</code>, MyRocks enters special mode to write all inserts into bottommost RocksDB levels, and skips writing data into MemTable and the following compactions. This is very efficient way to load data.</p> <p>The rocksdb_bulk_load mode operates with a few conditions:</p> <ul> <li> <p>None of the data being bulk loaded can overlap with existing data in the table. The easiest way to ensure this is to always bulk load into an empty table, but the mode will allow loading some data into the table, doing other operations, and then returning and bulk loading addition data if there is no overlap between what is being loaded and what already exists.</p> </li> <li> <p>The data may not be visible until bulk load mode is ended (i.e. the rocksdb_bulk_load is set to zero again). The method that is used is building up SST files which will later be added as-is to the database. Until a particular SST has been added the data will not be visible to the rest of the system, thus issuing a <code>SELECT</code> on the table currently being bulk loaded will only show older data and will likely not show the most recently added rows. Ending the bulk load mode will cause the most recent SST file to be added. When bulk loading multiple tables, starting a new table will trigger the code to add the most recent SST file to the system \u2013 as a result, it is inadvisable to interleave <code>INSERT</code> statements to two or more tables during bulk load mode.</p> </li> </ul> <p>By default, the rocksdb_bulk_load mode expects all data be inserted in primary key order (or reversed order). If the data is in the reverse order (i.e. the data is descending on a normally ordered primary key or is ascending on a reverse ordered primary key), the rows are cached in chunks to switch the order to match the expected order.</p> <p>Inserting one or more rows out of order will result in an error and may result in some of the data being inserted in the table and some not. To resolve the problem, one can either fix the data order of the insert, truncate the table, and restart.</p>"},{"location":"myrocks-data-loading.html#unsorted-bulk-loading","title":"Unsorted bulk loading","text":"<p>If your data is not ordered in primary key order, then this method is recommended. With this method, secondary keys do not need to be dropped and restored. However, writing to the primary key no longer goes directly to SST files, and are written to temporary files for sorted first, so there is extra cost to this method.</p> <p>To allow for loading unsorted data:</p> <pre><code>SET session sql_log_bin=0;\nSET session rocksdb_bulk_load_allow_unsorted=1;\nSET session rocksdb_bulk_load=1;\n...\nSET session rocksdb_bulk_load=0;\nSET session rocksdb_bulk_load_allow_unsorted=0;\n</code></pre> <p>Note that rocksdb_bulk_load_allow_unsorted can only be changed when rocksdb_bulk_load is disabled (set to <code>0</code>). In this case, all input data will go through an intermediate step that writes the rows to temporary SST files, sorts them rows in the primary key order, and then writes to final SST files in the correct order.</p>"},{"location":"myrocks-data-loading.html#other-approaches","title":"Other approaches","text":"<p>If rocksdb_commit_in_the_middle is enabled, MyRocks implicitly commits every rocksdb_bulk_load_size records (default is <code>1,000</code>) in the middle of your transaction. If your data loading fails in the middle of the statement (<code>LOAD DATA</code> or bulk <code>INSERT</code>), rows are not entirely rolled back, but some of rows are stored in the table. To restart data loading, you\u2019ll need to truncate the table and loading data again.</p> <p>Warning</p> <p>If you are loading large data without enabling rocksdb_bulk_load or rocksdb_commit_in_the_middle, please make sure transaction size is small enough. All modifications of the ongoing transactions are kept in memory.</p>"},{"location":"myrocks-data-loading.html#other-reading","title":"Other reading","text":"<ul> <li> <p>Data Loading - this document has been used as a source for writing this documentation</p> </li> <li> <p>ALTER TABLE \u2026 ENGINE=ROCKSDB uses too much memory</p> </li> </ul> <p></p>"},{"location":"myrocks-data-loading.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-differences.html","title":"Differences between Percona MyRocks and Facebook MyRocks","text":"<p>The original MyRocks was developed by Facebook and works with their implementation of MySQL. Percona MyRocks is a branch of MyRocks for Percona Server for MySQL and includes the following differences from the original implementation:</p> <ul> <li>The behavior of the <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code> statement depends on the transaction isolation level.</li> </ul> Storage Engine Transaction isolation level <code>READ COMMITTED</code> <code>REPEATABLE READ</code> InnoDB Success Success Facebook MyRocks Fail Success (MyRocks engine only; read-only, as all MyRocks engine snapshots) Percona MyRocks Fail with any DML which would violate the read-only snapshot constraint Success (read-only snapshots independent of the engines in use) <ul> <li>Percona MyRocks includes the <code>lz4</code> and <code>zstd</code> statically linked libraries.</li> </ul> <p></p>"},{"location":"myrocks-differences.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-gap-locks-detection.html","title":"Gap locks detection","text":"<p>The Gap locks detection is based on a Facebook MySQL patch.</p> <p>If a transactional storage engine does not support gap locks (for example MyRocks) and a gap lock is being attempted while the transaction isolation level is either <code>REPEATABLE READ</code> or <code>SERIALIZABLE</code>, the following SQL error will be returned to the client and no actual gap lock will be taken on the effected rows.</p> Error message <pre><code>ERROR HY000: Using Gap Lock without full unique key in multi-table or multi-statement transactions is not allowed. You need to either rewrite queries to use all unique key columns in WHERE equal conditions, or rewrite to single-table, single-statement transaction.\n</code></pre> <p></p>"},{"location":"myrocks-gap-locks-detection.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-index.html","title":"Percona MyRocks introduction","text":"<p>MyRocks is a storage engine for MySQL based on RocksDB, an embeddable, persistent key-value store. Percona MyRocks is an implementation for Percona Server for MySQL.</p> <p>The RocksDB store is based on the log-structured merge-tree (or LSM tree). It is optimized for fast storage and combines outstanding space and write efficiency with acceptable read performance. As a result, MyRocks has the following advantages compared to other storage engines, if your workload uses fast storage, such as SSD:</p> <ul> <li> <p>Requires less storage space</p> </li> <li> <p>Provides more storage endurance</p> </li> <li> <p>Ensures better IO capacity</p> </li> </ul> <p>Percona MyRocks Installation Guide</p> <p>MyRocks Limitations</p> <p>Differences between Percona MyRocks and Facebook MyRocks</p> <p>MyRocks Column Families</p> <p>MyRocks Server Variables</p> <p>MyRocks Information Schema Tables</p> <p>Performance Schema MyRocks changes</p> <p></p>"},{"location":"myrocks-index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-information-schema-tables.html","title":"MyRocks Information Schema tables","text":"<p>When you install the MyRocks plugin for MySQL, the Information Schema is extended to include the following tables:</p>"},{"location":"myrocks-information-schema-tables.html#rocksdb_global_info","title":"ROCKSDB_GLOBAL_INFO","text":""},{"location":"myrocks-information-schema-tables.html#columns","title":"Columns","text":"Column Name Type TYPE varchar(513) NAME varchar(513) VALUE varchar(513)"},{"location":"myrocks-information-schema-tables.html#rocksdb_cfstats","title":"ROCKSDB_CFSTATS","text":""},{"location":"myrocks-information-schema-tables.html#columns_1","title":"Columns","text":"Column Name Type CF_NAME varchar(193) STAT_TYPE varchar(193) VALUE bigint(8)"},{"location":"myrocks-information-schema-tables.html#rocksdb_trx","title":"ROCKSDB_TRX","text":"<p>This table stores mappings of RocksDB transaction identifiers to MySQL client identifiers to enable associating a RocksDB transaction with a MySQL client operation.</p>"},{"location":"myrocks-information-schema-tables.html#columns_2","title":"Columns","text":"Column Name Type TRANSACTION_ID bigint(8) STATE varchar(193) NAME varchar(193) WRITE_COUNT bigint(8) LOCK_COUNT bigint(8) TIMEOUT_SEC int(4) WAITING_KEY varchar(513) WAITING_COLUMN_FAMILY_ID int(4) IS_REPLICATION int(4) SKIP_TRX_API int(4) READ_ONLY int(4) HAS_DEADLOCK_DETECTION int(4) NUM_ONGOING_BULKLOAD int(4) THREAD_ID int(8) QUERY varchar(193)"},{"location":"myrocks-information-schema-tables.html#rocksdb_cf_options","title":"ROCKSDB_CF_OPTIONS","text":""},{"location":"myrocks-information-schema-tables.html#columns_3","title":"Columns","text":"Column Name Type CF_NAME varchar(193) OPTION_TYPE varchar(193) VALUE varchar(193)"},{"location":"myrocks-information-schema-tables.html#rocksdb_active_compaction_stats","title":"ROCKSDB_ACTIVE_COMPACTION_STATS","text":""},{"location":"myrocks-information-schema-tables.html#columns_4","title":"Columns","text":"Column Name Type THREAD_ID bigint CF_NAME varchar(193) INPUT_FILES varchar(513) OUTPUT_FILES varchar(513) COMPACTION_REASON varchar(513)"},{"location":"myrocks-information-schema-tables.html#rocksdb_compaction_history","title":"ROCKSDB_COMPACTION_HISTORY","text":""},{"location":"myrocks-information-schema-tables.html#columns_5","title":"Columns","text":"Column Name Type THREAD_ID bigint CF_NAME varchar(513) INPUT_LEVEL integer OUTPUT_LEVEL integer INPUT_FILES varchar(513) OUTPUT_FILES varchar(513) COMPACTION_REASON varchar(513) START_TIMESTAMP bigint END_TIMESTAMP bigint"},{"location":"myrocks-information-schema-tables.html#rocksdb_compaction_stats","title":"ROCKSDB_COMPACTION_STATS","text":""},{"location":"myrocks-information-schema-tables.html#columns_6","title":"Columns","text":"Column Name Type CF_NAME varchar(193) LEVEL varchar(513) TYPE varchar(513) VALUE double"},{"location":"myrocks-information-schema-tables.html#rocksdb_dbstats","title":"ROCKSDB_DBSTATS","text":""},{"location":"myrocks-information-schema-tables.html#columns_7","title":"Columns","text":"Column Name Type STAT_TYPE varchar(193) VALUE bigint(8)"},{"location":"myrocks-information-schema-tables.html#rocksdb_ddl","title":"ROCKSDB_DDL","text":""},{"location":"myrocks-information-schema-tables.html#columns_8","title":"Columns","text":"Column Name Type TABLE_SCHEMA varchar(193) TABLE_NAME varchar(193) PARTITION_NAME varchar(193) INDEX_NAME varchar(193) COLUMN_FAMILY int(4) INDEX_NUMBER int(4) INDEX_TYPE smallint(2) KV_FORMAT_VERSION smallint(2) TTL_DURATION bigint(8) INDEX_FLAGS bigint(8) CF varchar(193) AUTO_INCREMENT bigint(8) unsigned"},{"location":"myrocks-information-schema-tables.html#rocksdb_index_file_map","title":"ROCKSDB_INDEX_FILE_MAP","text":""},{"location":"myrocks-information-schema-tables.html#columns_9","title":"Columns","text":"Column Name Type COLUMN_FAMILY int(4) INDEX_NUMBER int(4) SST_NAME varchar(193) NUM_ROWS bigint(8) DATA_SIZE bigint(8) ENTRY_DELETES bigint(8) ENTRY_SINGLEDELETES bigint(8) ENTRY_MERGES bigint(8) ENTRY_OTHERS bigint(8) DISTINCT_KEYS_PREFIX varchar(400)"},{"location":"myrocks-information-schema-tables.html#rocksdb_live_files_metadata","title":"ROCKSDB_LIVE_FILES_METADATA","text":"Column Name Type CF_NAME varchar(193) LEVEL varchar(513) NAME varchar(513) DB_PATH varchar(513) FILE_NUMBER bigint FILE_TYPE varchar(193) SIZE bigint RELATIVE_FILENAME varchar(193) DIRECTORY varchar(513) TEMPERATURE varchar(193) FILE_CHECKSUM varchar(513) FILE_CHECKSUM_FUNC_NAME varchar(193) SMALLEST_SEQNO bigint LARGEST_SEQNO bigint SMALLEST_KEY varchar(513) LARGEST_KEY varchar(513) NUM_READS_SAMPLED bigint BEING_COMPACTED tinyint NUM_ENTRIES bigint NUM_DELETIONS bigint OLDEST_BLOB_FILE_NUMBER bigint OLDEST_ANCESTER_TIME bigint FILE_CREATION_TIME bigint"},{"location":"myrocks-information-schema-tables.html#rocksdb_locks","title":"ROCKSDB_LOCKS","text":"<p>This table contains the set of locks granted to MyRocks transactions.</p>"},{"location":"myrocks-information-schema-tables.html#columns_10","title":"Columns","text":"Column Name Type COLUMN_FAMILY_ID int(4) TRANSACTION_ID bigint KEY varchar(513) MODE varchar(32)"},{"location":"myrocks-information-schema-tables.html#rocksdb_perf_context","title":"ROCKSDB_PERF_CONTEXT","text":""},{"location":"myrocks-information-schema-tables.html#columns_11","title":"Columns","text":"Column Name Type TABLE_SCHEMA varchar(193) TABLE_NAME varchar(193) PARTITION_NAME varchar(193) STAT_TYPE varchar(193) VALUE bigint(8)"},{"location":"myrocks-information-schema-tables.html#rocksdb_perf_context_global","title":"ROCKSDB_PERF_CONTEXT_GLOBAL","text":""},{"location":"myrocks-information-schema-tables.html#columns_12","title":"Columns","text":"Column Name Type STAT_TYPE varchar(193) VALUE bigint(8)"},{"location":"myrocks-information-schema-tables.html#rocksdb_deadlock","title":"ROCKSDB_DEADLOCK","text":"<p>This table records information about deadlocks.</p>"},{"location":"myrocks-information-schema-tables.html#columns_13","title":"Columns","text":"Column Name Type DEADLOCK_ID bigint(8) TRANSACTION_ID bigint(8) CF_NAME varchar(193) WAITING_KEY varchar(513) LOCK_TYPE varchar(193) INDEX_NAME varchar(193) TABLE_NAME varchar(193) ROLLED_BACK bigint(8)"},{"location":"myrocks-information-schema-tables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-limitations.html","title":"MyRocks limitations","text":"<p>The MyRocks storage engine lacks the following features compared to InnoDB:</p> <ul> <li> <p>Online DDL is not supported due to the lack of atomic DDL support.</p> <ul> <li> <p>There is no <code>ALTER TABLE ... ALGORITHM=INSTANT</code> functionality</p> </li> <li> <p>A partition management operation only supports the <code>COPY</code> algorithms, which rebuilds the partition table and moves the data based on the new <code>PARTITION ... VALUE</code> definition. In the case of <code>DROP PARTITION</code>, the data not moved to another partition is deleted.</p> </li> </ul> </li> <li> <p>ALTER TABLE .. EXCHANGE PARTITION.</p> </li> <li> <p>SAVEPOINT</p> </li> <li> <p>Transportable tablespace</p> </li> <li> <p>Foreign keys</p> </li> <li> <p>Spatial indexes</p> </li> <li> <p>Fulltext indexes</p> </li> <li> <p>Gap locks</p> </li> <li> <p>Group Replication</p> </li> <li> <p>Partial Update of LOB in InnoDB</p> </li> </ul> <p>You should also consider the following:</p> <ul> <li> <p>All collations are supported on <code>CHAR</code> and <code>VARCHAR</code> indexed columns. By default, MyRocks prevents creating indexes with non-binary collations (including <code>latin1</code>). You can optionally use it by setting rocksdb_strict_collation_exceptions to <code>t1</code> (table names with regex format), but non-binary covering indexes other than <code>latin1</code> (excluding <code>german1</code>) still require a primary key lookup to return the <code>CHAR</code> or <code>VARCHAR</code> column.</p> </li> <li> <p>Either <code>ORDER BY DESC</code> or <code>ORDER BY ASC</code> is slow. This is because of \u201cPrefix Key Encoding\u201d feature in RocksDB. See https://www.slideshare.net/matsunobu/myrocks-deep-dive/58 for details. By default, ascending scan is faster and descending scan is slower. If the \u201creverse column family\u201d is configured, then descending scan will be faster and ascending scan will be slower. Note that InnoDB also imposes a cost when the index is scanned in the opposite order.</p> </li> <li> <p>When converting from large MyISAM/InnoDB tables, either by using the <code>ALTER</code> or <code>INSERT INTO SELECT</code> statements it\u2019s recommended that you check the Data loading documentation and create MyRocks tables as below (in case the table is sufficiently big it will cause the server to consume all the memory and then be terminated by the OOM killer):</p> </li> </ul> <pre><code> SET session sql_log_bin=0;\n SET session rocksdb_bulk_load=1;\n ALTER TABLE large_myisam_table ENGINE=RocksDB;\n SET session rocksdb_bulk_load=0;\n</code></pre> Expected output <pre><code>.. warning::\n\n   If you are loading large data without enabling :ref:`rocksdb_bulk_load`\n   or :ref:`rocksdb_commit_in_the_middle`, please make sure transaction\n   ize is small enough. All modifications of the ongoing transactions are\n   kept in memory.\n</code></pre> <ul> <li> <p>With partitioned tables that use the MyRocks storage engine, the upgrade only works with native partitioning.</p> <p>See also</p> <p>MySQL Documentation: Preparing Your Installation for Upgrade</p> </li> <li> <p>Percona Server for MySQL 8.4 and Unicode 9.0.0 standards have defined a change in the handling of binary collations. These collations are handled as NO PAD, trailing spaces are included in key comparisons. A binary collation comparison may result in two unique rows inserted and does not generate a`DUP_ENTRY` error. MyRocks key encoding and comparison does not account for this character set attribute.</p> </li> </ul>"},{"location":"myrocks-limitations.html#not-supported-on-myrocks","title":"Not supported on MyRocks","text":"<p>MyRocks does not support the following:</p> <ul> <li> <p>Operating as either a source or a replica in any replication topology that is not exclusively row-based. Statement-based and mixed-format binary logging is not supported. For more information, see Replication Formats.</p> </li> <li> <p>Using multi-valued indexes. InnoDB supports this feature.</p> </li> <li> <p>Using spatial data types .</p> </li> <li> <p>Using the Clone Plugin and the Clone Plugin API. InnoDB supports either these features.</p> </li> <li> <p>Using encryption in tables. At this time, during an <code>ALTER TABLE</code> operation, MyRocks mistakenly detects all InnoDB tables as encrypted. Therefore, any attempt to <code>ALTER</code> an InnoDB table to MyRocks fails.</p> <p>As a workaround, we recommend a manual move of the table. The following  steps are the same as the <code>ALTER TABLE ... ENGINE=...</code> process:</p> <ul> <li> <p>Use <code>SHOW CREATE TABLE ...</code> to return the InnoDB table definition.</p> </li> <li> <p>With the table definition as the source, perform a <code>CREATE TABLE ... ENGINE=RocksDB</code>.</p> </li> <li> <p>In the new table, use <code>INSERT INTO &lt;new table&gt; SELECT \\* FROM &lt;old table&gt;</code>.</p> </li> </ul> <p>Note</p> <p>With MyRocks and with large tables, it is recommended to set the session variable <code>rocksdb_bulk_load=1</code> during the load to prevent running out of memory. This recommendation is because of the MyRocks large transaction limitation. For more information, see MyRocks Data Loading</p> </li> </ul> <p></p>"},{"location":"myrocks-limitations.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-server-variables.html","title":"MyRocks server variables","text":"<p>The MyRocks server variables expose configuration of the underlying RocksDB engine. There several ways to set these variables:</p> <ul> <li> <p>For production deployments, you should have all variables defined in the configuration file.</p> </li> <li> <p>Dynamic variables can be changed at runtime using the <code>SET</code> statement.</p> </li> <li> <p>If you want to test things out, you can set some of the variables when starting <code>mysqld</code> using corresponding command-line options.</p> </li> </ul> <p>If a variable was not set in either the configuration file or as a command-line option, the default value is used.</p> <p>Also, all variables can exist in one or both of the following scopes:</p> <ul> <li> <p>Global scope defines how the variable affects overall server operation.</p> </li> <li> <p>Session scope defines how the variable affects operation for individual client connections.</p> </li> </ul> Variable Name <code>rocksdb_access_hint_on_compaction_start</code> <code>rocksdb_advise_random_on_open</code> <code>rocksdb_allow_concurrent_memtable_write</code> <code>rocksdb_allow_to_start_after_corruption</code> <code>rocksdb_allow_mmap_reads</code> <code>rocksdb_allow_mmap_writes</code> <code>rocksdb_allow_unsafe_alter</code> <code>rocksdb_alter_column_default_inplace</code> <code>rocksdb_alter_table_comment_inplace</code> <code>rocksdb_base_background_compactions</code> <code>rocksdb_blind_delete_primary_key</code> <code>rocksdb_block_cache_numshardbits</code> <code>rocksdb_block_cache_size</code> <code>rocksdb_bulk_load_fail_if_not_bottommost_level</code> <code>rocksdb_bulk_load_partial_index</code> <code>rocksdb_bulk_load_use_sst_partitioner</code> <code>rocksdb_block_restart_interval</code> <code>rocksdb_block_size</code> <code>rocksdb_block_size_deviation</code> <code>rocksdb_bulk_load</code> <code>rocksdb_bulk_load_allow_sk</code> <code>rocksdb_bulk_load_allow_unsorted</code> <code>rocksdb_bulk_load_size</code> <code>rocksdb_bytes_per_sync</code> <code>rocksdb_cache_dump</code> <code>rocksdb_cache_high_pri_pool_ratio</code> <code>rocksdb_cache_index_and_filter_blocks</code> <code>rocksdb_cache_index_and_filter_with_high_priority</code> <code>rocksdb_cancel_manual_compactions</code> <code>rocksdb_charge_memory</code> <code>rocksdb_check_iterate_bounds</code> <code>rocksdb_checksums_pct</code> <code>rocksdb_collect_sst_properties</code> <code>rocksdb_column_default_value_as_expression</code> <code>rocksdb_commit_in_the_middle</code> <code>rocksdb_commit_time_batch_for_recovery</code> <code>rocksdb_compact_cf</code> <code>rocksdb_compact_lzero_now</code> <code>rocksdb_compaction_readahead_size</code> <code>rocksdb_compaction_sequential_deletes</code> <code>rocksdb_compaction_sequential_deletes_count_sd</code> <code>rocksdb_compaction_sequential_deletes_file_size</code> <code>rocksdb_compaction_sequential_deletes_window</code> <code>rocksdb_concurrent_prepare</code> <code>rocksdb_converter_record_cached_length</code> <code>rocksdb_corrupt_data_action</code> <code>rocksdb_create_checkpoint</code> <code>rocksdb_create_if_missing</code> <code>rocksdb_create_missing_column_families</code> <code>rocksdb_create_temporary_checkpoint</code> <code>rocksdb_datadir</code> <code>rocksdb_db_write_buffer_size</code> <code>rocksdb_deadlock_detect</code> <code>rocksdb_deadlock_detect_depth</code> <code>rocksdb_debug_cardinality_multipler</code> <code>rocksdb_debug_manual_compaction_delay</code> <code>rocksdb_debug_optimizer_no_zero_cardinality</code> <code>rocksdb_debug_ttl_ignore_pk</code> <code>rocksdb_debug_ttl_read_filter_ts</code> <code>rocksdb_debug_ttl_rec_ts</code> <code>rocksdb_debug_ttl_snapshot_ts</code> <code>rocksdb_default_cf_options</code> <code>rocksdb_delayed_write_rate</code> <code>rocksdb_delete_cf</code> <code>rocksdb_delete_obsolete_files_period_micros</code> <code>rocksdb_disable_file_deletions</code> <code>rocksdb_disable_instant_ddl</code> <code>rocksdb_enable_bulk_load_api</code> <code>rocksdb_enable_delete_range_for_drop_index</code> <code>rocksdb_enable_insert_with_update_caching</code> <code>rocksdb_enable_iterate_bounds</code> <code>rocksdb_enable_pipelined_write</code> <code>rocksdb_enable_remove_orphaned_dropped_cfs</code> <code>rocksdb_enable_ttl</code> <code>rocksdb_enable_ttl_read_filtering</code> <code>rocksdb_enable_thread_tracking</code> <code>rocksdb_enable_write_thread_adaptive_yield</code> <code>rocksdb_error_if_exists</code> <code>rocksdb_error_on_suboptimal_collation</code> <code>rocksdb_file_checksums</code> <code>rocksdb_flush_log_at_trx_commit</code> <code>rocksdb_flush_memtable_on_analyze</code> <code>rocksdb_force_compute_memtable_stats</code> <code>rocksdb_force_compute_memtable_stats_cachetime</code> <code>rocksdb_force_flush_memtable_and_lzero_now</code> <code>rocksdb_force_flush_memtable_now</code> <code>rocksdb_force_index_records_in_range</code> <code>rocksdb_hash_index_allow_collision</code> <code>rocksdb_ignore_unknown_options</code> <code>rocksdb_index_type</code> <code>rocksdb_info_log_level</code> <code>rocksdb_is_fd_close_on_exec</code> <code>rocksdb_keep_log_file_num</code> <code>rocksdb_large_prefix</code> <code>rocksdb_lock_scanned_rows</code> <code>rocksdb_lock_wait_timeout</code> <code>rocksdb_log_file_time_to_roll</code> <code>rocksdb_manifest_preallocation_size</code> <code>rocksdb_manual_compaction_bottommost_level</code> <code>rocksdb_manual_compaction_threads</code> <code>rocksdb_manual_wal_flush</code> <code>rocksdb_master_skip_tx_api</code> <code>rocksdb_max_background_compactions</code> <code>rocksdb_max_background_flushes</code> <code>rocksdb_max_background_jobs</code> <code>rocksdb_max_bottom_pri_background_compactions</code> <code>rocksdb_max_compaction_history</code> <code>rocksdb_max_file_opening_threads</code> <code>rocksdb_max_latest_deadlocks</code> <code>rocksdb_max_log_file_size</code> <code>rocksdb_max_manifest_file_size</code> <code>rocksdb_max_manual_compactions</code> <code>rocksdb_max_open_files</code> <code>rocksdb_max_row_locks</code> <code>rocksdb_max_subcompactions</code> <code>rocksdb_max_total_wal_size</code> <code>rocksdb_merge_buf_size</code> <code>rocksdb_merge_combine_read_size</code> <code>rocksdb_merge_tmp_file_removal_delay_ms</code> <code>rocksdb_new_table_reader_for_compaction_inputs</code> <code>rocksdb_no_block_cache</code> <code>rocksdb_no_create_column_family</code> <code>rocksdb_override_cf_options</code> <code>rocksdb_paranoid_checks</code> <code>rocksdb_partial_index_ignore_killed</code> <code>rocksdb_partial_index_sort_max_mem</code> <code>rocksdb_pause_background_work</code> <code>rocksdb_partial_index_blind_delete</code> <code>rocksdb_perf_context_level</code> <code>rocksdb_persistent_cache_path</code> <code>rocksdb_persistent_cache_size_mb</code> <code>rocksdb_pin_l0_filter_and_index_blocks_in_cache</code> <code>rocksdb_print_snapshot_conflict_queries</code> <code>rocksdb_protection_bytes_per_key</code> <code>rocksdb_rate_limiter_bytes_per_sec</code> <code>rocksdb_read_free_rpl</code> <code>rocksdb_read_free_rpl_tables</code> <code>rocksdb_records_in_range</code> <code>rocksdb_reset_stats</code> <code>rocksdb_rollback_on_timeout</code> <code>rocksdb_rpl_skip_tx_api</code> <code>rocksdb_seconds_between_stat_computes</code> <code>rocksdb_signal_drop_index_thread</code> <code>rocksdb_sim_cache_size</code> <code>rocksdb_skip_bloom_filter_on_read</code> <code>rocksdb_skip_fill_cache</code> <code>rocksdb_skip_locks_if_skip_unique_check</code> <code>rocksdb_sst_mgr_rate_bytes_per_sec</code> <code>rocksdb_stats_dump_period_sec</code> <code>rocksdb_stats_level</code> <code>rocksdb_stats_recalc_rate</code> <code>rocksdb_store_row_debug_checksums</code> <code>rocksdb_strict_collation_check</code> <code>rocksdb_strict_collation_exceptions</code> <code>rocksdb_table_cache_numshardbits</code> <code>rocksdb_table_stats_background_thread_nice_value</code> <code>rocksdb_table_stats_max_num_rows_scanned</code> <code>rocksdb_table_stats_recalc_threshold_count</code> <code>rocksdb_table_stats_recalc_threshold_pct</code> <code>rocksdb_table_stats_sampling_pct</code> <code>rocksdb_table_stats_use_table_scan</code> <code>rocksdb_tmpdir</code> <code>rocksdb_two_write_queues</code> <code>rocksdb_trace_block_cache_access</code> <code>rocksdb_trace_queries</code> <code>rocksdb_trace_sst_api</code> <code>rocksdb_track_and_verify_wals_in_manifest</code> <code>rocksdb_unsafe_for_binlog</code> <code>rocksdb_update_cf_options</code> <code>rocksdb_use_adaptive_mutex</code> <code>rocksdb_use_default_sk_cf</code> <code>rocksdb_use_direct_io_for_flush_and_compaction</code> <code>rocksdb_use_direct_reads</code> <code>rocksdb_use_fsync</code> <code>rocksdb_use_hyper_clock_cache</code> <code>rocksdb_use_write_buffer_manager</code> <code>rocksdb_validate_tables</code> <code>rocksdb_verify_row_debug_checksums</code> <code>rocksdb_wal_bytes_per_sync</code> <code>rocksdb_wal_dir</code> <code>rocksdb_wal_recovery_mode</code> <code>rocksdb_wal_size_limit_mb</code> <code>rocksdb_wal_ttl_seconds</code> <code>rocksdb_whole_key_filtering</code> <code>rocksdb_write_batch_flush_threshold</code> <code>rocksdb_write_batch_max_bytes</code> <code>rocksdb_write_disable_wal</code> <code>rocksdb_write_ignore_missing_column_families</code> <code>rocksdb_write_policy</code>"},{"location":"myrocks-server-variables.html#rocksdb_access_hint_on_compaction_start","title":"<code>rocksdb_access_hint_on_compaction_start</code>","text":"Option Description Command-line \u2013rocksdb-access-hint-on-compaction-start Dynamic No Scope Global Data type String or numeric Default NORMAL or 1 <p>Specifies the file access pattern once a compaction is started, applied to all input files of a compaction. Possible values are:</p> <ul> <li> <p><code>0</code> = <code>NONE</code></p> </li> <li> <p><code>1</code> = <code>NORMAL</code> (default)</p> </li> <li> <p><code>2</code> = <code>SEQUENTIAL</code></p> </li> <li> <p><code>3</code> = <code>WILLNEED</code></p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_advise_random_on_open","title":"<code>rocksdb_advise_random_on_open</code>","text":"Option Description Command-line \u2013rocksdb-advise-random-on-open Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether to hint the underlying file system that the file access pattern is random, when a data file is opened. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_allow_concurrent_memtable_write","title":"<code>rocksdb_allow_concurrent_memtable_write</code>","text":"Option Description Command-line \u2013rocksdb-allow-concurrent-memtable-write Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to allow multiple writers to update memtables in parallel. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_allow_to_start_after_corruption","title":"<code>rocksdb_allow_to_start_after_corruption</code>","text":"Option Description Command-line \u2013rocksdb_allow_to_start_after_corruption Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to allow server to restart once MyRocks reported data corruption. Disabled by default.</p> <p>Once corruption is detected server writes marker file (named ROCKSDB_CORRUPTED) in the data directory and aborts. If marker file exists, then mysqld exits on startup with an error message. The restart failure will continue until the problem is solved or until mysqld is started with this variable turned on in the command line.</p> <p>Note</p> <p>Not all memtables support concurrent writes.</p>"},{"location":"myrocks-server-variables.html#rocksdb_allow_mmap_reads","title":"<code>rocksdb_allow_mmap_reads</code>","text":"Option Description Command-line \u2013rocksdb-allow-mmap-reads Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to allow the OS to map a data file into memory for reads. Disabled by default. If you enable this, make sure that rocksdb_use_direct_reads is disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_allow_mmap_writes","title":"<code>rocksdb_allow_mmap_writes</code>","text":"Option Description Command-line \u2013rocksdb-allow-mmap-writes Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to allow the OS to map a data file into memory for writes. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_allow_unsafe_alter","title":"<code>rocksdb_allow_unsafe_alter</code>","text":"Option Description Command-line \u2013rocksdb-allow-unsafe-alter Dynamic No Scope Global Data type Boolean Default OFF <p>Enables crash unsafe INPLACE ADD|DROP partition.</p>"},{"location":"myrocks-server-variables.html#rocksdb_alter_column_default_inplace","title":"<code>rocksdb_alter_column_default_inplace</code>","text":"Option Description Command-line \u2013rocksdb-alter-column-default-inplace Dynamic Yes Scope Global Data type Boolean Default ON <p>Allows an inplace alter for the <code>ALTER COLUMN</code> default operation.</p>"},{"location":"myrocks-server-variables.html#rocksdb_alter_table_comment_inplace","title":"<code>rocksdb_alter_table_comment_inplace</code>","text":"Option Description Command-line \u2013rocksdb_alter_table_comment_inplace Dynamic Yes Scope Global Data type Boolean Default OFF <p>Allows changing <code>ALTER TABLE COMMENT</code> inplace.</p> <p>This variable is disabled (OFF) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_base_background_compactions","title":"<code>rocksdb_base_background_compactions</code>","text":"Option Description Command-line \u2013rocksdb-base-background-compactions Dynamic No Scope Global Data type Numeric Default 1 <p>Specifies the suggested number of concurrent background compaction jobs, submitted to the default LOW priority thread pool in RocksDB. The default is <code>1</code>. The allowed range of values is from <code>-1</code> to <code>64</code>. The maximum value depends on the rocksdb_max_background_compactions variable. This variable was replaced with rocksdb_max_background_jobs, which automatically decides how many threads to allocate toward flush/compaction.</p>"},{"location":"myrocks-server-variables.html#rocksdb_blind_delete_primary_key","title":"<code>rocksdb_blind_delete_primary_key</code>","text":"Option Description Command-line \u2013rocksdb-blind-delete-primary-key Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Skips verifying if rows exists before executing deletes. The following conditions must be met:</p> <ul> <li> <p>The variable is enabled</p> </li> <li> <p>Only a single table listed in the <code>DELETE</code> statement</p> </li> <li> <p>The table has only a primary key with no secondary keys</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_block_cache_numshardbits","title":"<code>rocksdb_block_cache_numshardbits</code>","text":"Option Description Command-line \u2013rocksdb-block-cache-numshardbits Dynamic No Scope Global Data type Numeric Default -1 <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>This variable specifies the number of shards ,<code>numShardBits</code>, for the block cache in RocksDB. The cache is sharded into <code>2^numShardBits</code> shards by the key hash.</p> <p>The default value is <code>-1</code>. The <code>-1</code> value means that RocksDB automatically determines the number of shards for the block cache based on the cache capacity.</p> <p>The minimum value is <code>-1</code> and the maximum value is <code>8</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_block_cache_size","title":"<code>rocksdb_block_cache_size</code>","text":"Option Description Command-line \u2013rocksdb-block-cache-size Dynamic No Scope Global Data type Numeric Default 536870912 <p>Specifies the size of the LRU block cache for RocksDB. This memory is reserved for the block cache, which is in addition to any filesystem caching that may occur.</p> <p>Minimum value is <code>1024</code>, because that\u2019s the size of one block.</p> <p>Default value is <code>536870912</code>.</p> <p>Maximum value is <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_fail_if_not_bottommost_level","title":"<code>rocksdb_bulk_load_fail_if_not_bottommost_level</code>","text":"Option Description Command-line \u2013rocksdb_bulk_load_fail_if_not_bottommost_level Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>When this variable is enabled, the bulk load fails if an sst file created during bulk load cannot be placed to the bottommost level in the rocksdb. </p> <p>This variable can be enabled or disabled only when the <code>rocksdb_bulk_load</code> is <code>OFF</code>.</p> <p>This variable is disabled (OFF) by default.</p> <p>Warning</p> <p>When <code>rocksdb_bulk_load_fail_if_not_bottommost_level</code> is disabled, it may cause severe performance impact.</p>"},{"location":"myrocks-server-variables.html#rocksdb_block_restart_interval","title":"<code>rocksdb_block_restart_interval</code>","text":"Option Description Command-line \u2013rocksdb-block-restart-interval Dynamic No Scope Global Data type Numeric Default 16 <p>Specifies the number of keys for each set of delta encoded data. Default value is <code>16</code>. Allowed range is from <code>1</code> to <code>2147483647</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_block_size","title":"<code>rocksdb_block_size</code>","text":"Option Description Command-line \u2013rocksdb-block-size Dynamic No Scope Global Data type Numeric Default 16 KB <p>Specifies the size of the data block for reading RocksDB data files. The default value is <code>16 KB</code>. The allowed range is from <code>1024</code> to <code>18446744073709551615</code> bytes.</p>"},{"location":"myrocks-server-variables.html#rocksdb_block_size_deviation","title":"<code>rocksdb_block_size_deviation</code>","text":"Option Description Command-line \u2013rocksdb-block-size-deviation Dynamic No Scope Global Data type Numeric Default 10 <p>Specifies the threshold for free space allowed in a data block (see rocksdb_block_size). If there is less space remaining, close the block (and write to new block). Default value is <code>10</code>, meaning that the block is not closed until there is less than 10 bits of free space remaining.</p> <p>Allowed range is from <code>1</code> to <code>2147483647</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_allow_sk","title":"<code>rocksdb_bulk_load_allow_sk</code>","text":"Option Description Command-line \u2013rocksdb-bulk-load-allow-sk Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Enabling this variable allows secondary keys to be added using the bulk loading feature. This variable can be enabled or disabled only when the rocksdb_bulk_load is <code>OFF</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_allow_unsorted","title":"<code>rocksdb_bulk_load_allow_unsorted</code>","text":"Option Description Command-line \u2013rocksdb-bulk-load-allow-unsorted Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>By default, the bulk loader requires its input to be sorted in the primary key order. If enabled, unsorted inputs are allowed too, which are then sorted by the bulkloader itself, at a performance penalty.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load","title":"<code>rocksdb_bulk_load</code>","text":"Option Description Command-line \u2013rocksdb-bulk-load Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to use bulk load: MyRocks will ignore checking keys for uniqueness or acquiring locks during transactions. Disabled by default. Enable this only if you are certain that there are no row conflicts, for example, when setting up a new MyRocks instance from a MySQL dump.</p> <p>When the rocksdb_bulk_load variable is enabled, it behaves as if the variable rocksdb_commit_in_the_middle is enabled, even if the variable rocksdb_commit_in_the_middle is disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_partial_index","title":"<code>rocksdb_bulk_load_partial_index</code>","text":"Option Description Command-line \u2013rocksdb-bulk-load-partial-index Dynamic Yes Scope Local Data type Boolean Default ON <p>Materializes partial index during bulk load instead of leaving the index empty.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_use_sst_partitioner","title":"<code>rocksdb_bulk_load_use_sst_partitioner</code>","text":"Option Description Command-line \u2013rocksdb_bulk_load_use_sst_partitioner Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>If enabled, this variable uses sst partitioner to split sst files to ensure bulk load sst files can be ingested to bottommost level.</p> <p>This variable is disabled (OFF) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bulk_load_size","title":"<code>rocksdb_bulk_load_size</code>","text":"Option Description Command-line \u2013rocksdb-bulk-load-size Dynamic Yes Scope Global, Session Data type Numeric Default 1000 <p>Specifies the number of keys to accumulate before committing them to the storage engine when bulk load is enabled (see rocksdb_bulk_load). Default value is <code>1000</code>, which means that a batch can contain up to 1000 records before they are implicitly committed. Allowed range is from <code>1</code> to <code>1073741824</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_bytes_per_sync","title":"<code>rocksdb_bytes_per_sync</code>","text":"Option Description Command-line \u2013rocksdb-bytes-per-sync Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies how often should the OS sync files to disk as they are being written, asynchronously, in the background. This operation can be used to smooth out write I/O over time. Default value is <code>0</code> meaning that files are never synced. Allowed range is up to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_cache_dump","title":"<code>rocksdb_cache_dump</code>","text":"Option Description Command-line \u2013rocksdb-cache-dump Dynamic No Scope Global Data type Boolean Default ON <p>Includes RocksDB block cache content in core dump. This variable is enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_cache_high_pri_pool_ratio","title":"<code>rocksdb_cache_high_pri_pool_ratio</code>","text":"Option Description Command-line \u2013rocksdb-cache-high-pri-pool-ratio Dynamic No Scope Global Data type Double Default 0.0 <p>This variable specifies the size of the block cache high-pri pool. The default value and minimum value is 0.0. The maximum value is 1.0.</p>"},{"location":"myrocks-server-variables.html#rocksdb_cache_index_and_filter_blocks","title":"<code>rocksdb_cache_index_and_filter_blocks</code>","text":"Option Description Command-line \u2013rocksdb-cache-index-and-filter-blocks Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether RocksDB should use the block cache for caching the index and bloomfilter data blocks from each data file. Enabled by default. If you disable this feature, RocksDB allocates additional memory to maintain these data blocks.</p>"},{"location":"myrocks-server-variables.html#rocksdb_cache_index_and_filter_with_high_priority","title":"<code>rocksdb_cache_index_and_filter_with_high_priority</code>","text":"Option Description Command-line \u2013rocksdb-cache-index-and-filter-with-high-priority Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether RocksDB should use the block cache with high priority for caching the index and bloomfilter data blocks from each data file. Enabled by default. If you disable this feature, RocksDB allocates additional memory to maintain these data blocks.</p>"},{"location":"myrocks-server-variables.html#rocksdb_cancel_manual_compactions","title":"<code>rocksdb_cancel_manual_compactions</code>","text":"Option Description Command-line \u2013rocksdb-cancel-manual-compactions Dynamic Yes Scope Global Data type Boolean Default OFF <p>Cancels all ongoing manual compactions.</p>"},{"location":"myrocks-server-variables.html#rocksdb_charge_memory","title":"<code>rocksdb_charge_memory</code>","text":"Option Description Command-line \u2013rocksdb_charge_memory Dynamic No Scope Global Data type Boolean Default OFF <p>This variable is tech preview and may be removed in the future releases.</p> <p>Turns on RocksDB memory-charging related features (BlockBasedTableOptions::cache_usage_options.options.charged) from <code>cnf</code> files. This variable is related to <code>rocksdb_use_write_buffer_manager</code>.</p> <p>This variable is disabled (OFF) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_check_iterate_bounds","title":"<code>rocksdb_check_iterate_bounds</code>","text":"Option Description Command-line \u2013rocksdb-check-iterate-bounds Dynamic Yes Scope Global, Session Data type Boolean Default ON <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>This variable enables checking the upper and lower bounds of the RocksDB iterator during iteration. The default value in <code>ON</code> which means this variable is enabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_checksums_pct","title":"<code>rocksdb_checksums_pct</code>","text":"Option Description Command-line \u2013rocksdb-checksums-pct Dynamic Yes Scope Global, Session Data type Numeric Default 100 <p>Specifies the percentage of rows to be checksummed. Default value is <code>100</code> (checksum all rows). Allowed range is from <code>0</code> to <code>100</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_collect_sst_properties","title":"<code>rocksdb_collect_sst_properties</code>","text":"Option Description Command-line \u2013rocksdb-collect-sst-properties Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether to collect statistics on each data file to improve optimizer behavior. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_column_default_value_as_expression","title":"<code>rocksdb_column_default_value_as_expression</code>","text":"Option Description Command-line \u2013rocksdb_column_default_value_as_expression Dynamic Yes Scope Global Data type Boolean Default ON <p>Allows to set a function as the default value for a column.</p> <p>This variable is enabled (ON) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_commit_in_the_middle","title":"<code>rocksdb_commit_in_the_middle</code>","text":"Option Description Command-line \u2013rocksdb-commit-in-the-middle Dynamic Yes Scope Global Data type Boolean Default OFF <p>Specifies whether to commit rows implicitly when a batch contains more than the value of rocksdb_bulk_load_size.</p> <p>This option should only be enabled at the time of data import because it may cause locking errors.</p> <p>This variable is disabled by default. When the rocksdb_bulk_load variable is enabled, it behaves as if the variable rocksdb_commit_in_the_middle is enabled, even if the variable rocksdb_commit_in_the_middle is disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_commit_time_batch_for_recovery","title":"<code>rocksdb_commit_time_batch_for_recovery</code>","text":"Option Description Command-line \u2013rocksdb-commit-time-batch-for-recovery Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to write the commit time write batch into the database or not.</p> <p>Note</p> <p>If the commit time write batch is only useful for recovery, then writing to WAL is enough.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compact_cf","title":"<code>rocksdb_compact_cf</code>","text":"Option Description Command-line \u2013rocksdb-compact-cf Dynamic Yes Scope Global Data type String Default <p>Specifies the name of the column family to compact.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compact_lzero_now","title":"<code>rocksdb_compact_lzero_now</code>","text":"Option Description Command-line \u2013rocksdb-compact-lzero-now Dynamic Yes Scope Global Data type Boolean Default OFF <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>This variable acts as a trigger. Set the variable to <code>ON</code>, <code>rocksdb-compact-lzero-now=ON</code>, to immediately compact all the <code>Level 0</code> (L0) files. After all the <code>L0</code> files are compacted, the variable value automatically switches to <code>OFF</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compaction_readahead_size","title":"<code>rocksdb_compaction_readahead_size</code>","text":"Option Description Command-line \u2013rocksdb-compaction-readahead-size Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies the size of reads to perform ahead of compaction. Default value is <code>0</code>. Set this to at least 2 megabytes (<code>16777216</code>) when using MyRocks with spinning disks to ensure sequential reads instead of random. Maximum allowed value is <code>18446744073709551615</code>.</p> <p>Note</p> <p>If you set this variable to a non-zero value, rocksdb_new_table_reader_for_compaction_inputs is enabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compaction_sequential_deletes","title":"<code>rocksdb_compaction_sequential_deletes</code>","text":"Option Description Command-line \u2013rocksdb-compaction-sequential-deletes Dynamic Yes Scope Global Data type Numeric Default 149999 <p>Note</p> <p>In version Percona Server for MySQL 8.3.0-1 and later, the default value is changed from <code>0</code> to <code>149999</code>.</p> <p>Specifies the threshold to trigger compaction on a file if it has more than this number of sequential delete markers.</p> <p>The default value is <code>149999</code>.</p> <p>Maximum allowed value is <code>2000000</code> (two million delete markers).</p> <p>Note</p> <p>Depending on workload patterns, MyRocks can potentially maintain large numbers of delete markers, which increases latency of queries.  This compaction feature will reduce latency, but may also increase the MyRocks write rate.  Use this variable together with rocksdb_compaction_sequential_deletes_file_size to only perform compaction on large files.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compaction_sequential_deletes_count_sd","title":"<code>rocksdb_compaction_sequential_deletes_count_sd</code>","text":"Option Description Command-line \u2013rocksdb-compaction-sequential-deletes-count-sd Dynamic Yes Scope Global Data type Boolean Default ON <p>Note</p> <p>In version Percona Server for MySQL 8.3.0-1 and later, the default value is changed from <code>OFF</code> to <code>ON</code>.</p> <p>Specifies whether to count single deletes as delete markers recognized by <code>rocksdb_compaction_sequential_deletes</code>.</p> <p>The default value is <code>ON</code> which means the variable is enabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compaction_sequential_deletes_file_size","title":"<code>rocksdb_compaction_sequential_deletes_file_size</code>","text":"Option Description Command-line \u2013rocksdb-compaction-sequential-deletes-file-size Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies the minimum file size required to trigger compaction on it by rocksdb_compaction_sequential_deletes. Default value is <code>0</code>, meaning that compaction is triggered regardless of file size. Allowed range is from <code>-1</code> to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_compaction_sequential_deletes_window","title":"<code>rocksdb_compaction_sequential_deletes_window</code>","text":"Option Description Command-line \u2013rocksdb-compaction-sequential-deletes-window Dynamic Yes Scope Global Data type Numeric Default 150000 <p>Note</p> <p>In version Percona Server for MySQL 8.0.36-28 and later, the default value is changed from <code>0</code> to <code>150000</code>.</p> <p>Specifies the size of the window for counting delete markers by <code>rocksdb_compaction_sequential_deletes</code>. Default value is <code>150000</code>.</p> <p>Allowed range is up to <code>2000000</code> (two million).</p>"},{"location":"myrocks-server-variables.html#rocksdb_concurrent_prepare","title":"<code>rocksdb_concurrent_prepare</code>","text":"Option Description Command-line \u2013rocksdb-concurrent_prepare Dynamic No Scope Global Data type Boolean Default ON <p>When enabled this variable allows/encourages threads that are using two-phase commit to <code>prepare</code> in parallel. This variable was renamed in upstream to rocksdb_two_write_queues.</p>"},{"location":"myrocks-server-variables.html#rocksdb_corrupt_data_action","title":"<code>rocksdb_corrupt_data_action</code>","text":"Option Description Command-line \u2013rocksdb_corrupt_data_action Dynamic Yes Scope Global Data type enum { ERROR = 0, ABORT_SERVER, WARNING }; Default ERROR <p>This variable controls the behavior when hitting the data corruption in MyRocks. </p> <p>You can select one of the following actions:</p> <ul> <li> <p><code>ERROR</code> - fail the query with the error <code>HA_ERR_ROCKSDB_CORRUPT_DATA</code></p> </li> <li> <p><code>ABORT_SERVER</code> - crash the server</p> </li> <li> <p><code>WARNING</code> - pass the query with warning</p> </li> </ul> <p>The default value is <code>ERROR</code> that means the query fails with the error <code>HA_ERR_ROCKSDB_CORRUPT_DATA</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_converter_record_cached_length","title":"<code>rocksdb_converter_record_cached_length</code>","text":"Option Description Command-line \u2013rocksdb_converter_record_cached_length Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies the maximum number of bytes to cache on table handler for encoding table record data. </p> <p>If the used memory exceeds <code>rocksdb_converter_record_cached_length</code>, the memory is released when the handler is returned to the table handler cache.</p> <p>The minimum value is <code>0</code> (zero) that means there is no limit. The maximum value is <code>UINT64_MAX (0xffffffffffffffff)</code>.</p> <p>The default value is <code>0</code>(zero) that means there is no limit.</p>"},{"location":"myrocks-server-variables.html#rocksdb_create_checkpoint","title":"<code>rocksdb_create_checkpoint</code>","text":"Option Description Command-line \u2013rocksdb-create-checkpoint Dynamic Yes Scope Global Data type String Default <p>Specifies the directory where MyRocks should create a checkpoint. Empty by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_create_if_missing","title":"<code>rocksdb_create_if_missing</code>","text":"Option Description Command-line \u2013rocksdb-create-if-missing Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether MyRocks should create its database if it does not exist. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_create_missing_column_families","title":"<code>rocksdb_create_missing_column_families</code>","text":"Option Description Command-line \u2013rocksdb-create-missing-column-families Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether MyRocks should create new column families if they do not exist. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_create_temporary_checkpoint","title":"<code>rocksdb_create_temporary_checkpoint</code>","text":"Option Description Command-line \u2013rocksdb-create-temporary-checkpoint Dynamic Yes Scope Session Data type String <p>When specified it will create a temporary RocksDB \u2018checkpoint\u2019 or \u2018snapshot\u2019 in the datadir. If the session ends with an existing checkpoint, or if the variable is reset to another value, the checkpoint will get removed. This variable should be used by backup tools. Prolonged use or other misuse can have serious side effects to the server instance.</p>"},{"location":"myrocks-server-variables.html#rocksdb_datadir","title":"<code>rocksdb_datadir</code>","text":"Option Description Command-line \u2013rocksdb-datadir Dynamic No Scope Global Data type String Default <code>./.rocksdb</code> <p>Specifies the location of the MyRocks data directory. By default, it is created in the current working directory.</p>"},{"location":"myrocks-server-variables.html#rocksdb_db_write_buffer_size","title":"<code>rocksdb_db_write_buffer_size</code>","text":"Option Description Command-line \u2013rocksdb-db-write-buffer-size Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the maximum size of all memtables used to store writes in MyRocks across all column families. When this size is reached, the data is flushed to persistent media. The default value is <code>0</code>. The allowed range is up to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_deadlock_detect","title":"<code>rocksdb_deadlock_detect</code>","text":"Option Description Command-line \u2013rocksdb-deadlock-detect Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether MyRocks should detect deadlocks. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_deadlock_detect_depth","title":"<code>rocksdb_deadlock_detect_depth</code>","text":"Option Description Command-line \u2013rocksdb-deadlock-detect-depth Dynamic Yes Scope Global, Session Data type Numeric Default 50 <p>Specifies the number of transactions deadlock detection will traverse through before assuming deadlock.</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_cardinality_multiplier","title":"<code>rocksdb_debug_cardinality_multiplier</code>","text":"Option Description Command-line \u2013rocksdb-debug-cardinality-multiplier Dynamic Yes Scope Global Data type UINT Default 2 <p>The cardinality multiplier used in tests. The minimum value is 0. The maxium value is 2147483647 (INT_MAX).</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_manual_compaction_delay","title":"<code>rocksdb_debug_manual_compaction_delay</code>","text":"Option Description Command-line \u2013rocksdb-debug-manual-compaction-delay Dynamic Yes Scope Global Data type UINT Default 0 <p>Only use this variable when debugging.</p> <p>This variable specifies a sleep, in seconds, to simulate long-running compactions. The minimum value is 0. The maximum value is 4292967295 (UINT_MAX).</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_optimizer_no_zero_cardinality","title":"<code>rocksdb_debug_optimizer_no_zero_cardinality</code>","text":"Option Description Command-line \u2013rocksdb-debug-optimizer-no-zero-cardinality Dynamic Yes Scope Global Data type Boolean Default ON <p>Specifies whether MyRocks should prevent zero cardinality by always overriding it with some value.</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_ttl_ignore_pk","title":"<code>rocksdb_debug_ttl_ignore_pk</code>","text":"Option Description Command-line \u2013rocksdb-debug-ttl-ignore-pk Dynamic Yes Scope Global Data type Boolean Default OFF <p>For debugging purposes only. If true, compaction filtering will not occur on Primary Key TTL data. This variable is a no-op in non-debug builds.</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_ttl_read_filter_ts","title":"<code>rocksdb_debug_ttl_read_filter_ts</code>","text":"Option Description Command-line \u2013rocksdb_debug-ttl-read-filter-ts Dynamic Yes Scope Global Data type Numeric Default 0 <p>For debugging purposes only.  Overrides the TTL read filtering time to time + debug_ttl_read_filter_ts. A value of <code>0</code> denotes that the variable is not set. This variable is a no-op in non-debug builds.</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_ttl_rec_ts","title":"<code>rocksdb_debug_ttl_rec_ts</code>","text":"Option Description Command-line \u2013rocksdb-debug-ttl-rec-ts Dynamic Yes Scope Global Data type Numeric Default 0 <p>For debugging purposes only.  Overrides the TTL of records to <code>now()</code> + debug_ttl_rec_ts. The value can be \u00b1 to simulate a record inserted in the past vs a record inserted in the  future . A value of <code>0</code> denotes that the variable is not set. This variable is a no-op in non-debug builds.</p>"},{"location":"myrocks-server-variables.html#rocksdb_debug_ttl_snapshot_ts","title":"<code>rocksdb_debug_ttl_snapshot_ts</code>","text":"Option Description Command-line \u2013rocksdb-debug-ttl-snapshot-ts Dynamic Yes Scope Global Data type Numeric Default 0 <p>For debugging purposes only. Sets the snapshot during compaction to <code>now()</code> + rocksdb_debug_set_ttl_snapshot_ts.</p> <p>The value can be \u00b1 to simulate a snapshot in the past vs a snapshot created in the  future . A value of <code>0</code> denotes that the variable is not set. This variable is a no-op in non-debug builds.</p>"},{"location":"myrocks-server-variables.html#rocksdb_default_cf_options","title":"<code>rocksdb_default_cf_options</code>","text":"Option Description Command-line \u2013rocksdb-default-cf-options Dynamic No Scope Global Data type String <p>The dafault value is:</p> <pre><code>block_based_table_factory= {cache_index_and_filter_blocks=1;filter_policy=bloomfilter:10:false;whole_key_filtering=1};level_compaction_dynamic_level_bytes=true;optimize_filters_for_hits=true;compaction_pri=kMinOverlappingRatio;compression=kLZ4Compression;bottommost_compression=kLZ4Compression;\n</code></pre> <p>Specifies the default column family options for MyRocks. On startup, the server applies this option to all existing column families. This option is read-only at runtime.</p>"},{"location":"myrocks-server-variables.html#rocksdb_delayed_write_rate","title":"<code>rocksdb_delayed_write_rate</code>","text":"Option Description Command-line \u2013rocksdb-delayed-write-rate Dynamic Yes Scope Global Data type Numeric Default 16777216 <p>Specifies the write rate in bytes per second, which should be used if MyRocks hits a soft limit or threshold for writes. Default value is <code>16777216</code> (16 MB/sec). Allowed range is from <code>0</code> to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_delete_cf","title":"<code>rocksdb_delete_cf</code>","text":"Option Description Command-line \u2013rocksdb-delete-cf Dynamic Yes Scope Global Data type String Default \u201c\u201d <p>Deletes the column family by name. The default value is \u201c\u201d , an empty string.</p> <p>For example:</p> <pre><code>SET @@global.ROCKSDB_DELETE_CF = 'cf_primary_key';\n</code></pre>"},{"location":"myrocks-server-variables.html#rocksdb_delete_obsolete_files_period_micros","title":"<code>rocksdb_delete_obsolete_files_period_micros</code>","text":"Option Description Command-line \u2013rocksdb-delete-obsolete-files-period-micros Dynamic No Scope Global Data type Numeric Default 21600000000 <p>Specifies the period in microseconds to delete obsolete files regardless of files removed during compaction. Default value is <code>21600000000</code> (6 hours). Allowed range is up to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_disable_file_deletions","title":"<code>rocksdb_disable_file_deletions</code>","text":"Option Description Command-line \u2013rocksdb-disable-file-deletions Dynamic Yes Scope Session Data type Boolean Default OFF <p>It allows a client to temporarily disable RocksDB deletion of old <code>WAL</code> and <code>.sst</code> files for the purposes of making a consistent backup. If the client session terminates for any reason after disabling deletions and has not re-enabled deletions, they will be explicitly re-enabled. This variable should be used by backup tools. Prolonged use or other misuse can have serious side effects to the server instance.</p>"},{"location":"myrocks-server-variables.html#rocksdb_disable_instant_ddl","title":"<code>rocksdb_disable_instant_ddl</code>","text":"Option Description Command-line \u2013rocksdb_disable_instant_ddl Dynamic Yes Scope Global Data type Boolean Default ON <p>Disables instant DDL during <code>ALTER TABLE</code> operations.</p> <p>This variable is enabled (ON) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_bulk_load_api","title":"<code>rocksdb_enable_bulk_load_api</code>","text":"Option Description Command-line \u2013rocksdb-enable-bulk-load-api Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether to use the <code>SSTFileWriter</code> feature for bulk loading, This feature bypasses the memtable, but requires keys to be inserted into the table in either ascending or descending order. Enabled by default. If disabled, bulk loading uses the normal write path via the memtable and does not require keys to be inserted in any order.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_delete_range_for_drop_index","title":"<code>rocksdb_enable_delete_range_for_drop_index</code>","text":"Option Description Command-line \u2013rocksdb_enable_delete_range_for_drop_index Dynamic Yes Scope Global Data type Boolean Default OFF <p>Enables drop table / index by calling the DeleteRange.</p> <p>This option is disabled (OFF) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_insert_with_update_caching","title":"<code>rocksdb_enable_insert_with_update_caching</code>","text":"Option Description Command-line \u2013rocksdb-enable-insert-with-update-caching Dynamic Yes Scope Global Data type Boolean Default ON <p>Specifies whether to enable optimization where the read is cached from a failed insertion attempt in INSERT ON DUPLICATE KEY UPDATE.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_iterate_bounds","title":"<code>rocksdb_enable_iterate_bounds</code>","text":"Option Description Command-line \u2013rocksdb-enable-iterate-bounds Dynamic Yes Scope Global, Local Data type Boolean Default ON <p>Enables the rocksdb iterator upper bounds and lower bounds in read options.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_pipelined_write","title":"<code>rocksdb_enable_pipelined_write</code>","text":"Option Description Command-line \u2013rocksdb-enable-pipelined-write Dynamic No Scope Global Data type Boolean Default OFF <p>DBOptions::enable_pipelined_write for RocksDB.</p> <p>If <code>enable_pipelined_write</code> is <code>ON</code>, a separate write thread is maintained for WAL write and memtable write. A write thread first enters the WAL writer queue and then the memtable writer queue. A pending thread on the WAL writer queue only waits for the previous WAL write operations but does not wait for memtable write operations. Enabling the feature may improve write throughput and reduce latency of the prepare phase of a two-phase commit.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_remove_orphaned_dropped_cfs","title":"<code>rocksdb_enable_remove_orphaned_dropped_cfs</code>","text":"Option Description Command-line \u2013rocksdb-enable-remove-orphaned-dropped-cfs Dynamic Yes Scope Global Data type Boolean Default ON <p>Enables the removal of dropped column families (cfs) from metadata if the cfs do not exist in the cf manager.</p> <p>The default value is <code>ON</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_ttl","title":"<code>rocksdb_enable_ttl</code>","text":"Option Description Command-line \u2013rocksdb-enable-ttl Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether to keep expired TTL records during compaction. Enabled by default. If disabled, expired TTL records will be dropped during compaction.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_ttl_read_filtering","title":"<code>rocksdb_enable_ttl_read_filtering</code>","text":"Option Description Command-line \u2013rocksdb-enable-ttl-read-filtering Dynamic Yes Scope Global Data type Boolean Default ON <p>For tables with TTL, expired records are skipped/filtered out during processing and in query results. Disabling this will allow these records to be seen, but as a result rows may disappear in the middle of transactions as they are dropped during compaction. Use with caution.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_thread_tracking","title":"<code>rocksdb_enable_thread_tracking</code>","text":"Option Description Command-line \u2013rocksdb-enable-thread-tracking Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to enable tracking the status of threads accessing the database. Disabled by default. If enabled, thread status will be available via <code>GetThreadList()</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_enable_write_thread_adaptive_yield","title":"<code>rocksdb_enable_write_thread_adaptive_yield</code>","text":"Option Description Command-line \u2013rocksdb-enable-write-thread-adaptive-yield Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether the MyRocks write batch group leader should wait up to the maximum allowed time before blocking on a mutex. Disabled by default. Enable it to increase throughput for concurrent workloads.</p>"},{"location":"myrocks-server-variables.html#rocksdb_error_if_exists","title":"<code>rocksdb_error_if_exists</code>","text":"Option Description Command-line \u2013rocksdb-error-if-exists Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to report an error when a database already exists. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_error_on_suboptimal_collation","title":"<code>rocksdb_error_on_suboptimal_collation</code>","text":"Option Description Command-line \u2013rocksdb-error-on-suboptimal-collation Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether to report an error instead of a warning if an index is created on a char field where the table has a sub-optimal collation (case insensitive). Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_file_checksums","title":"<code>rocksdb_file_checksums</code>","text":"Option Description Command-line \u2013rocksdb-file-checksums Dynamic No Scope Global Data type Boolean Default OFF <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>This variable controls whether to write and check RocksDB file-level checksums. The default value is <code>OFF</code> which means the variable is disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_flush_log_at_trx_commit","title":"<code>rocksdb_flush_log_at_trx_commit</code>","text":"Option Description Command-line \u2013rocksdb-flush-log-at-trx-commit Dynamic Yes Scope Global, Session Data type Numeric Default 1 <p>Specifies whether to sync on every transaction commit, similar to innodb_flush_log_at_trx_commit. Enabled by default, which ensures ACID compliance.</p> <p>Possible values:</p> <ul> <li> <p><code>0</code>: Do not sync on transaction commit. This provides better performance, but may lead to data inconsistency in case of a crash.</p> </li> <li> <p><code>1</code>: Sync on every transaction commit. This is set by default and recommended as it ensures data consistency, but reduces performance.</p> </li> <li> <p><code>2</code>: Sync every second.</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_flush_memtable_on_analyze","title":"<code>rocksdb_flush_memtable_on_analyze</code>","text":"Option Description Command-line \u2013rocksdb-flush-memtable-on-analyze Dynamic Yes Scope Global, Session Data type Boolean Default ON <p>Specifies whether to flush the memtable when running <code>ANALYZE</code> on a table. Enabled by default. This ensures accurate cardinality by including data in the memtable for calculating stats.</p>"},{"location":"myrocks-server-variables.html#rocksdb_force_compute_memtable_stats","title":"<code>rocksdb_force_compute_memtable_stats</code>","text":"Option Description Command-line \u2013rocksdb-force-compute-memtable-stats Dynamic Yes Scope Global Data type Boolean Default ON <p>Specifies whether data in the memtables should be included for calculating index statistics used by the query optimizer. Enabled by default. This provides better accuracy, but may reduce performance.</p>"},{"location":"myrocks-server-variables.html#rocksdb_force_compute_memtable_stats_cachetime","title":"<code>rocksdb_force_compute_memtable_stats_cachetime</code>","text":"Option Description Command-line \u2013rocksdb-force-compute-memtable-stats-cachetime Dynamic Yes Scope Global Data type Numeric Default 60000000 <p>Specifies for how long the cached value of memtable statistics should be used instead of computing it every time during the query plan analysis.</p>"},{"location":"myrocks-server-variables.html#rocksdb_force_flush_memtable_and_lzero_now","title":"<code>rocksdb_force_flush_memtable_and_lzero_now</code>","text":"Option Description Command-line \u2013rocksdb-force-flush-memtable-and-lzero-now Dynamic Yes Scope Global Data type Boolean Default OFF <p>Works similar to <code>rocksdb_force_flush_memtable_now</code> but also flushes all L0 files.</p>"},{"location":"myrocks-server-variables.html#rocksdb_force_flush_memtable_now","title":"<code>rocksdb_force_flush_memtable_now</code>","text":"Option Description Command-line \u2013rocksdb-force-flush-memtable-now Dynamic Yes Scope Global Data type Boolean Default OFF <p>Forces MyRocks to immediately flush all memtables out to data files.</p> <p>Warning</p> <p>Use with caution! Write requests will be blocked until all memtables are flushed.</p>"},{"location":"myrocks-server-variables.html#rocksdb_force_index_records_in_range","title":"<code>rocksdb_force_index_records_in_range</code>","text":"Option Description Command-line \u2013rocksdb-force-index-records-in-range Dynamic Yes Scope Global, Session Data type Numeric Default 1 <p>Specifies the value used to override the number of rows returned to query optimizer when <code>FORCE INDEX</code> is used. Default value is <code>1</code>. Allowed range is from <code>0</code> to <code>2147483647</code>. Set to <code>0</code> if you do not want to override the returned value.</p>"},{"location":"myrocks-server-variables.html#rocksdb_hash_index_allow_collision","title":"<code>rocksdb_hash_index_allow_collision</code>","text":"Option Description Command-line \u2013rocksdb-hash-index-allow-collision Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether hash collisions are allowed. Enabled by default, which uses less memory. If disabled, full prefix is stored to prevent hash collisions.</p>"},{"location":"myrocks-server-variables.html#rocksdb_ignore_unknown_options","title":"<code>rocksdb_ignore_unknown_options</code>","text":"Option Description Command-line Dynamic No Scope Global Data type Boolean Default ON <p>When enabled, it allows RocksDB to receive unknown options and not exit.</p>"},{"location":"myrocks-server-variables.html#rocksdb_index_type","title":"<code>rocksdb_index_type</code>","text":"Option Description Command-line \u2013rocksdb-index-type Dynamic No Scope Global Data type Enum Default kBinarySearch <p>Specifies the type of indexing used by MyRocks:</p> <ul> <li> <p><code>kBinarySearch</code>: Binary search (default).</p> </li> <li> <p><code>kHashSearch</code>: Hash search.</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_info_log_level","title":"<code>rocksdb_info_log_level</code>","text":"Option Description Command-line \u2013rocksdb-info-log-level Dynamic Yes Scope Global Data type Enum Default error_level <p>Specifies the level for filtering messages written by MyRocks to the <code>mysqld</code> log.</p> <ul> <li> <p><code>debug_level</code>: Maximum logging (everything including debugging log messages)</p> </li> <li> <p><code>info_level</code></p> </li> <li> <p><code>warn_level</code></p> </li> <li> <p><code>error_level</code> (default)</p> </li> <li> <p><code>fatal_level</code>: Minimum logging (only fatal error messages logged)</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_is_fd_close_on_exec","title":"<code>rocksdb_is_fd_close_on_exec</code>","text":"Option Description Command-line \u2013rocksdb-is-fd-close-on-exec Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether child processes should inherit open file jandles. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_large_prefix","title":"<code>rocksdb_large_prefix</code>","text":"Option Description Command-line \u2013rocksdb-large-prefix Dynamic Yes Scope Global Data type Boolean Default ON <p>This variable is deprecated in <code>Percona Server for MySQL 8.3.0-1</code> and will be removed in a future release.</p> <p>When enabled, this option allows index key prefixes longer than 767 bytes (up to 3072 bytes). The values for <code>rocksdb_large_prefix</code> should be the same between source and replica.</p>"},{"location":"myrocks-server-variables.html#rocksdb_keep_log_file_num","title":"<code>rocksdb_keep_log_file_num</code>","text":"Option Description Command-line \u2013rocksdb-keep-log-file-num Dynamic No Scope Global Data type Numeric Default 1000 <p>Specifies the maximum number of info log files to keep. Default value is <code>1000</code>. Allowed range is from <code>1</code> to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_lock_scanned_rows","title":"<code>rocksdb_lock_scanned_rows</code>","text":"Option Description Command-line \u2013rocksdb-lock-scanned-rows Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to hold the lock on rows that are scanned during <code>UPDATE</code> and not actually updated. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_lock_wait_timeout","title":"<code>rocksdb_lock_wait_timeout</code>","text":"Option Description Command-line \u2013rocksdb-lock-wait-timeout Dynamic Yes Scope Global, Session Data type Numeric Default 1 <p>Specifies the number of seconds MyRocks should wait to acquire a row lock before aborting the request. Default value is <code>1</code>. Allowed range is up to <code>1073741824</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_log_file_time_to_roll","title":"<code>rocksdb_log_file_time_to_roll</code>","text":"Option Description Command-line \u2013rocksdb-log-file-time-to-roll Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the period (in seconds) for rotating the info log files. Default value is <code>0</code>, meaning that the log file is not rotated. Allowed range is up to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_manifest_preallocation_size","title":"<code>rocksdb_manifest_preallocation_size</code>","text":"Option Description Command-line \u2013rocksdb-manifest-preallocation-size Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the number of bytes to preallocate for the MANIFEST file used by MyRocks to store information about column families, levels, active files, etc. Default value is <code>0</code>. Allowed range is up to <code>18446744073709551615</code>.</p> <p>Note</p> <p>A value of <code>4194304</code> (4 MB) is reasonable to reduce random I/O on XFS.</p>"},{"location":"myrocks-server-variables.html#rocksdb_manual_compaction_bottommost_level","title":"<code>rocksdb_manual_compaction_bottommost_level</code>","text":"Option Description Command-line \u2013rocksdb-manual-compaction-bottommost-level Dynamic Yes Scope Local Data type Enum Default kForceOptimized <p>Option for bottommost level compaction during manual compaction:</p> <ul> <li> <p>kSkip - Skip bottommost level compaction</p> </li> <li> <p>kIfHaveCompactionFilter - Only compact bottommost level if there is a compaction filter</p> </li> <li> <p>kForce - Always compact bottommost level</p> </li> <li> <p>kForceOptimized -  Always compact bottommost level but in bottommost level avoid double-compacting files created in the same compaction</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_manual_compaction_threads","title":"rocksdb_manual_compaction_threads","text":"Option Description Command-line \u2013rocksdb-manual-compaction-threads Dynamic Yes Scope Local Data type INT Default 0 <p>The variable defines the number of RocksDB threads to run for a manual compaction. The minimum value is 0. The maximum value is 120. </p>"},{"location":"myrocks-server-variables.html#rocksdb_manual_wal_flush","title":"<code>rocksdb_manual_wal_flush</code>","text":"Option Description Command-line \u2013rocksdb-manual-wal-flush Dynamic No Scope Global Data type Boolean Default ON <p>This variable can be used to disable automatic/timed WAL flushing and instead rely on the application to do the flushing.</p>"},{"location":"myrocks-server-variables.html#rocksdb_master_skip_tx_api","title":"<code>rocksdb_master_skip_tx_api</code>","text":"Option Description Command-line Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>When enabled, uses the WriteBatch API, which is faster. The session does not hold any lock on row access. This variable is not effective on replica.</p> <p>Note</p> <p>Due to the disabled row locks, improper use of the variable can cause data corruption or inconsistency.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_background_compactions","title":"<code>rocksdb_max_background_compactions</code>","text":"Option Description Command-line \u2013rocksdb-max-background-compactions Dynamic Yes Scope Global Data type Numeric Default -1 <p>Sets DBOptions:: max_background_compactions for RocksDB. The default value is <code>-1</code> The allowed range is <code>-1</code> to <code>64</code>. This variable was replaced by rocksdb_max_background_jobs, which automatically decides how many threads to allocate towards flush/compaction.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_background_flushes","title":"<code>rocksdb_max_background_flushes</code>","text":"Option Description Command-line \u2013rocksdb-max-background-flushes Dynamic No Scope Global Data type Numeric Default -1 <p>Sets DBOptions:: max_background_flushes for RocksDB. The default value is <code>-1</code>. The allowed range is <code>-1</code> to <code>64</code>. This variable has been replaced by rocksdb_max_background_jobs, which automatically decides how many threads to allocate towards flush/compaction.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_background_jobs","title":"<code>rocksdb_max_background_jobs</code>","text":"Option Description Command-line \u2013rocksdb-max-background-jobs Dynamic Yes Scope Global Data type Numeric Default 2 <p>This variable replaced rocksdb_base_background_compactions, rocksdb_max_background_compactions, and rocksdb_max_background_flushes variables. This variable specifies the maximum number of background jobs. It automatically decides how many threads to allocate towards flush/compaction. It was implemented to reduce the number of (confusing) options users and can tweak and push the responsibility down to RocksDB level.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_bottom_pri_background_compactions","title":"<code>rocksdb_max_bottom_pri_background_compactions</code>","text":"Option Description Command-line \u2013rocksdb_max_bottom_pri_background_compactions Dynamic No Data type Unsigned integer Default 0 <p>Creates a specified number of threads, sets a lower CPU priority, and letting compactions use them. The maximum compaction concurrency is capped by <code>rocksdb_max_background_compactions</code> or <code>rocksdb_max_background_jobs</code></p> <p>The minimum value is <code>0</code> and the maximum value is <code>64</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_compaction_history","title":"<code>rocksdb_max_compaction_history</code>","text":"Option Description Command-line \u2013rocksdb-max-compaction-history Dynamic Yes Scope Global Data type Unsigned integer Default 64 <p>The minimum value is <code>0</code> and the maximum value is <code>UINT64_MAX</code>.</p> <p>Tracks the history for at most <code>rockdb_mx_compaction_history</code> completed compactions. The history is in the INFORMATION_SCHEMA.ROCKSDB_COMPACTION_HISTORY table.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_file_opening_threads","title":"<code>rocksdb_max_file_opening_threads</code>","text":"Option Description Command-line \u2013rocksdb-max-file-opening-threads Dynamic No Scope Global Data type Numeric Default 16 <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>This variable sets <code>DBOptions::max_file_opening_threads</code> for RocksDB. The default value is <code>16</code>. The minimum value is <code>1</code> and the maximum value is 2147483647 (<code>INT_MAX</code>).</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_latest_deadlocks","title":"<code>rocksdb_max_latest_deadlocks</code>","text":"Option Description Command-line \u2013rocksdb-max-latest-deadlocks Dynamic Yes Scope Global Data type Numeric Default 5 <p>Specifies the maximum number of recent deadlocks to store.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_log_file_size","title":"<code>rocksdb_max_log_file_size</code>","text":"Option Description Command-line \u2013rocksdb-max-log-file-size Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the maximum size for info log files, after which the log is rotated. Default value is <code>0</code>, meaning that only one log file is used. Allowed range is up to <code>18446744073709551615</code>.</p> <p>Also see rocksdb_log_file_time_to_roll.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_manifest_file_size","title":"<code>rocksdb_max_manifest_file_size</code>","text":"Option Description Command-line \u2013rocksdb-manifest-log-file-size Dynamic No Scope Global Data type Numeric Default 18446744073709551615 <p>Specifies the maximum size of the MANIFEST data file, after which it is rotated. Default value is also the maximum, making it practically unlimited: only one manifest file is used.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_manual_compactions","title":"<code>rocksdb_max_manual_compactions</code>","text":"Option Description Command-line \u2013rocksdb-max-manual-compactions Dynamic Yes Scope Global Data type UINT Default 10 <p>The variable defines the maximum number of pending plus ongoing manual compactions. The default value and the minimum value is 0. The maximum value is 4294967295 (UNIT_MAX).</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_open_files","title":"<code>rocksdb_max_open_files</code>","text":"Option Description Command-line \u2013rocksdb-max-open-files Dynamic No Scope Global Data type Numeric Default 1000 <p>Specifies the maximum number of file handles opened by MyRocks. Values in the range between <code>0</code> and <code>open_files_limit</code> are taken as they are. If rocksdb_max_open_files value is greater than <code>open_files_limit</code>, it will be reset to \u00bd of <code>open_files_limit</code>, and a warning will be emitted to the <code>mysqld</code> error log. A value of <code>-2</code> denotes auto tuning: just sets rocksdb_max_open_files value to \u00bd of <code>open_files_limit</code>. Finally, <code>-1</code> means no limit, i.e. an infinite number of file handles.</p> <p>Warning</p> <p>Setting rocksdb_max_open_files to <code>-1</code> is dangerous, as the server may quickly run out of file handles in this case.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_row_locks","title":"<code>rocksdb_max_row_locks</code>","text":"Option Description Command-line \u2013rocksdb-max-row-locks Dynamic Yes Scope Global Data type Numeric Default 1048576 <p>Specifies the limit on the maximum number of row locks a transaction can have before it fails. Default value is also the maximum, making it practically unlimited: transactions never fail due to row locks.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_subcompactions","title":"<code>rocksdb_max_subcompactions</code>","text":"Option Description Command-line \u2013rocksdb-max-subcompactions Dynamic No Scope Global Data type Numeric Default 1 <p>Specifies the maximum number of threads allowed for each compaction job. Default value of <code>1</code> means no subcompactions (one thread per compaction job). Allowed range is up to <code>64</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_max_total_wal_size","title":"<code>rocksdb_max_total_wal_size</code>","text":"Option Description Command-line \u2013rocksdb-max-total-wal-size Dynamic No Scope Global Data type Numeric Default 2 GB <p>Specifies the maximum total size of WAL (write-ahead log) files, after which memtables are flushed. Default value is <code>2 GB</code> The allowed range is up to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_merge_buf_size","title":"<code>rocksdb_merge_buf_size</code>","text":"Option Description Command-line \u2013rocksdb-merge-buf-size Dynamic Yes Scope Global Data type Numeric Default 67108864 <p>Specifies the size (in bytes) of the merge-sort buffers used to accumulate data during secondary key creation. New entries are written directly to the lowest level in the database, instead of updating indexes through the memtable and L0. These values are sorted using merge-sort, with buffers set to 64 MB by default (<code>67108864</code>). Allowed range is from <code>100</code> to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_merge_combine_read_size","title":"<code>rocksdb_merge_combine_read_size</code>","text":"Option Description Command-line \u2013rocksdb-merge-combine-read-size Dynamic Yes Scope Global Data type Numeric Default 1073741824 <p>Specifies the size (in bytes) of the merge-combine buffer used for the merge-sort algorithm as described in rocksdb_merge_buf_size. Default size is 1 GB (<code>1073741824</code>). Allowed range is from <code>100</code> to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_merge_tmp_file_removal_delay_ms","title":"<code>rocksdb_merge_tmp_file_removal_delay_ms</code>","text":"Option Description Command-line \u2013rocksdb_merge_tmp_file_removal_delay_ms Dynamic Yes Scope Global, Session Data type Numeric Default 0 <p>Fast secondary index creation creates merge files when needed. After finishing secondary index creation, merge files are removed. By default, the file removal is done without any sleep, so removing GBs of merge files within &lt;1s may happen, which will cause trim stalls on Flash. This variable can be used to rate limit the delay in milliseconds.</p>"},{"location":"myrocks-server-variables.html#rocksdb_new_table_reader_for_compaction_inputs","title":"<code>rocksdb_new_table_reader_for_compaction_inputs</code>","text":"Option Description Command-line \u2013rocksdb-new-table-reader-for-compaction-inputs Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether MyRocks should create a new file descriptor and table reader for each compaction input. Disabled by default. Enabling this may increase memory consumption, but will also allow pre-fetch options to be specified for compaction input files without impacting table readers used for user queries.</p>"},{"location":"myrocks-server-variables.html#rocksdb_no_block_cache","title":"<code>rocksdb_no_block_cache</code>","text":"Option Description Command-line \u2013rocksdb-no-block-cache Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to disable the block cache for column families. Variable is disabled by default, meaning that using the block cache is allowed.</p>"},{"location":"myrocks-server-variables.html#rocksdb_no_create_column_family","title":"<code>rocksdb_no_create_column_family</code>","text":"Option Description Command-line \u2013rocksdb-no-create-column-family Dynamic No Scope Global Data type Boolean Default ON <p>Controls the processing of the column family name given in the <code>COMMENT</code> clause in the <code>CREATE TABLE</code> or <code>ALTER TABLE</code> statement in case the column family name does not refer to an existing column family.</p> <p>If rocksdb_no_create_column_family is set to NO, a new column family will be created and the new index will be placed into it.</p> <p>If rocksdb_no_create_column_family is set to YES, no new column family will be created and the index will be placed into the default column family. A warning is issued in this case informing that the specified column family does not exist and cannot be created.</p>"},{"location":"myrocks-server-variables.html#rocksdb_override_cf_options","title":"<code>rocksdb_override_cf_options</code>","text":"Option Description Command-line \u2013rocksdb-override-cf-options Dynamic No Scope Global Data type String Default <p>Specifies option overrides for each column family. Empty by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_paranoid_checks","title":"<code>rocksdb_paranoid_checks</code>","text":"Option Description Command-line \u2013rocksdb-paranoid-checks Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether MyRocks should re-read the data file as soon as it is created to verify correctness. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_partial_index_ignore_killed","title":"<code>rocksdb_partial_index_ignore_killed</code>","text":"Option Description Command-line \u2013rocksdb-partial-index-ignore-killed Dynamic Yes Scope Global Data type Boolean Default ON <p>This variable has been implemented in Percona Server for MySQL 8.3.0-1.</p> <p>If this variable is set to <code>ON</code>, the partial index materialization ignores the killed flag and continues materialization until completion. If queries are killed during materialization due to timeout, the work done so far is wasted, and the killed query will likely be retried later, hitting the same issue.</p> <p>The dafault value is <code>ON</code> which means this variable is enabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_partial_index_sort_max_mem","title":"<code>rocksdb_partial_index_sort_max_mem</code>","text":"Option Description Command-line \u2013rocksdb-partial-index-sort-max-mem Dynamic Yes Scope Local Data type Unsigned Integer Default 0 <p>Maximum memory to use when sorting an unmaterialized group for partial indexes. The 0(zero) value is defined as no limit.</p>"},{"location":"myrocks-server-variables.html#rocksdb_pause_background_work","title":"<code>rocksdb_pause_background_work</code>","text":"Option Description Command-line \u2013rocksdb-pause-background-work Dynamic Yes Scope Global Data type Boolean Default OFF <p>Specifies whether MyRocks should pause all background operations. Disabled by default. There is no practical reason for a user to ever use this variable because it is intended as a test synchronization tool for the MyRocks MTR test suites.</p> <p>Warning</p> <p>If someone were to set a rocksdb_force_flush_memtable_now to <code>1</code> while rocksdb_pause_background_work is set to <code>1</code>, the client that issued the <code>rocksdb_force_flush_memtable_now=1</code> will be blocked indefinitely until rocksdb_pause_background_work is set to <code>0</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_partial_index_blind_delete","title":"<code>rocksdb_partial_index_blind_delete</code>","text":"Option Description Command-line \u2013rocksdb_partial_index_blind_delete Dynamic Yes Scope Global Data type Boolean Default ON <p>If enabled, the server does not read from the partial index to check if the key exists before  deleting the partial index and the delete marker is unconditionally written.</p> <p>If the variable is disabled (OFF), the server always reads from partial index to check if key exists before  deleting the partial index. </p> <p>This variable is enabled (ON) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_perf_context_level","title":"<code>rocksdb_perf_context_level</code>","text":"Option Description Command-line \u2013rocksdb-perf-context-level Dynamic Yes Scope Global, Session Data type Numeric Default 0 <p>Specifies the level of information to capture with the Perf Context plugins. The default value is <code>0</code>. The allowed range is up to <code>5</code>.</p> Value Description 1 Disable perf stats 2 Enable only count stats 3 Enable count stats and time stats except for mutexes 4 Enable count stats and time stats, except for wall time or CPU time for mutexes 5 Enable all count stats and time stats"},{"location":"myrocks-server-variables.html#rocksdb_persistent_cache_path","title":"<code>rocksdb_persistent_cache_path</code>","text":"Option Description Command-line \u2013rocksdb-persistent-cache-path Dynamic No Scope Global Data type String Default <p>Specifies the path to the persistent cache. Set this together with rocksdb_persistent_cache_size_mb.</p>"},{"location":"myrocks-server-variables.html#rocksdb_persistent_cache_size_mb","title":"<code>rocksdb_persistent_cache_size_mb</code>","text":"Option Description Command-line \u2013rocksdb-persistent-cache-size-mb Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the size of the persisten cache in megabytes. Default is <code>0</code> (persistent cache disabled). Allowed range is up to <code>18446744073709551615</code>. Set this together with rocksdb_persistent_cache_path.</p>"},{"location":"myrocks-server-variables.html#rocksdb_pin_l0_filter_and_index_blocks_in_cache","title":"<code>rocksdb_pin_l0_filter_and_index_blocks_in_cache</code>","text":"Option Description Command-line \u2013rocksdb-pin-l0-filter-and-index-blocks-in-cache Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether MyRocks pins the filter and index blocks in the cache if rocksdb_cache_index_and_filter_blocks is enabled. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_print_snapshot_conflict_queries","title":"<code>rocksdb_print_snapshot_conflict_queries</code>","text":"Option Description Command-line \u2013rocksdb-print-snapshot-conflict-queries Dynamic Yes Scope Global Data type Boolean Default OFF <p>Specifies whether queries that generate snapshot conflicts should be logged to the error log. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_protection_bytes_per_key","title":"<code>rocksdb_protection_bytes_per_key</code>","text":"Option Description Command-line \u2013rocksdb_protection_bytes_per_key Dynamic Yes Scope Global, Session Data type Numeric Default 0 <p>This variable is used to configure <code>WriteOptions::protection_bytes_per_key</code>. The default value is 0 (disabled). When this variable is set to 1, 2, 4, or 8, it uses that number of bytes per key value to protect entries in the WriteBatch.</p> <p>The minimum value is <code>0</code>.</p> <p>The maximum value is <code>ULONG_MAX (0xFFFFFFFF)</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_rate_limiter_bytes_per_sec","title":"<code>rocksdb_rate_limiter_bytes_per_sec</code>","text":"Option Description Command-line \u2013rocksdb-rate-limiter-bytes-per-sec Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies the maximum rate at which MyRocks can write to media via memtable flushes and compaction. Default value is <code>0</code> (write rate is not limited). Allowed range is up to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_read_free_rpl","title":"<code>rocksdb_read_free_rpl</code>","text":"Option Description Command-line \u2013rocksdb-read-free-rpl Dynamic Yes Scope Global Data type Enum Default OFF <p>Uses read-free replication, which allows no row lookup during replication, on the replica.</p> <p>The options are the following:</p> <ul> <li> <p>OFF - Disables the variable</p> </li> <li> <p>PK_SK - Enables the variable on all tables with a primary key</p> </li> <li> <p>PK_ONLY - Enables the variable on tables where the only key is the primary key</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_read_free_rpl_tables","title":"<code>rocksdb_read_free_rpl_tables</code>","text":"Option Description Command-line \u2013rocksdb-read-free-rpl-tables Dynamic Yes Scope Global, Session Data type String Default <p>We recommend that you use <code>rocksdb_read_free_rpl</code> instead of this variable.</p> <p>This variable lists tables (as a regular expression) that should use read-free replication on the replica (that is, replication without row lookups). Empty by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_records_in_range","title":"<code>rocksdb_records_in_range</code>","text":"Option Description Command-line \u2013rocksdb-records-in-range Dynamic Yes Scope Global, Session Data type Numeric Default 0 <p>Specifies the value to override the result of <code>records_in_range()</code>. Default value is <code>0</code>. Allowed range is up to <code>2147483647</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_reset_stats","title":"<code>rocksdb_reset_stats</code>","text":"Option Description Command-line \u2013rocksdb-reset-stats Dynamic Yes Scope Global Data type Boolean Default OFF <p>Resets MyRocks internal statistics dynamically (without restarting the server).</p>"},{"location":"myrocks-server-variables.html#rocksdb_rollback_on_timeout","title":"<code>rocksdb_rollback_on_timeout</code>","text":"Option Description Command-line \u2013rocksdb-rollback-on-timeout Dynamic Yes Scope Global Data type Boolean Default OFF <p>By default, only the last statement on a transaction is rolled back. If <code>--rocksdb-rollback-on-timeout=ON</code>, a transaction timeout causes a rollback of the entire transaction.</p>"},{"location":"myrocks-server-variables.html#rocksdb_rpl_skip_tx_api","title":"<code>rocksdb_rpl_skip_tx_api</code>","text":"Option Description Command-line \u2013rocksdb-rpl-skip-tx-api Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether write batches should be used for replication thread instead of the transaction API. Disabled by default.</p> <p>There are two conditions which are necessary to use it: row replication format and replica operating in super read only mode.</p>"},{"location":"myrocks-server-variables.html#rocksdb_seconds_between_stat_computes","title":"<code>rocksdb_seconds_between_stat_computes</code>","text":"Option Description Command-line \u2013rocksdb-seconds-between-stat-computes Dynamic Yes Scope Global Data type Numeric Default 3600 <p>Specifies the number of seconds to wait between recomputation of table statistics for the optimizer. During that time, only changed indexes are updated. Default value is <code>3600</code>. Allowed is from <code>0</code> to <code>4294967295</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_signal_drop_index_thread","title":"<code>rocksdb_signal_drop_index_thread</code>","text":"Option Description Command-line \u2013rocksdb-signal-drop-index-thread Dynamic Yes Scope Global Data type Boolean Default OFF <p>Signals the MyRocks drop index thread to wake up.</p>"},{"location":"myrocks-server-variables.html#rocksdb_sim_cache_size","title":"<code>rocksdb_sim_cache_size</code>","text":"Option Description Command-line \u2013rocksdb-sim-cache-size Dynamic No Scope Global Data type Numeric Default 0 <p>Enables the simulated cache, which allows us to figure out the hit/miss rate with a specific cache size without changing the real block cache.</p>"},{"location":"myrocks-server-variables.html#rocksdb_skip_bloom_filter_on_read","title":"<code>rocksdb_skip_bloom_filter_on_read</code>","text":"Option Description Command-line \u2013rocksdb-skip-bloom-filter-on_read Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether bloom filters should be skipped on reads. Disabled by default (bloom filters are not skipped).</p>"},{"location":"myrocks-server-variables.html#rocksdb_skip_fill_cache","title":"<code>rocksdb_skip_fill_cache</code>","text":"Option Description Command-line \u2013rocksdb-skip-fill-cache Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to skip caching data on read requests. Disabled by default (caching is not skipped).</p>"},{"location":"myrocks-server-variables.html#rocksdb_skip_locks_if_skip_unique_check","title":"<code>rocksdb_skip_locks_if_skip_unique_check</code>","text":"Option Description Command-line rocksdb_skip_locks_if_skip_unique_check Dynamic Yes Scope Global Data type Boolean Default OFF <p>Skip row locking when unique checks are disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_sst_mgr_rate_bytes_per_sec","title":"<code>rocksdb_sst_mgr_rate_bytes_per_sec</code>","text":"Option Description Command-line \u2013rocksdb-sst-mgr-rate-bytes-per-sec Dynamic Yes Scope Global, Session Data type Numeric Default 0 <p>Specifies the maximum rate for writing to data files. Default value is <code>0</code>. This option is not effective on HDD. Allowed range is from <code>0</code> to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_stats_dump_period_sec","title":"<code>rocksdb_stats_dump_period_sec</code>","text":"Option Description Command-line \u2013rocksdb-stats-dump-period-sec Dynamic No Scope Global Data type Numeric Default 600 <p>Specifies the period in seconds for performing a dump of the MyRocks statistics to the info log. Default value is <code>600</code>. Allowed range is up to <code>2147483647</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_stats_level","title":"<code>rocksdb_stats_level</code>","text":"Option Description Command-line \u2013rocksdb-stats-level Dynamic Yes Scope Global Data type Numeric Default 0 <p>Controls the RocksDB statistics level. The default value is \u201c0\u201d (kExceptHistogramOrTimers), which is the fastest level. The maximum value is \u201c4\u201d.</p>"},{"location":"myrocks-server-variables.html#rocksdb_stats_recalc_rate","title":"<code>rocksdb_stats_recalc_rate</code>","text":"Option Description Command-line \u2013rocksdb-stats-recalc-rate Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the number of indexes to recalculate per second. Recalculating index statistics periodically ensures it to match the actual sum from SST files. Default value is <code>0</code>. Allowed range is up to <code>4294967295</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_store_row_debug_checksums","title":"<code>rocksdb_store_row_debug_checksums</code>","text":"Option Description Command-line \u2013rocksdb-store-row-debug-checksums Dynamic Yes Scope Global Data type Boolean Default OFF <p>Specifies whether to include checksums when writing index or table records. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_strict_collation_check","title":"<code>rocksdb_strict_collation_check</code>","text":"Option Description Command-line \u2013rocksdb-strict-collation-check Dynamic Yes Scope Global Data type Boolean Default ON <p>This variable is removed in Percona Server for MySQL 8.2.0-1.</p> <p>This variable is considered deprecated in Percona Server for MySQL 8.0.23-14.</p> <p>Specifies whether to check and verify that table indexes have proper collation settings. Enabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_strict_collation_exceptions","title":"<code>rocksdb_strict_collation_exceptions</code>","text":"Option Description Command-line \u2013rocksdb-strict-collation-exceptions Dynamic Yes Scope Global Data type String Default <p>This variable is removed in Percona Server for MySQL 8.2.0-1.</p> <p>This variable is considered deprecated in Percona Server for MySQL 8.0.23-14.</p> <p>Lists tables (as a regular expression) that should be excluded from verifying case-sensitive collation enforced by rocksdb_strict_collation_check. Empty by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_cache_numshardbits","title":"<code>rocksdb_table_cache_numshardbits</code>","text":"Option Description Command-line \u2013rocksdb-table-cache-numshardbits Dynamic No Scope Global Data type Numeric Default 6 <p>Specifies the number if table caches. The default value is <code>6</code>. The allowed range is from <code>0</code> to <code>19</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_background_thread_nice_value","title":"<code>rocksdb_table_stats_background_thread_nice_value</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-background-thread-nice-value Dynamic Yes Scope Global Data type Numeric Default 19 <p>The nice value for index stats. The minimum = -20 (THREAD_PRIO_MIN) The maximum = 19 (THREAD_PRIO_MAX)</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_max_num_rows_scanned","title":"<code>rocksdb_table_stats_max_num_rows_scanned</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-max-num-rows-scanned Dynamic Yes Scope Global Data type Numeric Default 0 <p>The maximum number of rows to scan in a table scan based on a cardinality calculation. The minimum is <code>0</code> (every modification triggers a stats recalculation). The maximum is <code>18,446,744,073,709,551,615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_recalc_threshold_count","title":"<code>rocksdb_table_stats_recalc_threshold_count</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-recalc-threshold-count Dynamic Yes Scope Global Data type Numeric Default 100 <p>The number of modified rows to trigger a stats recalculation. This is a dependent variable for stats recalculation. The minimum is <code>0</code>. The maximum is <code>18,446,744,073,709,551,615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_recalc_threshold_pct","title":"<code>rocksdb_table_stats_recalc_threshold_pct</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-recalc-threshold-pct Dynamic Yes Scope Global Data type Numeric Default 10 <p>The percentage of the number of modified rows over the total number of rows to trigger stats recalculations. This is a dependent variable for stats recalculation. The minimum value is <code>0</code> The maximum value is <code>100</code> (RDB_TBL_STATS_RECALC_THRESHOLD_PCT_MAX).</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_sampling_pct","title":"<code>rocksdb_table_stats_sampling_pct</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-sampling-pct Dynamic Yes Scope Global Data type Numeric Default 10 <p>Specifies the percentage of entries to sample when collecting statistics about table properties. Default value is <code>10</code>. Allowed range is from <code>0</code> to <code>100</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_table_stats_use_table_scan","title":"<code>rocksdb_table_stats_use_table_scan</code>","text":"Option Description Command-line \u2013rocksdb-table-stats-use-table-scan Dynamic Yes Scope Global Data type Boolean Default OFF. <p>Enables table-scan-based index calculations. The default value is <code>OFF</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_tmpdir","title":"<code>rocksdb_tmpdir</code>","text":"Option Description Command-line \u2013rocksdb-tmpdir Dynamic Yes Scope Global, Session Data type String Default <p>Specifies the path to the directory for temporary files during DDL operations.</p>"},{"location":"myrocks-server-variables.html#rocksdb_trace_block_cache_access","title":"<code>rocksdb_trace_block_cache_access</code>","text":"Option Description Command-line \u2013rocksdb-trace-block-cache-access Dynamic Yes Scope Global Data type String Default \"\" <p>Defines the block cache trace option string. The format is sampling frequency: max_trace_file_size:trace_file_name. The sampling frequency value and max_trace_file_size value are positive integers. The block accesses are saved to the <code>rocksdb_datadir/block_cache_traces/trace_file_name</code>. The default value is an empty string.</p>"},{"location":"myrocks-server-variables.html#rocksdb_trace_queries","title":"<code>rocksdb_trace_queries</code>","text":"Option Description Command-line \u2013rocksdb-trace-queries Dynamic Yes Scope Global Data type String Default \"\" <p>This variable is a trace option string. The format is sampling_frequency:max_trace_file_size:trace_file_name. The sampling_frequency and max_trace_file_size are positive integers. The queries are saved to the rocksdb_datadir/queries_traces/trace_file_name.</p>"},{"location":"myrocks-server-variables.html#rocksdb_trace_sst_api","title":"<code>rocksdb_trace_sst_api</code>","text":"Option Description Command-line \u2013rocksdb-trace-sst-api Dynamic Yes Scope Global Data type Boolean Default OFF <p>Specifies whether to generate trace output in the log for each call to <code>SstFileWriter</code>. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_track_and_verify_wals_in_manifest","title":"<code>rocksdb_track_and_verify_wals_in_manifest</code>","text":"Option Description Command-line \u2013rocksdb-track-and-verify-wals-in-manifest Dynamic No Scope Global Data type Boolean Default ON <p>DBOptions::track_and_verify_wals_in_manifest for RocksDB.</p>"},{"location":"myrocks-server-variables.html#rocksdb_two_write_queues","title":"<code>rocksdb_two_write_queues</code>","text":"Option Description Command-line \u2013rocksdb-track-and-verify-wals-in-manifest Dynamic No Scope Global Data type Boolean Default ON <p>When enabled this variable allows/encourages threads that are using two-phase commit to <code>prepare</code> in parallel.</p>"},{"location":"myrocks-server-variables.html#rocksdb_unsafe_for_binlog","title":"<code>rocksdb_unsafe_for_binlog</code>","text":"Option Description Command-line \u2013rocksdb-unsafe-for-binlog Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to allow statement-based binary logging which may break consistency. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_update_cf_options","title":"<code>rocksdb_update_cf_options</code>","text":"Option Description Command-line \u2013rocksdb-update-cf-options Dynamic No Scope Global Data type String Default <p>Specifies option updates for each column family. Empty by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_adaptive_mutex","title":"<code>rocksdb_use_adaptive_mutex</code>","text":"Option Description Command-line \u2013rocksdb-use-adaptive-mutex Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to use adaptive mutex which spins in user space before resorting to the kernel. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_default_sk_cf","title":"<code>rocksdb_use_default_sk_cf</code>","text":"Option Description Command-line \u2013rocksdb-use-default-sk-cf Dynamic No Scope Global Data type Boolean Default OFF <p>Use <code>default_sk</code> column family for secondary keys.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_direct_io_for_flush_and_compaction","title":"<code>rocksdb_use_direct_io_for_flush_and_compaction</code>","text":"Option Description Command-line \u2013rocksdb-use-direct-io-for-flush-and-compaction Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to write to data files directly, without caches or buffers. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_direct_reads","title":"<code>rocksdb_use_direct_reads</code>","text":"Option Description Command-line \u2013rocksdb-use-direct-reads Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether to read data files directly, without caches or buffers. Disabled by default. If you enable this, make sure that rocksdb_allow_mmap_reads is disabled.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_fsync","title":"<code>rocksdb_use_fsync</code>","text":"Option Description Command-line \u2013rocksdb-use-fsync Dynamic No Scope Global Data type Boolean Default OFF <p>Specifies whether MyRocks should use <code>fsync</code> instead of <code>fdatasync</code> when requesting a sync of a data file. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_hyper_clock_cache","title":"<code>rocksdb_use_hyper_clock_cache</code>","text":"Option Description Command-line \u2013rocksdb_use_hyper_clock_cache Dynamic No Scope Global Data type Boolean Default OFF <p>If enabled, this variable uses HyperClockCache instead of default LRUCache for RocksDB.</p> <p>This variable is disabled (OFF) by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_use_write_buffer_manager","title":"<code>rocksdb_use_write_buffer_manager</code>","text":"Option Description Command-line \u2013rocksdb_use_write_buffer_manager Dynamic No Scope Global Data type Boolean Default OFF <p>This variable is tech preview and may be removed in the future releases.</p> <p>Allows to turn on the write buffer manager (WriteBufferManager) from <code>cnf</code> files. This variable is related to <code>rocksdb_charge_memory</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_validate_tables","title":"<code>rocksdb_validate_tables</code>","text":"Option Description Command-line \u2013rocksdb-validate-tables Dynamic No Scope Global Data type Numeric Default 1 <p>Specifies whether to verify that MySQL data dictionary is equal to the MyRocks data dictionary.</p> <ul> <li> <p><code>0</code>: do not verify.</p> </li> <li> <p><code>1</code>: verify and fail on error (default).</p> </li> <li> <p><code>2</code>: verify and continue with error.</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_verify_row_debug_checksums","title":"<code>rocksdb_verify_row_debug_checksums</code>","text":"Option Description Command-line \u2013rocksdb-verify-row-debug-checksums Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to verify checksums when reading index or table records. Disabled by default.</p>"},{"location":"myrocks-server-variables.html#rocksdb_wal_bytes_per_sync","title":"<code>rocksdb_wal_bytes_per_sync</code>","text":"Option Description Command-line \u2013rocksdb-wal-bytes-per-sync Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies how often should the OS sync WAL (write-ahead log) files to disk as they are being written, asynchronously, in the background. This operation can be used to smooth out write I/O over time. Default value is <code>0</code>, meaning that files are never synced. Allowed range is up to <code>18446744073709551615</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_wal_dir","title":"<code>rocksdb_wal_dir</code>","text":"Option Description Command-line \u2013rocksdb-wal-dir Dynamic No Scope Global Data type String Default <p>Specifies the path to the directory where MyRocks stores WAL files.</p>"},{"location":"myrocks-server-variables.html#rocksdb_wal_recovery_mode","title":"<code>rocksdb_wal_recovery_mode</code>","text":"Option Description Command-line \u2013rocksdb-wal-recovery-mode Dynamic Yes Scope Global Data type Numeric Default 2 <p>Specifies the level of tolerance when recovering write-ahead logs (WAL) files after a system crash.</p> <p>The following are the options:</p> <ul> <li> <p><code>0</code>: if the last WAL entry is corrupted, truncate the entry and either start the server normally or refuse to start.</p> </li> <li> <p><code>1</code>: if a WAL entry is corrupted, the server fails to start and does not recover from the crash.</p> </li> <li> <p><code>2</code> (default): if a corrupted WAL entry is detected, truncate all entries after the detected corrupted entry. You can select this setting for replication replicas.</p> </li> <li> <p><code>3</code>: If a corrupted WAL entry is detected, skip only the corrupted entry and continue the apply WAL entries. This option can be dangerous.</p> </li> </ul>"},{"location":"myrocks-server-variables.html#rocksdb_wal_size_limit_mb","title":"<code>rocksdb_wal_size_limit_mb</code>","text":"Option Description Command-line \u2013rocksdb-wal-size-limit-mb Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the maximum size of all WAL files in megabytes before attempting to flush memtables and delete the oldest files. Default value is <code>0</code> (never rotated). Allowed range is up to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_wal_ttl_seconds","title":"<code>rocksdb_wal_ttl_seconds</code>","text":"Option Description Command-line \u2013rocksdb-wal-ttl-seconds Dynamic No Scope Global Data type Numeric Default 0 <p>Specifies the timeout in seconds before deleting archived WAL files. Default is <code>0</code> (archived WAL files are never deleted). Allowed range is up to <code>9223372036854775807</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_whole_key_filtering","title":"<code>rocksdb_whole_key_filtering</code>","text":"Option Description Command-line \u2013rocksdb-whole-key-filtering Dynamic No Scope Global Data type Boolean Default ON <p>Specifies whether the bloomfilter should use the whole key for filtering instead of just the prefix. Enabled by default. Make sure that lookups use the whole key for matching.</p>"},{"location":"myrocks-server-variables.html#rocksdb_write_batch_flush_threshold","title":"<code>rocksdb_write_batch_flush_threshold</code>","text":"Option Description Command-line \u2013rocksdb-write-batch-flush-threshold Dynamic Yes Scope Local Data type Integer Default 0 <p>This variable specifies the maximum size of the write batch in bytes before flushing. Only valid if <code>rockdb_write_policy</code> is WRITE_UNPREPARED. There is no limit if the variable is set to the default setting.</p>"},{"location":"myrocks-server-variables.html#rocksdb_write_batch_max_bytes","title":"<code>rocksdb_write_batch_max_bytes</code>","text":"Option Description Command-line \u2013rocksdb-write-batch-max-bytes Dynamic Yes Scope Global Data type Numeric Default 0 <p>Specifies the maximum size of a RocksDB write batch in bytes. <code>0</code> means no limit. In case user exceeds the limit following error will be shown: <code>ERROR HY000: Status error 10 received from RocksDB: Operation aborted: Memory limit reached</code>.</p>"},{"location":"myrocks-server-variables.html#rocksdb_write_disable_wal","title":"<code>rocksdb_write_disable_wal</code>","text":"Option Description Command-line \u2013rocksdb-write-disable-wal Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Lets you temporarily disable writes to WAL files, which can be useful for bulk loading.</p>"},{"location":"myrocks-server-variables.html#rocksdb_write_ignore_missing_column_families","title":"<code>rocksdb_write_ignore_missing_column_families</code>","text":"Option Description Command-line \u2013rocksdb-write-ignore-missing-column-families Dynamic Yes Scope Global, Session Data type Boolean Default OFF <p>Specifies whether to ignore writes to column families that do not exist. Disabled by default (writes to non-existent column families are not ignored).</p>"},{"location":"myrocks-server-variables.html#rocksdb_write_policy","title":"<code>rocksdb_write_policy</code>","text":"Option Description Command-line \u2013rocksdb-write-policy Dynamic No Scope Global Data type String Default write_committed <p>Specifies when two-phase commit data are written into the database. Allowed values are <code>write_committed</code>, <code>write_prepared</code>, and <code>write_unprepared</code>.</p> Value Description <code>write_committed</code> Data written at commit time <code>write_prepared</code> Data written after the prepare phase of a two-phase transaction <code>write_unprepared</code> Data written before the prepare phase of a two-phase transaction <p></p>"},{"location":"myrocks-server-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"myrocks-status-variables.html","title":"MyRocks status variables","text":"<p>MyRocks status variables provide details about the inner workings of the storage engine and they can be useful in tuning the storage engine to a particular environment.</p> <p>You can view these variables and their values by running:</p> <pre><code>mysql&gt; SHOW STATUS LIKE 'rocksdb%';\n</code></pre> <p>The following global status variables are available:</p> Name Var Type <code>rocksdb_rows_deleted</code> Numeric <code>rocksdb_rows_inserted</code> Numeric <code>rocksdb_rows_read</code> Numeric <code>rocksdb_rows_unfiltered_no_snapshot</code> Numeric <code>rocksdb_rows_updated</code> Numeric <code>rocksdb_rows_expired</code> Numeric <code>rocksdb_system_rows_deleted</code> Numeric <code>rocksdb_system_rows_inserted</code> Numeric <code>rocksdb_system_rows_read</code> Numeric <code>rocksdb_system_rows_updated</code> Numeric <code>rocksdb_memtable_total</code> Numeric <code>rocksdb_memtable_unflushed</code> Numeric <code>rocksdb_queries_point</code> Numeric <code>rocksdb_queries_range</code> Numeric <code>rocksdb_covered_secondary_key_lookups</code> Numeric <code>rocksdb_additional_compactions_trigger</code> Numeric <code>rocksdb_block_cache_add</code> Numeric <code>rocksdb_block_cache_add_failures</code> Numeric <code>rocksdb_block_cache_bytes_read</code> Numeric <code>rocksdb_block_cache_bytes_write</code> Numeric <code>rocksdb_block_cache_data_add</code> Numeric <code>rocksdb_block_cache_data_bytes_insert</code> Numeric <code>rocksdb_block_cache_data_hit</code> Numeric <code>rocksdb_block_cache_data_miss</code> Numeric <code>rocksdb_block_cache_filter_add</code> Numeric <code>rocksdb_block_cache_filter_bytes_evict</code> Numeric <code>rocksdb_block_cache_filter_bytes_insert</code> Numeric <code>rocksdb_block_cache_filter_hit</code> Numeric <code>rocksdb_block_cache_filter_miss</code> Numeric <code>rocksdb_block_cache_hit</code> Numeric <code>rocksdb_block_cache_index_add</code> Numeric <code>rocksdb_block_cache_index_bytes_evict</code> Numeric <code>rocksdb_block_cache_index_bytes_insert</code> Numeric <code>rocksdb_block_cache_index_hit</code> Numeric <code>rocksdb_block_cache_index_miss</code> Numeric <code>rocksdb_block_cache_miss</code> Numeric <code>rocksdb_block_cache_compressed_hit</code> Numeric <code>rocksdb_block_cache_compressed_miss</code> Numeric <code>rocksdb_bloom_filter_prefix_checked</code> Numeric <code>rocksdb_bloom_filter_prefix_useful</code> Numeric <code>rocksdb_bloom_filter_useful</code> Numeric <code>rocksdb_bytes_read</code> Numeric <code>rocksdb_bytes_written</code> Numeric <code>rocksdb_compact_read_bytes</code> Numeric <code>rocksdb_compact_write_bytes</code> Numeric <code>rocksdb_compaction_key_drop_new</code> Numeric <code>rocksdb_compaction_key_drop_obsolete</code> Numeric <code>rocksdb_compaction_key_drop_user</code> Numeric <code>rocksdb_flush_write_bytes</code> Numeric <code>rocksdb_get_hit_l0</code> Numeric <code>rocksdb_get_hit_l1</code> Numeric <code>rocksdb_get_hit_l2_and_up</code> Numeric <code>rocksdb_get_updates_since_calls</code> Numeric <code>rocksdb_iter_bytes_read</code> Numeric <code>rocksdb_memtable_hit</code> Numeric <code>rocksdb_memtable_miss</code> Numeric <code>rocksdb_no_file_closes</code> Numeric <code>rocksdb_no_file_errors</code> Numeric <code>rocksdb_no_file_opens</code> Numeric <code>rocksdb_num_iterators</code> Numeric <code>rocksdb_number_block_not_compressed</code> Numeric <code>rocksdb_number_db_next</code> Numeric <code>rocksdb_number_db_next_found</code> Numeric <code>rocksdb_number_db_prev</code> Numeric <code>rocksdb_number_db_prev_found</code> Numeric <code>rocksdb_number_db_seek</code> Numeric <code>rocksdb_number_db_seek_found</code> Numeric <code>rocksdb_number_deletes_filtered</code> Numeric <code>rocksdb_number_keys_read</code> Numeric <code>rocksdb_number_keys_updated</code> Numeric <code>rocksdb_number_keys_written</code> Numeric <code>rocksdb_number_merge_failures</code> Numeric <code>rocksdb_number_multiget_bytes_read</code> Numeric <code>rocksdb_number_multiget_get</code> Numeric <code>rocksdb_number_multiget_keys_read</code> Numeric <code>rocksdb_number_reseeks_iteration</code> Numeric <code>rocksdb_number_sst_entry_delete</code> Numeric <code>rocksdb_number_sst_entry_merge</code> Numeric <code>rocksdb_number_sst_entry_other</code> Numeric <code>rocksdb_number_sst_entry_put</code> Numeric <code>rocksdb_number_sst_entry_singledelete</code> Numeric <code>rocksdb_number_stat_computes</code> Numeric <code>rocksdb_number_superversion_acquires</code> Numeric <code>rocksdb_number_superversion_cleanups</code> Numeric <code>rocksdb_number_superversion_releases</code> Numeric <code>rocksdb_rate_limit_delay_millis</code> Numeric <code>rocksdb_row_lock_deadlocks</code> Numeric <code>rocksdb_row_lock_wait_timeouts</code> Numeric <code>rocksdb_snapshot_conflict_errors</code> Numeric <code>rocksdb_stall_l0_file_count_limit_slowdowns</code> Numeric <code>rocksdb_stall_locked_l0_file_count_limit_slowdowns</code> Numeric <code>rocksdb_stall_l0_file_count_limit_stops</code> Numeric <code>rocksdb_stall_locked_l0_file_count_limit_stops</code> Numeric <code>rocksdb_stall_pending_compaction_limit_stops</code> Numeric <code>rocksdb_stall_pending_compaction_limit_slowdowns</code> Numeric <code>rocksdb_stall_memtable_limit_stops</code> Numeric <code>rocksdb_stall_memtable_limit_slowdowns</code> Numeric <code>rocksdb_stall_total_stops</code> Numeric <code>rocksdb_stall_total_slowdowns</code> Numeric <code>rocksdb_stall_micros</code> Numeric <code>rocksdb_wal_bytes</code> Numeric <code>rocksdb_wal_group_syncs</code> Numeric <code>rocksdb_wal_synced</code> Numeric <code>rocksdb_write_other</code> Numeric <code>rocksdb_write_self</code> Numeric <code>rocksdb_write_timedout</code> Numeric <code>rocksdb_write_wal</code> Numeric"},{"location":"myrocks-status-variables.html#rocksdb_rows_deleted","title":"<code>rocksdb_rows_deleted</code>","text":"<p>This variable shows the number of rows that were deleted from MyRocks tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_rows_inserted","title":"<code>rocksdb_rows_inserted</code>","text":"<p>This variable shows the number of rows that were inserted into MyRocks tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_rows_read","title":"<code>rocksdb_rows_read</code>","text":"<p>This variable shows the number of rows that were read from MyRocks tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_rows_unfiltered_no_snapshot","title":"<code>rocksdb_rows_unfiltered_no_snapshot</code>","text":"<p>This variable shows how many reads need TTL and have no snapshot timestamp.</p>"},{"location":"myrocks-status-variables.html#rocksdb_rows_updated","title":"<code>rocksdb_rows_updated</code>","text":"<p>This variable shows the number of rows that were updated in MyRocks tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_rows_expired","title":"<code>rocksdb_rows_expired</code>","text":"<p>This variable shows the number of expired rows in MyRocks tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_system_rows_deleted","title":"<code>rocksdb_system_rows_deleted</code>","text":"<p>This variable shows the number of rows that were deleted from MyRocks system tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_system_rows_inserted","title":"<code>rocksdb_system_rows_inserted</code>","text":"<p>This variable shows the number of rows that were inserted into MyRocks system tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_system_rows_read","title":"<code>rocksdb_system_rows_read</code>","text":"<p>This variable shows the number of rows that were read from MyRocks system tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_system_rows_updated","title":"<code>rocksdb_system_rows_updated</code>","text":"<p>This variable shows the number of rows that were updated in MyRocks system tables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_memtable_total","title":"<code>rocksdb_memtable_total</code>","text":"<p>This variable shows the memory usage, in bytes, of all memtables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_memtable_unflushed","title":"<code>rocksdb_memtable_unflushed</code>","text":"<p>This variable shows the memory usage, in bytes, of all unflushed memtables.</p>"},{"location":"myrocks-status-variables.html#rocksdb_queries_point","title":"<code>rocksdb_queries_point</code>","text":"<p>This variable shows the number of single row queries.</p>"},{"location":"myrocks-status-variables.html#rocksdb_queries_range","title":"<code>rocksdb_queries_range</code>","text":"<p>This variable shows the number of multi/range row queries.</p>"},{"location":"myrocks-status-variables.html#rocksdb_covered_secondary_key_lookups","title":"<code>rocksdb_covered_secondary_key_lookups</code>","text":"<p>This variable shows the number of lookups via the secondary index that returned all fields requested directly from the secondary index.</p>"},{"location":"myrocks-status-variables.html#rocksdb_additional_compactions_trigger","title":"<code>rocksdb_additional_compactions_trigger</code>","text":"<p>This variable shows the number of triggered additional compactions. MyRocks triggers an additional compaction if (number of deletions / number of entries) &gt; (rocksdb_compaction_sequential_deletes / rocksdb_compaction_sequential_deletes_window) in the SST file.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_add","title":"<code>rocksdb_block_cache_add</code>","text":"<p>This variable shows the number of blocks added to block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_add_failures","title":"<code>rocksdb_block_cache_add_failures</code>","text":"<p>This variable shows the number of failures when adding blocks to block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_bytes_read","title":"<code>rocksdb_block_cache_bytes_read</code>","text":"<p>This variable shows the number of bytes read from cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_bytes_write","title":"<code>rocksdb_block_cache_bytes_write</code>","text":"<p>This variable shows the number of bytes written into cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_data_add","title":"<code>rocksdb_block_cache_data_add</code>","text":"<p>This variable shows the number of data blocks added to block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_data_bytes_insert","title":"<code>rocksdb_block_cache_data_bytes_insert</code>","text":"<p>This variable shows the number of bytes of data blocks inserted into cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_data_hit","title":"<code>rocksdb_block_cache_data_hit</code>","text":"<p>This variable shows the number of cache hits when accessing the data block from the block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_data_miss","title":"<code>rocksdb_block_cache_data_miss</code>","text":"<p>This variable shows the number of cache misses when accessing the data block from the block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_filter_add","title":"<code>rocksdb_block_cache_filter_add</code>","text":"<p>This variable shows the number of filter blocks added to block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_filter_bytes_evict","title":"<code>rocksdb_block_cache_filter_bytes_evict</code>","text":"<p>This variable shows the number of bytes of bloom filter blocks removed from cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_filter_bytes_insert","title":"<code>rocksdb_block_cache_filter_bytes_insert</code>","text":"<p>This variable shows the number of bytes of bloom filter blocks inserted into cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_filter_hit","title":"<code>rocksdb_block_cache_filter_hit</code>","text":"<p>This variable shows the number of times cache hit when accessing filter block from block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_filter_miss","title":"<code>rocksdb_block_cache_filter_miss</code>","text":"<p>This variable shows the number of times cache miss when accessing filter block from block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_hit","title":"<code>rocksdb_block_cache_hit</code>","text":"<p>This variable shows the total number of block cache hits.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_index_add","title":"<code>rocksdb_block_cache_index_add</code>","text":"<p>This variable shows the number of index blocks added to block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_index_bytes_evict","title":"<code>rocksdb_block_cache_index_bytes_evict</code>","text":"<p>This variable shows the number of bytes of index block erased from cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_index_bytes_insert","title":"<code>rocksdb_block_cache_index_bytes_insert</code>","text":"<p>This variable shows the number of bytes of index blocks inserted into cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_index_hit","title":"<code>rocksdb_block_cache_index_hit</code>","text":"<p>This variable shows the total number of block cache index hits.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_index_miss","title":"<code>rocksdb_block_cache_index_miss</code>","text":"<p>This variable shows the number of times cache hit when accessing index block from block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_miss","title":"<code>rocksdb_block_cache_miss</code>","text":"<p>This variable shows the total number of block cache misses.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_compressed_hit","title":"<code>rocksdb_block_cache_compressed_hit</code>","text":"<p>This variable shows the number of hits in the compressed block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_block_cache_compressed_miss","title":"<code>rocksdb_block_cache_compressed_miss</code>","text":"<p>This variable shows the number of misses in the compressed block cache.</p>"},{"location":"myrocks-status-variables.html#rocksdb_bloom_filter_prefix_checked","title":"<code>rocksdb_bloom_filter_prefix_checked</code>","text":"<p>This variable shows the number of times bloom was checked before creating iterator on a file.</p>"},{"location":"myrocks-status-variables.html#rocksdb_bloom_filter_prefix_useful","title":"<code>rocksdb_bloom_filter_prefix_useful</code>","text":"<p>This variable shows the number of times the check was useful in avoiding iterator creation (and thus likely IOPs).</p>"},{"location":"myrocks-status-variables.html#rocksdb_bloom_filter_useful","title":"<code>rocksdb_bloom_filter_useful</code>","text":"<p>This variable shows the number of times bloom filter has avoided file reads.</p>"},{"location":"myrocks-status-variables.html#rocksdb_bytes_read","title":"<code>rocksdb_bytes_read</code>","text":"<p>This variable shows the total number of uncompressed bytes read. It could be either from memtables, cache, or table files.</p>"},{"location":"myrocks-status-variables.html#rocksdb_bytes_written","title":"<code>rocksdb_bytes_written</code>","text":"<p>This variable shows the total number of uncompressed bytes written.</p>"},{"location":"myrocks-status-variables.html#rocksdb_compact_read_bytes","title":"<code>rocksdb_compact_read_bytes</code>","text":"<p>This variable shows the number of bytes read during compaction</p>"},{"location":"myrocks-status-variables.html#rocksdb_compact_write_bytes","title":"<code>rocksdb_compact_write_bytes</code>","text":"<p>This variable shows the number of bytes written during compaction.</p>"},{"location":"myrocks-status-variables.html#rocksdb_compaction_key_drop_new","title":"<code>rocksdb_compaction_key_drop_new</code>","text":"<p>This variable shows the number of key drops during compaction because it was overwritten with a newer value.</p>"},{"location":"myrocks-status-variables.html#rocksdb_compaction_key_drop_obsolete","title":"<code>rocksdb_compaction_key_drop_obsolete</code>","text":"<p>This variable shows the number of key drops during compaction because it was obsolete.</p>"},{"location":"myrocks-status-variables.html#rocksdb_compaction_key_drop_user","title":"<code>rocksdb_compaction_key_drop_user</code>","text":"<p>This variable shows the number of key drops during compaction because user compaction function has dropped the key.</p>"},{"location":"myrocks-status-variables.html#rocksdb_flush_write_bytes","title":"<code>rocksdb_flush_write_bytes</code>","text":"<p>This variable shows the number of bytes written during flush.</p>"},{"location":"myrocks-status-variables.html#rocksdb_get_hit_l0","title":"<code>rocksdb_get_hit_l0</code>","text":"<p>This variable shows the number of <code>Get()</code> queries served by L0.</p>"},{"location":"myrocks-status-variables.html#rocksdb_get_hit_l1","title":"<code>rocksdb_get_hit_l1</code>","text":"<p>This variable shows the number of <code>Get()</code> queries served by L1.</p>"},{"location":"myrocks-status-variables.html#rocksdb_get_hit_l2_and_up","title":"<code>rocksdb_get_hit_l2_and_up</code>","text":"<p>This variable shows the number of <code>Get()</code> queries served by L2 and up.</p>"},{"location":"myrocks-status-variables.html#rocksdb_get_updates_since_calls","title":"<code>rocksdb_get_updates_since_calls</code>","text":"<p>This variable shows the number of calls to <code>GetUpdatesSince</code> function. Useful to keep track of transaction log iterator refreshes</p>"},{"location":"myrocks-status-variables.html#rocksdb_iter_bytes_read","title":"<code>rocksdb_iter_bytes_read</code>","text":"<p>This variable shows the number of uncompressed bytes read from an iterator. It includes size of key and value.</p>"},{"location":"myrocks-status-variables.html#rocksdb_memtable_hit","title":"<code>rocksdb_memtable_hit</code>","text":"<p>This variable shows the number of memtable hits.</p>"},{"location":"myrocks-status-variables.html#rocksdb_memtable_miss","title":"<code>rocksdb_memtable_miss</code>","text":"<p>This variable shows the number of memtable misses.</p>"},{"location":"myrocks-status-variables.html#rocksdb_no_file_closes","title":"<code>rocksdb_no_file_closes</code>","text":"<p>This variable shows the number of time file were closed.</p>"},{"location":"myrocks-status-variables.html#rocksdb_no_file_errors","title":"<code>rocksdb_no_file_errors</code>","text":"<p>This variable shows number of errors trying to read in data from an sst file.</p>"},{"location":"myrocks-status-variables.html#rocksdb_no_file_opens","title":"<code>rocksdb_no_file_opens</code>","text":"<p>This variable shows the number of time file were opened.</p>"},{"location":"myrocks-status-variables.html#rocksdb_num_iterators","title":"<code>rocksdb_num_iterators</code>","text":"<p>This variable shows the number of currently open iterators.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_block_not_compressed","title":"<code>rocksdb_number_block_not_compressed</code>","text":"<p>This variable shows the number of uncompressed blocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_next","title":"<code>rocksdb_number_db_next</code>","text":"<p>This variable shows the number of calls to <code>next</code>.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_next_found","title":"<code>rocksdb_number_db_next_found</code>","text":"<p>This variable shows the number of calls to <code>next</code> that returned data.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_prev","title":"<code>rocksdb_number_db_prev</code>","text":"<p>This variable shows the number of calls to <code>prev</code>.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_prev_found","title":"<code>rocksdb_number_db_prev_found</code>","text":"<p>This variable shows the number of calls to <code>prev</code> that returned data.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_seek","title":"<code>rocksdb_number_db_seek</code>","text":"<p>This variable shows the number of calls to <code>seek</code>.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_db_seek_found","title":"<code>rocksdb_number_db_seek_found</code>","text":"<p>This variable shows the number of calls to <code>seek</code> that returned data.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_deletes_filtered","title":"<code>rocksdb_number_deletes_filtered</code>","text":"<p>This variable shows the number of deleted records that were not required to be written to storage because key did not exist.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_keys_read","title":"<code>rocksdb_number_keys_read</code>","text":"<p>This variable shows the number of keys read.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_keys_updated","title":"<code>rocksdb_number_keys_updated</code>","text":"<p>This variable shows the number of keys updated, if inplace update is enabled.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_keys_written","title":"<code>rocksdb_number_keys_written</code>","text":"<p>This variable shows the number of keys written to the database.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_merge_failures","title":"<code>rocksdb_number_merge_failures</code>","text":"<p>This variable shows the number of failures performing merge operator actions in RocksDB.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_multiget_bytes_read","title":"<code>rocksdb_number_multiget_bytes_read</code>","text":"<p>This variable shows the number of bytes read during RocksDB <code>MultiGet()</code> calls.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_multiget_get","title":"<code>rocksdb_number_multiget_get</code>","text":"<p>This variable shows the number <code>MultiGet()</code> requests to RocksDB.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_multiget_keys_read","title":"<code>rocksdb_number_multiget_keys_read</code>","text":"<p>This variable shows the keys read via <code>MultiGet()</code>.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_reseeks_iteration","title":"<code>rocksdb_number_reseeks_iteration</code>","text":"<p>This variable shows the number of times reseek happened inside an iteration to skip over large number of keys with same userkey.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_sst_entry_delete","title":"<code>rocksdb_number_sst_entry_delete</code>","text":"<p>This variable shows the total number of delete markers written by MyRocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_sst_entry_merge","title":"<code>rocksdb_number_sst_entry_merge</code>","text":"<p>This variable shows the total number of merge keys written by MyRocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_sst_entry_other","title":"<code>rocksdb_number_sst_entry_other</code>","text":"<p>This variable shows the total number of non-delete, non-merge, non-put keys written by MyRocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_sst_entry_put","title":"<code>rocksdb_number_sst_entry_put</code>","text":"<p>This variable shows the total number of put keys written by MyRocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_sst_entry_singledelete","title":"<code>rocksdb_number_sst_entry_singledelete</code>","text":"<p>This variable shows the total number of single delete keys written by MyRocks.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_stat_computes","title":"<code>rocksdb_number_stat_computes</code>","text":"<p>This variable isn\u2019t used anymore and will be removed in future releases.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_superversion_acquires","title":"<code>rocksdb_number_superversion_acquires</code>","text":"<p>This variable shows the number of times the superversion structure has been acquired in RocksDB, this is used for tracking all of the files for the database.</p>"},{"location":"myrocks-status-variables.html#rocksdb_number_superversion_cleanups","title":"<code>rocksdb_number_superversion_cleanups</code>","text":""},{"location":"myrocks-status-variables.html#rocksdb_number_superversion_releases","title":"<code>rocksdb_number_superversion_releases</code>","text":""},{"location":"myrocks-status-variables.html#rocksdb_rate_limit_delay_millis","title":"<code>rocksdb_rate_limit_delay_millis</code>","text":"<p>This variable was removed in Percona Server for MySQL Percona Server 5.7.23-23.</p>"},{"location":"myrocks-status-variables.html#rocksdb_row_lock_deadlocks","title":"<code>rocksdb_row_lock_deadlocks</code>","text":"<p>This variable shows the total number of deadlocks that have been detected since the instance was started.</p>"},{"location":"myrocks-status-variables.html#rocksdb_row_lock_wait_timeouts","title":"<code>rocksdb_row_lock_wait_timeouts</code>","text":"<p>This variable shows the total number of row lock wait timeouts that have been detected since the instance was started.</p>"},{"location":"myrocks-status-variables.html#rocksdb_snapshot_conflict_errors","title":"<code>rocksdb_snapshot_conflict_errors</code>","text":"<p>This variable shows the number of snapshot conflict errors occurring during write transactions that forces the transaction to rollback.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_l0_file_count_limit_slowdowns","title":"<code>rocksdb_stall_l0_file_count_limit_slowdowns</code>","text":"<p>This variable shows the slowdowns in write due to L0 being close to full.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_locked_l0_file_count_limit_slowdowns","title":"<code>rocksdb_stall_locked_l0_file_count_limit_slowdowns</code>","text":"<p>This variable shows the slowdowns in write due to L0 being close to full and compaction for L0 is already in progress.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_l0_file_count_limit_stops","title":"<code>rocksdb_stall_l0_file_count_limit_stops</code>","text":"<p>This variable shows the stalls in write due to L0 being full.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_locked_l0_file_count_limit_stops","title":"<code>rocksdb_stall_locked_l0_file_count_limit_stops</code>","text":"<p>This variable shows the stalls in write due to L0 being full and compaction for L0 is already in progress.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_pending_compaction_limit_stops","title":"<code>rocksdb_stall_pending_compaction_limit_stops</code>","text":"<p>This variable shows the stalls in write due to hitting limits set for max number of pending compaction bytes.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_pending_compaction_limit_slowdowns","title":"<code>rocksdb_stall_pending_compaction_limit_slowdowns</code>","text":"<p>This variable shows the slowdowns in write due to getting close to limits set for max number of pending compaction bytes.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_memtable_limit_stops","title":"<code>rocksdb_stall_memtable_limit_stops</code>","text":"<p>This variable shows the stalls in write due to hitting max number of <code>memTables</code> allowed.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_memtable_limit_slowdowns","title":"<code>rocksdb_stall_memtable_limit_slowdowns</code>","text":"<p>This variable shows the slowdowns in writes due to getting close to max number of memtables allowed.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_total_stops","title":"<code>rocksdb_stall_total_stops</code>","text":"<p>This variable shows the total number of write stalls.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_total_slowdowns","title":"<code>rocksdb_stall_total_slowdowns</code>","text":"<p>This variable shows the total number of write slowdowns.</p>"},{"location":"myrocks-status-variables.html#rocksdb_stall_micros","title":"<code>rocksdb_stall_micros</code>","text":"<p>This variable shows how long (in microseconds) the writer had to wait for compaction or flush to finish.</p>"},{"location":"myrocks-status-variables.html#rocksdb_wal_bytes","title":"<code>rocksdb_wal_bytes</code>","text":"<p>This variables shows the number of bytes written to WAL.</p>"},{"location":"myrocks-status-variables.html#rocksdb_wal_group_syncs","title":"<code>rocksdb_wal_group_syncs</code>","text":"<p>This variable shows the number of group commit WAL file syncs that have occurred.</p>"},{"location":"myrocks-status-variables.html#rocksdb_wal_synced","title":"<code>rocksdb_wal_synced</code>","text":"<p>This variable shows the number of times WAL sync was done.</p>"},{"location":"myrocks-status-variables.html#rocksdb_write_other","title":"<code>rocksdb_write_other</code>","text":"<p>This variable shows the number of writes processed by another thread.</p>"},{"location":"myrocks-status-variables.html#rocksdb_write_self","title":"<code>rocksdb_write_self</code>","text":"<p>This variable shows the number of writes that were processed by a requesting thread.</p>"},{"location":"myrocks-status-variables.html#rocksdb_write_timedout","title":"<code>rocksdb_write_timedout</code>","text":"<p>This variable shows the number of writes ending up with timed-out.</p>"},{"location":"myrocks-status-variables.html#rocksdb_write_wal","title":"<code>rocksdb_write_wal</code>","text":"<p>This variable shows the number of Write calls that request WAL.</p> <p></p>"},{"location":"myrocks-status-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"pam-plugin.html","title":"PAM authentication plugin","text":"<p>Percona PAM Authentication Plugin is a free and Open Source implementation of the MySQL\u2019s authentication plugin. This plugin acts as a mediator between the MySQL server, the MySQL client, and the PAM stack. The server plugin requests authentication from the PAM stack, forwards any requests and messages from the PAM stack over the wire to the client (in cleartext) and reads back any replies for the PAM stack.</p> <p>PAM plugin uses dialog as its client side plugin. Dialog plugin can be loaded to any client application that uses <code>libperconaserverclient</code>/<code>libmysqlclient</code> library.</p> <p>Here are some of the benefits that Percona dialog plugin offers over the default one:</p> <ul> <li> <p>It correctly recognizes whether PAM wants input to be echoed or not, while the default one always echoes the input on the user\u2019s console.</p> </li> <li> <p>It can use the password which is passed to MySQL client via \u201c-p\u201d parameter.</p> </li> <li> <p>Dialog client installation bug has been fixed.</p> </li> </ul> <p>Percona offers two versions of this plugin:</p> <ul> <li> <p>Full PAM plugin called auth_pam. This plugin uses dialog.so. It fully supports the PAM protocol with arbitrary communication between client and server.</p> </li> <li> <p>Oracle-compatible PAM called auth_pam_compat. This plugin uses mysql_clear_password which is a part of Oracle MySQL client. It also has some limitations, such as, it supports only one password input. You must use <code>-p</code> option in order to pass the password to auth_pam_compat.</p> </li> </ul> <p>These two versions of plugins are physically different. To choose which one you want used, you must use IDENTIFIED WITH \u2018auth_pam\u2019 for auth_pam, and IDENTIFIED WITH \u2018auth_pam_compat\u2019 for auth_pam_compat.</p>"},{"location":"pam-plugin.html#version-specific-information","title":"Version specific information","text":"<p>A plugin may not be supported in later releases of MySQL or Percona Server for MySQL since version changes may introduce incompatible changes.</p>"},{"location":"pam-plugin.html#installation","title":"Installation","text":"<p>This plugin requires manual installation because it isn\u2019t installed by default.</p> <pre><code>mysql&gt; INSTALL PLUGIN auth_pam SONAME 'auth_pam.so';\n</code></pre> <p>After the plugin has been installed it should be present in the plugins list. To check if the plugin has been correctly installed and active</p> <pre><code>mysql&gt; SHOW PLUGINS;\n</code></pre> Expected output <pre><code>...\n| auth_pam                       | ACTIVE   | AUTHENTICATION     | auth_pam.so | GPL     |\n</code></pre>"},{"location":"pam-plugin.html#configuration","title":"Configuration","text":"<p>In order to use the plugin, authentication method should be configured. Simple setup can be to use the standard UNIX authentication method (<code>pam_unix</code>).</p> <p>Note</p> <p>To use <code>pam_unix</code>, mysql will need to be added to the shadow group in order to have enough privileges to read the /etc/shadow.</p> <p>A sample /etc/pam.d/mysqld file:</p> <pre><code>auth       required     pam_unix.so\naccount    required     pam_unix.so\n</code></pre> <p>For added information in the system log, you can expand it to be:</p> <pre><code>auth       required     pam_warn.so\nauth       required     pam_unix.so audit\naccount    required     pam_unix.so audit\n</code></pre>"},{"location":"pam-plugin.html#creating-a-user","title":"Creating a user","text":"<p>After the PAM plugin has been configured, users can be created with the PAM plugin as authentication method</p> <pre><code>mysql&gt; CREATE USER 'newuser'@'localhost' IDENTIFIED WITH auth_pam;\n</code></pre> <p>This will create a user <code>newuser</code> that can connect from <code>localhost</code> who will be authenticated using the PAM plugin. If the <code>pam_unix</code> method is being used user will need to exist on the system.</p>"},{"location":"pam-plugin.html#supplementary-groups-support","title":"Supplementary groups support","text":"<p>Percona Server for MySQL has implemented PAM plugin support for supplementary groups. Supplementary or secondary groups are extra groups a specific user is member of. For example user <code>joe</code> might be a member of groups: <code>joe</code> (his primary group) and secondary groups <code>developers</code> and <code>dba</code>. A complete list of groups and users belonging to them can be checked with <code>cat /etc/group</code> command.</p> <p>This feature enables using secondary groups in the mapping part of the authentication string, like \u201c<code>mysql, developers=joe, dba=mark</code>\u201d. Previously only primary groups could have been specified there. If user is a member of both <code>developers</code> and <code>dba</code>, PAM plugin will map it to the <code>joe</code> because <code>developers</code> matches first.</p>"},{"location":"pam-plugin.html#known-issues","title":"Known issues","text":"<p>Default mysql stack size is not enough to handle <code>pam_encryptfs</code> module. The workaround is to increase the MySQL stack size by setting the thread-stack variable to at least <code>512KB</code> or by increasing the old value by <code>256KB</code>.</p> <p>PAM authentication can fail with <code>mysqld: pam_unix(mysqld:account): Fork failed: Cannot allocate memory</code> error in the <code>/var/log/secure</code> even when there is enough memory available. Current workaround is to set vm.overcommit_memory to <code>1</code>:</p> <pre><code>echo 1 /proc/sys/vm/overcommit_memory\n</code></pre> <p>and by adding the <code>vm.overcommit_memory = 1</code> to <code>/etc/sysctl.conf</code> to make the change permanent after reboot. Authentication of internal (i.e. non PAM) accounts continues to work fine when <code>mysqld</code> reaches this memory utilization level. NOTE: Setting the <code>vm.overcommit_memory</code> to <code>1</code> will cause kernel to perform no memory overcommit handling which could increase the potential for memory overload and invoking of OOM killer.</p> <p></p>"},{"location":"pam-plugin.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"percona-sequence-table.html","title":"PERCONA_SEQUENCE_TABLE(n) function","text":"<p>Using the <code>PERCONA_SEQUENCE_TABLE()</code> function provides the following:</p> Benefit Description Generates Sequences Acts as an inline table-valued function that generates a sequence of numbers. Table-Valued Function Unlike traditional scalar functions, <code>PERCONA_SEQUENCE_TABLE()</code> returns a virtual table with a single column named <code>value</code> containing the generated sequence. Simpler Syntax Simplifies queries that need to generate predictable sequences of numbers. Flexibility Allows dynamic definition of sequences within queries, offering more control compared to pre-defined tables for sequences. Predefined Sequence Does not manage sequences like Oracle or PostgreSQL; instead, it allows definition and generation of sequences within a <code>SELECT</code> statement. Customization Enables customization of starting value, increment/decrement amount, and number of values to generate."},{"location":"percona-sequence-table.html#version-update","title":"Version update","text":"<p>Percona Server for MySQL 8.4 deprecated <code>SEQUENCE_TABLE()</code>, and Percona may remove this function in a future release. We recommend that you use <code>PERCONA_SEQUENCE_TABLE()</code> instead.</p> <p>To maintain compatibility with existing third-party software, <code>SEQUENCE_TABLE</code> is no longer a reserved term and can be used as a regular identifier.</p>"},{"location":"percona-sequence-table.html#table-functions","title":"Table functions","text":"<p>The function is an inline table-valued function. This function creates a temporary table with multiple rows. You can use this function within a single SELECT statement. Oracle MySQL Server only has the <code>JSON_TABLE</code> table function. The Percona Server for MySQL has the <code>JSON_TABLE</code> and <code>PERCONA_SEQUENCE_TABLE()</code> table functions. A single SELECT statement generates a multi-row result set. In contrast, a scalar function (like EXP(x) or LOWER(str) always returns a single value of a specific data type.</p>"},{"location":"percona-sequence-table.html#syntax","title":"Syntax","text":"<p>As with any derived tables, a table function requires an alias in the <code>SELECT</code> statement.</p> <p>The result set is a single column with the predefined column name <code>value</code> of type <code>BIGINT UNSIGNED</code>. You can reference the <code>value</code> column in <code>SELECT</code> statements. The following statements are valid. Using <code>n</code> as the number of generated values, the following is the basic syntax:</p>"},{"location":"percona-sequence-table.html#percona_sequence_tablen-as-alias","title":"PERCONA_SEQUENCE_TABLE(n) [AS] alias","text":"<pre><code>SELECT \u2026 FROM PERCONA_SEQUENCE_TABLE(n) [AS] alias\n\nPERCONA_SEQUENCE_TABLE(n) [AS] alias\n</code></pre> <pre><code>SELECT * FROM PERCONA_SEQUENCE_TABLE(n) AS tt;\nSELECT &lt;expr(value)&gt; FROM PERCONA_SEQUENCE_TABLE(n) AS tt;\n</code></pre> <p>The first number in the series, the initial term, is defined as <code>0</code>, and the series ends with a value less than <code>n</code>.</p>"},{"location":"percona-sequence-table.html#basic-sequence-generation","title":"Basic sequence generation","text":"<p>In this example, the following statement generates a sequence:</p> <pre><code>mysql&gt; SELECT * FROM PERCONA_SEQUENCE_TABLE(3) AS tt;\n</code></pre> Expected output <pre><code>+-------+\n| value |\n+-------+\n|     0 |\n|     1 |\n|     2 |\n+-------+\n</code></pre>"},{"location":"percona-sequence-table.html#start-with-a-specific-value","title":"Start with a specific value","text":"<p>You can define the initial value using the <code>WHERE</code> clause. The following example starts the sequence with <code>4</code>.</p> <pre><code>mysql&gt; SELECT value AS result \\\n       FROM \\\n            (SELECT seq AS value\n             FROM PERCONA_SEQUENCE_TABLE(8)) AS tt \\\n       WHERE value &gt;= 4;\n</code></pre> Expected output <pre><code>+--------+\n| result |\n+--------+\n|      4 |\n|      5 |\n|      6 |\n|      7 |\n+--------+\n</code></pre>"},{"location":"percona-sequence-table.html#filter-even-numbers","title":"Filter even numbers","text":"<p>Consecutive terms increase or decrease by a common difference. The default common difference value is <code>1</code>. However, it is possible to filter the results using the WHERE clause to simulate common differences greater than 1.</p> <p>The following example prints only even numbers from the 0..7 range:</p> <pre><code>mysql&gt; SELECT value AS result \\\n       FROM PERCONA_SEQUENCE_TABLE(8) AS tt \\\n       WHERE value % 2 = 0;\n</code></pre> Expected output <pre><code>+--------+\n| result |\n+--------+\n|      0 |\n|      2 |\n|      4 |\n|      6 |\n+--------+\n</code></pre>"},{"location":"percona-sequence-table.html#generate-random-numbers","title":"Generate random numbers","text":"<p>The following is an example of using the function to populate a table with a set of random numbers:</p> <pre><code>mysql&gt; SELECT FLOOR(RAND() * 100) AS result \\\n       FROM PERCONA_SEQUENCE_TABLE(4) AS tt;\n</code></pre> <p>The output could be the following:</p> Expected output <pre><code>+--------+\n| result |\n+--------+\n|     24 |\n|     56 |\n|     70 |\n|     25 |\n+--------+\n</code></pre>"},{"location":"percona-sequence-table.html#generate-random-strings","title":"Generate random strings","text":"<p>You can populate a table with a set of pseudo-random strings with the following statement:</p> <pre><code>mysql&gt; SELECT MD5(value) AS result \\\n       FROM PERCONA_SEQUENCE_TABLE(4) AS tt;\n</code></pre> Expected output <pre><code>+----------------------------------+\n| result                           |\n+----------------------------------+\n| f17d9c990f40f8ac215f2ecdfd7d0451 |\n| 2e5751b7cfd7f053cd29e946fb2649a4 |\n| b026324c6904b2a9cb4b88d6d61c81d1 |\n| 26ab0db90d72e28ad0ba1e22ee510510 |\n+----------------------------------+\n</code></pre>"},{"location":"percona-sequence-table.html#add-a-sequence-to-a-table","title":"Add a sequence to a table","text":"<p>You can add the sequence as a column to a new table or an existing table, as shown in this example:</p> <pre><code>mysql&gt; CREATE TABLE t1 AS SELECT * FROM PERCONA_SEQUENCE_TABLE(4) AS tt;\n\nmysql&gt; SELECT * FROM t1;\n</code></pre> Expected output <pre><code>+-------+\n| value |\n+-------+\n|     0 |\n|     1 |\n|     2 |\n|     3 |\n+-------+\n</code></pre> <p>Sequences are helpful for various purposes, such as populating tables and generating test data.</p> <p></p>"},{"location":"percona-sequence-table.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"percona-server-system-variables.html","title":"Percona Server for MySQL 8.4 variables","text":""},{"location":"percona-server-system-variables.html#system-variables","title":"System variables","text":"Name Cmd-Line Option File Var Scope Dynamic csv_mode Yes Yes Both Yes enforce_storage_engine Yes Yes Global No expand_fast_index_creation Yes No Both Yes extra_max_connections Yes Yes Global Yes extra_port Yes Yes Global No have_backup_locks Yes No Global No have_backup_safe_binlog_info Yes No Global No have_snapshot_cloning Yes No Global No innodb_cleaner_lsn_age_factor Yes Yes Global Yes innodb_corrupt_table_action Yes Yes Global Yes innodb_empty_free_list_algorithm Yes Yes Global Yes innodb_encrypt_online_alter_logs Yes Yes Global Yes innodb_encrypt_tables Yes Yes Global Yes innodb_kill_idle_transaction Yes Yes Global Yes innodb_max_bitmap_file_size Yes Yes Global Yes innodb_max_changed_pages Yes Yes Global Yes innodb_print_lock_wait_timeout_info Yes Yes Global Yes innodb_show_locks_held Yes Yes Global Yes innodb_temp_tablespace_encrypt Yes Yes Global No innodb_track_changed_pages Yes Yes Global No keyring_vault_config Yes Yes Global Yes keyring_vault_timeout Yes Yes Global Yes log_slow_filter Yes Yes Both Yes log_slow_rate_limit Yes Yes Both Yes log_slow_rate_type Yes Yes Global Yes log_slow_sp_statements Yes Yes Global Yes log_slow_verbosity Yes Yes Both Yes log_warnings_suppress Yes Yes Global Yes proxy_protocol_networks Yes Yes Global No query_response_time_flush Yes No Global No query_response_time_range_base Yes Yes Global Yes query_response_time_stats Yes Yes Global Yes secure_log_path Yes Yes Global No slow_query_log_always_write_time Yes Yes Global Yes slow_query_log_use_global_control Yes Yes Global Yes thread_pool_high_prio_mode Yes Yes Both Yes thread_pool_high_prio_tickets Yes Yes Both Yes thread_pool_idle_timeout Yes Yes Global Yes thread_pool_max_threads Yes Yes Global Yes thread_pool_oversubscribe Yes Yes Global Yes thread_pool_size Yes Yes Global Yes thread_pool_stall_limit Yes Yes Global No thread_statistics Yes Yes Global Yes userstat Yes Yes Global Yes version_comment Yes Yes Global Yes version_suffix Yes Yes Global Yes"},{"location":"percona-server-system-variables.html#status-variables","title":"Status variables","text":"Name Var Type Var Scope Binlog_snapshot_file String Global Binlog_snapshot_position Numeric Global Com_lock_binlog_for_backup Numeric Both Com_lock_tables_for_backup Numeric Both Com_show_client_statistics Numeric Both Com_show_index_statistics Numeric Both Com_show_table_statistics Numeric Both Com_show_thread_statistics Numeric Both Com_show_user_statistics Numeric Both Com_unlock_binlog Numeric Both Innodb_background_log_sync Numeric Global Innodb_buffer_pool_pages_LRU_flushed Numeric Global Innodb_buffer_pool_pages_made_not_young Numeric Global Innodb_buffer_pool_pages_made_young Numeric Global Innodb_buffer_pool_pages_old Numeric Global Innodb_checkpoint_age Numeric Global Innodb_checkpoint_max_age Numeric Global Innodb_ibuf_free_list Numeric Global Innodb_ibuf_segment_size Numeric Global Innodb_lsn_current Numeric Global Innodb_lsn_flushed Numeric Global Innodb_lsn_last_checkpoint Numeric Global Innodb_max_trx_id Numeric Global Innodb_mem_adaptive_hash Numeric Global Innodb_mem_dictionary Numeric Global Innodb_oldest_view_low_limit_trx_id Numeric Global Innodb_purge_trx_id Numeric Global Innodb_purge_undo_no Numeric Global Threadpool_idle_threads Numeric Global Threadpool_threads Numeric Global"},{"location":"percona-server-system-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"percona-server-versions-comparison.html","title":"Percona server versions comparison","text":""},{"location":"percona-server-versions-comparison.html#list-of-features-available-in-percona-server-for-mysql-releases","title":"List of features available in Percona Server for MySQL releases","text":"Percona Server for MySQL 5.7 Percona Server for MySQL 8.0 Improved Buffer Pool Scalability Improved Buffer Pool Scalability Improved InnoDB I/O Scalability Improved InnoDB I/O Scalability Multiple Adaptive Hash Search Partitions Multiple Adaptive Hash Search Partitions Atomic write support for Fusion-io devices Atomic write support for Fusion-io devices Query Cache Enhancements Feature not implemented Improved NUMA support Improved NUMA support Thread Pool Thread Pool Suppress Warning Messages Suppress Warning Messages Ability to change the database for mysqlbinlog Ability to change the database for mysqlbinlog Fixed Size for the Read Ahead Area Fixed Size for the Read Ahead Area Improved MEMORY Storage Engine Improved MEMORY Storage Engine Restricting the number of binlog files Restricting the number of binlog files Ignoring missing tables in mysqldump Ignoring missing tables in mysqldump Too Many Connections Warning Too Many Connections Warning Handle Corrupted Tables Handle Corrupted Tables Lock-Free SHOW SLAVE STATUS Lock-Free SHOW REPLICA STATUS Expanded Fast Index Creation Expanded Fast Index Creation Percona Toolkit UDFs Percona Toolkit UDFs Support for Fake Changes Support for Fake Changes Kill Idle Transactions Kill Idle Transactions XtraDB changed page tracking XtraDB changed page tracking Enforcing Storage Engine Replaced with upstream implementation Utility user Utility user Extending the secure-file-priv server option Extending the secure-file-priv server option Expanded Program Option Modifiers Feature not implemented PAM Authentication Plugin PAM Authentication Plugin Log Archiving for XtraDB Log Archiving for XtraDB User Statistics User Statistics Slow Query Log Slow Query Log Count InnoDB Deadlocks Count InnoDB Deadlocks Log All Client Commands (syslog) Log All Client Commands (syslog) Response Time Distribution Feature not implemented Show Storage Engines Show Storage Engines Show Lock Names Show Lock Names Process List Process List Misc. INFORMATION_SCHEMA Tables Misc. INFORMATION_SCHEMA Tables Extended Show Engine InnoDB Status Extended Show Engine InnoDB Status Thread Based Profiling Thread Based Profiling XtraDB Performance Improvements for I/O-Bound Highly-Concurrent Workloads XtraDB Performance Improvements for I/O-Bound Highly-Concurrent Workloads Page cleaner thread tuning Page cleaner thread tuning Statement Timeout Statement Timeout Extended SELECT INTO OUTFILE/DUMPFILE Extended SELECT INTO OUTFILE/DUMPFILE Per-query variable statement Per-query variable statement Extended mysqlbinlog Extended mysqlbinlog Slow Query Log Rotation and Expiration Slow Query Log Rotation and Expiration Metrics for scalability measurement Feature not implemented Audit Log Audit Log Backup Locks Backup Locks CSV engine mode for a standard-compliant quote and comma parsing CSV engine mode for a standard-compliant quote and comma parsing Super read-only Super read-only"},{"location":"percona-server-versions-comparison.html#other-reading","title":"Other reading","text":"<ul> <li> <p>What Is New in MySQL 5.7</p> </li> <li> <p>What Is New in MySQL 8.0</p> </li> </ul> <p></p>"},{"location":"percona-server-versions-comparison.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"percona-xtradb.html","title":"The Percona XtraDB storage engine","text":"<p>Percona XtraDB is an enhanced version of the InnoDB storage engine, designed to better scale on modern hardware.  It also includes a variety of other features useful in high-performance environments. It is fully backward compatible, and so can be used as a drop-in replacement for standard InnoDB.</p> <p>Percona XtraDB includes all of InnoDB \u2018s robust, reliable <code>ACID</code>-compliant design and advanced <code>MVCC</code> architecture, and builds on that solid foundation with more features, more tunability, more metrics, and more scalability. In particular, it is designed to scale better on many cores, use memory more efficiently, and be more convenient and useful. The new features are specially designed to alleviate some of InnoDB\u2019s limitations. We choose features and fixes based on customer requests and on our best judgment of real-world needs as a high-performance consulting company.</p> <p>Percona XtraDB engine will not have further binary releases, it is distributed as part of the Percona Server for MySQL.</p> <p></p>"},{"location":"percona-xtradb.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"performance-schema-myrocks-changes.html","title":"Performance Schema MyRocks changes","text":"<p>RocksDB WAL file information can be seen in the performance_schema.log_status table in the <code>STORAGE ENGINE</code> column.</p>"},{"location":"performance-schema-myrocks-changes.html#example","title":"Example","text":"<pre><code>mysql&gt; select * from performance_schema.log_status\\G\n</code></pre> Expected output <pre><code>*************************** 1. row ***************************\n\nSERVER_UUID: f593b4f8-6fde-11e9-ad90-080027c2be11\n     LOCAL: {\"gtid_executed\": \"\", \"binary_log_file\": \"binlog.000004\", \"binary_log_position\": 1698222}\nREPLICATION: {\"channels\": []}\nSTORAGE_ENGINES: {\"InnoDB\": {\"LSN\": 36810235, \"LSN_checkpoint\": 36810235}, \"RocksDB\": {\"wal_files\": [{\"path_name\": \"/000026.log\", \"log_number\": 26, \"size_file_bytes\": 371869}]}}\n1 row in set (0.00 sec)\n</code></pre>"},{"location":"performance-schema-myrocks-changes.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"post-installation.html","title":"Post-installation","text":"<p>Depending on the type of installation, you may need to do the following tasks:</p>"},{"location":"post-installation.html#installed-using-binary-files-or-compiling-from-source","title":"Installed using binary files or compiling from source","text":"Task Initialize the data dictionary Test the server Set service to start at boot time"},{"location":"post-installation.html#initialize-the-data-directory","title":"Initialize the data directory","text":"<p>If you install the server using either the source distribution or generic binary distribution files, the data directory is not initialized, and you must run the initialization process after installation.</p> <p>Run mysqld with the \u2013initialize option or the initialize-insecure option.</p> <p>Executing <code>mysqld</code> with either option does the following:</p> <ul> <li> <p>Verifies the existence of the data directory</p> </li> <li> <p>Initializes the system tablespace and related structures</p> </li> <li> <p>Creates system tables including grant tables, time zone tables, and server-side help tables</p> </li> <li> <p>Creates <code>root@localhost</code></p> </li> </ul> <p>You should run the following steps with the <code>mysql</code> login.</p> <ol> <li> <p>Navigate to the MySQL directory. The example uses the default location.</p> <pre><code>$ cd /usr/local/mysql\n</code></pre> </li> <li> <p>Create a directory for the MySQL files. The secure_file_priv uses the directory path as a value.</p> <pre><code>$ mkdir mydata\n</code></pre> <p>The <code>mysql</code> user account should have the <code>drwxr-x---</code> permissions. Four sections define the permissions; file or directory, User, Group, and Others.</p> <p>The first character designates if the permissions are for a file or directory. The first character is <code>d</code> for a directory.</p> <p>The rest of the sections are specified in three-character sets.</p> Permission User Group Other Read Yes Yes No Write Yes No No Execute Yes Yes No </li> <li> <p>Run the command to initialize the data directory.</p> <pre><code>$ bin/mysqld --initialize\n</code></pre> </li> </ol>"},{"location":"post-installation.html#test-the-server","title":"Test the server","text":"<p>After you have initialized the data directory, and the server is started, you can run tests on the server.</p> <p>This section assumes you have used the default installation settings. If you have modified the installation, navigate to the installation location. You can also add the location by Setting the Environment Variables.</p> <p>You can use the mysqladmin client to access the server.</p> <p>If you have issues connecting to the server, use the <code>root</code> user and the root account password.</p> <pre><code>$ sudo mysqladmin -u root -p version\n</code></pre> Expected output <pre><code>Enter password:\nmysql Ver 8.4.0-1 for debian-linux-gnu on x86_64 (Percona Server (GPL), Release '10', Revision 'f446c04')\n...\nServer version      8.4.0-1\nProtocol version    10\nConnection          Localhost via UNIX socket\nUNIX socket         /var/run/mysqld/mysqld.sock\nUptime:             4 hours 58 min 10 section\n\nThreads:    2 Questions:    16 Slow queries: 0 Opens: 139 Flush tables: 3\nOpen tables: 59  Queries per second avg: 0.0000\n</code></pre> <p>Use mysqlshow to display database and table information.</p> <pre><code>$ sudo mysqlshow -u root -p\n</code></pre> Expected output <pre><code>Enter password:\n\n+---------------------+\n|      Databases      |\n+=====================+\n| information_schema  |\n+---------------------+\n| mysql               |\n+---------------------+\n| performance_schema  |\n+---------------------+\n| sys                 |\n+---------------------+\n</code></pre>"},{"location":"post-installation.html#set-service-to-run-at-boot-time","title":"Set service to run at boot time","text":"<p>After a generic binary installation, manually configure systemd support.</p> <p>The following commands start, check the status, and stop the server:</p> <pre><code>$ sudo systemctl start mysqld\n$ sudo systemctl status mysqld\n$ sudo systemctl stop mysqld\n</code></pre> <p>Run the following command to start the service at boot time:</p> <p><pre><code>$ sudo systemctl enable mysqld\n</code></pre> Run the following command to prevent a service from starting at boot time:</p> <pre><code>$ sudo systemctl disable mysqld\n</code></pre>"},{"location":"post-installation.html#all-installations","title":"All installations","text":"Task Update the root password Secure the server Populate the time zone tables"},{"location":"post-installation.html#update-the-root-password","title":"Update the root password","text":"<p>During an installation on Debian/Ubuntu, you are prompted to enter a root password. On Red Hat Enterprise Linux and derivatives, you update the root password after installation.</p> <p>Restart the server with the <code>--skip-grant-tables</code> option to allow access without a password. This option is insecure. This option also disables remote connections.</p> <pre><code>$ sudo systemctl stop mysqld\n$ sudo systemctl set-environment MYSQLD_OPTS=\"--skip-grant-tables\"\n$ sudo systemctl start mysqld \n$ mysql\n</code></pre> <p>Reload the grant tables to be able to run the <code>ALTER USER</code> statement. Enter a password that satisfies the current policy.</p> <p><pre><code>mysql&gt; FLUSH PRIVILEGES;\nmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'rootPassword_12';\nmysql&gt; exit\n</code></pre> If, when adding the password, MySQL returns <code>ERROR 1819 (HY000) Your password does not satisfy the current policy</code>, run the following command to see policy requirement.</p> <p><pre><code>mysql&gt; SHOW VARIABLES LIKE 'validate_password%';\n</code></pre> Redo your password to satisfy the requirements.</p> <p>Stop the server, remove the <code>--skip-grant-tables</code> option, start the server, and log into the server with the updated password.</p> <pre><code>$ sudo systemctl stop mysqld \n$ sudo systemctl unset-environment MYSQLD_OPTS \n$ sudo systemctl start mysqld \n$ mysql -u root -p\n</code></pre>"},{"location":"post-installation.html#secure-the-server","title":"Secure the server","text":"<p>The mysql_secure_installation script improves the security of the instance.</p> <p>The script does the following:</p> <ul> <li> <p>Changes the <code>root</code> password</p> </li> <li> <p>Disallows remote login for <code>root</code> accounts</p> </li> <li> <p>Removes anonymous users</p> </li> <li> <p>Removes the <code>test</code> database</p> </li> <li> <p>Reloads the privilege tables</p> </li> </ul> <p>The following statement runs the script:</p> <pre><code>$ mysql_secure_installation\n</code></pre>"},{"location":"post-installation.html#populate-the-time-zone-tables","title":"Populate the time zone tables","text":"<p>The time zone system tables are the following:</p> <ul> <li> <p><code>time_zone</code></p> </li> <li> <p><code>time_zone_leap_second</code></p> </li> <li> <p><code>time_zone_name</code></p> </li> <li> <p><code>time_zone_transition</code></p> </li> <li> <p><code>time_zone_transition_type</code></p> </li> </ul> <p>If you install the server using either the source distribution or the generic binary distribution files, the installation creates the time zone tables, but the tables are not populated.</p> <p>The mysql_tzinfo_to_sql program populates the tables from the <code>zoneinfo</code> directory data available in Linux.</p> <p>A common method to populate the tables is to add the zoneinfo directory path to <code>mysql_tzinfo_to_sql</code> and then send the output into the mysql system schema.</p> <p>The example assumes you are running the command with the <code>root</code> account. The account must have the privileges for modifying the <code>mysql</code> system schema.</p> <pre><code>$ mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root -p -D mysql\n</code></pre> <p></p>"},{"location":"post-installation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"prefix-index-queries-optimization.html","title":"Prefix index queries optimization","text":"<p>Percona Server for MySQL has ported Prefix Index Queries Optimization feature from Facebook patch for MySQL.</p> <p>Prior to this InnoDB would always fetch the clustered index for all prefix columns in an index, even when the value of a particular record was smaller than the prefix length. This implementation optimizes that case to use the record from the secondary index and avoid the extra lookup.</p>"},{"location":"prefix-index-queries-optimization.html#status-variables","title":"Status variables","text":""},{"location":"prefix-index-queries-optimization.html#innodb_secondary_index_triggered_cluster_reads","title":"<code>Innodb_secondary_index_triggered_cluster_reads</code>","text":"Option Description Scope: Global Data type: Numeric <p>This variable shows the number of times secondary index lookup triggered cluster lookup.</p>"},{"location":"prefix-index-queries-optimization.html#innodb_secondary_index_triggered_cluster_reads_avoided","title":"<code>Innodb_secondary_index_triggered_cluster_reads_avoided</code>","text":"Option Description Scope: Global Data type: Numeric <p>This variable shows the number of times prefix optimization avoided triggering cluster lookup.</p> <p></p>"},{"location":"prefix-index-queries-optimization.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"process-list.html","title":"Process list","text":"<p>This page describes Percona changes to both the standard MySQL <code>SHOW PROCESSLIST</code> command and the standard MySQL <code>INFORMATION_SCHEMA</code> table <code>PROCESSLIST</code>.</p>"},{"location":"process-list.html#information_schema-tables","title":"INFORMATION_SCHEMA Tables","text":"<p><code>INFORMATION_SCHEMA.PROCESSLIST</code></p> <p>This table implements modifications to the standard MySQL <code>INFORMATION_SCHEMA</code> table <code>PROCESSLIST</code>.</p> Column Name Description \u2018ID\u2019 \u2018The connection identifier.\u2019 \u2018USER\u2019 \u2018The MySQL user who issued the statement.\u2019 \u2018HOST\u2019 \u2018The host name of the client issuing the statement.\u2019 \u2018DB\u2019 \u2018The default database, if one is selected, otherwise NULL.\u2019 \u2018COMMAND\u2019 \u2018The type of command the thread is executing.\u2019 \u2018TIME\u2019 \u2018The time in seconds that the thread has been in its current state.\u2019 \u2018STATE\u2019 \u2018An action, event, or state that indicates what the thread is doing.\u2019 \u2018INFO\u2019 \u2018The statement that the thread is executing, or NULL if it is not executing any statement.\u2019 \u2018TIME_MS\u2019 \u2018The time in milliseconds that the thread has been in its current state.\u2019 \u2018ROWS_EXAMINED\u2019 \u2018The number of rows examined by the statement being executed (NOTE: This column is not updated for each examined row so it does not necessarily show an up-to-date value while the statement is executing. It only shows a correct value after the statement has completed.).\u2019 \u2018ROWS_SENT\u2019 \u2018The number of rows sent by the statement being executed.\u2019 \u2018TID\u2019 \u2018The Linux Thread ID. For Linux, this corresponds to light-weight process ID (LWP ID) and can be seen in the ps -L output. In case when Thread Pool is enabled, \u201cTID\u201d is not null for only currently executing statements and statements received via \u201cextra\u201d connection.\u2019"},{"location":"process-list.html#example-output","title":"Example output","text":"<p>Table PROCESSLIST:</p> <pre><code>mysql&gt; SELECT * FROM INFORMATION_SCHEMA.PROCESSLIST;\n</code></pre> Expected output <pre><code>+----+------+-----------+--------------------+---------+------+-----------+---------------------------+---------+-----------+---------------+\n| ID | USER | HOST      | DB                 | COMMAND | TIME | STATE     | INFO                      | TIME_MS | ROWS_SENT | ROWS_EXAMINED |\n+----+------+-----------+--------------------+---------+------+-----------+---------------------------+---------+-----------+---------------+\n| 12 | root | localhost | information_schema | Query   |    0 | executing | select * from processlist |       0 |         0 |             0 |\n+----+------+-----------+--------------------+---------+------+-----------+---------------------------+---------+-----------+---------------+\n</code></pre> <p></p>"},{"location":"process-list.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"procfs-plugin.html","title":"The ProcFS plugin","text":"<p>The ProcFS plugin provides access to the Linux performance counters by running SQL queries against a Percona Server for MySQL 8.4.</p> <p>You may be unable to capture operating system metrics in certain environments, such as Cloud installations or MySQL-as-a-Service installations. These metrics are essential for complete system performance monitoring.</p> <p>The plugin does the following:</p> <ul> <li> <p>Reads selected files from the <code>/proc</code> file system and the <code>/sys</code> file system.</p> </li> <li> <p>Populates the file names and their content as rows in the INFORMATION_SCHEMA.PROCFS view.</p> </li> </ul> <p>The system variable procfs_files_spec provides access to the <code>/proc</code> and the <code>/sys</code> files and directories. This variable cannot be changed at run time, preventing a compromised account from giving itself greater access to those file systems.</p>"},{"location":"procfs-plugin.html#install-the-plugin-manually","title":"Install the PLUGIN manually","text":"<p>We recommend installing the plugin as part of the package. If needed, you can install this plugin manually. Copy the <code>procfs.so</code> file to the mysql plugin installation directory and execute the following command:</p> <pre><code>INSTALL PLUGIN procfs SONAME 'procfs.so';\n</code></pre>"},{"location":"procfs-plugin.html#access-privileges-required","title":"Access privileges required","text":"<p>Only users with the <code>ACCESS_PROCFS</code> dynamic privilege can access the <code>INFORMATION_SCHEMA.PROCFS</code> view. During the plugin startup, this dynamic privilege is registered with the server.</p> <p>After the plugin installation, grant a user access to the INFORMATION_SCHEMA.PROCFS view by executing the following command:</p> <pre><code>GRANT ACCESS_PROCFS ON *.* TO 'user'@'host';\n</code></pre> <p>Important</p> <p>An SELinux policy or an AppArmor profile may prevent access to file locations needed by the ProcFS plugin, such as the \u2018/proc/sys/fs/file-nr\u2019 directory or any sub-directories or files under \u2018/proc/irq/\u2019. Either edit the policy or profile to ensure that the plugin has the necessary access. If the policy and profile do not allow access, the plugin may may have unexpected behavior.</p> <p>For more information, see Working with SELinux and Working with AppArmor.</p>"},{"location":"procfs-plugin.html#using-the-procfs-plugin","title":"Using the ProcFS plugin","text":"<p>Authorized users can obtain information from individual files by specifying the exact file name within a WHERE clause. Files that are not included are ignored and considered not to exist.</p> <p>All files that match the procfs_files_spec are opened, read, stored in memory, and, finally, returned to the client. It is critical to add a WHERE clause to return only specific files to limit the impact of the plugin on the server\u2019s performance. A failure to use a WHERE clause can lead to lengthy query response times, high load, and high memory usage on the server. The WHERE clause can contain either an equality operator, the LIKE operator, or the IN operator. The LIKE operator limits file globbing. You can write file access patterns in the glob(7) style, such as <code>/sys/block/sd[a-z]/stat;/proc/version\\*</code></p> <p>The following example returns the <code>proc/version</code>:</p> <pre><code>SELECT * FROM INFORMATION_SCHEMA.PROCFS WHERE FILE = '/proc/version';\n</code></pre>"},{"location":"procfs-plugin.html#tables","title":"Tables","text":""},{"location":"procfs-plugin.html#procfs","title":"PROCFS","text":"<p>The schema definition of the INFORMATION_SCHEMA.PROCFS view is:</p> <pre><code>CREATE TEMPORARY TABLE `PROCFS` (\n`FILE` varchar(1024) NOT NULL DEFAULT '',\n`CONTENTS` longtext NOT NULL\n) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n</code></pre> <p>Status variables provide the basic metrics:</p> Name Description procfs_access_violations The number of attempted queries by users without the ACCESS_PROCFS privilege. procfs_queries The number of queries made against the procfs view. procfs_files_read The number of files read to provide content procfs_bytes_read The number of bytes read to provide content"},{"location":"procfs-plugin.html#variable","title":"Variable","text":""},{"location":"procfs-plugin.html#procfs_files_spec","title":"procfs_files_spec","text":"Option Description Scope: Global Dynamic: Yes Read, Write, or Read-Only: Read-Only <p>The default value for <code>procfs_files_spec</code> is: /proc/cpuinfo;/proc/irq//;/proc/loadavg/proc/net/dev;/proc/net/sockstat;/proc/net/sockstat_rhe4;/proc/net/tcpstat;/proc/self/net/netstat;/proc/self/stat;/proc/self/io;/proc/self/numa_maps/proc/softirqs;/proc/spl/kstat/zfs/arcstats;/proc/stat;/proc/sys/fs/file-nr;/proc/version;/proc/vmstat</p> <p>Enables access to the <code>/proc</code> and <code>/sys</code> directories and files. This variable is global, read only, and is set by using either the mysqld command line or by editing <code>my.cnf</code>.</p>"},{"location":"procfs-plugin.html#limitations","title":"Limitations","text":"<p>The following limitations are:</p> <ul> <li> <p>Only first 60k of /proc/ /sys/ files are returned</p> </li> <li> <p>The file name size is limited to 1k</p> </li> <li> <p>The plugin cannot read files if path does not start from /proc or /sys</p> </li> <li> <p>Complex WHERE conditions may force the plugin to read all configured files.</p> </li> </ul>"},{"location":"procfs-plugin.html#uninstall-plugin","title":"Uninstall plugin","text":"<p>The following statement removes the procfs plugin.</p> <pre><code>UNINSTALL PLUGIN procfs;\n</code></pre> <p></p>"},{"location":"procfs-plugin.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"proxy-protocol-support.html","title":"Support for PROXY protocol","text":"<p>The proxy protocol allows an intermediate proxying server speaking proxy protocol (ie. HAProxy) between the server and the ultimate client (i.e. mysql client etc) to provide the source client address to the server, which normally would only see the proxying server address instead.</p> <p>As the proxy protocol amounts to spoofing the client address, it is disabled by default, and can be enabled on per-host or per-network basis for the trusted source addresses where trusted proxy servers are known to run. Unproxied connections are not allowed from these source addresses.</p> <p>Note</p> <p>Ensure that proper firewall access control lists (ACL) are in place when this feature is enabled.</p> <p>Proxying is supported only for TCP over IPv4 and IPv6 connections. The UNIX socket connections can not be proxied and do not fall under the effect of using the asterisk symbol (*).</p> <p>You cannot have a proxied IP address that is <code>127.0.0.1</code> or <code>::1</code>, even if the IP address is in the proxy_protocol_networks.</p>"},{"location":"proxy-protocol-support.html#system-variables","title":"System variables","text":""},{"location":"proxy-protocol-support.html#proxy_protocol_networks","title":"<code>proxy_protocol_networks</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic No Default (empty string) <p>This variable is a global-only, read-only variable, which is either an asterisk symbol(*), or a list of comma-separated IPv4 and IPv6 network and host addresses. For security reasons we do not recommend using an asterisk symbol for the IP address. This symbol causes the server to accept the proxy protocol from any host. Network addresses are specified in CIDR notation, i.e. <code>192.168.0.0/24</code>. To prevent source host spoofing, the setting of this variable must be as restrictive as possible to include only trusted proxy hosts.</p>"},{"location":"proxy-protocol-support.html#related-reading","title":"Related reading","text":"<ul> <li>PROXY protocol specification</li> </ul>"},{"location":"proxy-protocol-support.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"query-limit-records.html","title":"Query limit records","text":""},{"location":"query-limit-records.html#limit-the-estimation-of-records-in-a-query","title":"Limit the estimation of records in a Query","text":"<p>Important</p> <p>This feature is a tech preview. Before using this feature in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> <p>This page describes an alternative when running queries against a large number of table partitions. When a query runs, InnoDB estimates the records in each partition. This process can result in more pages read and more disk I/O, if the buffer pool must fetch the pages from disk. This process increases the query time if there are a large number of partitions.</p> <p>The addition of two variables makes it possible to override records_in_range which effectively bypasses the process.</p> <p>Warning</p> <p>The use of these variables may result in improper index selection by the optimizer.</p>"},{"location":"query-limit-records.html#innodb_records_in_range","title":"<code>innodb_records_in_range</code>","text":"Option Description Command-line: <code>--innodb-records-in-range</code> Scope: Global Dynamic: Yes Data type: Numeric Default 0 <p>Important</p> <p>This feature is a tech preview. Before using this feature in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> <p>The variable provides a method to limit the number of records estimated for a query.</p> <pre><code>mysql&gt; SET @@GLOBAL.innodb_records_in_range=100;\n100\n</code></pre>"},{"location":"query-limit-records.html#innodb_force_index_records_in_range","title":"<code>innodb_force_index_records_in_range</code>","text":"Option Description Command-line: <code>--innodb-force-index-records-in-range</code> Scope: Global Dynamic: Yes Data type: Numeric Default 0 <p>Important</p> <p>This feature is a tech preview. Before using this feature in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> <p>This variable provides a method to override the records_in_range result when a FORCE INDEX is used in a query.</p> <pre><code>mysql&gt; SET @@GLOBAL.innodb_force_index_records_in_range=100;\n100\n</code></pre>"},{"location":"query-limit-records.html#using-the-favor_range_scan-optimizer-switch","title":"Using the favor_range_scan optimizer switch","text":"<p>Important</p> <p>This feature is a tech preview. Before using this feature in production, we recommend that you test restoring production from physical backups in your environment, and also use the alternative backup method for redundancy.</p> <p>In specific scenarios, the optimizer chooses to scan a table instead of using a range scan. The conditions are the following:</p> <ul> <li> <p>Table with an extremely large number of rows</p> </li> <li> <p>Compound primary keys made of two or more columns</p> </li> <li> <p>WHERE clause contains multiple range conditions</p> </li> </ul> <p>The optimizer_switch controls the optimizer behavior. The favor_range_scan switch arbitrarily lowers the cost of a range scan by a factor of 10.</p> <p>The available values are:</p> <ul> <li> <p>ON</p> </li> <li> <p>OFF (Default)</p> </li> <li> <p>DEFAULT</p> </li> </ul> <pre><code>mysql&gt; SET optimizer_switch='favor_range_scan=on';\n</code></pre> <p></p>"},{"location":"query-limit-records.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"quickstart-overview.html","title":"Quickstart guide for Percona Server for MySQL","text":"<p>Percona Server for MySQL is a freely available, fully compatible, enhanced, and open source drop-in replacement for any MySQL database. It provides superior and optimized performance, greater scalability and availability, enhanced backups, increased visibility, and instrumentation. Percona Server for MySQL is trusted by thousands of enterprises to provide better performance and concurrency for their most demanding workloads.</p>"},{"location":"quickstart-overview.html#install-percona-server-for-mysql","title":"Install Percona Server for MySQL","text":"<p>You can install Percona Server for MySQL using different methods. </p> <ul> <li>Use the Percona Repositories</li> <li>Use APT</li> <li>Use YUM</li> <li>Use binary tarballs</li> <li>Use Docker</li> </ul>"},{"location":"quickstart-overview.html#for-backups-and-restores","title":"For backups and restores","text":"<p>Percona XtraBackup (PXB) is a 100% open source backup solution for all versions of Percona Server for MySQL and MySQL\u00ae that performs online non-blocking, tightly compressed, highly secure full backups on transactional systems. Maintain fully available applications during planned maintenance windows with Percona XtraBackup.</p> <p>Install Percona XtraBackup</p>"},{"location":"quickstart-overview.html#for-monitoring-and-management","title":"For Monitoring and Management","text":"<p>Percona Monitoring and Management (PMM )monitors and provides actionable performance data for MySQL variants, including Percona Server for MySQL, Percona XtraDB Cluster, Oracle MySQL Community Edition, Oracle MySQL Enterprise Edition, and MariaDB. PMM captures metrics and data for the InnoDB, XtraDB, and MyRocks storage engines, and has specialized dashboards for specific engine details.</p> <p>Install PMM and connect your MySQL instances to it.</p>"},{"location":"quickstart-overview.html#for-high-availability","title":"For high availability","text":"<p>Percona XtraDB Cluster (PXC) is a 100% open source, enterprise-grade, highly available clustering solution for MySQL multi-source setups based on Galera. PXC helps enterprises minimize unexpected downtime and data loss, reduce costs, and improve performance and scalability of your database environments supporting your critical business applications in the most demanding public, private, and hybrid cloud environments.</p> <p>Percona XtraDB Cluster Quick start guide</p>"},{"location":"quickstart-overview.html#operators","title":"Operators","text":"<p>Percona Operator for MySQL and Percona Operator for MySQL based on Percona XtraDB Cluster are tools designed to simplify the deployment, management, and scaling of MySQL and Percona XtraDB Cluster (PXC) instances in Kubernetes environments. These operators automate various database tasks such as backups, recovery, and updates, ensuring high availability and reliability. They provide robust features like automated failover, self-healing, and seamless scaling, which help maintain optimal database performance and reduce manual intervention. By leveraging Kubernetes\u2019 orchestration capabilities, these operators enhance the efficiency and resilience of MySQL and PXC deployments, making them well-suited for modern cloud-native applications.</p> <p>Percona Operator for MySQL Documentation</p> <p>Percona Operator for MySQL based on Percona XtraDB Cluster</p>"},{"location":"quickstart-overview.html#cloud-native-database-services","title":"Cloud-native database services","text":"<p>Percona Everest is an open-source cloud-native database platform that helps developers deploy code faster, scale deployments rapidly, and reduce database administration overhead while regaining control over their data, database configuration, and DBaaS costs.</p> <p>Percona Everest</p> <p></p>"},{"location":"quickstart-overview.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"reading-audit-log-filter-files.html","title":"Reading Audit Log Filter files","text":"<p>The Audit Log Filter functions can provide a SQL interface to read JSON-format audit log files. The functions cannot read log files in other formats. Configuring the component for JSON logging lets the functions use the directory that contains the current audit log filter file and search in that location for readable files. The value of the <code>audit_log_filter.file</code> system variable provides the file location, base name, and the suffix and then searches for names that match the pattern.</p> <p>If the file is renamed and no longer fits the pattern, the file is ignored.</p>"},{"location":"reading-audit-log-filter-files.html#functions-used-for-reading-the-files","title":"Functions used for reading the files","text":"<p>The following functions read the files in the JSON-format:</p> <ul> <li><code>audit_log_read</code> - reads audit log filter events</li> <li>[<code>audit_log_read_bookmark()](audit-log-filter-variables.md#audit_log_read_bookmark) - for the most recently read event, returns a bookmark. The bookmark can be passed to</code>audit_log_read()`.</li> </ul> <p>Initialize a read sequence by using a bookmark or an argument that specifies the start position:</p> <pre><code>mysql&gt; SELECT audit_log_read(audit_log_read_bookmark());\n\nThe following example continues reading from the current position:\n\n```{.bash data-prompt=\"mysql&gt;\"}\nmysql&gt; SELECT audit_log_read();\n</code></pre> <p>Reading a file is closed when the session ends or calling <code>audit_log_read()</code> with another argument.</p> <p></p>"},{"location":"reading-audit-log-filter-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"restrict-dynamic-log-locations.html","title":"Restrict dynamic log file locations","text":"<p>The <code>secure_log_path</code> system variable restricts the dynamic log file locations.</p>"},{"location":"restrict-dynamic-log-locations.html#secure_log_path","title":"secure_log_path","text":"<p>The variable is read-only and must be set up in a configuration file or the command line.</p> <p>The accepted value is the directory name as a string. The default value is an empty string. When the value is an empty string, the variable only adds a warning to the error log and does nothing. If the value contains a directory name, then the slow query log and the general log must be located in that directory. An attempt to move either of these files outside of the specified directory results in an error.</p> <p></p>"},{"location":"restrict-dynamic-log-locations.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"rotate-master-key.html","title":"Rotate the master encryption key","text":"<p>Rotate the master encryption key periodically and if the key has been compromised.</p> <p>Rotating the master encryption key changes that key and tablespace keys are re-encrypted and updated in the tablespace headers. The rotation only succeeds if all operations are successful. If the rotation is interrupted, the operation is rolled forward when the server restarts.</p> <p>The rotation operation does not affect tablespace data. To change a tablespace key, disable and then re-enable encryption for that tablespace.</p> <p>The <code>ENCRYPTION_KEY_ADMIN</code> privilege is required to rotate the master encryption key.</p> <p>InnoDB reads the encryption data from the tablespace header, if certain tablespace keys have been encrypted with the prior master key, InnoDB retrieves the master key from the keyring to decrypt the tablespace key. InnoDB re-encrypts the tablespace key with the new Master key.</p> <p>Rotate the master encryption key with following statement:</p> <pre><code>mysql&gt; ALTER INSTANCE ROTATE INNODB MASTER KEY;\n</code></pre> <p>The rotation operation must complete before any tablespace encryption operation can begin.</p> <p></p>"},{"location":"rotate-master-key.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"select.html","title":"SELECT statement","text":"<p>The syntax of a SELECT statement in MySQL is straightforward. You start with the keyword SELECT, followed by the columns from which you want to retrieve data. You can specify the table from which to retrieve data using the FROM keyword. Optionally, you can include conditions to filter the results using the WHERE clause.</p> <p>The following table is a breakdown of the syntax:</p> Syntax Description SELECT This keyword indicates that you want to retrieve data from the database. Columns Specify the columns you want to retrieve data from. You can use the asterisk (*) to select all columns or specify individual column names separated by commas. FROM Use the FROM keyword to specify the table from which you want to retrieve data. WHERE (optional) If you want to filter the results based on specific conditions, you can use the WHERE clause. This clause allows you to specify conditions using comparison operators like =, &gt;, &lt;, etc., and logical operators like AND, OR, NOT. <pre><code>SELECT column1, column2\nFROM table_name\nWHERE condition;\n</code></pre> <ul> <li><code>SELECT column1, column2</code> specifies that you want to retrieve data from column1 and column2.</li> <li><code>FROM table_name</code> specifies the table from which you want to retrieve data.</li> <li><code>WHERE condition</code> is an optional clause that filters the results based on the specified condition.</li> </ul> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SQL Basics</li> <li>INSERT</li> <li>DELETE</li> <li>UPDATE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"select.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"selinux-contexts.html","title":"SELinux contexts and labels","text":"<p>Viewing SELinux Contexts Example of viewing SELinux context for a process using ps command Listing SELinux Types or Domains Explanation of SELinux type security property Example of listing SELinux types associated with MySQL directories and files</p> <p>SELinux context is like a label that tells the system how to handle files, processes, and other resources. For example, it determines which processes can access certain files and what actions they can perform on them. Understanding SELinux context helps you know how your applications interact with the system and ensures that they have the necessary permissions to function correctly. It\u2019s like giving each item on your computer a tag that says what it is and what it\u2019s allowed to do. So when your application tries to access a file, SELinux checks its context to see if it\u2019s allowed. If the context matches what\u2019s expected, the action is allowed; if not, it\u2019s denied. So knowing the SELinux context is essential for managing security and troubleshooting issues on your system.</p>"},{"location":"selinux-contexts.html#viewing-selinux-context-for-a-process-using-ps-command","title":"Viewing SELinux context for a process using ps command","text":"<p>To view the SELinux context for a process using the <code>ps</code> command, you can add the <code>-Z</code> option to display the context information. Here\u2019s how you can do it:</p> <pre><code>$ ps -eZ | grep &lt;process_name&gt;\n</code></pre> <p>Replace <code>&lt;process_name&gt;</code> with the process name you want to check. For example, if you want to see the SELinux context for the MySQL process, you would use:</p> <pre><code>$ ps -eZ | grep mysqld\n</code></pre> <p>The output displays the SELinux context for the specified process and typically consists of four parts: user, role, type (or domain), and sensitivity level.</p> Expected output <pre><code>system_u:system_r:mysqld_t:s0    3356 ?        00:00:01 mysqld\n</code></pre> <ul> <li><code>system_u</code> represents the user context.</li> <li><code>system_r</code> represents the role context.</li> <li><code>mysqld_t</code> represents the type (or domain) context.</li> <li><code>s0</code> represents the sensitivity level.</li> </ul> <p>This information helps you understand how SELinux enforces security policies for the specified process.</p>"},{"location":"selinux-contexts.html#list-selinux-types-or-domains","title":"List SELinux Types or Domains","text":"<p>SELinux types or domains categorize different resources on the system, such as files, directories, and processes. Each type or domain has specific permissions and restrictions associated with it, determining how resources interact with each other. To list SELinux types or domains associated with files, you can use the <code>ls</code> command with the <code>-Z</code> option. For example:</p> <pre><code>$ ls -laZ /var/lib/mysql\n</code></pre> Expected output <pre><code>drwxr-x--x. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql\ndrwxr-x---. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql-files\ndrwxr-x---. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql-keyring\n</code></pre> <p>This command lists the files and directories under <code>/var/lib/mysql</code> along with their SELinux context, which includes the type or domain associated with each resource. Understanding these types or domains helps manage SELinux policies and ensure proper access control for MySQL-related resources.</p> <p></p>"},{"location":"selinux-contexts.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"selinux.html","title":"Secure Percona Server for MySQL with SELinux","text":"<p>Understanding SELinux labels and their components (user, role, type, sensitivity level) Importance of SELinux context for administrators and users</p> <p>MySQL SELinux Policy Explanation of SELinux policy for MySQL Compatibility of Percona Server for MySQL with CentOS 7 and CentOS 8 SELinux policies</p> <p>SELinux is a mandatory access control system implemented in the Linux kernel. It\u2019s designed to enhance system security by enforcing strict rules on how processes interact with files, directories, and other system resources. Unlike discretionary access control (DAC), where users have some control over permissions, SELinux imposes policies that must be followed regardless of user settings.</p> <p>In SELinux, access policies are defined based on the context of processes and files. Each process and file is assigned a security context, which includes information about its identity and permissions. These contexts determine a process\u2019s actions on a file or resource.</p> <p>For processes, SELinux defines policies based on their security context, such as their domain and role. These policies specify which operations a process can perform and what resources it can access. For example, a web server process may be allowed to read web content files but not modify system configuration files. Similarly, files and directories are assigned security contexts that dictate how processes can access them. SELinux policies define rules governing interactions between processes and files based on their contexts. For instance, a database file may only be accessible for reading and writing by the database server process, while other processes are restricted from accessing it.</p> <p>Overall, SELinux acts as a guardrail for system resources, ensuring that only authorized processes can access sensitive files and directories, thereby bolstering system security. Understanding SELinux and its access policies is crucial for maintaining a secure and robust MySQL environment.</p>"},{"location":"selinux.html#understanding-selinux-labels-and-their-components","title":"Understanding SELinux labels and their components","text":"Component Description User Represents the identity of the user or process attempting an action. It helps SELinux determine which user is initiating the action. Role Defines the role or function of a process within the system. It assists SELinux in determining the purpose or responsibility of the process. Type Represents the type or category of an object such as files, directories, or processes. It aids SELinux in identifying the nature of the resource being accessed. Sensitivity Level Indicates the sensitivity level or security classification of an object. It assists SELinux in enforcing security policies based on the object\u2019s sensitivity."},{"location":"selinux.html#importance-of-selinux-context-for-administrators-and-users","title":"Importance of SELinux context for administrators and users","text":"<p>Understanding SELinux context is crucial for administrators and users because it determines how processes interact with system resources. By assigning specific labels to users, roles, types, and sensitivity levels, SELinux ensures that only authorized actions are permitted. This granular control enhances system security by restricting unauthorized access and preventing malicious activities. Administrators rely on SELinux context to configure policies that align with organizational security requirements, while users benefit from a secure environment where their actions are safeguarded against potential threats. Overall, SELinux context plays a pivotal role in maintaining the integrity and confidentiality of system operations.</p>"},{"location":"selinux.html#explanation-of-selinux-policy-for-mysql","title":"Explanation of SELinux Policy for MySQL","text":"<p>SELinux is a security feature in Linux that controls access to various resources such as files, directories, and network ports based on defined policies. For MySQL, SELinux has a specific policy that governs how the MySQL server process interacts with the system and other resources.</p> <p>This policy defines rules for MySQL\u2019s behavior, including which files it can access, which network ports it can use, and what actions it can perform. These rules help enforce security by restricting MySQL\u2019s actions to only those that are necessary for its operation, preventing unauthorized access and potential security breaches.</p> <p>The SELinux policy for MySQL ensures that the MySQL server process operates within predefined boundaries, limiting its capabilities to minimize the risk of exploitation or unauthorized access to sensitive data.</p>"},{"location":"selinux.html#compatibility-of-percona-server-for-mysql-with-selinux-policies","title":"Compatibility of Percona Server for MySQL with SELinux Policies","text":"<p>Percona Server for MySQL is a drop-in replacement for MySQL that offers enhanced performance, scalability, and other features. When running Percona Server for MySQL on Red Hat Enterprise Linux (RHEL) 8, RHEL 9, or their derivatives, compatibility with SELinux policies is essential for ensuring secure and reliable operation.</p> <p>Percona Server for MySQL is designed to be compatible with SELinux policies on these Linux distributions. This means that Percona Server for MySQL can seamlessly integrate with SELinux, allowing administrators to enforce security policies and restrictions without sacrificing the functionality or performance of the database server.</p> <p>By adhering to SELinux policies, Percona Server for MySQL ensures that it operates within the confines defined by SELinux, preventing any unauthorized or potentially malicious actions that could compromise the system\u2019s security. This compatibility with SELinux policies enhances the overall security posture of Percona Server for MySQL deployments on RHEL and its derivatives, providing peace of mind to administrators and users alike.</p>"},{"location":"selinux.html#selinux-context-example","title":"SELinux context example","text":"<p>To view the SELinux context, add the <code>-Z</code> switch to many of the utilities. Here is an example of the context for <code>mysqld</code>:</p> <pre><code>$ ps -eZ | grep mysqld_t\n</code></pre> Expected output <pre><code>system_u:system_r:mysqld_t:s0    3356 ?        00:00:01 mysqld\n</code></pre> <p>The context has the following properties:</p> <ul> <li> <p>User - system_u</p> </li> <li> <p>Role - system_r</p> </li> <li> <p>Type or domain - mysqld_t</p> </li> <li> <p>Sensitivity level - s0    3356</p> </li> </ul> <p>Most SELinux policy rules are based on the type or domain.</p>"},{"location":"selinux.html#list-selinux-types-or-domains-associated-with-files","title":"List SELinux types or domains associated with files","text":"<p>The security property that SELinux relies on is the Type security property. The type name often end with a <code>_t</code>. A group of objects with the same type security value belongs to the same domain.</p> <p>To view the <code>mysqldb_t</code> types associated with the MySQL directories and files, run the following command:</p> <pre><code>$ ls -laZ /var/lib/ | grep mysql\n</code></pre> Expected output <pre><code>drwxr-x--x. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql\ndrwxr-x---. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql-files\ndrwxr-x---. mysql   mysql   system_u:object_r:mysqld_db_t:s0 mysql-keyring\n</code></pre> <p>Note</p> <p>If a policy type does not define the type property for an object, the default value is <code>unconfined_t</code>.</p>"},{"location":"selinux.html#selinux-modes","title":"SELinux modes","text":"<p>SELinux has the following modes:</p> <ul> <li> <p>Disabled - No SELinux policy modules loaded, which disables policies. Nothing is reported.</p> </li> <li> <p>Permissive - SELinux is active, but policy modules are not enforced. A policy violation is reported but does not stop the action.</p> </li> <li> <p>Enforcing - SELinux is active, and violations are reported and denied. If there is no rule to allow access to a confined resource, SELinux denies the access.</p> </li> </ul>"},{"location":"selinux.html#policy-types","title":"Policy types","text":"<p>SELinux has several policy types:</p> <ul> <li> <p>Targeted - Most processes operate without restriction. Specific services are contained in security domains and defined by policies.</p> </li> <li> <p>Strict - All processes are contained in security domains and defined by policies.</p> </li> </ul> <p>SELinux has confined processes that run in a domain and restricts everything unless explicitly allowed. An unconfined process in an unconfined domain is allowed almost all access.</p> <p>MySQL is a confined process, and the policy module defines which files are read, which ports are opened, and so on. SELinux assumes the Percona Server for MySQL installation uses the default file locations and default ports.</p> <p>If you change the default, you must also edit the policy. If you do not update the policy, SELinux, in enforcing mode, denies access to all non-default resources.</p>"},{"location":"selinux.html#check-the-selinux-mode","title":"Check the SELinux mode","text":"<p>To check the current SELinux mode, use either of the following commands:</p> <pre><code>$ sestatus\n</code></pre> Expected output <pre><code>SELinux status:                 enabled\nSELinuxfs mount:                /sys/fs/selinux\nSELinux root directory:         /etc/selinux\nLoaded policy name:             targeted\nCurrent mode:                   enforcing\nMode from config file:          enforcing\nPolicy MLS status:              enabled\nPolicy deny_unknown status:     allowed\nMemory protection checking:     actual (secure)\nMax kernel policy version:      31\n</code></pre> <p>or</p> <pre><code>$ grep ^SELINUX= /etc/selinux/config\n</code></pre> Expected output <pre><code>SELINUX=enforcing\n</code></pre> <p>Note</p> <p>Add the <code>-b</code> parameter to <code>sestatus</code> to display the <code>Policy booleans</code>. The boolean values for each parameter is shown. An example of using the <code>b</code> parameter is the following:</p> <pre><code>$ sestatus -b | grep mysql\n</code></pre> Expected output <pre><code>mysql_connect_any                           off\nselinuxuser_mysql_connect_enabled\n</code></pre> <p>The <code>/etc/selinux/config</code> file controls if SELinux is disabled or enabled, and if enabled, whether SELinux operates in enforcing mode or permissive mode.</p>"},{"location":"selinux.html#disable-selinux","title":"Disable SELinux","text":"<p>If you plan to use the enforcing mode at another time, use the permissive mode instead of disabling SELinux. During the time that SELinux is disabled, the system may contain mislabeled objects or objects with no label. If you re-enable SELinux and plan to set SELinux to enforcing, you must follow the steps to Relabel the entire file system.</p> <p>On boot, to disable SELinux, set the <code>selinux=0</code> kernel option. The kernel does not load the SELinux infrastructure. This option has the same effect as changing the <code>SELINUX=disabled</code> instruction in the configuration file and then rebooting the system.</p>"},{"location":"selinux.html#additional-selinux-tools","title":"Additional SELinux tools","text":"<p>Install the SELinux management tools, such as <code>semanage</code> or <code>sesearch</code>, if needed.</p> <p>On RHEL 8 or compatible operating systems, use the following command as root:</p> <pre><code>$ yum -y install policycoreutils-python-utils\n</code></pre> <p>Note</p> <p>You may need root privileges to run SELinux management commands.</p>"},{"location":"selinux.html#switch-the-mode-in-the-configuration-file","title":"Switch the mode in the configuration file","text":"<p>Switching between modes may help when troubleshooting or when modifying rules.</p> <p>To permanently change the mode, edit the <code>/etc/selinux/config</code> file and change the <code>SELINUX=</code> value. You should also verify the change.</p> <pre><code>$ cat /etc/selinux/config | grep SELINUX= | grep -v ^#\n</code></pre> Expected output <pre><code>SELINUX=enforcing\nSELINUX=enforcing\n</code></pre> <pre><code>$ sudo sed -i 's/^SELINUX=.*/SELINUX=permissive/g' /etc/selinux/config\n\n$ cat /etc/selinux/config | grep SELINUX= | grep -v ^#\n</code></pre> Expected output <pre><code>SELINUX=permissive\nSELINUX=permissive\n</code></pre> <p>Reboot your system after the change.</p> <p>If switching from either disabled mode or permissive mode to enforcing, see Relabel the entire file system.</p>"},{"location":"selinux.html#switch-the-mode-until-the-next-reboot","title":"Switch the mode until the next reboot","text":"<p>To change the mode until the next reboot, use either of the following commands as root:</p> <pre><code>$ setenforce Enforcing\n</code></pre> <p>or</p> <pre><code>$ setenforce 1\n</code></pre> <p>The following <code>setenforce</code> parameters are available:</p> setenforce parameters Also Permitted 0 Permissive 1 Enforcing <p>You can view the current mode by running either of the following commands:</p> <pre><code>$ getenforce\n</code></pre> Expected output <pre><code>Enforcing\n</code></pre> <p>or</p> <pre><code>$ sestatus | grep -i mode\n</code></pre> Expected output <pre><code>Current mode:                   permissive\nMode from config file:          enforcing\n</code></pre>"},{"location":"selinux.html#switch-the-mode-for-a-service","title":"Switch the mode for a service","text":"<p>You can move one or more services into a permissive domain. The other services remain in enforcing mode.</p> <p>To add a service to the permissive domain, run the following as root:</p> <pre><code>$ sudo semanage permissive -a mysqld_t\n</code></pre> <p>To list the current permissive domains, run the following command:</p> <pre><code>$ sudo semanage permissive -l\n</code></pre> Expected output <pre><code>...\nCustomized Permissive Types\n\nmysqld_t\n\nBuiltin Permissive Types\n...\n</code></pre> <p>To delete a service from the permissive domain, run the following:</p> <pre><code>$ sudo semanage permissive -d mysqld_t\n</code></pre> <p>The service returns to the system\u2019s SELinux mode. Be sure to follow the steps to Relabel the entire file system.</p>"},{"location":"selinux.html#relabel-the-entire-file-system","title":"Relabel the entire file system","text":"<p>Switching from disabled or permissive to enforcing requires additional steps. The enforcing mode requires the correct contexts, or labels, to function. The permissive mode allows users and processes to label files and system objects incorrectly. The disabled mode does not load the SELinux infrastructure and does not label resources or processes.</p> <p>RHEL and compatible systems, use the <code>fixfiles</code> application for relabeling. You can relabel the entire file system or the file contexts of an application.</p> <p>For one application, run the following command:</p> <pre><code>$ fixfiles -R mysqld restore\n</code></pre> <p>To relabel the file system without rebooting the system, use the following command:</p> <pre><code>$ fixfiles -f -F relabel\n</code></pre> <p>Another option relabels the file system during a reboot. You can either add a touch file, read during the reboot operation, or configure a kernel boot parameter. The completion of the relabeling operation automatically removes the touch file.</p> <p>Add the touch file as root:</p> <pre><code>$ touch /.autorelabel\n</code></pre> <p>To configure the kernel, add the <code>autorelabel=1</code> kernel parameter to the boot parameter list. The parameter forces a system relabel. Reboot in permissive mode to allow the process to complete before changing to enforcing.</p> <p>Note</p> <p>Relabeling an entire filesystem takes time. When the relabeling is complete, the system reboots again.</p>"},{"location":"selinux.html#set-a-custom-data-directory","title":"Set a custom data directory","text":"<p>If you do not use the default settings, SELinux, in enforcing mode, prevents access to the system.</p> <p>For example, during installation, you have used the following configuration:</p> <pre><code>datadir=/var/lib/mysqlcustom\nsocket=/var/lib/mysqlcustom/mysql.sock\n</code></pre> <p>Restart the service.</p> <pre><code>$ service mysqld restart\n</code></pre> Expected output <pre><code>Redirecting to /bin/systemctl restart mysqld.service\nJob for mysqld.service failed because the control process exited with error code.\nSee \"systemctl status mysqld.service\" and \"journalctl -xe\" for details.\n</code></pre> <p>Check the journal log to see the error code.</p> <pre><code>$ journalctl -xe\n</code></pre> Expected output <pre><code>...\nSELinux is preventing mysqld from getattr access to the file /var/lib/mysqlcustom/ibdata1.\n...\n</code></pre> <p>Check the SELinux types in <code>/var/lib/mysqlcustom</code>.</p> <pre><code>ls -1aZ /var/lib/mysqlcustom\n</code></pre> Expected output <pre><code>  total 164288\n  drwxr-x--x.  6 mysql mysql system_u:object_r:var_lib_t:s0       4096 Dec  2 07:58  .\n  drwxr-xr-x. 38 root  root  system_u:object_r:var_lib_t:s0       4096 Dec  1 14:29  ..\n  ...\n  -rw-r-----.  1 mysql mysql system_u:object_r:var_lib_t:s0   12582912 Dec  1 14:29  ibdata1\n  ...\n</code></pre> <p>To solve the issue, use the following methods:</p> <ul> <li> <p>Set the proper labels for <code>mysqlcustom</code> files</p> </li> <li> <p>Change the mysqld SELinux policy to allow mysqld access to <code>var_lib_t</code> files.</p> </li> </ul> <p>The recommended solution is to set the proper labels. The following procedure assumes you have already created and set ownership to the custom data directory location:</p> <ol> <li> <p>To change the SELinux context, use <code>semanage fcontext</code>. In this step, you define how SELinux deals with the custom paths:</p> <pre><code>$ semanage fcontext -a -e /var/lib/mysql /var/lib/mysqlcustom\n</code></pre> <p>SELinux applies the same labeling schema, defined in the mysqld policy, for the <code>/var/lib/mysql</code> directory to the custom directory. Files created within the custom directory are labeled as if they were in <code>/var/lib/mysql</code>.</p> </li> <li> <p>To <code>restorecon</code> command applies the change.</p> <pre><code>$ restorecon -R -v /var/lib/mysqlcustom\n</code></pre> </li> <li> <p>Restart the mysqld service:</p> <pre><code>$ service mysqld start\n</code></pre> </li> </ol>"},{"location":"selinux.html#set-a-custom-log-location","title":"Set a custom log location","text":"<p>If you do not use the default settings, SELinux, in enforcing mode, prevents access to the location. Change the log location to a custom location in my.cnf:</p> <pre><code>log-error=/logs/mysqld.log\n</code></pre> <p>Verify the log location with the following command:</p> <pre><code>$ ls -laZ /\n</code></pre> Expected output <pre><code>  ...\n  drwxrwxrwx.   2 root root unconfined_u:object_r:default_t:s0    6 Dec  2 09:16 logs\n  ...\n</code></pre> <p>Starting MySQL returns the following message:</p> <pre><code>$ service mysql start\n</code></pre> Expected output <pre><code>Redirecting to /bin/systemctl start mysql.service\nJob for mysqld.service failed because the control process exited with error code.\nSee \"systemctl status mysqld.service\" and \"journalctl -xe\" for details.\n\n$ journalctl -xe\n...\nSELinux is preventing mysqld from write access to the directory logs.\n...\n</code></pre> <p>The default SELinux policy allows mysqld to write logs into a location tagged with <code>var_log_t</code>, which is the <code>/var/log</code> location. You can solve the issue with either of the following methods:</p> <ul> <li> <p>Tag the <code>/logs</code> location properly</p> </li> <li> <p>Edit the SELinux policy to allow mysqld access to all directories.</p> </li> </ul> <p>To tag the custom <code>/logs</code> location is the recommended method since it locks down access. Run the following commands to tag the custom location:</p> <pre><code>$ semanage fcontext -a -t var_log_t /logs\n$ restorecon -v /logs\n</code></pre> <p>You may not be able to change the <code>/logs</code> directory label. For example, other applications, with their own rules, use the same directory.</p> <p>To adjust the SELinux policy when a directory is shared, follow these steps:</p> <ol> <li> <p>Create a local policy:</p> <pre><code>ausearch -c 'mysqld' --raw | audit2allow -M my-mysqld\n</code></pre> </li> <li> <p>This command generates the my-mysqld.te and the my-mysqld.pp files. The mysqld.te is the type enforcement policy file. The my-mysqld.pp is the policy module loaded as a binary file into the SELinux subsystem.</p> <p>An example of the my-myslqd.te file:</p> <pre><code>module my-mysqld 1.0;\n\nrequire {\n    *type mysqld_t*;\n    type var_lib_t;\n    *type default_t*;\n    class file getattr;\n    *class dir write*;\n}\n\n============= mysqld_t ==============\n*allow mysqld_t default_t:dir write*;\nallow mysqld_t var_lib_t:file getattr;\n</code></pre> <p>The policy contains rules for the custom data directory and the custom logs directory. We have set the proper labels for the data directory location, and applying this auto-generated policy would loosen our hardening by allowing mysqld to access <code>var_lib_t</code> tags.</p> </li> <li> <p>SELinux-generated events are converted to rules. A generated policy may contain rules for recent violations and include unrelated rules. Unrelated rules are generated from actions, such as changing the data directory location, that are not related to the logs directory. Add the <code>--start</code> parameter to use log events after a specific time to filter out the unwanted events. This parameter captures events when the time stamp is equal to the specified time or later. SELinux generates a policy for the current actions.</p> <pre><code>$ ausearch --start 10:00:00 -c 'mysqld' --raw | audit2allow -M my-mysqld\n</code></pre> </li> <li> <p>This policy allows mysqld writing into the tagged directories. Open the my_mysqld file:</p> <pre><code>module my-mysqld 1.0;\n\nrequire {\n    type mysqld_t;\n    type default_t;\n    class dir write;\n}\n\n============= mysqld_t ==============\nallow mysqld_t default_t:dir write;\n</code></pre> </li> <li> <p>Install the SELinux policy module:</p> <pre><code>$ semodule -i my-mysqld.pp\n</code></pre> </li> </ol> <p>Restart the service. If you have a failure, check the journal log and follow the same procedure.</p> <p>If SELinux prevents mysql from creating a log file inside the directory. You can view all the violations by changing the SELinux mode to <code>permissive</code> and then running mysqld. All violations are logged in the journal log. After this run, you can generate a local policy module, install it, and switch SELinux back to <code>enforcing</code> mode. </p> <p>Follow this procedure:</p> <ol> <li> <p>Unload the current local my-mysqld policy module:</p> <pre><code>$ semodule -r my-mysqld\n</code></pre> </li> <li> <p>You can put a single domain into permissive mode. Other domains on the system to remain in enforcing mode. Use <code>semanage permissive</code> with the <code>-a</code> parameter to change mysqld_t to permissive mode:</p> <pre><code>$ semanage permissive -a mysqld_t\n</code></pre> </li> <li> <p>Verify the mode change:</p> <pre><code>$ semdule -l | grep permissive\n</code></pre> Expected output <pre><code>...\npermissive_mysqld_t\n...\n</code></pre> </li> <li> <p>To make searching the log easier, return the time:</p> <pre><code>$ date\n</code></pre> </li> <li> <p>Start the service.</p> <pre><code>$ service mysqld start\n</code></pre> </li> <li> <p>MySQL starts, and SELinux logs the violations in the journal log. Check the journal log:</p> <pre><code>$ journalctl -xe\n</code></pre> </li> <li> <p>Stop the service:</p> <pre><code>$ service mysqld stop\n</code></pre> </li> <li> <p>Generate a local mysqld policy, using the time returned from step 4:</p> <pre><code>$ ausearch --start &lt;date-c 'mysqld' --raw | audit2allow -M my-mysqld\n</code></pre> </li> <li> <p>Review the policy (the policy you generate may be different):</p> <pre><code>$ cat my-mysqld.te\n</code></pre> Expected output <pre><code>module my-mysqld 1.0;\n\nrequire {\ntype default_t;\n    type mysqld_t;\n    class dir { add_name write };\n    class file { append create open };\n}\n\n============= mysqld_t ==============\nallow mysqld_t default_t:dir { add_name write };\nallow mysqld_t default_t:file { append create open };\n</code></pre> </li> <li> <p>Install the policy:</p> <pre><code>$ semodule -i my-mysqld.pp\n</code></pre> </li> <li> <p>Use <code>semanage permissive</code> with the <code>-d</code> parameter, which deletes the permissive domain for the service:</p> <pre><code>$ semanage permissive -d mysqld_t\n</code></pre> </li> <li> <p>Restart the service:</p> <pre><code>$ service mysqld start\n</code></pre> </li> </ol> <p>Note</p> <p>Use this procedure to adjust the local mysqld policy module. You should review the changes which are generated to ensure the rules are not too tolerant.</p>"},{"location":"selinux.html#set-secure_file_priv-directory","title":"Set <code>secure_file_priv</code> directory","text":"<p>Update the SELinux tags for the <code>/var/lib/mysql-files/</code> directory, used for <code>SELECT ... INTO OUTFILE</code> or similar operations, if required. The server needs only read/write access to the destination directory.</p> <p>To set <code>secure_file_priv</code> to use this directory, run the following commands to set the context:</p> <pre><code>$ semanage fcontext -a -t mysqld_db_t \"/var/lib/mysql-files/(/.*)?\"\n$ restorecon -Rv /var/lib/mysql-files\n</code></pre> <p>Edit the path for a different location, if needed.</p> <p></p>"},{"location":"selinux.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sequence-table.html","title":"SEQUENCE_TABLE(n) function","text":"<p>Using <code>SEQUENCE_TABLE()</code> function provides the following:</p> Benefit Description Generates Sequences Acts as an inline table-valued function that generates a sequence of numbers. Table-Valued Function Unlike traditional scalar functions, <code>SEQUENCE_TABLE()</code> returns a virtual table with a single column named <code>value</code> containing the generated sequence. Simpler Syntax Simplifies queries that need to generate predictable sequences of numbers. Flexibility Allows dynamic definition of sequences within queries, offering more control compared to pre-defined tables for sequences. Predefined Sequence Does not manage sequences like Oracle or PostgreSQL; instead, it allows definition and generation of sequences within a <code>SELECT</code> statement. Customization Enables customization of starting value, increment/decrement amount, and number of values to generate."},{"location":"sequence-table.html#version-update","title":"Version update","text":"<p>Percona Server for MySQL 8.4 deprecated <code>SEQUENCE_TABLE()</code>, and this function can be removed in a future release. We recommend that you use <code>PERCONA_SEQUENCE_TABLE()</code> instead.</p> <p>To maintain compatibility with existing third-party software, <code>SEQUENCE_TABLE</code> is no longer a reserved term and can be used as a regular identifier.</p>"},{"location":"sequence-table.html#table-functions","title":"Table functions","text":"<p>The function is an inline table-valued function. This function creates a temporary table with multiple rows. You can use this function within a single SELECT statement. Oracle MySQL Server only has the <code>JSON_TABLE</code> table function. The Percona Server for MySQL has the <code>JSON_TABLE</code> and <code>SEQUENCE_TABLE()</code> table functions. A single SELECT statement generates a multi-row result set. In contrast, a scalar function (like EXP(x) or LOWER(str) always returns a single value of a specific data type.</p>"},{"location":"sequence-table.html#syntax","title":"Syntax","text":"<p>As with any derived tables, a table function requires an alias in the <code>SELECT</code> statement.</p> <p>The result set is a single column with the predefined column name <code>value</code> of type <code>BIGINT UNSIGNED</code>. You can reference the <code>value</code> column in <code>SELECT</code> statements. The following statements are valid. Using <code>n</code> as the number of generated values, the following is the basic syntax:</p> <ul> <li>SEQUENCE_TABLE(n) [AS] alias</li> </ul> <pre><code>SELECT \u2026 FROM SEQUENCE_TABLE(n) [AS] alias\n\nSEQUENCE_TABLE(n) [AS] alias\n</code></pre> <pre><code>SELECT * FROM SEQUENCE_TABLE(n) AS tt;\nSELECT &lt;expr(value)&gt; FROM SEQUENCE_TABLE(n) AS tt;\n</code></pre> <p>The first number in the series, the initial term, is defined as <code>0</code>, and the series ends with a value less than <code>n</code>.</p>"},{"location":"sequence-table.html#example-usage","title":"Example usage","text":"<p>Using <code>SEQUENCE_TABLE()</code>:</p> <pre><code>mysql&gt; SELECT * FROM SEQUENCE_TABLE(5)) AS sequence_data;\n</code></pre> <p>Using <code>PERCONA_SEQUENCE_TABLE()</code>:</p> <pre><code>mysql&gt; SELECT * FROM PERCONA_SEQUENCE_TABLE(5)) AS sequence_data;\n</code></pre>"},{"location":"sequence-table.html#basic-sequence-generation","title":"Basic sequence generation","text":"<p>In this example, the following statement generates a sequence:</p> <pre><code>mysql&gt; SELECT * FROM SEQUENCE_TABLE(3) AS tt;\n</code></pre> Expected output <pre><code>+-------+\n| value |\n+-------+\n|     0 |\n|     1 |\n|     2 |\n+-------+\n</code></pre>"},{"location":"sequence-table.html#start-with-a-specific-value","title":"Start with a specific value","text":"<p>You can define the initial value using the <code>WHERE</code> clause. The following example starts the sequence with <code>4</code>.</p> <pre><code>SELECT value AS result FROM SEQUENCE_TABLE(8) AS tt WHERE value &gt;= 4;\n</code></pre> Expected output <pre><code>+--------+\n| result |\n+--------+\n|      4 |\n|      5 |\n|      6 |\n|      7 |\n+--------+\n</code></pre>"},{"location":"sequence-table.html#filter-even-numbers","title":"Filter even numbers","text":"<p>Consecutive terms increase or decrease by a common difference. The default common difference value is <code>1</code>. However, it is possible to filter the results using the WHERE clause to simulate common differences greater than 1.</p> <p>The following example prints only even numbers from the 0..7 range:</p> <pre><code>SELECT value AS result FROM SEQUENCE_TABLE(8) AS tt WHERE value % 2 = 0;\n</code></pre> Expected output <pre><code>+--------+\n| result |\n+--------+\n|      0 |\n|      2 |\n|      4 |\n|      6 |\n+--------+\n</code></pre>"},{"location":"sequence-table.html#generate-random-numbers","title":"Generate random numbers","text":"<p>The following is an example of using the function to populate a table with a set of random numbers:</p> <pre><code>mysql&gt; SELECT FLOOR(RAND() * 100) AS result FROM SEQUENCE_TABLE(4) AS tt;\n</code></pre> <p>The output could be the following:</p> Expected output <pre><code>+--------+\n| result |\n+--------+\n|     24 |\n|     56 |\n|     70 |\n|     25 |\n+--------+\n</code></pre>"},{"location":"sequence-table.html#generate-random-strings","title":"Generate random strings","text":"<p>You can populate a table with a set of pseudo-random strings with the following statement:</p> <pre><code>mysql&gt; SELECT MD5(value) AS result FROM SEQUENCE_TABLE(4) AS tt;\n</code></pre> Expected output <pre><code>+----------------------------------+\n| result                           |\n+----------------------------------+\n| f17d9c990f40f8ac215f2ecdfd7d0451 |\n| 2e5751b7cfd7f053cd29e946fb2649a4 |\n| b026324c6904b2a9cb4b88d6d61c81d1 |\n| 26ab0db90d72e28ad0ba1e22ee510510 |\n+----------------------------------+\n</code></pre>"},{"location":"sequence-table.html#add-a-sequence-to-a-table","title":"Add a sequence to a table","text":"<p>You can add the sequence as a column to a new table or an existing table, as shown in this example:</p> <pre><code>mysql&gt; CREATE TABLE t1 AS SELECT * FROM SEQUENCE_TABLE(4) AS tt;\n\nmysql&gt; SELECT * FROM t1;\n</code></pre> Expected output <pre><code>+-------+\n| value |\n+-------+\n|     0 |\n|     1 |\n|     2 |\n|     3 |\n+-------+\n</code></pre> <p>Sequences are helpful for various purposes, such as populating tables and generating test data.</p> <p></p>"},{"location":"sequence-table.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"server-version-numbers.html","title":"Understand version numbers","text":"<p>A version number identifies the innovtion product release. The product contains the latest features, improvements, and bug fixes at the time of that release.</p> <p>| 8.1.0 | -1 | |\u2014|\u2014|\u2014| | Base version | Minor build version |</p> <p>Percona uses semantic version numbering, which follows the pattern of base version and build version. Percona assigns unique, non-negative integers in increasing order for each version release. The version number combines the base MySQL 8.4 version number and the minor build version.</p> <p>The version numbers for Percona Server for MySQL 8.4.0-1 define the following information:</p> <ul> <li> <p>Base version - the leftmost numbers indicate MySQL 8.4 version used as a base. </p> </li> <li> <p>Minor build version - an internal number that increases by one every time Percona Server for MySQL is released.</p> </li> </ul> <p></p>"},{"location":"server-version-numbers.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"show-engines.html","title":"Show storage engines","text":"<p>This feature changes the comment field displayed when the <code>SHOW STORAGE ENGINES</code> command is executed and XtraDB is the storage engine.</p> <p>Before the Change:</p> <pre><code>mysql&gt; show storage engines;\n</code></pre> Expected output <pre><code>+------------+---------+----------------------------------------------------------------+--------------+------+------------+\n| Engine     | Support | Comment                                                        | Transactions | XA   | Savepoints |\n+------------+---------+----------------------------------------------------------------+--------------+------+------------+\n| InnoDB     | YES     | Supports transactions, row-level locking, and foreign keys     | YES          | YES  | YES        |\n...\n+------------+---------+----------------------------------------------------------------+--------------+------+------------+\n</code></pre> <p>After the Change:</p> <pre><code>mysql&gt; show storage engines;\n</code></pre> Expected output <pre><code>+------------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n| Engine     | Support | Comment                                                                    | Transactions |   XA | Savepoints |\n+------------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n| InnoDB     | YES     | Percona-XtraDB, Supports transactions, row-level locking, and foreign keys |          YES | YES  | YES        |\n...\n+------------+---------+----------------------------------------------------------------------------+--------------+------+------------+\n</code></pre> <p></p>"},{"location":"show-engines.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"slow-extended.html","title":"Slow query log","text":"<p>This feature adds microsecond time resolution and additional statistics to the slow query log output. It lets you enable or disable the slow query log at runtime, adds logging for the replica SQL thread, and adds fine-grained control over what and how much to log into the slow query log.</p> <p>You can use Percona-Toolkit\u2019s pt-query-digest tool to aggregate similar queries together and report on those that consume the most execution time.</p>"},{"location":"slow-extended.html#system-variables","title":"System Variables","text":""},{"location":"slow-extended.html#log_slow_filter","title":"<code>log_slow_filter</code>","text":"Option Description Command-line Yes Config file Yes Scope Global, Session Dynamic Yes <p>Filters the slow log by the query\u2019s execution plan. The value is a comma-delimited string, and can contain any combination of the following values:</p> <ul> <li> <p><code>full_scan</code>: The query performed a full table scan.</p> </li> <li> <p><code>full_join</code>: The query performed a full join (a join without indexes).</p> </li> <li> <p><code>tmp_table</code>: The query created an implicit internal temporary table.</p> </li> <li> <p><code>tmp_table_on_disk</code>: The query\u2019s temporary table was stored on disk.</p> </li> <li> <p><code>filesort</code>: The query used a filesort.</p> </li> <li> <p><code>filesort_on_disk</code>: The filesort was performed on disk.</p> </li> </ul> <p>Values are OR\u2019ed together. If the string is empty, then the filter is disabled. If it is not empty, then queries will only be logged to the slow log if their execution plan matches one of the types of plans present in the filter.</p> <p>For example, to log only queries that perform a full table scan, set the value to <code>full_scan</code>. To log only queries that use on-disk temporary storage for intermediate results, set the value to <code>tmp_table_on_disk,filesort_on_disk</code>.</p>"},{"location":"slow-extended.html#log_slow_rate_type","title":"<code>log_slow_rate_type</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic yes Data type Enumerated Default session, query <p>Specifies semantic of log_slow_rate_limit - <code>session</code> or <code>query</code>.</p>"},{"location":"slow-extended.html#log_slow_rate_limit","title":"<code>log_slow_rate_limit</code>","text":"Option Description Command-line Yes Config file Yes Scope Global, session Dynamic yes Default 1 Range 1-1000 <p>Behavior of this variable depends on the selected log_slow_rate_type.</p> <p>Specifies that only a fraction of <code>session/query</code> should be logged. Logging is enabled for every nth <code>session/query</code>. By default, n is 1, so logging is enabled for every <code>session/query</code>. Please note: when log_slow_rate_type is <code>session</code> rate limiting is disabled for the replication thread.</p> <p>Logging all queries might consume I/O bandwidth and cause the log file to grow large.</p> <ul> <li> <p>When log_slow_rate_type is <code>session</code>, this option lets you log full sessions, so you have complete records of sessions for later analysis; but you can rate-limit the number of sessions that are logged. Note that this feature will not work well if your application uses any type of connection pooling or persistent connections. Note that you change log_slow_rate_limit in <code>session</code> mode, you should reconnect for get effect.</p> </li> <li> <p>When log_slow_rate_type is <code>query</code>, this option lets you log just some queries for later analysis. For example, if you set the value to 100, then one percent of queries will be logged.</p> </li> </ul> <p>Note that every query has global unique <code>query_id</code> and every connection can has it own (session) log_slow_rate_limit. Decision \u201clog or no\u201d calculated in following manner:</p> <ul> <li> <p>if <code>log_slow_rate_limit</code> is 1 - log every query</p> </li> <li> <p>If <code>log_slow_rate_limit</code> 1 - randomly log every 1/<code>log_slow_rate_limit</code> query.</p> </li> </ul> <p>This allows flexible setup logging behavior.</p> <p>For example, if you set the value to 100, then one percent of <code>sessions/queries</code> will be logged. In Percona Server for MySQL information about the log_slow_rate_limit has been added to the slow query log. This means that if the log_slow_rate_limit is effective it will be reflected in the slow query log for each written query. </p> Expected output <pre><code>Log_slow_rate_type: query  Log_slow_rate_limit: 10\n</code></pre>"},{"location":"slow-extended.html#log_slow_sp_statements","title":"<code>log_slow_sp_statements</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type Enumerated Default session Range session, query <p>If <code>TRUE</code>, statements executed by stored procedures are logged to the slow if it is open.</p> <p>Percona Server for MySQL implemented improvements for logging of stored procedures to the slow query log:</p> <ul> <li> <p>Each query from a stored procedure is now logged to the slow query log individually</p> </li> <li> <p><code>CALL</code> itself isn\u2019t logged to the slow query log anymore as this would be counting twice for the same query which would lead to incorrect results</p> </li> <li> <p>Queries that were called inside of stored procedures are annotated in the slow query log with the stored procedure name in which they run.</p> </li> </ul> <p>Example of the improved stored procedure slow query log entry:</p> <pre><code>mysqlDELIMITER //\nmysqlCREATE PROCEDURE improved_sp_log()\n       BEGIN\n        SELECT * FROM City;\n        SELECT * FROM Country;\n       END//\nmysqlDELIMITER ;\nmysqlCALL improved_sp_log();\n</code></pre> <p>When we check the slow query log after running the stored procedure, with <code>log_slow_sp_statements</code> set to <code>TRUE</code>, it should look like this:</p> Expected output <pre><code># Time: 150109 11:38:55\n# User@Host: root[root] @ localhost []\n# Thread_id: 40  Schema: world  Last_errno: 0  Killed: 0\n# Query_time: 0.012989  Lock_time: 0.000033  Rows_sent: 4079  Rows_examined: 4079  Rows_affected: 0  Rows_read: 4079\n# Bytes_sent: 161085\n# Stored routine: world.improved_sp_log\nSET timestamp=1420803535;\nSELECT * FROM City;\n# User@Host: root[root] @ localhost []\n# Thread_id: 40  Schema: world  Last_errno: 0  Killed: 0\n# Query_time: 0.001413  Lock_time: 0.000017  Rows_sent: 4318  Rows_examined: 4318  Rows_affected: 0  Rows_read: 4318\n# Bytes_sent: 194601\n# Stored routine: world.improved_sp_log\nSET timestamp=1420803535;\n</code></pre> <p>If variable log_slow_sp_statements is set to <code>FALSE</code>:</p> <ul> <li> <p>Entry is added to a slow-log for a <code>CALL</code> statement only and not for any of the individual statements run in that stored procedure</p> </li> <li> <p>Execution time is reported for the <code>CALL</code> statement as the total execution time of the <code>CALL</code> including all its statements</p> </li> </ul> <p>If we run the same stored procedure with the <code>log_slow_sp_statements</code> is set to <code>FALSE</code> slow query log should look like this:</p> Expected output <pre><code># Time: 150109 11:51:42\n# User@Host: root[root] @ localhost []\n# Thread_id: 40  Schema: world  Last_errno: 0  Killed: 0\n# Query_time: 0.013947  Lock_time: 0.000000  Rows_sent: 4318  Rows_examined: 4318  Rows_affected: 0  Rows_read: 4318\n# Bytes_sent: 194612\nSET timestamp=1420804302;\nCALL improved_sp_log();\n</code></pre> <p>Note</p> <p>Support for logging stored procedures doesn\u2019t involve triggers, so they won\u2019t be logged even if this feature is enabled.</p>"},{"location":"slow-extended.html#log_slow_verbosity","title":"<code>log_slow_verbosity</code>","text":"Option Description Command-line Yes Config file Yes Scope Global, session Dynamic Yes <p>Specifies how much information to include in your slow log. The value is a comma-delimited string, and can contain any combination of the following values: </p> <ul> <li> <p><code>microtime</code>: Log queries with microsecond precision.</p> </li> <li> <p><code>query_plan</code>: Log information about the query\u2019s execution plan.</p> </li> <li> <p><code>innodb</code>: Log InnoDB statistics.</p> </li> <li> <p><code>minimal</code>: Equivalent to enabling just <code>microtime</code>.</p> </li> <li> <p><code>standard</code>: Equivalent to enabling <code>microtime,query_plan</code>.</p> </li> <li> <p><code>full</code>: Equivalent to all other values OR\u2019ed together without the <code>profiling</code> and <code>profiling_use_getrusage</code> options.</p> </li> <li> <p><code>profiling</code>: Enables profiling of all queries in all connections.</p> </li> <li> <p><code>profiling_use_getrusage</code>: Enables usage of the getrusage function.</p> </li> <li> <p><code>query_info</code>: Enables printing <code>Query_tables</code> and <code>Query_digest</code> into the slow query log. These fields are disabled by default.</p> </li> </ul> <p>Values are OR\u2019ed together.</p> <p>For example, to enable microsecond query timing and InnoDB statistics, set this option to <code>microtime,innodb</code> or <code>standard</code>. To turn all options on, set the option to <code>full</code>.</p>"},{"location":"slow-extended.html#slow_query_log_use_global_control","title":"<code>slow_query_log_use_global_control</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Default None <p>Specifies which variables have global scope instead of local. For such variables, the global variable value is used in the current session, but without copying this value to the session value. Value is a \u201cflag\u201d variable - you can specify multiple values separated by commas</p> <ul> <li> <p><code>none</code>: All variables use local scope</p> </li> <li> <p><code>log_slow_filter</code>: Global variable log_slow_filter has effect (instead of local)</p> </li> <li> <p><code>log_slow_rate_limit</code>: Global variable log_slow_rate_limit has effect (instead of local)</p> </li> <li> <p><code>log_slow_verbosity</code>: Global variable log_slow_verbosity has effect (instead of local)</p> </li> <li> <p><code>long_query_time</code>: Global variable long_query_time has effect (instead of local)</p> </li> <li> <p><code>min_examined_row_limit</code>: Global variable <code>min_examined_row_limit</code> has effect (instead of local)</p> </li> <li> <p><code>all</code> Global variables has effect (instead of local)</p> </li> </ul>"},{"location":"slow-extended.html#slow_query_log_always_write_time","title":"<code>slow_query_log_always_write_time</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Default 10 <p>This variable can be used to specify the query execution time after which the query will be written to the slow query log. It can be used to specify an additional execution time threshold for the slow query log, that, when exceeded, will cause a query to be logged unconditionally, that is, log_slow_rate_limit will not apply to it.</p>"},{"location":"slow-extended.html#other-information","title":"Other information","text":""},{"location":"slow-extended.html#changes-to-the-log-format","title":"Changes to the log format","text":"<p>The feature adds more information to the slow log output.</p> Expected output <pre><code># Time: 130601  8:01:06.058915\n# User@Host: root[root] @ localhost []  Id:    42\n# Schema: imdb  Last_errno: 0  Killed: 0\n# Query_time: 7.725616  Lock_time: 0.000328  Rows_sent: 4  Rows_examined: 1543720  Rows_affected: 0\n# Bytes_sent: 272  Tmp_tables: 0  Tmp_disk_tables: 0  Tmp_table_sizes: 0\n# Full_scan: Yes  Full_join: No  Tmp_table: No  Tmp_table_on_disk: No\n# Filesort: No  Filesort_on_disk: No  Merge_passes: 0\nSET timestamp=1370073666;\nSELECT id,title,production_year FROM title WHERE title = 'Bambi';\n</code></pre> <p>Another example (log_slow_verbosity <code>=profiling</code>):</p> Expected output <pre><code># Time: 130601  8:03:20.700441\n# User@Host: root[root] @ localhost []  Id:    43\n# Schema: imdb  Last_errno: 0  Killed: 0\n# Query_time: 7.815071  Lock_time: 0.000261  Rows_sent: 4  Rows_examined: 1543720  Rows_affected: 0\n# Bytes_sent: 272\n# Profile_starting: 0.000125 Profile_starting_cpu: 0.000120\nProfile_checking_permissions: 0.000021 Profile_checking_permissions_cpu: 0.000021\nProfile_Opening_tables: 0.000049 Profile_Opening_tables_cpu: 0.000048 Profile_init: 0.000048\nProfile_init_cpu: 0.000049 Profile_System_lock: 0.000049 Profile_System_lock_cpu: 0.000048\nProfile_optimizing: 0.000024 Profile_optimizing_cpu: 0.000024 Profile_statistics: 0.000036 \nProfile_statistics_cpu: 0.000037 Profile_preparing: 0.000029 Profile_preparing_cpu: 0.000029\nProfile_executing: 0.000012 Profile_executing_cpu: 0.000012 Profile_Sending_data: 7.814583\nProfile_Sending_data_cpu: 7.811634 Profile_end: 0.000013 Profile_end_cpu: 0.000012\nProfile_query_end: 0.000014 Profile_query_end_cpu: 0.000014 Profile_closing_tables: 0.000023\nProfile_closing_tables_cpu: 0.000023 Profile_freeing_items: 0.000051\nProfile_freeing_items_cpu: 0.000050 Profile_logging_slow_query: 0.000006\nProfile_logging_slow_query_cpu: 0.000006\n# Profile_total: 7.815085 Profile_total_cpu: 7.812127\nSET timestamp=1370073800;\nSELECT id,title,production_year FROM title WHERE title = 'Bambi';\n</code></pre> <p>Notice that the <code>Killed: \\</code>` keyword is followed by zero when the query successfully completes. If the query was killed, the ``Killed:` keyword is followed by a number other than zero:</p> Killed Numeric Code Exception 0 NOT_KILLED 1 KILL_BAD_DATA 1053 ER_SERVER_SHUTDOWN (see MySQL Documentation) 1317 ER_QUERY_INTERRUPTED (see MySQL Documentation) 3024 ER_QUERY_TIMEOUT (see MySQL Documentation) Any other number KILLED_NO_VALUE (Catches all other cases)"},{"location":"slow-extended.html#connection-and-schema-identifier","title":"Connection and Schema Identifier","text":"<p>Each slow log entry now contains a connection identifier, so you can trace all the queries coming from a single connection. This is the same value that is shown in the Id column in <code>SHOW FULL PROCESSLIST</code> or returned from the <code>CONNECTION_ID()</code> function.</p> <p>Each entry also contains a schema name, so you can trace all the queries whose default database was set to a particular schema.</p> Expected output <pre><code># Id: 43  Schema: imdb\n</code></pre>"},{"location":"slow-extended.html#microsecond-time-resolution-and-extra-row-information","title":"Microsecond time resolution and extra row information","text":"<p>This is the original functionality offered by the <code>microslow</code> feature. <code>Query_time</code> and <code>Lock_time</code> are logged with microsecond resolution.</p> <p>The feature also adds information about how many rows were examined for <code>SELECT</code> queries, and how many were analyzed and affected for <code>UPDATE</code>, <code>DELETE</code>, and <code>INSERT</code> queries,</p> Expected output <pre><code># Query_time: 0.962742  Lock_time: 0.000202  Rows_sent: 4  Rows_examined: 1543719  Rows_affected: 0\n</code></pre> <p>Values and context:</p> <ul> <li> <p><code>Rows_examined</code>: Number of rows scanned - <code>SELECT</code></p> </li> <li> <p><code>Rows_affected</code>: Number of rows changed - <code>UPDATE</code>, <code>DELETE</code>, <code>INSERT</code></p> </li> </ul>"},{"location":"slow-extended.html#memory-footprint","title":"Memory footprint","text":"<p>The feature provides information about the amount of bytes sent for the result of the query and the number of temporary tables created for its execution - differentiated by whether they were created on memory or on disk - with the total number of bytes used by them.</p> Expected output <pre><code># Bytes_sent: 8053  Tmp_tables: 1  Tmp_disk_tables: 0  Tmp_table_sizes: 950528\n</code></pre> <p>Values and context:</p> <ul> <li> <p><code>Bytes_sent</code>: The amount of bytes sent for the result of the query</p> </li> <li> <p><code>Tmp_tables</code>: Number of temporary tables created on memory for the query</p> </li> <li> <p><code>Tmp_disk_tables</code>: Number of temporary tables created on disk for the query</p> </li> <li> <p><code>Tmp_table_sizes</code>: Total Size in bytes for all temporary tables used in the query</p> </li> </ul>"},{"location":"slow-extended.html#query-plan-information","title":"Query plan information","text":"<p>Each query can be executed in various ways. For example, it may use indexes or do a full table scan, or a temporary table may be needed. These are the things that you can usually see by running <code>EXPLAIN</code> on the query. The feature will now allow you to see the most important facts about the execution in the log file.</p> Expected output <pre><code># Full_scan: Yes  Full_join: No  Tmp_table: No  Tmp_table_on_disk: No\n# Filesort: No  Filesort_on_disk: No  Merge_passes: 0\n</code></pre> <p>The values and their meanings are documented with the log_slow_filter option.</p>"},{"location":"slow-extended.html#innodb-usage-information","title":"InnoDB usage information","text":"<p>The final part of the output is the InnoDB usage statistics. MySQL currently shows many per-session statistics for operations with <code>SHOW SESSION STATUS</code>, but that does not include those of InnoDB, which are always global and shared by all threads. This feature lets you see those values for a given query.</p> Expected output <pre><code>#   InnoDB_IO_r_ops: 6415  InnoDB_IO_r_bytes: 105103360  InnoDB_IO_r_wait: 0.001279\n#   InnoDB_rec_lock_wait: 0.000000  InnoDB_queue_wait: 0.000000\n#   InnoDB_pages_distinct: 6430\n</code></pre> <p>Values:</p> <ul> <li> <p><code>innodb_IO_r_ops</code>: Counts the number of page read operations scheduled. The actual number of read operations may be different, but since this can be done asynchronously, there is no good way to measure it.</p> </li> <li> <p><code>innodb_IO_r_bytes</code>: Similar to innodb_IO_r_ops, but the unit is bytes.</p> </li> <li> <p><code>innodb_IO_r_wait</code>: Shows how long (in seconds) it took InnoDB to actually read the data from storage.</p> </li> <li> <p><code>innodb_rec_lock_wait</code>: Shows how long (in seconds) the query waited for row locks.</p> </li> <li> <p><code>innodb_queue_wait</code>: Shows how long (in seconds) the query spent either waiting to enter the InnoDB queue or inside that queue waiting for execution.</p> </li> <li> <p><code>innodb_pages_distinct</code>: Counts approximately the number of unique pages the query accessed. The approximation is based on a small hash array representing the entire buffer pool, because it could take a lot of memory to map all the pages. The inaccuracy grows with the number of pages accessed by a query, because there is a higher probability of hash collisions.</p> </li> </ul> <p>If the query did not use InnoDB tables, that information is written into the log instead of the above statistics.</p>"},{"location":"slow-extended.html#related-reading","title":"Related reading","text":"<ul> <li> <p>Impact of logging on MySQL\u2019s performance</p> </li> <li> <p>log_slow_filter Usage</p> </li> <li> <p>Added microseconds to the slow query log event time</p> </li> </ul> <p></p>"},{"location":"slow-extended.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"slowlog-rotation.html","title":"Slow query log rotation and expiration","text":"<p>Percona has implemented two new variables, <code>max_slowlog_size</code> and <code>max_slowlog_files</code> to provide users with ability to control the slow query log disk usage. These variables have the same behavior as the max_binlog_size variable and the max_binlog_files variable used for controlling the binary log.</p>"},{"location":"slowlog-rotation.html#max_slowlog_size","title":"<code>max_slowlog_size</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type numeric Default 0 (unlimited) Range 0 - 1073741824 <p>The <code>max_slowlog_size</code> variable controls when the server rotates the slow query log file based on size.</p> <p>By default, the value is set to <code>0</code>, which means the server does not automatically rotate the slow query log file.</p> <p>The block size is <code>4096</code> bytes. If you set a value that is not a multiple of <code>4096</code>, the server rounds it down to the nearest multiple of <code>4096</code>. For example, setting <code>max_slowlog_size</code> to any value less than <code>4096</code> will effectively set the value to <code>0</code>.</p> <p>If you set a limit for this size and enable this feature, the server will rename the slow query log file to <code>slow_query_log_file.000001</code> once it reaches the specified size.</p>"},{"location":"slowlog-rotation.html#max_slowlog_files","title":"<code>max_slowlog_files</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type numeric Default 0 (unlimited) Range 0 - 102400 <p>This variable limits the total amount of slow query log files and is used with max_slowlog_size.</p> <p>The server creates and adds slow query logs until reaching the range\u2019s upper value. When the upper value is reached, the server creates a new slow query log file with a higher sequence number and deletes the log file with the lowest sequence number maintaining the total amount defined in the range.</p> <p></p>"},{"location":"slowlog-rotation.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"source-tarball.html","title":"Install Percona Server for MySQL from a source tarball","text":"<p>Fetch and extract the source tarball. For example:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-innovative-release/Percona-Server-8.4.0-1/binary/tarball/Percona-Server-8.4.0-1-Linux.x86_64.glibc2.35.tar.gz\n</code></pre> <p>Unpack the download to get the packages:</p> <pre><code>$ tar xfz Percona-Server-8.4.0-1-Linux.x86_64.glibc2.35.tar.gz\n</code></pre> <p>To complete the installation, follow the instructions in Compile Percona Server for MySQL from Source.</p> <p></p>"},{"location":"source-tarball.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sql-basics.html","title":"SQL basics","text":"<p>SQL stands for Structured Query Language. It\u2019s a powerful tool used to communicate with databases. Think of a database as a digital filing cabinet where you store and organize information. SQL is like the language you use to talk to that filing cabinet and ask questions or tell it what you want to do with the data inside.</p> <p>With SQL, you can do a variety of tasks:</p> <ul> <li> <p>Retrieve Data: You can ask the database to give you specific information, like all the names of customers who bought a certain product.</p> </li> <li> <p>Insert Data: You can add new information into the database, such as adding a new customer\u2019s details.</p> </li> <li> <p>Update Data: If information changes, like a customer\u2019s address, you can update it in the database.</p> </li> <li> <p>Delete Data: If information is no longer needed, you can remove it from the database.</p> </li> </ul> <p>SQL provides a standardized way to interact with a database. It uses simple commands and statements to perform these tasks, making it easy to learn and use for managing data effectively.</p> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SELECT</li> <li>INSERT</li> <li>DELETE</li> <li>UPDATE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"sql-basics.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sql-conventions.html","title":"SQL conventions","text":"<p>Sure, here\u2019s a description of common SQL style conventions with examples using common MySQL commands:</p>"},{"location":"sql-conventions.html#naming-conventions","title":"Naming Conventions","text":"<p>Naming conventions refer to the rules and guidelines for naming database objects such as tables, columns, indexes, and stored procedures.</p> <ul> <li>Use descriptive names: Choose names that clearly describe the purpose or content of the database object.</li> </ul> <pre><code>mysql&gt; CREATE TABLE users (\nmysql&gt;     user_id INT AUTO_INCREMENT PRIMARY KEY,\nmysql&gt;     username VARCHAR(50),\nmysql&gt;     email VARCHAR(100)\nmysql&gt; );\n</code></pre> <ul> <li>Avoid abbreviations: Prefer full and meaningful words over abbreviations to enhance readability and understanding.</li> </ul> <pre><code>mysql&gt; ALTER TABLE customers\nmysql&gt; ADD COLUMN date_of_birth DATE;\n</code></pre>"},{"location":"sql-conventions.html#indentation-and-formatting","title":"Indentation and Formatting","text":"<p>Indentation and formatting conventions improve the readability and maintainability of SQL code.</p> <ul> <li>Indent SQL statements: Indent SQL statements consistently to show the logical structure of queries and commands.</li> </ul> <pre><code>mysql&gt; SELECT\nmysql&gt;     user_id,\nmysql&gt;     username,\nmysql&gt;     email\nmysql&gt; FROM\nmysql&gt;     users\nmysql&gt; WHERE\nmysql&gt;     user_id = 1;\n</code></pre> <ul> <li>Use consistent casing: Use consistent casing for keywords, identifiers, and SQL functions to improve code consistency.</li> </ul> <pre><code>mysql&gt; SELECT\nmysql&gt;     first_name,\nmysql&gt;     last_name,\nmysql&gt;     CONCAT_WS(' ', first_name, last_name) AS full_name\nmysql&gt; FROM\nmysql&gt;     customers;\n</code></pre>"},{"location":"sql-conventions.html#comments","title":"Comments","text":"<p>Comments are annotations added to SQL code to explain its purpose, logic, or any other relevant information.</p> <ul> <li>Document intent: Use comments to document the intent or purpose of SQL statements and code blocks.</li> </ul> <pre><code>mysql&gt; -- Retrieve all active users\nmysql&gt; SELECT * FROM users WHERE status = 'active';\n</code></pre> <ul> <li>Avoid redundant comments: Avoid adding comments that merely repeat the code without adding meaningful information.</li> </ul> <pre><code>mysql&gt; -- This query retrieves all users\nmysql&gt; SELECT * FROM users;\n</code></pre> <p>These SQL style conventions help maintain consistency, readability, and clarity in SQL code, making it easier to understand, debug, and maintain.</p>"},{"location":"sql-conventions.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"sql-conventions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sql-errors.html","title":"Common SQL errors","text":"<p>Error handling in SQL commands involves managing and responding to errors that may occur during database operations. It ensures that the database remains consistent and provides feedback to users when errors occur.</p>"},{"location":"sql-errors.html#select-statement","title":"SELECT statement","text":"<p>When executing a SELECT statement, errors may occur due to invalid syntax, missing tables, or insufficient permissions.</p> <pre><code>mysql&gt; SELECT * FROM non_existent_table;\nERROR 1146 (42S02): Table 'database_name.non_existent_table' doesn't exist\n</code></pre>"},{"location":"sql-errors.html#insert-statement","title":"INSERT Statement","text":"<p>Errors can occur during INSERT operations if data violates constraints or exceeds column limits.</p> <pre><code>mysql&gt; INSERT INTO table_name (id, name) VALUES (1, 'John');\nERROR 1136 (21S01): Column count doesn't match value count at row 1\n</code></pre>"},{"location":"sql-errors.html#update-statement","title":"UPDATE Statement","text":"<p>UPDATE statements may encounter errors when attempting to modify non-existent rows or violating constraints.</p> <pre><code>mysql&gt; UPDATE table_name SET non_existent_column = 'value';\nERROR 1054 (42S22): Unknown column 'non_existent_column' in 'field list'\n</code></pre>"},{"location":"sql-errors.html#delete-statement","title":"DELETE Statement","text":"<p>Errors in DELETE statements can occur if the WHERE clause condition is invalid or violates constraints.</p> <pre><code>mysql&gt; DELETE FROM table_name WHERE id = 'non_numeric_value';\nERROR 1054 (42S22): Unknown column 'non_numeric_value' in 'where clause'\n</code></pre>"},{"location":"sql-errors.html#ddl-statements-create-alter-drop","title":"DDL Statements (CREATE, ALTER, DROP)","text":"<p>DDL statements may fail due to syntax errors, existing object conflicts, or insufficient privileges.</p> <pre><code>mysql&gt; CREATE TABLE existing_table (id INT PRIMARY KEY);\nERROR 1050 (42S01): Table 'existing_table' already exists\n</code></pre>"},{"location":"sql-errors.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"sql-errors.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sql-operators.html","title":"SQL operators","text":""},{"location":"sql-operators.html#purpose-of-sql-operators","title":"Purpose of SQL Operators","text":"<p>SQL operators are symbols or keywords used to perform operations on data in SQL queries. They allow developers to manipulate and compare data, perform calculations, and filter results based on specified conditions.</p> <p>Advantages and Disadvantages of Using SQL Operators:</p> Trade-Offs Description Advantages - Enables developers to perform various operations on data, such as arithmetic calculations, comparisons, logical operations, and string concatenation. - Provides flexibility in crafting complex queries to extract, transform, and manipulate data according to specific requirements. - Enhances query efficiency by allowing filtering and sorting of data directly within SQL queries, reducing the need for post-processing in application code. Disadvantages - May introduce complexity to queries, especially when multiple operators are combined or when dealing with complex logical conditions. - Requires careful consideration of operator precedence and evaluation order to ensure the desired results are obtained. - Can sometimes result in less readable or maintainable queries, particularly for developers unfamiliar with the SQL syntax or operators being used. <p>Syntax of Using SQL Operators:</p> Option Description Arithmetic Arithmetic operators such as <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, and <code>%</code> are used to perform mathematical calculations on numeric data. Comparison Comparison operators like <code>=</code>, <code>&lt;&gt;</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, and <code>&gt;=</code> are used to compare values and determine their relationship. Logical Logical operators such as <code>AND</code>, <code>OR</code>, and <code>NOT</code> are used to perform logical operations on boolean values or expressions. Concatenation The <code>CONCAT()</code> function or <code>||</code> operator is used to concatenate strings together. Bitwise Bitwise operators like <code>&amp;</code>, <code>|</code>, <code>^</code>, <code>~</code>, <code>&lt;&lt;</code>, and <code>&gt;&gt;</code> are used to perform bitwise operations on binary data. Assignment The <code>=</code> and <code>:=</code> operators are used to assign values to variables or columns. In The <code>IN</code> operator is used to check whether a value matches any value in a list or subquery. Like The <code>LIKE</code> operator is used to compare a value to a pattern using wildcard characters <code>%</code> and <code>_</code>. <p>Example of Using SQL Operators:</p> <ul> <li>Arithmetic Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT 10 * 5; -- Multiplication\n</code></pre> <ul> <li>Comparison Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT * FROM products WHERE price &gt; 100; -- Select products with price greater than 100\n</code></pre> <ul> <li>Logical Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT * FROM customers WHERE age &gt;= 18 AND age &lt;= 30; -- Select customers aged between 18 and 30\n</code></pre> <ul> <li>Concatenation Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT CONCAT(first_name, ' ', last_name) AS full_name FROM employees; -- Concatenate first name and last name\n</code></pre> <ul> <li>Bitwise Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT id, name FROM permissions WHERE permission_flags &amp; 4 = 4; -- Select permissions with specific flag\n</code></pre> <ul> <li>Assignment Operator Example:</li> </ul> <pre><code>mysql&gt; SET @total_sales := 500; -- Assigning a value to a variable\n</code></pre> <ul> <li>In Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT * FROM products WHERE category_id IN (1, 2, 3); -- Select products in specified categories\n</code></pre> <ul> <li>Like Operator Example:</li> </ul> <pre><code>mysql&gt; SELECT * FROM customers WHERE email LIKE '%@example.com'; -- Select customers with email domain example.com\n</code></pre> <p>These examples illustrate how SQL operators are used in Percona Server for MySQL queries to perform various data operations.</p> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SQL Basics</li> <li>SELECT</li> <li>INSERT</li> <li>DELETE</li> <li>UPDATE</li> </ul> <p></p>"},{"location":"sql-operators.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"sql-syntax.html","title":"SQL syntax","text":"<p>SQL (Structured Query Language) is a standardized language used to communicate with databases. Percona Server for MySQL follows SQL syntax, which consists of commands and statements for performing various operations on databases and their objects.</p> <p>The SQL syntax includes commands for data manipulation (e.g., SELECT, INSERT, UPDATE, DELETE), data definition (e.g., CREATE, ALTER, DROP), data control (e.g., GRANT, REVOKE), and transaction control (e.g., COMMIT, ROLLBACK).</p> Syntax type Description Data Manipulation MySQL supports powerful data manipulation features, allowing you to retrieve, insert, update, and delete data Data Definition With MySQL, you can define the structure of your database objects such as tables, indexes, views, and stored procedures Data Control MySQL provides commands for controlling access to database objects and defining user privileges Transaction Management MySQL supports transactions, which allow you to group multiple SQL statements into a single unit of work Stored Procedures MySQL allows you to define stored procedures and functions using SQL syntax Triggers MySQL supports triggers, which are special types of stored procedures that automatically execute in response to specific events Indexes MySQL provides features for optimizing query performance, including the ability to create indexes on columns Views MySQL allows you to create views, which are virtual tables generated from SQL queries Data Types MySQL supports a wide range of data types for storing different types of data <p>These features make MySQL a powerful and versatile database management system, capable of handling a wide range of database tasks efficiently and effectively using SQL syntax.</p> <p>While MySQL SQL syntax may deviate from the standard SQL syntax in some aspects, it generally aims to be compatible with standard SQL to ensure interoperability with other database systems and tools. However, developers should be aware of these differences and consult the MySQL documentation for guidance when writing SQL queries and statements.</p> <p>MySQL SQL syntax largely adheres to the standard SQL syntax, but there are some differences and extensions that set it apart:</p> Syntax Description Data Types MySQL supports additional data types beyond the standard SQL specification, such as <code>ENUM</code>, <code>SET</code>, and <code>BOOLEAN</code>. These data types provide additional flexibility but may not be compatible with other database systems. String Quoting MySQL allows both single quotes (<code>'</code>) and double quotes (<code>\"</code>) for string literals, while standard SQL typically only uses single quotes. Additionally, MySQL supports backticks (<code>`</code>) for quoting identifiers, which is not standard SQL syntax. Case Sensitivity By default, MySQL treats table and column names as case-insensitive, while standard SQL treats them as case-sensitive. However, this behavior can be changed by adjusting the server configuration. LIMIT Clause MySQL uses the <code>LIMIT</code> clause to restrict the number of rows returned by a query, while standard SQL uses the <code>FETCH FIRST</code> or <code>OFFSET</code> clauses for similar functionality. AUTO_INCREMENT MySQL uses the <code>AUTO_INCREMENT</code> attribute to automatically generate unique values for a column, while standard SQL uses <code>IDENTITY</code> or sequences for this purpose. SQL Functions MySQL provides additional built-in functions and extensions beyond the standard SQL functions. For example, MySQL has functions like <code>GROUP_CONCAT()</code> and <code>IFNULL()</code>, which may not be available in other database systems. Storage Engines MySQL supports multiple storage engines, each with its own set of features and capabilities. This option allows users to choose the most suitable storage engine for their specific requirements, but it introduces differences in behavior and syntax."},{"location":"sql-syntax.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"sql-syntax.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"ssl-improvement.html","title":"SSL improvements","text":"<p>Percona Server for MySQL passes Elliptic Curve Cryptography (ECC) ciphers to OpenSSL by default.</p> <p>Note</p> <p>Although documented as supported, elliptic-curve crypto-based ciphers do not work with MySQL.</p> <p></p>"},{"location":"ssl-improvement.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"stacktrace.html","title":"Stacktrace","text":""},{"location":"stacktrace.html#stack-trace","title":"Stack trace","text":"<p>Developers use the stack trace in the debug process, either an interactive investigation or during the post-mortem. No configuration is required to generate a stack trace.</p> <p>Stack trace adds the following:</p> Name Description Prints binary BuildID The Strip utility removes unneeded sections and debugging information to reduce the size. This method is standard with containers where the size of the image is essential. The BuildID lets you resolve the stack trace when the Strip utility removes the binary symbols table. Print the server version information The version information establishes the starting point for analysis. Some applications, such as MySQL, only print this information to a log on startup, and when the crash occurs, the size of the log may be large, rotated, or truncated. <p></p>"},{"location":"stacktrace.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"start-transaction-with-consistent-snapshot.html","title":"Start transaction with consistent snapshot","text":"<p>Percona Server for MySQL has ported MariaDB enhancement for <code>START TRANSACTION WITH CONSISTENT SNAPSHOTS</code> feature to the group commit implementation. This enhancement makes binary log positions consistent with InnoDB transaction snapshots.</p> <p>This feature obtains logical backups with correct positions without running a <code>FLUSH TABLES WITH READ LOCK</code>. Binary log position can be obtained by two newly implemented status variables: Binlog_snapshot_file and Binlog_snapshot_position. After starting a transaction using the <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code>, these two variables provide you with the binlog position that corresponds to the state of the database when the consistent snapshot is created and ignores which other transactions have been committed since the snapshot was created.</p>"},{"location":"start-transaction-with-consistent-snapshot.html#snapshot-cloning","title":"Snapshot cloning","text":"<p>The Percona Server for MySQL implementation extends the <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code> syntax with the optional <code>FROM SESSION</code> clause:</p> <pre><code>START TRANSACTION WITH CONSISTENT SNAPSHOT FROM SESSION &lt;session_id&gt;;\n</code></pre> <p>When specified, all participating storage engines and binary log instead of creating a new snapshot of data (or binary log coordinates), create a copy of the snapshot which has been created by an active transaction in the specified session. <code>session_id</code> is the session identifier reported in the <code>Id</code> column of <code>SHOW PROCESSLIST</code>.</p> <p>Currently snapshot cloning is only supported by XtraDB and the binary log. As with the regular <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code>, snapshot clones can only be created with the <code>REPEATABLE READ</code> isolation level.</p> <p>For XtraDB, a transaction with a cloned snapshot will only see data visible or changed by the donor transaction. That is, the cloned transaction will see no changes committed by transactions that started after the donor transaction, not even changes made by itself. Note that in case of chained cloning the donor transaction is the first one in the chain. For example, if transaction A is cloned into transaction B, which is in turn cloned into transaction C, the latter will have read view from transaction A (i.e., the donor transaction). Therefore, it will see changes made by transaction A, but not by transaction B.</p>"},{"location":"start-transaction-with-consistent-snapshot.html#mysqldump","title":"mysqldump","text":"<p><code>mysqldump</code> has been updated to use new status variables automatically when they are supported by the server and both \u2013single-transaction and \u2013source-data are specified on the command line. Along with the <code>mysqldump</code> improvements introduced in Backup Locks there is now a way to generate <code>mysqldump</code> backups that are guaranteed to be consistent without using <code>FLUSH TABLES WITH READ LOCK</code> even if <code>--source-data</code> is requested.</p>"},{"location":"start-transaction-with-consistent-snapshot.html#system-variables","title":"System variables","text":""},{"location":"start-transaction-with-consistent-snapshot.html#have_snapshot_cloning","title":"<code>have_snapshot_cloning</code>","text":"Option Description Command Line: Yes Config file No Scope: Global Dynamic: No Data type Boolean <p>This server variable is implemented to help other utilities detect if the server supports the <code>FROM SESSION</code> extension. When available, the snapshot cloning feature and the syntax extension to <code>START TRANSACTION WITH CONSISTENT SNAPSHOT</code> are supported by the server, and the variable value is always <code>YES</code>.</p>"},{"location":"start-transaction-with-consistent-snapshot.html#status-variables","title":"Status variables","text":""},{"location":"start-transaction-with-consistent-snapshot.html#binlog_snapshot_file","title":"<code>Binlog_snapshot_file</code>","text":"Option Description Scope: Global Data type String"},{"location":"start-transaction-with-consistent-snapshot.html#binlog_snapshot_position","title":"<code>Binlog_snapshot_position</code>","text":"Option Description Scope: Global Data type Numeric <p>These status variables are only available when the binary log is enabled globally.</p> <p></p>"},{"location":"start-transaction-with-consistent-snapshot.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"stored-procedure-error-handling.html","title":"Error handling in stored procedures","text":"<p>Error handling in stored procedures allows developers to gracefully handle exceptions and errors that may occur during the execution of the procedure. It enables better control over error messages and the ability to perform custom actions in response to errors.</p>"},{"location":"stored-procedure-error-handling.html#advantages-of-using-error-handling","title":"Advantages of Using Error Handling:","text":"Benefits Description Graceful Error handling provides a way to handle exceptions gracefully, preventing unexpected termination of the procedure and providing users with meaningful error messages. Customized Developers can customize error handling to perform specific actions based on the type of error encountered, such as logging errors, rolling back transactions, or retrying operations. Control Error handling gives developers greater control over error propagation and recovery, allowing them to handle errors at different levels of granularity and complexity. Robustness By implementing error handling, developers can make stored procedures more robust and resilient to unexpected conditions, enhancing the overall stability and reliability of the system."},{"location":"stored-procedure-error-handling.html#disadvantages-of-using-error-handling","title":"Disadvantages of Using Error Handling:","text":"Disadvantages Description Complexity Error handling can introduce additional complexity to stored procedures, making them harder to understand, debug, and maintain, especially when dealing with nested error handling. Overhead Implementing error handling may add overhead in terms of code complexity and execution time, particularly for procedures with extensive error-checking logic or frequent error conditions. Performance Error handling may impact performance, especially in scenarios where error-checking logic needs to be executed repeatedly or in tight loops, leading to increased CPU and resource utilization. Dependency Error handling can create dependencies between stored procedures and error-handling routines, making it challenging to modify or refactor procedures without affecting error handling. <p>To add error handling to a stored procedure, developers can use constructs like <code>DECLARE</code>, <code>SIGNAL</code>, <code>RESIGNAL</code>, and <code>HANDLER</code> to declare variables, raise errors, and handle exceptions. Here\u2019s an example of error handling in a stored procedure:</p> <pre><code>mysql&gt; DELIMITER //\nmysql&gt; CREATE PROCEDURE my_procedure()\n    -&gt; BEGIN\n    -&gt;     DECLARE exit handler for sqlexception\n    -&gt;     BEGIN\n    -&gt;         -- Handle SQL exceptions\n    -&gt;         ROLLBACK;\n    -&gt;         SELECT 'An error occurred: ' || SQLSTATE();\n    -&gt;     END;\n    -&gt;\n    -&gt;     -- Procedure logic here\n    -&gt; END //\nmysql&gt; DELIMITER ;\n</code></pre> <p>In this example, the <code>DECLARE</code> statement declares an exit handler for SQL exceptions. Inside the handler block, the procedure rolls back any changes made and returns a custom error message with the SQL state.</p> <pre><code>mysql&gt; CALL my_procedure();\n</code></pre> <p>This command executes the stored procedure and triggers the error handling logic if an exception occurs during execution.</p>"},{"location":"stored-procedure-error-handling.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"stored-procedure-error-handling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"stored-procedure-variables.html","title":"Variables in stored procedures, functions, and triggers","text":"<p>To add a variable in MySQL, you use the <code>DECLARE</code> keyword within the context of a stored program, such as a stored procedure, function, or trigger. The <code>DECLARE</code> keyword is used to define a new variable along with its data type and optionally, its initial value.</p> Value Description variable_name This is the name of the variable you want to declare. Variable names must follow the rules for identifiers in MySQL. data_type This specifies the data type of the variable, such as <code>INT</code>, <code>VARCHAR</code>, <code>DECIMAL</code>, <code>DATE</code>, etc. default_value This is an optional parameter that specifies the default value for the variable. If not provided, the variable will be initialized to <code>NULL</code> by default. <pre><code>DECLARE variable_name data_type [DEFAULT default_value];\n</code></pre> <ul> <li> <p>When you declare a variable using the <code>DECLARE</code> keyword, you are essentially telling MySQL to reserve space in memory to store a value of the specified data type.</p> </li> <li> <p>Variables in MySQL are scoped to the block in which they are declared. This means they can only be used within the block of code (for example, stored procedure, function) in which they are declared.</p> </li> <li> <p>Variables can be used to store and manipulate values within the context of the stored program. They are commonly used for temporary storage of intermediate results, loop counters, or parameters passed to the program.</p> </li> </ul> <pre><code>mysql&gt; DECLARE total_sales DECIMAL(10, 2) DEFAULT 0.0;\n</code></pre> <p>This statement has the following settings:</p> Description Value <code>total_sales</code> is the name of the variable. <code>total_sales</code> <code>DECIMAL(10, 2)</code> specifies that <code>total_sales</code> will hold decimal numbers with a precision of 10 digits and a scale of 2 decimal places. <code>DECIMAL(10, 2)</code> <code>DEFAULT 0.0</code> sets the initial value of <code>total_sales</code> to 0.0. If not provided, the default value would be <code>NULL</code>. <code>DEFAULT 0.0</code>"},{"location":"stored-procedure-variables.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"stored-procedure-variables.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"stored-procedures.html","title":"Stored Procedures","text":"<p>A stored procedure is a set of pre-defined SQL statements stored in the database and executed as a single unit. It allows users to execute complex operations without rewriting the same code multiple times.</p> Benefit Description Code Reusability Stored procedures can be reused multiple times in different parts of an application, reducing code duplication. Improved Performance By executing multiple SQL statements in a single call, stored procedures can reduce network traffic and improve performance. Enhanced Security Users can execute stored procedures without needing direct access to underlying tables, improving security and data integrity. Centralized Logic Business logic is encapsulated within stored procedures, making it easier to manage and maintain. Disadvantage Description Difficulty in Debugging Stored procedures can be challenging to debug, as they are executed on the database server rather than within the application code. Vendor Lock-in Stored procedures are specific to a particular database system, making it difficult to migrate to another database platform. Limited Portability Stored procedures written in one database system may not be compatible with other systems, limiting portability and interoperability."},{"location":"stored-procedures.html#stored-procedure-examples","title":"Stored Procedure examples","text":""},{"location":"stored-procedures.html#create-a-stored-procedure","title":"Create a Stored Procedure","text":"<pre><code>mysql&gt; DELIMITER //\nmysql&gt; CREATE PROCEDURE GetCustomerDetails (IN customerId INT)\n    -&gt; BEGIN\n    -&gt;     SELECT * FROM customers WHERE id = customerId;\n    -&gt; END //\nmysql&gt; DELIMITER ;\n</code></pre>"},{"location":"stored-procedures.html#call-a-stored-procedure","title":"Call a Stored Procedure","text":"<pre><code>mysql&gt; CALL GetCustomerDetails(123);\n</code></pre>"},{"location":"stored-procedures.html#modify-a-stored-procedure","title":"Modify a Stored Procedure","text":"<pre><code>mysql&gt; DELIMITER //\nmysql&gt; ALTER PROCEDURE GetCustomerDetails (IN customerId INT)\n    -&gt; BEGIN\n    -&gt;     SELECT name, email FROM customers WHERE id = customerId;\n    -&gt; END //\nmysql&gt; DELIMITER ;\n</code></pre>"},{"location":"stored-procedures.html#drop-a-stored-procedure","title":"Drop a Stored Procedure","text":"<pre><code>mysql&gt; DROP PROCEDURE IF EXISTS GetCustomerDetails;\n</code></pre>"},{"location":"stored-procedures.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"stored-procedures.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"table.html","title":"Introduction to database tables","text":"<p>A database table is a collection of data organized into rows and columns. Each table consists of records (rows) and fields (columns). Tables help organize and manage data efficiently.</p>"},{"location":"table.html#advantages","title":"Advantages","text":"Advantages Description Organized Data Tables allow you to organize data into rows and columns, making it easy to understand and manage. Efficient Queries You can use SQL queries to quickly search, filter, and retrieve data from tables. Data Integrity Tables support constraints like primary keys and foreign keys, ensuring data integrity and consistency. Scalability You can add or modify tables as your data grows, making it easy to scale your database. Relational Management Tables allow you to create relationships between different sets of data, making it easier to manage complex datasets."},{"location":"table.html#disadvantages","title":"Disadvantages","text":"Disadvantages Description Complexity Designing and maintaining tables, especially with relationships, can become complex and time-consuming. Performance Issues Large tables with many rows can lead to performance issues, requiring optimization and indexing. Storage Overhead Tables with many columns or large data types can consume significant storage space. Maintenance Regular maintenance tasks, such as backups and indexing, are necessary to ensure optimal performance and data integrity. Learning Curve Beginners may find it challenging to learn SQL and understand how to design and manage tables effectively."},{"location":"table.html#permissions-required","title":"Permissions required","text":"<p>To create a table in a database, you need appropriate permissions granted to your database user account. These permissions are typically managed by the database administrator (DBA) or system administrator. Database permissions control what actions a user can perform on a database. In the context of creating a table, the user needs specific permissions related to database management.</p> Permission Description CREATE TABLE The most fundamental permission required to create a table is the CREATE TABLE permission. This permission allows the user to create new tables within the database. CREATE In addition to CREATE TABLE, the user might also need the more general CREATE permission. This permission grants the ability to create other database objects besides tables, such as indexes, views, or stored procedures. ALTER Depending on the database configuration, the user might also need the ALTER permission. This permission allows the user to modify the structure of existing tables, such as adding or removing columns."},{"location":"table.html#create-a-table","title":"Create a table","text":"<p>To create a table, use the <code>CREATE TABLE</code> command. Follow it with the table name and define the columns and their data types. For example, to create a table named <code>customers</code> with columns for <code>id</code>, <code>name</code>, and <code>email</code>, use this command:</p> <pre><code>CREATE TABLE customers (\n    id INT AUTO_INCREMENT PRIMARY KEY,\n    name VARCHAR(100),\n    email VARCHAR(100)\n);\n</code></pre>"},{"location":"table.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Create table</li> <li>Isolation Levels</li> <li>Transaction Management</li> <li>Views</li> </ul>"},{"location":"table.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"telemetry.html","title":"Telemetry on Percona Server for MySQL","text":"<p>Percona telemetry fills in the gaps in our understanding of how you use Percona Server for MySQL to improve our products. Participation in the anonymous program is optional. You can opt-out if you prefer to not share this information.</p>"},{"location":"telemetry.html#what-information-is-collected","title":"What information is collected","text":"<p>At this time, telemetry is added only to the Percona packages and Docker images. Percona Server for MySQL collects only information about the installation environment. Future releases may add additional metrics.</p> <p>Be assured that access to this raw data is rigorously controlled. Percona does not collect personal data. All data is anonymous and cannot be traced to a specific user. To learn more about our privacy practices, read our Percona Privacy statement.</p> <p>An example of the data collected is the following:</p> <pre><code>[{\"id\" : \"c416c3ee-48cd-471c-9733-37c2886f8231\",\n\"product_family\" : \"PRODUCT_FAMILY_PS\",\n\"instanceId\" : \"6aef422e-56a7-4530-af9d-94cc02198343\",\n\"createTime\" : \"2023-10-16T10:46:23Z\",\n\"metrics\":\n[{\"key\" : \"deployment\",\"value\" : \"PACKAGE\"},\n{\"key\" : \"pillar_version\",\"value\" : \"8.1.0-1\"},\n{\"key\" : \"OS\",\"value\" : \"Oracle Linux Server 8.8\"},\n{\"key\" : \"hardware_arch\",\"value\" : \"x86_64 x86_64\"}]}]\n</code></pre>"},{"location":"telemetry.html#disable-telemetry","title":"Disable telemetry","text":"<p>Telemetry is enabled by default. If you decide not to send usage data to Percona, you can set the <code>PERCONA_TELEMETRY_DISABLE=1</code> environment variable for either the root user or in the operating system prior to the installation process.</p> Debian-derived distributionRed Hat-derived distributionDOCKER <p>Add the environment variable before the install process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 apt install percona-server-server\n</code></pre> <p>Add the environment variable before the install process.</p> <pre><code>$ sudo PERCONA_TELEMETRY_DISABLE=1 yum install percona-server-server\n</code></pre> <p>Add the environment variable when running a command in a new container.</p> <pre><code>$ docker run -d -e MYSQL_ROOT_PASSWORD=test1234# -e PERCONA_TELEMETRY_DISABLE=1 -e --name=percona-server percona/percona-server:8.1\n</code></pre> <p></p>"},{"location":"telemetry.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"thread-based-profiling.html","title":"Thread based profiling","text":"<p>Percona Server for MySQL now uses thread based profiling by default, instead of process based profiling. This was implemented because with process based profiling, threads on the server, other than the one being profiled, can affect the profiling information.</p> <p>Thread based profiling is using the information provided by the kernel getrusage function. Since the 2.6.26 kernel version, thread based resource usage is available with the RUSAGE_THREAD. This means that the thread based profiling will be used if you\u2019re running the 2.6.26 kernel or newer, or if the RUSAGE_THREAD has been ported back.</p> <p>This feature is enabled by default if your system supports it, in other cases it uses process based profiling.</p> <p></p>"},{"location":"thread-based-profiling.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"threadpool.html","title":"Thread pool","text":"<p>MySQL executes statements using one thread per client connection. Once the number of connections increases past a certain point performance will degrade.</p> <p>This feature enables the server to keep the top performance even with a large number of client connections by introducing a dynamic thread pool. By using the thread pool server would decrease the number of threads, which will then reduce the context switching and hot locks contentions. Using the thread pool will have the most effect with <code>OLTP</code> workloads (relatively short CPU-bound queries).</p> <p>In order to enable the thread pool variable <code>thread_handling</code> should be set up to <code>pool-of-threads</code> value. This can be done by adding:</p> <pre><code>thread_handling=pool-of-threads\n</code></pre> <p>Although the default values for the thread pool should provide good performance, additional tuning can be performed with the dynamic system variables.</p> <p>Note</p> <p>Current implementation of the thread pool is built in the server, unlike the upstream version which is implemented as a plugin. Another significant implementation difference is that this implementation doesn\u2019t try to minimize the number of concurrent transactions like the <code>MySQL Enterprise Threadpool</code>. Because of these differences, this implementation is not compatible with the upstream version.</p>"},{"location":"threadpool.html#priority-connection-scheduling","title":"Priority connection scheduling","text":"<p>Even though thread pool puts a limit on the number of concurrently running queries, the number of open transactions may remain high, because connections with already started transactions are put to the end of the queue. Higher number of open transactions has a number of implications on the currently running queries. To improve the performance new thread_pool_high_prio_tickets variable has been introduced.</p> <p>This variable controls the high priority queue policy. Each new connection is assigned this many tickets to enter the high priority queue. Whenever a query has to be queued to be executed later because no threads are available, the thread pool puts the connection into the high priority queue if the following conditions apply:</p> <ul> <li> <p>The connection has an open transaction in the server.</p> </li> <li> <p>The number of high priority tickets of this connection is non-zero.</p> </li> </ul> <p>If both the above conditions hold, the connection is put into the high priority queue and its tickets value is decremented. Otherwise the connection is put into the common queue with the initial tickets value specified with this option.</p> <p>Each time the thread pool looks for a new connection to process, first it checks the high priority queue, and picks connections from the common queue only when the high priority one is empty.</p> <p>The goal is to minimize the number of open transactions in the server. In many cases it is beneficial to give short-running transactions a chance to commit faster and thus deallocate server resources and locks without waiting in the same queue with other connections that are about to start a new transaction, or those that have run out of their high priority tickets.</p> <p>The default thread pool behavior is to always put events from already started transactions into the high priority queue, as we believe that results in better performance in vast majority of cases.</p> <p>With the value of <code>0</code>, all connections are always put into the common queue, i.e. no priority scheduling is used as in the original implementation in MariaDB. The higher is the value, the more chances each transaction gets to enter the high priority queue and commit before it is put in the common queue.</p> <p>In some cases it is required to prioritize all statements for a specific connection regardless of whether they are executed as a part of a multi-statement transaction or in the autocommit mode. Or vice versa, some connections may require using the low priority queue for all statements unconditionally. To implement this new thread_pool_high_prio_mode variable has been introduced in Percona Server for MySQL.</p>"},{"location":"threadpool.html#low-priority-queue-throttling","title":"Low priority queue throttling","text":"<p>One case that can limit thread pool performance and even lead to deadlocks under high concurrency is a situation when thread groups are oversubscribed due to active threads reaching the oversubscribe limit, but all/most worker threads are actually waiting on locks currently held by a transaction from another connection that is not currently in the thread pool.</p> <p>What happens in this case is that those threads in the pool that have marked themselves inactive are not accounted to the oversubscribe limit. As a result, the number of threads (both active and waiting) in the pool grows until it hits thread_pool_max_threads value. If the connection executing the transaction which is holding the lock has managed to enter the thread pool by then, we get a large (depending on the thread_pool_max_threads value) number of concurrently running threads, and thus, suboptimal performance as a result. Otherwise, we get a deadlock as no more threads can be created to process those transaction(s) and release the lock(s).</p> <p>Such situations are prevented by throttling the low priority queue when the total number of worker threads (both active and waiting ones) reaches the oversubscribe limit. That is, if there are too many worker threads, do not start new transactions and create new threads until queued events from the already started transactions are processed.</p>"},{"location":"threadpool.html#handling-of-long-network-waits","title":"Handling of long network waits","text":"<p>Certain types of workloads (large result sets, BLOBs, slow clients) can have longer waits on network I/O (socket reads and writes). Whenever server waits, this should be communicated to the Thread Pool, so it can start new query by either waking a waiting thread or sometimes creating a new one. This implementation has been ported from MariaDB patch MDEV-156.</p>"},{"location":"threadpool.html#system-variables","title":"System variables","text":""},{"location":"threadpool.html#thread_pool_idle_timeout","title":"<code>thread_pool_idle_timeout</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: Numeric Default value: 60 (seconds) <p>This variable can be used to limit the time an idle thread should wait before exiting.</p>"},{"location":"threadpool.html#thread_pool_high_prio_mode","title":"<code>thread_pool_high_prio_mode</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global, Session Dynamic: Yes Data type: String Default value: <code>transactions</code> Allowed values: <code>transactions</code>, <code>statements</code>, <code>none</code> <p>This variable is used to provide more fine-grained control over high priority scheduling either globally or per connection.</p> <p>The following values are allowed:</p> <ul> <li> <p><code>transactions</code> (the default). In this mode only statements from already started transactions may go into the high priority queue depending on the number of high priority tickets currently available in a connection (see thread_pool_high_prio_tickets).</p> </li> <li> <p><code>statements</code>. In this mode all individual statements go into the high priority queue, regardless of connection\u2019s transactional state and the number of available high priority tickets. This value can be used to prioritize <code>AUTOCOMMIT</code> transactions or other kinds of statements such as administrative ones for specific connections. Note that setting this value globally essentially disables high priority scheduling, since in this case all statements from all connections will use a single queue (the high priority one)</p> </li> <li> <p><code>none</code>. This mode disables high priority queue for a connection. Some connections (e.g. monitoring) may be insensitive to execution latency and/or never allocate any server resources that would otherwise impact performance in other connections and thus, do not really require high priority scheduling. Note that setting thread_pool_high_prio_mode to <code>none</code> globally has essentially the same effect as setting it to <code>statements</code> globally: all connections will always use a single queue (the low priority one in this case).</p> </li> </ul>"},{"location":"threadpool.html#thread_pool_high_prio_tickets","title":"<code>thread_pool_high_prio_tickets</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global, Session Dynamic: Yes Data type: Numeric Default value: 4294967295 <p>This variable controls the high priority queue policy. Each new connection is assigned this many tickets to enter the high priority queue. Setting this variable to <code>0</code> will disable the high priority queue.</p>"},{"location":"threadpool.html#thread_pool_max_threads","title":"<code>thread_pool_max_threads</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: Numeric Default value: 100000 <p>This variable can be used to limit the maximum number of threads in the pool. Once this number is reached no new threads will be created.</p>"},{"location":"threadpool.html#thread_pool_oversubscribe","title":"<code>thread_pool_oversubscribe</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: Numeric Default value: 3 <p>The higher the value of this parameter the more threads can be run at the same time, if the values is lower than <code>3</code> it could lead to more sleeps and wake-ups.</p>"},{"location":"threadpool.html#thread_pool_size","title":"<code>thread_pool_size</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: Numeric Default value: Number of processors <p>This variable can be used to define the number of threads that can use the CPU at the same time.</p>"},{"location":"threadpool.html#thread_pool_stall_limit","title":"<code>thread_pool_stall_limit</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: No Data type: Numeric Default value: 500 (ms) <p>The number of milliseconds before a running thread is considered stalled. When this limit is reached thread pool will wake up or create another thread. This is being used to prevent a long-running query from monopolizing the pool.</p>"},{"location":"threadpool.html#status-variables","title":"Status variables","text":""},{"location":"threadpool.html#threadpool_idle_threads","title":"<code>Threadpool_idle_threads</code>","text":"Option Description Scope: Global Data type: Numeric <p>This status variable shows the number of idle threads in the pool.</p>"},{"location":"threadpool.html#threadpool_threads","title":"<code>Threadpool_threads</code>","text":"Option Description Scope: Global Data type: Numeric <p>This status variable shows the number of threads in the pool.</p>"},{"location":"threadpool.html#other-reading","title":"Other reading","text":"<ul> <li> <p>Thread pool in MariaDB 5.5</p> </li> <li> <p>Thread pool implementation in Oracle MySQL</p> </li> </ul> <p></p>"},{"location":"threadpool.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"trademark-policy.html","title":"Trademark policy","text":"<p>This Trademark Policy is to ensure that users of Percona-branded products or services know that what they receive has really been developed, approved, tested, and maintained by Percona. Trademarks help to prevent confusion in the marketplace, by distinguishing one company\u2019s or person\u2019s products and services from another\u2019s.</p> <p>Percona owns a number of marks, including but not limited to Percona, XtraDB, Percona XtraDB, XtraBackup, Percona XtraBackup, Percona Server for MySQL, and Percona Live, plus the distinctive visual icons and logos associated with these marks. Both the unregistered and registered marks of Percona are protected.</p> <p>Use of any Percona trademark in the name, URL, or another identifying characteristic of any product, service, website, or other use is not permitted without Percona\u2019s written permission with the following three limited exceptions.</p> <p>First, you may use the appropriate Percona mark when making a nominative fair use reference to a bona fide Percona product.</p> <p>Second, when Percona has released a product under a version of the GNU General Public License (\u201cGPL\u201d), you may use the appropriate Percona mark when distributing a verbatim copy of that product in accordance with the terms and conditions of the GPL.</p> <p>Third, you may use the appropriate Percona mark to refer to a distribution of GPL-released  Percona software that has been modified with minor changes for the sole purpose of allowing the software to operate on an operating system or hardware platform for which Percona has not yet released the software, provided that those third party changes do not affect the behavior, functionality, features, design or performance of the software. Users who acquire this Percona-branded software receive substantially exact implementations of the Percona software.</p> <p>Percona reserves the right to revoke this authorization at any time in its sole discretion.  For example, if Percona believes that your modification is beyond the scope of the limited license granted in this Policy or that your use of the Percona mark is detrimental to Percona, Percona will revoke this authorization.  Upon revocation, you must immediately cease using the applicable Percona mark.  If you do not immediately cease using the Percona mark upon revocation, Percona may take action to protect its rights and interests in the Percona mark.  Percona does not grant any license to use any Percona mark for any other modified versions of Percona software; such use will require our prior written permission.</p> <p>Neither trademark law nor any of the exceptions set forth in this Trademark Policy permit you to truncate, modify, or otherwise use any Percona mark as part of your own brand.  For example, if XYZ creates a modified version of the Percona Server for MySQL, XYZ may not brand that modification as \u201cXYZ Percona Server\u201d or \u201cPercona XYZ Server\u201d, even if that modification otherwise complies with the third exception noted above.</p> <p>In all cases, you must comply with applicable law, the underlying license, and this Trademark Policy, as amended from time to time.  For instance, any mention of Percona trademarks should include the full trademarked name, with proper spelling and capitalization, along with attribution of ownership to Percona Inc.  For example, the full proper name for XtraBackup is Percona XtraBackup. However, it is acceptable to omit the word \u201cPercona\u201d for brevity on the second and subsequent uses, where such omission does not cause confusion.</p> <p>In the event of doubt as to any of the conditions or exceptions outlined in this Trademark Policy, please contact trademarks@percona.com for assistance and we will do our very best to be helpful.</p> <p></p>"},{"location":"trademark-policy.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"transaction-mgmt.html","title":"Transaction management","text":"<p>A database transaction is a unit of work performed within a database management system (DBMS) that must be executed atomically and consistently. A transaction represents a series of operations (such as queries, inserts, updates, or deletes) that are treated as a single, indivisible unit. Transactions ensure data integrity by guaranteeing that all of the transaction\u2019s operations are completed successfully and permanently saved to the database (committed) or none of them are applied (rolled back).</p> <p>Percona Server for MySQL provides features for managing transactions to ensure the consistency and reliability of data.Transactions in Percona Server for MySQL are typically managed using the following commands and techniques:</p> <ul> <li> <p>START TRANSACTION: This command begins a new transaction. Once started, all subsequent SQL statements will be part of the transaction until it is either committed or rolled back.</p> </li> <li> <p>COMMIT: The COMMIT command is used to save the changes made during the transaction to the database permanently. Once committed, the changes become visible to other transactions.</p> </li> <li> <p>ROLLBACK: The ROLLBACK command is used to undo the changes made during the transaction and restore the database to its state before the transaction begins. It cancels any modifications made within the transaction.</p> </li> <li> <p>SAVEPOINT: SAVEPOINTs are markers within a transaction that allow you to set points to which you can later roll back. They provide a way to partially undo changes within a transaction without rolling back the entire transaction.</p> </li> </ul> <p>Transactions in Percona Server for MySQL are ACID-compliant, meaning they adhere to the principles of Atomicity, Consistency, Isolation, and Durability:</p> Type Description Atomicity Transactions are atomic, meaning that all the operations within a transaction are treated as a single unit of work. Either all operations are completed successfully, or none of them are applied. Consistency Transactions ensure that the database remains in a consistent state before and after the transaction. Constraints, triggers, and other rules are enforced to maintain data integrity. Isolation Transactions are isolated from each other, meaning that the changes made within one transaction are not visible to other transactions until the transaction is committed. Durability Once a transaction is committed, the changes made to the database are permanent and cannot be lost, even in the event of system failure. <p>Percona Server for MySQL supports different transaction isolation levels, such as READ UNCOMMITTED, READ COMMITTED, REPEATABLE READ, and SERIALIZABLE, which control how transactions interact with each other and with the data in the database.</p>"},{"location":"transaction-mgmt.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Modify Tables</li> <li>Isolation Levels</li> <li>Views</li> </ul>"},{"location":"transaction-mgmt.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"trigger-updates.html","title":"Trigger updates","text":"<p>In MySQL, the system efficiently handles multiple client queries to the same table by opening separate table instances for each query. This prevents delays and conflicts. The use of a \u201cTable Cache\u201d speeds up access by reducing the need to repeatedly open and close tables, improving overall performance.</p> <p>The table_open_cache system variable controls the number of tables MySQL can keep open simultaneously across all threads. By increasing this setting, MySQL can handle more open files, although this requires more file descriptors. Despite a soft limit, MySQL can temporarily exceed it if queries demand more open tables. Upon query completion, MySQL automatically manages the cache by closing the least recently used tables.</p> <p>The table_open_cache_instances system variable controls the number of open table cache instances in MySQL. By splitting the open tables cache into smaller segments (table_open_cache divided by table_open_cache_instances), sessions can access only one instance at a time for DML operations, reducing contention and improving performance when many sessions are running. For systems with 16 or more CPU cores, a value of 8 or 16 is recommended. However, if many large triggers are causing high memory usage, setting this variable to 1 can help limit memory consumption.</p> <p>When a table with triggers is opened in the Table Cache, it also reads the trigger definitions and links the open table instance to its specific trigger instances. When a connection executes a Data Manipulation Language (DML) statement that activates a trigger, that connection uses its own instance of the trigger body for that particular table instance. This method of caching both the open table instances and their associated trigger bodies can unexpectedly use a significant amount of memory.</p> <p>Percona Server for MySQL has the following abilities:</p> <ul> <li> <p>Avoid using table instances with fully-loaded and parsed triggers by read-only queries</p> </li> <li> <p>Show trigger CREATE statements even if the statement is unparseable</p> </li> </ul> <p>The additional system variable reduces the Table Cache memory consumption on the server when tables that contain trigger definitions also are part of a significant read-only workload.</p>"},{"location":"trigger-updates.html#system-variables","title":"System variables","text":""},{"location":"trigger-updates.html#table_open_cache_triggers","title":"table_open_cache_triggers","text":"Option Description Command-line <code>--table-open-cache-triggers</code> Dynamic Yes Scope Global Data type Integer Default 524288 Minimum value 1 Maximum value 524288 <p>This variable sets a soft limit on the maximum number of open tables in the Table Cache, which holds fully loaded triggers. By default, this value is set to the maximum to prevent any changes in behavior for existing users. If the number of open table instances with fully loaded triggers exceeds this limit, the system removes the least recently used unused table instances. You can set this value as a start-up option or change it dynamically while the system runs.</p>"},{"location":"trigger-updates.html#status-variables","title":"Status variables","text":"<p>The following status variables are available:</p> Variable name Description <code>table_open_cache_triggers_hits</code> A hit means the statement required an open table instance with fully-loaded triggers and was able to get one from the <code>table_open_cache</code>. <code>table_open_cache_triggers_misses</code> A miss means the statement requiring an open table instance with fully-loaded triggers was not found one in the <code>table_open_cache</code>. The statement may find a table instance without fully-loaded triggers and finalized their loading for it. <code>table_open_cache_triggers_overflows</code> An overflow indicates the number of unused table instances with triggers that were expelled from the <code>table_open_cache</code> due to the <code>table_open_cache_triggers</code> soft limit. This variable may demonstrate that the <code>table_open_cache_triggers</code> value should be increased."},{"location":"trigger-updates.html#show-create-trigger-statment-changes","title":"SHOW CREATE TRIGGER statment changes","text":"<p>The <code>SHOW CREATE TRIGGER</code> statement displays the SQL command that created a trigger, including definitions that may no longer be understandable. For example, if a trigger was created before a server upgrade that changed the trigger syntax, this statement will still show its definition.</p>"},{"location":"trigger-updates.html#additional-resources","title":"Additional resources","text":"<p>For more information, see How MySQL opens and closes tables.</p> <p></p>"},{"location":"trigger-updates.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"triggers.html","title":"Triggers","text":""},{"location":"triggers.html#using-triggers","title":"Using triggers","text":"<p>A trigger is a database object that automatically performs a specified action in response to certain events on a table or view. It allows users to enforce business rules, maintain data integrity, and automate tasks within the database.</p>"},{"location":"triggers.html#advantages-of-using-triggers","title":"Advantages of Using Triggers","text":"Benefits Description Data Integrity Triggers can enforce data integrity constraints by automatically validating or modifying data before it is inserted, updated, or deleted in a table. Audit Trails Triggers can be used to create audit trails by recording changes made to the database, including who made the changes and when they occurred. Simplified Triggers simplify application logic by moving complex business rules and validation checks into the database, reducing the amount of code needed in the application layer. Automated Triggers automate repetitive tasks, such as updating denormalized data or sending notifications, by executing predefined actions in response to specified events."},{"location":"triggers.html#disadvantages-of-using-triggers","title":"Disadvantages of Using Triggers","text":"Disadvantages Description Complexity Triggers can add complexity to the database schema and make it harder to understand and maintain, especially when dealing with multiple triggers and complex logic. Performance Triggers may impact database performance, particularly if they involve complex operations or are triggered frequently, leading to increased overhead and slower response times. Debugging Triggers can be difficult to debug and troubleshoot, as they are executed automatically in response to events and may not provide detailed error messages or logging information. Dependency Triggers create dependencies between database objects, making it challenging to modify or refactor the database schema without considering the impact on existing triggers."},{"location":"triggers.html#create-a-before_insert-trigger","title":"Create a before_insert trigger","text":"<pre><code>mysql&gt; CREATE TRIGGER before_insert_customer\n    -&gt; BEFORE INSERT ON customers\n    -&gt; FOR EACH ROW\n    -&gt; BEGIN\n    -&gt;     SET NEW.created_at = NOW();\n    -&gt; END;\n</code></pre>"},{"location":"triggers.html#create-an-after_update-trigger","title":"Create an after_update trigger","text":"<pre><code>mysql&gt; CREATE TRIGGER after_update_inventory\n    -&gt; AFTER UPDATE ON inventory\n    -&gt; FOR EACH ROW\n    -&gt; BEGIN\n    -&gt;     INSERT INTO inventory_changes (product_id, old_quantity, new_quantity, change_date)\n    -&gt;     VALUES (OLD.product_id, OLD.quantity, NEW.quantity, NOW());\n    -&gt; END;\n</code></pre>"},{"location":"triggers.html#drop-a-before_insert-trigger","title":"Drop a before_insert trigger","text":"<pre><code>mysql&gt; DROP TRIGGER IF EXISTS before_insert_customer;\n</code></pre>"},{"location":"triggers.html#drop-an-after_update-trigger","title":"Drop an after_update trigger","text":"<pre><code>mysql&gt; DROP TRIGGER IF EXISTS after_update_inventory;\n</code></pre>"},{"location":"triggers.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Troubleshooting SQL</li> </ul>"},{"location":"triggers.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot-apparmor.html","title":"Troubleshoot AppArmor profiles","text":"<p>Troubleshooting AppArmor profiles ensure that applications can access necessary resources without compromising system security. </p>"},{"location":"troubleshoot-apparmor.html#profile-modes","title":"Profile Modes","text":"<p>AppArmor profiles operate in different modes:</p> Mode Description Enforce Applications are restricted by profile rules, and any violation results in denial of access. Complain Applications are allowed to take restricted actions, but these actions are logged. Disabled Profile restrictions are turned off, allowing applications to take any action without logging."},{"location":"troubleshoot-apparmor.html#check-status","title":"Check status","text":"<p>Use commands like <code>aa-status</code> to check the current status of AppArmor profiles. This check helps identify if profiles are enforcing or complaining about actions.</p>"},{"location":"troubleshoot-apparmor.html#switch-modes","title":"Switch modes","text":"<p>You may need to switch profiles between <code>enforce</code> and <code>complain</code> modes when troubleshooting. Use <code>aa-enforce</code> to switch to enforce mode and <code>aa-complain</code> to switch to complain mode.</p>"},{"location":"troubleshoot-apparmor.html#disable-profiles","title":"Disable profiles","text":"<p>If necessary, profiles can be temporarily disabled. However, this is not recommended for security reasons. Use commands like <code>ln -s</code> or <code>aa-disable</code> to disable profiles.</p>"},{"location":"troubleshoot-apparmor.html#reload-profiles","title":"Reload profiles","text":"<p>After making changes to profiles or switching modes, reloading profiles for changes to take effect is essential. Use commands like <code>service apparmor reload</code> or <code>apparmor_parser -r</code> to reload profiles.</p>"},{"location":"troubleshoot-apparmor.html#check-log-entries","title":"Check Log Entries","text":"<p>Monitor log entries for DENIED or ALLOWED actions. DENIED entries indicate that a profile is blocking an action, while ALLOWED entries suggest that an action is permitted.</p>"},{"location":"troubleshoot-apparmor.html#edit-profiles","title":"Edit Profiles","text":"<p>You may need to edit AppArmor profiles to troubleshoot access issues and allow specific actions. Edit the profile files in the <code>/etc/apparmor.d/</code> directory to adjust access permissions.</p>"},{"location":"troubleshoot-apparmor.html#apparmor-links","title":"AppArmor links","text":"<p>AppArmor AppArmor Profiles Manage AppArmor Profiles Disable AppArmor Configure AppArmor</p> <p></p>"},{"location":"troubleshoot-apparmor.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshoot-selinux.html","title":"Troubleshoot SELinux issues","text":""},{"location":"troubleshoot-selinux.html#relabel-the-entire-file-system","title":"Relabel the Entire File System","text":"<p>Relabeling the entire file system is updating SELinux contexts for all files and directories. This operation ensures that SELinux can enforce its policies correctly.</p> <p>When relabeling the entire file system for SELinux, you should use <code>fixfiles</code> when you want to initiate the relabeling process manually. This command is useful when you need to perform the relabeling operation immediately or if you want to specify additional options, such as forcing the operation with the <code>-f</code> flag.</p> <p>On the other hand, <code>.autorelabel</code> is used when you want the relabeling process to occur automatically during system boot. This method is convenient when scheduling the relabeling task without manual intervention. The <code>.autorelabel</code> in the root directory triggers the relabeling process during the boot sequence, ensuring that all files and directories are relabeled according to the SELinux policy.</p>"},{"location":"troubleshoot-selinux.html#manually-relabeling","title":"Manually relabeling","text":"<p>This command relabels the entire file system without requiring a system reboot.</p> <p><pre><code>$ fixfiles -f relabel\n</code></pre> The command <code>fixfiles -f relabel</code> is a directive used within the context of SELinux, a security feature in Linux systems. This specific command instructs the system to forcefully reapply SELinux labels, also known as contexts, to files and directories.</p> <p>Here\u2019s a breakdown of what each part of the command does:</p> Option Description fixfiles This is the name of the command being executed. It\u2019s a tool provided by SELinux specifically designed to fix file contexts. -f This is an option passed to the <code>fixfiles</code> command. In this context, the <code>-f</code> option stands for \u201cforce\u201d. It tells the <code>fixfiles</code> command to perform the relabeling operation forcefully, regardless of the current state or any potential errors. relabel This is an argument passed to the <code>fixfiles</code> command. It specifies the action that <code>fixfiles</code> should take: relabel the files and directories on the system. <p>When you run <code>fixfiles -f relabel</code>, SELinux goes through all files and directories on the system and applies the appropriate SELinux labels to each one. These labels are crucial for SELinux to enforce its security policies effectively. They determine how processes and users can interact with the files and directories, ensuring that only authorized actions are allowed.</p> <p>This command is typically used in scenarios where there may have been changes to the file system that require SELinux labels to be updated. For example, if files or directories have been moved or copied from one location to another or if SELinux policies have been modified, running <code>fixfiles -f relabel</code> ensures that the SELinux labels remain consistent with the system\u2019s current configuration.</p> <p>It\u2019s important to note that running <code>fixfiles -f relabel</code> can be a resource-intensive operation and may take some time to complete, especially on systems with many files and directories. Additionally, since it forcefully relabels all files and directories, use it cautiously and preferably during maintenance windows to minimize potential disruptions to system operations.</p>"},{"location":"troubleshoot-selinux.html#automatic-relabeling","title":"Automatic relabeling","text":"<p>Creating the <code>.autorelabel</code> file initiates a relabeling process that often requires a reboot to apply the changes effectively. During this reboot, SELinux relabels all files based on their defined policies.</p> <pre><code>$ touch /.autorelabel\n</code></pre> <p>This command creates a file named <code>.autorelabel</code> in the root directory of the Linux filesystem. The \u201ctouch\u201d command creates a new file.</p> <p>The purpose of the <code>.autorelabel</code> file is to trigger an automatic relabeling of the entire filesystem when the system boots up. Relabeling involves assigning security labels to files and directories based on SELinux policies. This process ensures that all files and directories have the correct security context, which is essential for SELinux to enforce its security policies effectively.</p> <p>Creating this file tells the system to perform a relabeling operation during the next boot. This operation can be useful in situations where SELinux policies or file contexts have been modified, and we want to ensure that all files are correctly labeled according to the updated policies.</p> <p>It\u2019s important to note that the <code>.autorelabel</code> file contains no data or configuration. The file acts as a trigger for the relabeling process. Once the relabeling is complete, the system automatically removes the <code>.autorelabel</code> file.</p>"},{"location":"troubleshoot-selinux.html#set-custom-data-directory","title":"Set Custom Data Directory","text":"<p>Setting a custom data directory for the server involves configuring SELinux contexts to allow the server to access the new directory properly.</p> <p>It would be best to use <code>semanage</code> when you defining or modifying SELinux policy rules related to a custom data directory. This command allows you to manage SELinux policy modules, including adding, deleting, and modifying SELinux policy rules for specific file contexts or directories.</p> <p>It would be best to use <code>restorecon</code> when you restore the default SELinux context for files and directories, including those in a custom data directory. <code>restorecon</code> resets the SELinux context of specified files or directories to match the default context defined in the SELinux policy. It\u2019s typically used after file or directory modifications to ensure they have the correct SELinux context.</p>"},{"location":"troubleshoot-selinux.html#use-semanage","title":"Use semanage","text":"<p>The following command configures the SELinux context for a custom data directory in the server.</p> <pre><code>$ semanage fcontext -a -t mysqld_db_t \"/path/to/custom/data(/.*)?\"\n</code></pre> <p>Each part of the command is as follows:</p> Option Description <code>semanage</code> Command-line tool used to manage SELinux policy settings. <code>fcontext</code> Sub-command of <code>semanage</code> specifically used to manage file contexts, which define how SELinux labels files and directories. <code>-a</code> Stands for \u201cadd\u201d and indicates the intention to add a new file context configuration. <code>-t mysqld_db_t</code> Specifies the type of context to assign to the specified path. In this case, <code>mysqld_db_t</code> is the SELinux type context for The server database files. <code>\"/path/to/custom/data(/.*)?\"</code> Path to the custom data directory in the Server setup. The <code>(/.*)?</code> part is a regular expression pattern matching any files or subdirectories within the specified directory. <p>This command tells SELinux to label all files and subdirectories within the <code>/path/to/custom/data</code> directory with the SELinux type context <code>mysqld_db_t</code>. This operation ensures that SELinux treats these files and directories as part of the server\u2019s database, allowing the server to access them according to its SELinux policy.</p>"},{"location":"troubleshoot-selinux.html#use-restorecon","title":"Use restorecon","text":"<pre><code>$ restorecon -Rv /path/to/custom/data\n</code></pre> <p>The <code>restorecon -Rv /path/to/custom/data</code> command restores the SELinux context for a specific directory and subdirectory. Here\u2019s what each part of the command does:</p> <ul> <li><code>restorecon</code>: This is the main command used to restore the SELinux context of files and directories.</li> <li><code>-R</code>: This option stands for \u201crecursive\u201d and indicates that the command should operate recursively on all files and subdirectories within the specified directory.</li> <li><code>-v</code>: This option stands for \u201cverbose\u201d and instructs the command to display detailed information about the actions it performs, providing feedback on which files and directories had their SELinux context restored.</li> </ul> <p>The <code>/path/to/custom/data</code> part of the command should be replaced with the actual path to the directory for which you want to restore the SELinux context.</p> <p>Typically, <code>restorecon</code> does not require a system reboot. It simply restores the SELinux context for the specified directory and its contents. However, if you\u2019re experiencing issues with SELinux after running the command, a system reboot may be necessary to ensure all changes take effect.</p>"},{"location":"troubleshoot-selinux.html#setting-custom-log-location","title":"Setting Custom Log Location","text":"<p>When setting a custom log location for the server, SELinux permissions may need adjustment to allow the server to write to the new directory.</p> <p>This command associates the <code>var_log_t</code> type with the custom log directory and contents.</p> <pre><code>$ semanage fcontext -a -t var_log_t \"/path/to/custom/logs(/.*)?\"\n</code></pre> <p>This command restores SELinux contexts recursively for the custom log directory, ensuring proper permissions for the server to write logs.</p> <pre><code>$ restorecon -Rv /path/to/custom/logs\n</code></pre>"},{"location":"troubleshoot-selinux.html#setting-secure_file_priv-directory","title":"Setting secure_file_priv Directory","text":"<p>When configuring the server\u2019s <code>secure_file_priv</code> directory, you must update the SELinux tags to allow the server to access this directory.</p> <p>This command associates the <code>mysqld_db_t</code> type with the <code>secure_file_priv</code> directory and its contents.</p> <pre><code>$ semanage fcontext -a -t mysqld_db_t \"/path/to/secure_file_priv(/.*)?\"\n</code></pre> <p>This command restores SELinux contexts recursively for the <code>secure_file_priv</code> directory, ensuring proper permissions for the server file operations.</p> <pre><code>$ restorecon -Rv /path/to/secure_file_priv\n</code></pre> <p></p>"},{"location":"troubleshoot-selinux.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"troubleshooting-sql.html","title":"Troubleshoot SQL code","text":""},{"location":"troubleshooting-sql.html#troubleshooting-sql-code","title":"Troubleshooting SQL Code","text":"<p>To troubleshoot SQL code, follow these steps:</p> Action Description Review Error Messages Carefully read any error messages returned by the MySQL server. They often provide valuable clues about what went wrong. Check Syntax Verify that the SQL syntax is correct. A single typo or missing keyword can cause errors. Verify Table and Column Names Ensure that table and column names are spelled correctly and match the actual names in the database. Test in Isolation Test each part of the SQL statement separately to identify which part is causing the issue. Use Logging Tools Enable query logging or use debugging tools to track the execution of SQL queries and identify any issues. Review Documentation Consult the MySQL documentation to understand the correct usage of SQL statements and functions. Seek Help Don\u2019t hesitate to ask for help from more experienced developers or consult online forums and communities for assistance. <p>Troubleshooting SQL Code example:</p> <p>Suppose you have the following SQL query that is not returning the expected results:</p> <pre><code>SELECT * FORM users WHERE age = 30;\n</code></pre> <p>After reviewing the error message returned by MySQL, you notice a typo in the query. The keyword \u201cFORM\u201d should be \u201cFROM\u201d. After correcting the typo, the query becomes:</p> <pre><code>SELECT * FROM users WHERE age = 30;\n</code></pre> <p>Now, the query should execute successfully and return the desired results.</p>"},{"location":"troubleshooting-sql.html#advanced-sql-features","title":"Advanced SQL features","text":"<ul> <li>Data Types Basic</li> <li>Functions</li> <li>SQL Conventions</li> <li>SQL Errors</li> <li>SQL Syntax</li> <li>Stored Procedures</li> <li>Stored Procedure Error Handling</li> <li>Stored Procedure Variables</li> <li>Triggers</li> </ul>"},{"location":"troubleshooting-sql.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"udf-percona-toolkit.html","title":"Percona Toolkit UDFs","text":"<p>Three Percona Toolkit UDFs that provide faster checksums are provided:</p> <ul> <li> <p><code>libfnv1a_udf</code></p> </li> <li> <p><code>libfnv_udf</code></p> </li> <li> <p><code>libmurmur_udf</code></p> </li> </ul>"},{"location":"udf-percona-toolkit.html#other-information","title":"Other information","text":"<ul> <li>Author/Origin: Baron Schwartz</li> </ul>"},{"location":"udf-percona-toolkit.html#installation","title":"Installation","text":"<p>These UDFs are part of the Percona Server for MySQL packages. To install one of the UDFs into the server, execute one of the following commands, depending on which UDF you want to install:</p> <pre><code>mysql -e \"CREATE FUNCTION fnv1a_64 RETURNS INTEGER SONAME 'libfnv1a_udf.so'\"\nmysql -e \"CREATE FUNCTION fnv_64 RETURNS INTEGER SONAME 'libfnv_udf.so'\"\nmysql -e \"CREATE FUNCTION murmur_hash RETURNS INTEGER SONAME 'libmurmur_udf.so'\"\n</code></pre> <p>Executing each of these commands will install its respective UDF into the server.</p>"},{"location":"udf-percona-toolkit.html#troubleshooting","title":"Troubleshooting","text":"<p>If you get the error:</p> Error message <pre><code>ERROR 1126 (HY000): Can't open shared library 'fnv_udf.so' (errno: 22 fnv_udf.so: cannot open shared object file: No such file or directory)\n</code></pre> <p>Then you may need to copy the .so file to another location in your system. Try both <code>/lib</code> and <code>/usr/lib</code>. Look at your environment\u2019s <code>$LD_LIBRARY_PATH</code> variable for clues. If none is set, and neither <code>/lib</code> nor <code>/usr/lib</code> works, you may need to set <code>LD_LIBRARY_PATH</code> to <code>/lib</code> or <code>/usr/lib</code>.</p>"},{"location":"udf-percona-toolkit.html#other-reading","title":"Other reading","text":"<ul> <li>Percona Toolkit documentation</li> </ul>"},{"location":"udf-percona-toolkit.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-audit-log-filter.html","title":"Uninstall Audit Log Filter","text":"<p>To remove the component, run the following:</p> <pre><code>mysql&gt; UNINSTALL COMPONENT 'file://component_audit_log_filter';\n</code></pre> <p></p>"},{"location":"uninstall-audit-log-filter.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-component.html","title":"UNINSTALL COMPONENT","text":"<p>The <code>UNINSTALL COMPONENT</code> does the following:</p> <ul> <li>Deactivates the component</li> <li>Uninstalls the component</li> </ul> <p>If the statement does not undo any persisted variables. </p> <p>If an error, such as a misspelled component name, occurs, the statement fails and nothing happens.</p> <p>You can uninstall multiple components at the same time.</p>"},{"location":"uninstall-component.html#required-privilege","title":"Required privilege","text":"<p>The statement requires the <code>DELETE</code> privilege for the <code>mysql.component</code> system table. Executing the statement removes the registration row from this table. </p>"},{"location":"uninstall-component.html#example","title":"Example","text":"<p>The following is an example of the <code>UNINSTALL COMPONENT</code> statement.</p> <pre><code>mysql &gt; UNINSTALL COMPONENT 'file://componentA' ;\n</code></pre> <p>Find more information in the UNINSTALL COMPONENT document.</p> <p></p>"},{"location":"uninstall-component.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uninstall-data-masking-component.html","title":"Uninstall the component","text":"<p>The following steps uninstall the component:</p> <ol> <li> <p>Uninstall the component with <code>UNINSTALL_COMPONENT</code> and the loadable functions.</p> <pre><code>mysql&gt; UNINSTALL COMPONENT 'file://component_masking_functions';\n</code></pre> </li> <li> <p>Drop <code>masking_dictionaries</code>.</p> <pre><code>mysql&gt; DROP TABLE mysql.masking_dictionaries;\n</code></pre> </li> </ol>"},{"location":"uninstall-data-masking-component.html#useful-links","title":"Useful links","text":"<p>Install the data masking component</p> <p>Data masking component functions</p> <p></p>"},{"location":"uninstall-data-masking-component.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"update.html","title":"UPDATE statement","text":""},{"location":"update.html#purpose-of-the-update-statement","title":"Purpose of the UPDATE Statement","text":"<p>The UPDATE statement modifies existing records in a table. It allows developers to change the values of one or more columns in a specific row or set of rows based on certain conditions.</p> <p>Advantages and Disadvantages of Using the UPDATE Statement:</p> Trade-offs Description Advantages - Allows for updating existing data without the need to delete and re-insert records. - Provides flexibility in modifying specific columns or rows based on specified conditions. - Can be used in conjunction with WHERE clause to update only selected rows, reducing unnecessary updates and improving performance. - Supports bulk updates, allowing multiple rows to be modified in a single statement. Disadvantages - Incorrectly formulated UPDATE statements can lead to unintended data changes or data loss. - Lack of proper WHERE clause can result in updating all rows in a table, potentially causing data corruption or performance issues. - May cause locking and contention issues in high-concurrency environments, impacting the performance of other queries accessing the same table. <p>Syntax of an UPDATE Statement:</p> Option Description <code>UPDATE table_name</code> This clause specifies the name of the table you want to modify. <code>SET column_name1 = value1, column_name2 = value2, ...</code> This clause defines which columns you want to update and their corresponding new values. You can update multiple columns by separating them with commas. <code>WHERE condition</code> (optional) This clause specifies a condition that filters which rows in the table will be affected by the update. If omitted, all rows in the table will be updated. <pre><code>UPDATE table_name\nSET column1 = value1, column2 = value2, ...\n[WHERE condition];\n</code></pre> <p>In this example, the statement does the following:</p> <ul> <li> <p>Modifies the <code>salary</code> column for employees in the \u2018Sales\u2019 department.</p> </li> <li> <p>Increases the salary of each employee by 10% (<code>salary * 1.1</code>).</p> </li> </ul> <pre><code>UPDATE employees\nSET salary = salary * 1.1\nWHERE department = 'Sales';\n</code></pre> <p>Fundamental SQL links:</p> <ul> <li>Common SQL</li> <li>SQL Basics</li> <li>SELECT</li> <li>INSERT</li> <li>DELETE</li> <li>SQL Operators</li> </ul> <p></p>"},{"location":"update.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"upgrade-components.html","title":"Upgrading from plugins to components","text":"<p>The following plugins have changed:</p> Plugin 8.0 information 8.4 changes Notes <code>keyring_vault</code> Only available as a plugin <code>component_keyring_vault</code> A manual upgrade path is required. For example, the plugin configuration file, specified by the <code>keyring_vault_config</code> system variable, must be transformed to a JSON format for the <code>component_keyring_vault.cnf</code>. <code>audit_log</code> Only available as a plugin removed Recommended that you use the <code>component_audit_log_filter</code>. <code>audit_log_filter</code> Only available as a plugin <code>component_audit_log_filter</code> Migrate the plugin to the component in 8.0 before the upgrade to 8.4. <code>data_masking</code> Available as a plugin and component <code>component_masking_functions</code> Migrate the plugin to the component in 8.0 before the upgrade to 8.4 <code>binlog_utils_udf</code> user defined functions Only available as plugin. Users must install the plugin and then run <code>CREATE FUNCTION ... SONAME...</code> <code>component_binlog_utils_udf</code> Run <code>INSTALL COMPONENT</code> and all functions are registered automatically. <code>percona-udf</code> user defined functions Must create individual functions with <code>CREATE FUNCTION ... SONAME ...</code>. <code>component_percona_udf</code> Run <code>INSTALL COMPONENT</code> and all functions are registered automatically. Can still use <code>CREATE FUNCTION ... SONAME ...</code> if needed. <p>We recommend if you use a plugin and the feature also available a component, switch to the component in 8.0 series before upgrading to 8.4.</p>"},{"location":"upgrade-components.html#transition-from-a-plugin-to-a-component","title":"Transition from a plugin to a component","text":"<p>The operation to transition from a plugin to a component can be complicated. You should plan for downtime while you plan and test each step in the procedure.</p> <p>Before you start, review the differences between the plugin and the component. A plugin configuration has plugin-specific system variables and uses the <code>--early-plugin-load</code> option. A component has a configuration file and loads using a manifest.</p> <ol> <li> <p>Setup the component\u2019s configuration file.</p> </li> <li> <p>Use the manifest to load the component.</p> </li> <li> <p>Confirm that the component works. Run queries or other operations and test the component in your environment.</p> </li> <li> <p>After confirmation, remove the plugin.</p> </li> </ol> <p>Some plugins may require more configuration and setup during the transition to a component. For those plugins, you may have the following scenario:</p> <ol> <li> <p>Test the plugin in 8.0.</p> </li> <li> <p>Stop the service</p> </li> <li> <p>Upgrade the packages to 8.4</p> </li> <li> <p>Review and edit configurations, as needed</p> </li> <li> <p>Start 8.4</p> </li> <li> <p>Test the component in 8.4</p> </li> </ol> <p></p>"},{"location":"upgrade-components.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"upgrade-percona-repos.html","title":"Upgrade using the Percona repositories","text":"<p>We recommend using the Percona repositories to upgrade your server.</p> <p>Find the instructions on how to enable the repositories in the following documents:</p> <ul> <li> <p>Percona APT Repository</p> </li> <li> <p>Percona RPM Repository</p> </li> </ul> DEB-based distributionsRPM-based distributions <p>Run the following commands as root or use the <code>sudo</code> command.</p> <ol> <li> <p>Make a full backup (or dump if possible) of your database. Move the database configuration file, <code>my.cnf</code>, to another directory to save it. If the configuration file is not moved, it can be overwritten.</p> </li> <li> <p>Stop the server with the appropriate command for your system:</p> </li> </ol> <pre><code>systemctl stop mysql`\n</code></pre> <ol> <li> <p>Modify the database configuration file, <code>my.cnf</code>, as needed.</p> </li> <li> <p>Install Percona Server for MySQL:</p> <pre><code>$ sudo apt update\n$ sudo apt install curl\n$ curl -0 https://repo.percona.com/apt/percona-release_latest.generic_all.deb \n$ sudo apt install gnupg2 lsb-release ./percona-release_latest.generic_all.deb\n$ sudo apt update\n$ sudo percona-release setup  ps-84-lts\n$ sudo apt install percona-server-server\n</code></pre> </li> <li> <p>Install the storage engine packages.</p> <p>If you used the MyRocks storage engine in Percona Server for MySQL 8.4, install the <code>percona-server-rocksdb</code> package:</p> <pre><code>$ sudo apt install percona-server-rocksdb\n</code></pre> </li> <li> <p>Running the upgrade:</p> <p>The mysqld binary automatically runs the upgrade process if needed. To find more information, see MySQL Upgrade Process Upgrades</p> </li> <li> <p>Restart the service </p> <pre><code>$ sudo systemctl restart mysqld\n</code></pre> </li> </ol> <p>After the service has been successfully restarted you can use the new Percona Server for MySQL 8.4.</p> <p>Run the following commands as root or use the sudo command.</p> <ol> <li> <p>Make a full backup (or dump if possible) of your database. Copy the database configuration file, for example, <code>my.cnf</code>, to another directory to save it.</p> </li> <li> <p>Stop the server with the appropriate command for your system:</p> <pre><code>$ systemctl stop mysql`\n</code></pre> </li> <li> <p>Check your installed packages with <code>rpm -qa | grep Percona-Server</code>.</p> </li> <li> <p>Remove only the packages without dependencies and leave dependent packages. The command does not prompt for confirmation:</p> <pre><code>$ rpm -qa | grep Percona-Server | xargs rpm -e --nodeps\n</code></pre> </li> <li> <p>Remove the mysql-related packages, run:</p> <pre><code>$ rpm -qa | grep '^mysql-' | xargs rpm -e --nodeps\n</code></pre> </li> <li> <p>Install the <code>percona-server-server</code> package:</p> <pre><code>$ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n$ sudo percona-release setup ps-84-lts\n$ sudo yum install percona-server-server\n</code></pre> </li> <li> <p>Install the storage engine packages.</p> <p>If you used the MyRocks storage engine in the previous version, install the <code>percona-server-rocksdb</code> package:</p> <pre><code>$ yum install percona-server-rocksdb\n</code></pre> </li> <li> <p>Modify your configuration file, <code>my.cnf</code>, and reinstall the plugins if necessary.</p> </li> <li> <p>Running the upgrade</p> <p>The mysqld binary automatically runs the upgrade process if needed. To find more information, see MySQL Upgrade Process Upgrades</p> </li> </ol> <p>Restart the server and you can use the Percona Server for MySQL 8.4.</p> <p></p>"},{"location":"upgrade-percona-repos.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"upgrade-standalone-packages.html","title":"Upgrade using standalone packages","text":"<p>Make a full backup (or dump if possible) of your database. Move the database configuration file, <code>my.cnf</code>, to another direction to save it. Stop the server with <code>/etc/init.d/mysql stop</code>.</p> Debian-derived distributionRed Hat-derived distributions <ol> <li> <p>Remove the installed packages with their dependencies: <code>sudo apt autoremove percona-server percona-client</code></p> </li> <li> <p>Do the required modifications in the database configuration file <code>my.cnf</code>.</p> </li> <li> <p>Download the following packages for your architecture:</p> <ul> <li> <p><code>percona-server-server</code></p> </li> <li> <p><code>percona-server-client</code></p> </li> <li> <p><code>percona-server-common</code></p> </li> <li> <p><code>libperconaserverclient21</code></p> </li> </ul> <p>The following example downloads Percona Server for MySQL 8.4.0-1 packages for Debian 11.0:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-innovative-release/Percona-Server-8.4.0-1/binary/debian/bullseye/x86_64/Percona-Server-8.4.0-1-r582ebeef-bullseye-x86_64-bundle.tar\n</code></pre> </li> <li> <p>Unpack the bundle to get the packages: <code>tar xvf Percona-Server-8.4.0-1-x86_64-bundle.tar</code>.</p> <p>After you unpack the bundle, you should see the following packages:</p> <pre><code>$ ls *.deb\n</code></pre> Expected output <pre><code>llibperconaserverclient21-dev_8.4.0-1.bullseye_amd64.deb  \npercona-server-dbg_8.4.0-1.bullseye_amd64.deb\nlibperconaserverclient21_8.4.0-1.bullseye_amd64.deb      \npercona-server-rocksdb_8.4.0-1.bullseye_amd64.deb\npercona-mysql-router_8.4.0-1.bullseye_amd64.deb\npercona-server-server_8.4.0-1.bullseye_amd64.deb\npercona-server-client_8.4.0-1.bullseye_amd64.deb     \npercona-server-source_8.4.0-1.bullseye_amd64.deb\npercona-server-common_8.4.0-1.bullseye_amd64.deb     \npercona-server-test_8.4.0-1.bullseye_amd64.deb\n</code></pre> </li> <li> <p>Install Percona Server for MySQL:</p> <pre><code>$ sudo dpkg -i *.deb\n</code></pre> <p>This command installs the packages from the bundle. Another option is to download or specify only the packages you need for running Percona Server for MySQL installation (<code>libperconaserverclient21-dev_8.4.0-1.bullseye_amd64.deb</code>, <code>percona-server-client-8.4.0-1.bullseye_amd64.deb</code>, <code>percona-server-common-8.4.0-1.bullseye_amd64.deb</code>, and <code>percona-server-server-8.4.0-1.bullseye_amd64.deb</code>. </p> <p>Warning</p> <p>When installing packages manually, you must resolve all the dependencies and install missing packages yourself. At least the following packages should be installed before installing Percona Server for MySQL 8.4.0-1: * <code>libmecab2</code>, * <code>libjemalloc1</code>, * <code>zlib1g-dev</code>, * <code>libaio1</code>.</p> </li> <li> <p>Running the upgrade:</p> <p>The mysqld binary automatically runs the upgrade process. To find more information, see MySQL Upgrade Process Upgrades</p> </li> <li> <p>Restart the service with <code>service mysql restart</code>. After the service has been successfully restarted use the new Percona Server for MySQL 8.4.0-1.</p> </li> </ol> <ol> <li> <p>Check the installed packages:</p> <pre><code>$ rpm -qa | grep percona-server\n</code></pre> Expected output <pre><code>percona-server-shared-8.4.0-1.el9.x86_64\npercona-server-shared-compat-8.4.0-1.el9.x86_64\npercona-server-client-8.4.0-1.el9.x86_64\npercona-server-server-8.4.0-1.el9.x86_64\n</code></pre> <p>You may have the <code>shared-compat</code> package, which is required for compatibility.</p> </li> <li> <p>Remove the packages without dependencies with <code>rpm -qa | grep percona-server | xargs rpm -e --nodeps</code>.</p> <p>It is important that you remove the packages without dependencies as many packages may depend on these (as they replace <code>mysql</code>) and will be removed if omitted.</p> <p>To remove the listed packages, run:</p> <pre><code>$ rpm -qa | grep '^mysql-'| xargs rpm -e --nodeps`\n</code></pre> </li> <li> <p>Download the packages of the desired series for your architecture from the download page. The easiest way is to download the bundle which contains all the packages. The following example downloads Percona Server for MySQL 8.4.0-1 packages for CentOS 9:</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-innovative-release/Percona-Server-8.4.0-1/binary/redhat/9/x86_64/Percona-Server-8.4.0-1-r582ebeef-el9-x86_64-bundle.tar\n</code></pre> </li> <li> <p>Unpack the bundle to get the packages</p> <pre><code>$ tar xvf Percona-Server-8.4.0-1-r582ebeef-el9-x86_64-bundle.tar\n</code></pre> <p>After you unpack the bundle, you should see the following packages: <code>ls \\*.rpm</code></p> </li> <li> <p>Install Percona Server for MySQL:</p> <pre><code>$ sudo rpm -ivh percona-server-server-8.4.0-1.el9.x86_64.rpm \\\n&gt; percona-server-client-8.4.0-1.el9.x86_64.rpm \\\n&gt; percona-server-shared-8.4.0-1.el9.x86_64.rpm \\\n&gt; percona-server-shared-compat-8.4.0-1.el9.x86_64.rpm\n</code></pre> <p>This command installs only packages required to run the Percona Server for MySQL 8.4.0-1.</p> </li> <li> <p>You can install all the packages (for debugging, testing, etc.) with <code>sudo rpm -ivh \\*.rpm</code>.</p> <p>Note</p> <p>When manually installing packages, you must resolve all the dependencies and install missing ones.</p> </li> <li> <p>Modify your configuration file, <code>my.cnf</code>, and install the plugins if necessary.</p> </li> </ol> <p>RHEL/CentOS automatically backs up the previous configuration file to <code>/etc/my.cnf.rpmsave</code> and installs the default <code>my.cnf</code>. After the upgrade/install process completes you can move the old configuration file back (after you remove all the unsupported system variables).</p> <ol> <li>The schema of the grant table has changed, the server must be started without reading the grants. Add a line to my.cnf in the [mysqld] section,</li> </ol> <pre><code>[mysqld]\nskip-grant-tables\n</code></pre> <p>Restart the mysql server with <code>service mysql start</code>. </p> <ol> <li> <p>Running the upgrade:</p> <p>The mysqld binary automatically runs the upgrade process. To find more information, see MySQL Upgrade Process Upgrades</p> </li> <li> <p>Restart the server with <code>service mysql restart</code>. After the service has been successfully restarted you can use the new Percona Server for MySQL 8.4.0-1.</p> </li> </ol> <p></p>"},{"location":"upgrade-standalone-packages.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"upgrade-strategies.html","title":"Upgrade strategies","text":"<p>There are different strategies to consider when upgrading from 8.0 to 8.4.</p>"},{"location":"upgrade-strategies.html#in-place-upgrade","title":"In-place upgrade","text":"<p>An upgrade to 8.4 does not allow a rollback. The in-place upgrade strategy is not recommended, and it should be used only as a last resort.</p> <p>An in-place upgrade involves shutting down the 8.0 server, and replacing the server binaries, or packages, with new ones. At this point the new server version can be started on the existing data directory. Note that the server should be configured to perform a slow shutdown by setting <code>innodb_fast_shutdown=0</code> prior to shutdown.</p> <p>The benefits are:</p> <ul> <li>Less additional infrastructure cost compared to a new environment, but nodes must be tested.</li> <li>An upgrade can be completed over weeks with cool-down periods between reader node upgrades.</li> <li>Requires a failover of production traffic, and for minimal downtime you must have good high-availability tools.</li> </ul> <p>If you use XA transactions with InnoDB, running XA RECOVER before upgrading checks for uncommitted XA transactions. If results are returned, either commit or rollback the XA transactions by issuing an XA COMMIT or XA ROLLBACK statement.</p>"},{"location":"upgrade-strategies.html#new-environment-with-cut-over","title":"New environment with cut over","text":"<p>Upgrading with a new environment involves provisioning a duplicate environment with the same number of servers with the same hardware specs and same operating system as the current production nodes.</p> <p>On the newly provided hardware, the target MySQL version will be installed. The new environment will be set up, and the production data will be recovered. Remember that you can use pt-config-diff to verify MySQL configurations. </p> <p>Replication from the current source to the newly built environment will be established. At cutover time, all writes on the current source will be halted, and the application traffic will need to be redirected to the new source. The cutover can be done using a Virtual IP address or manually redirecting the application itself. Once writes are being received on the new environment, you are in a fail forward situation, and the old environment can be torn down.</p> <p>The new environment strategy has the following pros and cons:</p> <ul> <li> <p>Additional infrastructure cost since a new environment must be built.</p> </li> <li> <p>Ability to upgrade both the OS and the DBMS at the same time.</p> </li> <li> <p>Allows upgrade of hardware easily.</p> </li> <li> <p>Requires only a single cutover window.</p> </li> </ul> <p></p>"},{"location":"upgrade-strategies.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"upgrade.html","title":"Upgrade from 8.0 to 8.4 overview","text":"<p>Upgrading your server to 8.4 has the following benefits:</p> Benefits Description Security fixes These patches and updates protect your data from cyberattacks and address vulnerabilities or bugs in the database software. New or improved features You have access to new or improved features that enhance the functionality, performance, and availability of the database. Reduced labor You can automate some routine tasks. Relevance Your customers and stakeholders have changing needs and expectations. Using the latest version can help to deliver solutions faster. Reduced operational costs An upgraded database server can help reduce your operational costs because the server has improved efficiency and scalability. <p>Not upgrading your database can have the following risks:</p> Risks Description Security risks Your database server is vulnerable to cyberattacks because you do not receive security fixes. These attacks can result in data breaches, data loss, and data corruption. These actions can harm the organization\u2019s reputation and lose money. Service risks You do not benefit from new or improved features. This risk may cause poor user experience, reduced productivity, and increased downtime. Support risks You are limited in support access. This risk can result in longer resolution times, unresolved issues, and higher support costs. Compatibility risks You can experience compatibility issues with hardware, operating systems, or applications since the older version is not supported on newer platforms. At some point, the database server is no longer supportable. Failure risk A failure in either hardware, operating system, or application may force an upgrade at the wrong time. <p>Create a test environment to verify the upgrade before you upgrade the production servers. The test environment is crucial to the success of the upgrade. There is no supported downgrade procedure. You can try to replicate from an 8.4 version to an 8.0 version or restore a backup.</p> <p>Tools, such as the <code>pt-upgrade</code> tool in the Percona Toolkit, can help with the upgrade process.</p> <p>We recommend upgrading to the latest version.</p> <p>Review the documentation for other changes between 8.0 to 8.4.</p> <p>Review Upgrade Strategies for an overview of the major strategies.</p> <p>The following list summarizes a number of the changes in the 8.0 series and has useful guides that can help you perform a smooth upgrade. We strongly recommend reading this information:</p> <ul> <li> <p>Upgrading MySQL</p> </li> <li> <p>Before You Begin</p> </li> <li> <p>Upgrade Paths</p> </li> <li> <p>Changes in MySQL 8.0</p> </li> <li> <p>Preparing your Installation for Upgrade</p> </li> <li> <p>Percona Server for MySQL 8.4 Release notes</p> </li> <li> <p>Upgrade Troubleshooting</p> </li> <li> <p>Rebuilding or Repairing Tables or Indexes</p> </li> </ul> <p>Review other Percona blogs that contain upgrade information.</p>"},{"location":"upgrade.html#limitations","title":"Limitations","text":"<p>An upgrade on Ubuntu 20.04 from the following releases does not restart the MySQL service automatically. You must start the service manually.</p> <ul> <li> <p>Percona Server for MySQL 8.0.x to Percona Server for MySQL 8.1</p> </li> <li> <p>Percona Server for MySQL 8.0.x to Percona Server for MySQL 8.2</p> </li> <li> <p>Percona Server for MySQL 8.1 to Percona Server for MySQL 8.2</p> </li> </ul> <p></p>"},{"location":"upgrade.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use-keyring-file.html","title":"Use the keyring file component","text":"<p>The <code>keyring_file</code> component is part of the component-based MySQL infrastructure which extends the server capabilities.</p> <p>Important</p> <p>Percona Server for MySQL 8.4 does not support the <code>keyring_file</code> plugin.</p> <p>See the MySQL documentation on the component installation and on the keyring_file component usage for more information.</p> <p>The component must be installed with a manifest. A keyring component is not loaded with the <code>--early-plugin-load</code> option on the server. The server uses a manifest and the component consults its configuration file during initialization. You should only load a keyring component with a manifest file. Do not use the <code>INSTALL_COMPONENT</code> statement, which loads the keyring components too late in the startup sequence of the server. For example, <code>InnoDB</code> requires the component, but because the components are registered in the <code>mysql.component</code> table, this table is loaded after <code>InnoDB</code> initialization.</p> <p>You should create a global manifest file named <code>mysqld.my</code> in the installation directory and, optionally, create a local manifest file, also named <code>mysqld.my</code> in a data directory.</p> <p>To install a keyring component, do the following:</p> <ol> <li> <p>Write a manifest in a valid JSON format</p> </li> <li> <p>Write a configuration file</p> </li> </ol> <p>A manifest file indicates which component to load. If the manifest file does not exist, the server does not load the component associated with that file. During startup, the server reads the global manifest file from the installation directory. The global manifest file can contain the required information or point to a local manifest file located in the data directory. If you have multiple server instances that use different keyring components use a local manifest file in each data directory to load the correct keyring component for that instance.</p> <p>Warning</p> <p>Enable only one keyring plugin or one keyring component at a time for each server instance. Enabling multiple keyring plugins or keyring components or mixing keyring plugins or keyring components is not supported and may result in data loss.</p> <p>An example of a manifest and a configuration file is the following:</p> <p>An example of <code>./bin/mysqld.my</code>:</p> <pre><code>{\n    \"components\": \"file://component_keyring_file\"\n}\n</code></pre> <p>An example of <code>/lib/plugin/component_keyring_file.cnf</code>:</p> <pre><code>{\n    \"path\": \"/var/lib/mysql-keyring/keyring_file\", \"read_only\": false\n}\n</code></pre> <p></p>"},{"location":"use-keyring-file.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"use-keyring-vault-component.html","title":"Use the keyring vault component","text":"<p>The <code>keyring_vault</code> component extends the server capabilities and provides an interface for the database with a HashiCorp Vault server to store key and secure encryption keys. </p> <p>The component must be installed with a manifest. A keyring component is not loaded with the <code>--early-plugin-load</code> option on the server. The server uses a manifest and the component consults its configuration file during initialization. You should only load a keyring component with a manifest file. Do not use the <code>INSTALL_COMPONENT</code> statement, which loads the keyring components too late in the startup sequence of the server. For example, <code>InnoDB</code> requires the component, but because the components are registered in the <code>mysql.component</code> table, this table is loaded after <code>InnoDB</code> initialization.</p> <p>You should create a global manifest file named <code>mysqld.my</code> in the installation directory and, optionally, create a local manifest file, also named <code>mysqld.my</code> in a data directory.</p> <p>To install a keyring component, do the following:</p> <ol> <li> <p>Write a manifest in a valid JSON format</p> </li> <li> <p>Write a configuration file</p> </li> </ol> <p>A manifest file indicates which component to load. If the manifest file does not exist, the server does not load the component associated with that file. During startup, the server reads the global manifest file from the installation directory. The global manifest file can contain the required information or point to a local manifest file located in the data directory. If you have multiple server instances that use different keyring components use a local manifest file in each data directory to load the correct keyring component for that instance.</p> <p>Warning</p> <p>Enable only one keyring plugin or one keyring component at a time for each server instance. Enabling multiple keyring plugins or keyring components or mixing keyring plugins or keyring components is not supported and may result in data loss.</p> <p>The following example is a global manifest file that does not use local manifests:</p> <pre><code>{\n \"read_local_manifest\": false,\n \"components\": \"file://component_keyring_vault\"\n}\n</code></pre> <p>The following is an example of a global manifest file that points to a local manifest file:</p> <pre><code>{\n \"read_local_manifest\": true\n}\n</code></pre> <p>The following is an example of a local manifest file:</p> <pre><code>{\n \"components\": \"file://component_keyring_vault\"\n}\n</code></pre> <p>The configuration settings are either in a global configuration file or a local configuration file.</p> <p>The component communicates with the Hashicorp Vault server. Prepare the certificate and key files for a secure HTTPS connection to the server. You must have an organizational Certificate Authority (CA), a private vault key, and certificate for the Hashicorp Vault server instance. </p> <p>You can use OpenSL to generate these files or use existing files. The key files contain sensitive information. Store these key files and the password used to create each key in a secure location. </p> <p>You can use the Hashicorp Vault to build your own CA, if needed, and then create a Hashicorp Vault server certificate.</p> <p>The <code>component_keyring_vault.cnf</code> file contains the following information:</p> <ul> <li> <p><code>read_local_config [optional]</code> - this option can be used only in the global configuration file. This option indicates whether the component should read configuration information from the local configuration file. The allowed values are <code>true</code> or <code>false</code>. If you do not use this option, the component uses only the global configuration file.</p> <p>If you use the <code>read_local_config</code> option in the global configuration file along with other items, the component checks the <code>read_local_config</code> item value first:</p> <p><code>false</code> - the component processes other items in the global configuration file and ignores the local configuration file.</p> <p><code>true</code> - the component ignores other items in the global configuration file and attempts to read the local configuration file.</p> </li> <li> <p><code>timeout</code> - the duration in seconds for the Vault server connection timeout. The default value is 15. The allowed range is from 0 to 86400. The timeout can be also disabled to wait an infinite amount of time by setting this variable to 0.</p> </li> <li> <p><code>vault_url</code> - the Vault server address.</p> </li> <li> <p><code>secret_mount_point</code> - the mount point name where the keyring_vault stores the keys.</p> </li> <li> <p><code>token</code> - a token generated by the Vault server.</p> </li> <li> <p><code>secret_mount_point_version [optional]</code> - the <code>KV Secrets Engine version (kv or kv-v2)</code> used. The allowed values are <code>AUTO</code>, <code>1</code>, and <code>2</code>. The default value is <code>AUTO</code>.</p> </li> <li> <p><code>vault_ca [optional]</code> - if the machine does not trust the Vault\u2019s CA certificate, this variable points to the CA certificate used to sign the Vault\u2019s certificates.</p> </li> </ul> Example of a configuration file in JSON format <pre><code>{\n \"timeout\": 15,\n \"vault_url\": \"https://vault.public.com:8202\",\n \"secret_mount_point\": \"secret\",\n \"secret_mount_point_version\": \"AUTO\",\n \"token\": \"{randomly-generated-alphanumeric-string}\",\n \"vault_ca\": \"/data/keyring_vault_confs/vault_ca.crt\"\n}\n</code></pre> <p>Warning</p> <p>Each <code>secret_mount_point</code> must be used by only one server. The behavior is unpredictable if multiple servers use the same <code>secret_mount_point</code>.</p> <p>The first time a key is fetched from a keyring, the <code>keyring_vault</code> communicates with the Vault server to retrieve the key type and data.</p>"},{"location":"use-keyring-vault-component.html#secret_mount_point_version-information","title":"secret_mount_point_version information","text":"<p>The <code>secret_mount_point_version</code> can be either a <code>1</code>, <code>2</code>, <code>AUTO</code>, or the <code>secret_mount_point_version</code> parameter is not listed in the configuration file.</p> Value Description 1 Works with <code>KV Secrets Engine - Version 1 (kv)</code>. When forming key operation URLs, the <code>secret_mount_point</code> is always used without any transformations. For example, to return a key named <code>skey</code>, the URL is /v1//skey 2 Works with <code>KV Secrets Engine - Version 2 (kv)</code> The initialization logic splits the <code>secret_mount_point</code> parameter into two parts:<ul><li>The <code>mount_point_path</code> - the mount path under which the Vault Server secret was created</li><li>The <code>directory_path</code> - a virtual directory suffix that can be used to create virtual namespaces with the same real mount point</li></ul> For example, both the <code>mount_point_path</code> and the <code>directory_path</code> are needed to form key access URLs: /v1/&lt;mount_point_path/data//skey AUTO An autodetection mechanism probes and determines if the secrets engine version is <code>kv</code> or <code>kv-v2</code> and based on the outcome will either use the <code>secret_mount_point</code> as is, or split the <code>secret_mount_point</code> into two parts. Not listed If the <code>secret_mount_point_version</code> is not listed in the configuration file, the behavior is the same as <code>AUTO</code>. <p>If you set the <code>secret_mount_point_version</code> to <code>2</code> but the path pointed by <code>secret_mount_point</code> is based on <code>KV Secrets Engine - Version 1 (kv)</code>, an error is reported, and the component fails to initialize.</p> <p>If you set the <code>secret_mount_point_version</code> to <code>1</code> but the path pointed by <code>secret_mount_point</code> is based on <code>KV Secrets Engine - Version 2 (kv-v2)</code>, the component initialization succeeds but any MySQL keyring-related operations fail.</p>"},{"location":"use-keyring-vault-component.html#upgrade-from-vault-secrets-engine-version-1-to-version-2","title":"Upgrade from Vault Secrets Engine Version 1 to Version 2","text":"<p>You can upgrade from the Vault Secrets Engine Version 1 to Version 2.</p> <p>Use either of the following methods:</p> <ul> <li> <p>Set the <code>secret_mount_point_version</code> to <code>AUTO</code> or the variable is not set in the <code>keyring_vault</code> component configuration files in all Percona Servers. The <code>AUTO</code> value ensures the autodetection mechanism is invoked during the component initialization.</p> </li> <li> <p>Set the <code>secret_mount_point_version</code> to <code>2</code> to ensure that components do not initialize unless the <code>kv</code> to <code>kv-v2</code> upgrade completes.</p> </li> </ul> <p>Note</p> <p>The <code>keyring_vault</code> component that works with <code>kv-v2</code> secret engines does not use the built-in key versioning capabilities. The keyring key versions are encoded into key names.</p> <p>See also</p> <p>Hashicorp Documentation: Installing Vault</p> <p>Hashicorp Documentation: Production Hardening</p> <p></p>"},{"location":"use-keyring-vault-component.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"user-stats.html","title":"User statistics","text":"<p>This feature adds several <code>INFORMATION_SCHEMA</code> tables, several commands, and the userstat variable. The tables and commands can be used to understand the server activity better and identify the source of the load.</p> <p>The functionality is disabled by default and must be enabled by setting <code>userstat</code> to <code>ON</code>. It works by keeping several hash tables in memory. To avoid contention over global mutexes, each connection has its own local statistics, which are occasionally merged into the global statistics, and the local statistics are then reset to 0.</p>"},{"location":"user-stats.html#system-variables","title":"System variables","text":""},{"location":"user-stats.html#userstat","title":"<code>userstat</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type BOOLEAN Default OFF Range ON/OFF <p>Enables or disables collection of statistics. The default is <code>OFF</code>, meaning no statistics are gathered. This is to ensure that the statistics collection doesn\u2019t cause any extra load on the server unless desired.</p>"},{"location":"user-stats.html#thread_statistics","title":"<code>thread_statistics</code>","text":"Option Description Command-line Yes Config file Yes Scope Global Dynamic Yes Data type BOOLEAN Default OFF Range ON/OFF <p>Enables or disables collection of thread statistics. The default is <code>OFF</code>, meaning no thread statistics are gathered. This is to ensure that the statistics collection doesn\u2019t cause any extra load on the server unless desired. The variable <code>userstat</code> must be enabled as well in order for thread statistics to be collected.</p>"},{"location":"user-stats.html#information_schema-tables","title":"INFORMATION_SCHEMA Tables","text":""},{"location":"user-stats.html#information_schemaclient_statistics","title":"<code>INFORMATION_SCHEMA.CLIENT_STATISTICS</code>","text":"Column Name Description \u2018CLIENT\u2019 \u2018The IP address or hostname from which the connection originated.\u2019 \u2018TOTAL_CONNECTIONS\u2019 \u2018The number of connections created for this client.\u2019 \u2018CONCURRENT_CONNECTIONS\u2019 \u2018The number of concurrent connections for this client.\u2019 \u2018CONNECTED_TIME\u2019 \u2018The cumulative number of seconds elapsed while there were connections from this client.\u2019 \u2018BUSY_TIME\u2019 \u2018The cumulative number of seconds there was activity on connections from this client.\u2019 \u2018CPU_TIME\u2019 \u2018The cumulative CPU time elapsed, in seconds, while servicing this client\u2019s connections.\u2019 \u2018BYTES_RECEIVED\u2019 \u2018The number of bytes received from this client\u2019s connections.\u2019 \u2018BYTES_SENT\u2019 \u2018The number of bytes sent to this client\u2019s connections.\u2019 \u2018BINLOG_BYTES_WRITTEN\u2019 \u2018The number of bytes written to the binary log from this client\u2019s connections.\u2019 \u2018ROWS_FETCHED\u2019 \u2018The number of rows fetched by this client\u2019s connections.\u2019 \u2018ROWS_UPDATED\u2019 \u2018The number of rows updated by this client\u2019s connections.\u2019 \u2018TABLE_ROWS_READ\u2019 \u2018The number of rows read from tables by this client\u2019s connections. (It may be different from ROWS_FETCHED.)\u2019 \u2018SELECT_COMMANDS\u2019 \u2018The number of SELECT commands executed from this client\u2019s connections.\u2019 \u2018UPDATE_COMMANDS\u2019 \u2018The number of UPDATE commands executed from this client\u2019s connections.\u2019 \u2018OTHER_COMMANDS\u2019 \u2018The number of other commands executed from this client\u2019s connections.\u2019 \u2018COMMIT_TRANSACTIONS\u2019 \u2018The number of COMMIT commands issued by this client\u2019s connections.\u2019 \u2018ROLLBACK_TRANSACTIONS\u2019 \u2018The number of ROLLBACK commands issued by this client\u2019s connections.\u2019 \u2018DENIED_CONNECTIONS\u2019 \u2018The number of connections denied to this client.\u2019 \u2018LOST_CONNECTIONS\u2019 \u2018The number of this client\u2019s connections that were terminated uncleanly.\u2019 \u2018ACCESS_DENIED\u2019 \u2018The number of times this client\u2019s connections issued commands that were denied.\u2019 \u2018EMPTY_QUERIES\u2019 \u2018The number of times this client\u2019s connections sent empty queries to the server.\u2019 <p>This table holds statistics about client connections. The Percona version of the feature restricts this table\u2019s visibility to users who have the <code>SUPER</code> or <code>PROCESS</code> privilege.</p> <p>For example:</p> <pre><code>mysql&gt;SELECT * FROM INFORMATION_SCHEMA.CLIENT_STATISTICS\\G\n</code></pre> Expected output <pre><code>*************************** 1. row ***************************\n                CLIENT: 10.1.12.30\n     TOTAL_CONNECTIONS: 20\nCONCURRENT_CONNECTIONS: 0\n        CONNECTED_TIME: 0\n             BUSY_TIME: 93\n              CPU_TIME: 48\n        BYTES_RECEIVED: 5031\n            BYTES_SENT: 276926\n   BINLOG_BYTES_WRITTEN: 217\n          ROWS_FETCHED: 81\n          ROWS_UPDATED: 0\n       TABLE_ROWS_READ: 52836023\n       SELECT_COMMANDS: 26\n       UPDATE_COMMANDS: 1\n        OTHER_COMMANDS: 145\n   COMMIT_TRANSACTIONS: 1\n ROLLBACK_TRANSACTIONS: 0\n    DENIED_CONNECTIONS: 0\n      LOST_CONNECTIONS: 0\n         ACCESS_DENIED: 0\n         EMPTY_QUERIES: 0\n</code></pre>"},{"location":"user-stats.html#information_schema-tables_1","title":"INFORMATION_SCHEMA tables","text":""},{"location":"user-stats.html#information_schemaindex_statistics","title":"<code>INFORMATION_SCHEMA.INDEX_STATISTICS</code>","text":"Column Name Description \u2018TABLE_SCHEMA\u2019 \u2018The schema (database) name.\u2019 \u2018TABLE_NAME\u2019 \u2018The table name.\u2019 \u2018INDEX_NAME\u2019 \u2018The index name (as visible in SHOW CREATE TABLE).\u2019 \u2018ROWS_READ\u2019 \u2018The number of rows read from this index.\u2019 <p>This table shows statistics on index usage. An older version of the feature contained a single column that had the <code>TABLE_SCHEMA</code>, <code>TABLE_NAME</code>, and <code>INDEX_NAME</code> columns concatenated together. The Percona version of the feature separates these into three columns. Users can see entries only for tables to which they have <code>SELECT</code> access.</p> <p>This table makes it possible to do many things that were difficult or impossible previously. For example, you can use it to find unused indexes and generate DROP commands to remove them.</p> <p>Example:</p> <pre><code>mysql&gt; SELECT * FROM INFORMATION_SCHEMA.INDEX_STATISTICS WHERE TABLE_NAME='tables_priv';\n</code></pre> Expected output <pre><code>+--------------+-----------------------+--------------------+-----------+\n| TABLE_SCHEMA | TABLE_NAME            | INDEX_NAME         | ROWS_READ |\n+--------------+-----------------------+--------------------+-----------+\n| mysql        | tables_priv           | PRIMARY            |         2 |\n+--------------+-----------------------+--------------------+-----------+\n</code></pre> <p>Note</p> <p>The current implementation of index statistics doesn\u2019t support partitioned tables.</p>"},{"location":"user-stats.html#information_schematable_statistics","title":"<code>INFORMATION_SCHEMA.TABLE_STATISTICS</code>","text":"Column Name Description \u2018TABLE_SCHEMA\u2019 \u2018The schema (database) name.\u2019 \u2018TABLE_NAME\u2019 \u2018The table name.\u2019 \u2018ROWS_READ\u2019 \u2018The number of rows read from the table.\u2019 \u2018ROWS_CHANGED\u2019 \u2018The number of rows changed in the table.\u2019 \u2018ROWS_CHANGED_X_INDEXES\u2019 \u2018The number of rows changed in the table, multiplied by the number of indexes changed.\u2019 <p>This table is similar in function to the <code>INDEX_STATISTICS</code> table.</p> <p>For example:</p> <pre><code>mysql&gt; SELECT * FROM INFORMATION_SCHEMA.TABLE_STATISTICS WHERE TABLE_NAME=``tables_priv``;\n</code></pre> Expected output <pre><code>+--------------+-------------------------------+-----------+--------------+------------------------+\n| TABLE_SCHEMA | TABLE_NAME                    | ROWS_READ | ROWS_CHANGED | ROWS_CHANGED_X_INDEXES |\n+--------------+-------------------------------+-----------+--------------+------------------------+\n| mysql        | tables_priv                   |         2 |            0 |                      0 |\n+--------------+-------------------------------+-----------+--------------+------------------------+\n</code></pre> <p>Note</p> <p>The current implementation of table statistics doesn\u2019t support partitioned tables.</p>"},{"location":"user-stats.html#information_schemathread_statistics","title":"<code>INFORMATION_SCHEMA.THREAD_STATISTICS</code>","text":"Column Name Description \u2018THREAD_ID\u2019 \u2018Thread ID\u2019 \u2018TOTAL_CONNECTIONS\u2019 \u2018The number of connections created from this thread.\u2019 \u2018CONNECTED_TIME\u2019 \u2018The cumulative number of seconds elapsed while there were connections from this thread.\u2019 \u2018BUSY_TIME\u2019 \u2018The cumulative number of seconds there was activity from this thread.\u2019 \u2018CPU_TIME\u2019 \u2018The cumulative CPU time elapsed while servicing this thread.\u2019 \u2018BYTES_RECEIVED\u2019 \u2018The number of bytes received from this thread.\u2019 \u2018BYTES_SENT\u2019 \u2018The number of bytes sent to this thread.\u2019 \u2018BINLOG_BYTES_WRITTEN\u2019 \u2018The number of bytes written to the binary log from this thread.\u2019 \u2018ROWS_FETCHED\u2019 \u2018The number of rows fetched by this thread.\u2019 \u2018ROWS_UPDATED\u2019 \u2018The number of rows updated by this thread.\u2019 \u2018TABLE_ROWS_READ\u2019 \u2018The number of rows read from tables by this tread.\u2019 \u2018SELECT_COMMANDS\u2019 \u2018The number of SELECT commands executed from this thread.\u2019 \u2018UPDATE_COMMANDS\u2019 \u2018The number of UPDATE commands executed from this thread.\u2019 \u2018OTHER_COMMANDS\u2019 \u2018The number of other commands executed from this thread.\u2019 \u2018COMMIT_TRANSACTIONS\u2019 \u2018The number of COMMIT commands issued by this thread.\u2019 \u2018ROLLBACK_TRANSACTIONS\u2019 \u2018The number of ROLLBACK commands issued by this thread.\u2019 \u2018DENIED_CONNECTIONS\u2019 \u2018The number of connections denied to this thread.\u2019 \u2018LOST_CONNECTIONS\u2019 \u2018The number of thread connections that were terminated uncleanly.\u2019 \u2018ACCESS_DENIED\u2019 \u2018The number of times this thread issued commands that were denied.\u2019 \u2018EMPTY_QUERIES\u2019 \u2018The number of times this thread sent empty queries to the server.\u2019 \u2018TOTAL_SSL_CONNECTIONS\u2019 \u2018The number of thread connections that used SSL.\u2019 <p>In order for this table to be populated with statistics, the additional variable thread_statistics should be set to <code>ON</code>.</p>"},{"location":"user-stats.html#information_schemauser_statistics","title":"<code>INFORMATION_SCHEMA.USER_STATISTICS</code>","text":"Column Name Description \u2018USER\u2019 \u2018The username. The value #mysql_system_user# appears when there is no username (such as for the replica SQL thread).\u2019 \u2018TOTAL_CONNECTIONS\u2019 \u2018The number of connections created from this user.\u2019 \u2018CONCURRENT_CONNECTIONS\u2019 \u2018The number of concurrent connections for this user.\u2019 \u2018CONNECTED_TIME\u2019 \u2018The cumulative number of seconds elapsed while there were connections from this user.\u2019 \u2018BUSY_TIME\u2019 \u2018The cumulative number of seconds there was activity on connections from this user.\u2019 \u2018CPU_TIME\u2019 \u2018The cumulative CPU time elapsed, in seconds, while servicing this user\u2019s connections.\u2019 \u2018BYTES_RECEIVED\u2019 \u2018The number of bytes received from this user\u2019s connections.\u2019 \u2018BYTES_SENT\u2019 \u2018The number of bytes sent to this user\u2019s connections.\u2019 \u2018BINLOG_BYTES_WRITTEN\u2019 \u2018The number of bytes written to the binary log from this user\u2019s connections.\u2019 \u2018ROWS_FETCHED\u2019 \u2018The number of rows fetched by this user\u2019s connections.\u2019 \u2018ROWS_UPDATED\u2019 \u2018The number of rows updated by this user\u2019s connections.\u2019 \u2018TABLE_ROWS_READ\u2019 \u2018The number of rows read from tables by this user\u2019s connections. (It may be different from ROWS_FETCHED.)\u2019 \u2018SELECT_COMMANDS\u2019 \u2018The number of SELECT commands executed from this user\u2019s connections.\u2019 \u2018UPDATE_COMMANDS\u2019 \u2018The number of UPDATE commands executed from this user\u2019s connections.\u2019 \u2018OTHER_COMMANDS\u2019 \u2018The number of other commands executed from this user\u2019s connections.\u2019 \u2018COMMIT_TRANSACTIONS\u2019 \u2018The number of COMMIT commands issued by this user\u2019s connections.\u2019 \u2018ROLLBACK_TRANSACTIONS\u2019 \u2018The number of ROLLBACK commands issued by this user\u2019s connections.\u2019 \u2018DENIED_CONNECTIONS\u2019 \u2018The number of connections denied to this user.\u2019 \u2018LOST_CONNECTIONS\u2019 \u2018The number of this user\u2019s connections that were terminated uncleanly.\u2019 \u2018ACCESS_DENIED\u2019 \u2018The number of times this user\u2019s connections issued commands that were denied.\u2019 \u2018EMPTY_QUERIES\u2019 \u2018The number of times this user\u2019s connections sent empty queries to the server.\u2019 <p>This table contains information about user activity. The Percona version of the patch restricts this table\u2019s visibility to users who have the <code>SUPER</code> or <code>PROCESS</code> privilege.</p> <p>The table gives answers to questions such as which users cause the most load, and whether any users are being abusive. It also lets you measure how close to capacity the server may be. For example, you can use it to find out whether replication is likely to start falling behind.</p> <p>Example:</p> <pre><code>mysql&gt;SELECT * FROM INFORMATION_SCHEMA.USER_STATISTICS\\G\n</code></pre> Expected output <pre><code>*************************** 1. row ***************************\n                  USER: root\n     TOTAL_CONNECTIONS: 5592\n CONCURRENT_CONNECTIONS: 0\n         CONNECTED_TIME: 6844\n             BUSY_TIME: 179\n              CPU_TIME: 72\n        BYTES_RECEIVED: 603344\n            BYTES_SENT: 15663832\n  BINLOG_BYTES_WRITTEN: 217\n          ROWS_FETCHED: 9793\n          ROWS_UPDATED: 0\n       TABLE_ROWS_READ: 52836023\n       SELECT_COMMANDS: 9701\n       UPDATE_COMMANDS: 1\n        OTHER_COMMANDS: 2614\n   COMMIT_TRANSACTIONS: 1\n ROLLBACK_TRANSACTIONS: 0\n    DENIED_CONNECTIONS: 0\n      LOST_CONNECTIONS: 0\n         ACCESS_DENIED: 0\n         EMPTY_QUERIES: 0\n</code></pre>"},{"location":"user-stats.html#commands-provided","title":"Commands Provided","text":"<ul> <li> <p><code>FLUSH CLIENT_STATISTICS</code></p> </li> <li> <p><code>FLUSH INDEX_STATISTICS</code></p> </li> <li> <p><code>FLUSH TABLE_STATISTICS</code></p> </li> <li> <p><code>FLUSH THREAD_STATISTICS</code></p> </li> <li> <p><code>FLUSH USER_STATISTICS</code></p> </li> </ul> <p>These commands discard the specified type of stored statistical information.</p> <ul> <li> <p><code>SHOW CLIENT_STATISTICS</code></p> </li> <li> <p><code>SHOW INDEX_STATISTICS</code></p> </li> <li> <p><code>SHOW TABLE_STATISTICS</code></p> </li> <li> <p><code>SHOW THREAD_STATISTICS</code></p> </li> <li> <p><code>SHOW USER_STATISTICS</code></p> </li> </ul> <p>These commands are another way to display the information you can get from the <code>INFORMATION_SCHEMA</code> tables. The commands accept <code>WHERE</code> clauses. They also accept but ignore <code>LIKE</code> clauses.</p>"},{"location":"user-stats.html#status-variables","title":"Status Variables","text":""},{"location":"user-stats.html#com_show_client_statistics","title":"<code>Com_show_client_statistics</code>","text":"Option Description Scope Global/Session Data type numeric <p>The Com_show_client_statistics statement counter variable indicates the number of times the statement <code>SHOW CLIENT_STATISTICS</code> has been executed.</p>"},{"location":"user-stats.html#com_show_index_statistics","title":"<code>Com_show_index_statistics</code>","text":"Option Description Scope Global/Session Data type numeric <p>The Com_show_index_statistics statement counter variable indicates the number of times the statement <code>SHOW INDEX_STATISTICS</code> has been executed.</p>"},{"location":"user-stats.html#com_show_table_statistics","title":"<code>Com_show_table_statistics</code>","text":"Option Description Scope Global/Session Data type numeric <p>The Com_show_table_statistics statement counter variable indicates the number of times the statement <code>SHOW TABLE_STATISTICS</code> has been executed.</p>"},{"location":"user-stats.html#com_show_thread_statistics","title":"<code>Com_show_thread_statistics</code>","text":"Option Description Scope Global/Session Data type numeric <p>The Com_show_thread_statistics statement counter variable indicates the number of times the statement <code>SHOW THREAD_STATISTICS</code> has been executed.</p>"},{"location":"user-stats.html#com_show_user_statistics","title":"<code>Com_show_user_statistics</code>","text":"Option Description Scope Global/Session Data type numeric <p>The Com_show_user_statistics statement counter variable indicates the number of times the statement <code>SHOW USER_STATISTICS</code> has been executed.</p> <p></p>"},{"location":"user-stats.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"using-amz-kms.html","title":"Use the Amazon Key Management Service (AWS KMS)","text":"<p>Percona Server for MySQL supports the Amazon Key Management Service (AWS KMS). Percona Server generates the keyring keys. Amazon Web Services (AWS) encrypts the keyring data.</p> <p>The AWS KMS lets you create and manage cryptographic keys across AWS services. For more information, see the AWS Key Management Service Documentation.</p> <p>To use the AWS KMS component, do the following:</p> <ul> <li> <p>Have an AWS user account. This account has an access key and a secret key.</p> </li> <li> <p>Create a KMS key ID. The KMS key can then be referenced in the configuration either by its ID, alias (the key can have any number of aliases), or ARN.</p> </li> </ul>"},{"location":"using-amz-kms.html#component-installation","title":"Component installation","text":"<p>The component must be installed with a manifest. A keyring component is not loaded with the <code>--early-plugin-load</code> option on the server. The server uses a manifest and the component consults its configuration file during initialization. You should only load a keyring component with a manifest file. Do not use the <code>INSTALL_COMPONENT</code> statement, which loads the keyring components too late in the startup sequence of the server. For example, <code>InnoDB</code> requires the component, but because the components are registered in the <code>mysql.component</code> table, this table is loaded after <code>InnoDB</code> initialization.</p> <p>You should create a global manifest file named <code>mysqld.my</code> in the installation directory and, optionally, create a local manifest file, also named <code>mysqld.my</code> in a data directory.</p> <p>To install a keyring component, do the following:</p> <ol> <li> <p>Write a manifest in a valid JSON format</p> </li> <li> <p>Write a configuration file</p> </li> </ol> <p>A manifest file indicates which component to load. If the manifest file does not exist, the server does not load the component associated with that file. During startup, the server reads the global manifest file from the installation directory. The global manifest file can contain the required information or point to a local manifest file located in the data directory. If you have multiple server instances that use different keyring components use a local manifest file in each data directory to load the correct keyring component for that instance.</p> <p>Warning</p> <p>Enable only one keyring plugin or one keyring component at a time for each server instance. Enabling multiple keyring plugins or keyring components or mixing keyring plugins or keyring components is not supported and may result in data loss.</p> <p>For more information, see Installing and Uninstalling Components.</p> <p>The following example is a global manifest file that does not use local manifests:</p> <pre><code>{\n \"read_local_manifest\": false,\n \"components\": \"file://component_keyring_kms\"\n}\n</code></pre> <p>The following is an example of a global manifest file that points to a local manifest file:</p> <pre><code>{\n \"read_local_manifest\": true\n}\n</code></pre> <p>The following is an example of a local manifest file:</p> <pre><code>{\n \"components\": \"file://component_keyring_kms\"\n}\n</code></pre> <p>The configuration settings are either in a global configuration file or a local configuration file. The settings are the same.</p> <p>The KMS configuration file has the following options:</p> <ul> <li> <p>read_local_config</p> </li> <li> <p>path - the location of the JSON keyring database file.</p> </li> <li> <p>read_only - if true, the keyring cannot be modified.</p> </li> <li> <p>kms_key - the identifier of an AWS KMS master key. The user must create this key before creating the manifest file. The identifier can be one of the following:</p> <ul> <li> <p>UUID</p> </li> <li> <p>Alias</p> </li> <li> <p>ARN</p> </li> </ul> </li> </ul> <p>For more information, see Finding the key ID and key ARN.</p> <ul> <li> <p>region - the AWS where the KMS is stored. Any HTTP request connect to this region.</p> </li> <li> <p>auth_key - an AWS user authentication key. The user must have access to the KMS key.</p> </li> <li> <p>secret_access_key - the secret key (API \u201cpassword\u201d) for the AWS user.</p> </li> </ul> <p>Note</p> <p>The configuration file contains authentication information. Only the MySQL process should be able to read this file.</p> Example of a configuration file in JSON format <pre><code>{\n \"read_local_config\": \"true/false\",\n \"path\": \"/usr/local/mysql/keyring-mysql/aws-keyring-data\",\n \"region\": \"eu-central-1\",\n \"kms_key\": \"UUID, alias or ARN as displayed by the KMS console\",\n \"auth_key\": \"AWS user key\",\n \"secret_access_key\": \"AWS user secret key\"\n}\n</code></pre> <p>For more information, see Keyring Component installation.</p> <p></p>"},{"location":"using-amz-kms.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"using-kmip.html","title":"Use the Key Management Interoperability Protocol (KMIP)","text":"<p>Percona Server for MySQL supports the OASIS Key Management Interoperability Protocol (KMIP). This implementation was tested with the PyKMIP server and the HashiCorp Vault Enterprise KMIP Secrets Engine.</p> <p>KMIP enables communication between key management systems and the database server. The protocol can do the following:</p> <ul> <li> <p>Streamline encryption key management</p> </li> <li> <p>Eliminate redundant key management processes</p> </li> </ul>"},{"location":"using-kmip.html#component-installation","title":"Component installation","text":"<p>The component must be installed with a manifest. A keyring component is not loaded with the <code>--early-plugin-load</code> option on the server. The server uses a manifest and the component consults its configuration file during initialization. You should only load a keyring component with a manifest file. Do not use the <code>INSTALL_COMPONENT</code> statement, which loads the keyring components too late in the startup sequence of the server. For example, <code>InnoDB</code> requires the component, but because the components are registered in the <code>mysql.component</code> table, this table is loaded after <code>InnoDB</code> initialization.</p> <p>You should create a global manifest file named <code>mysqld.my</code> in the installation directory and, optionally, create a local manifest file, also named <code>mysqld.my</code> in a data directory.</p> <p>To install a keyring component, do the following:</p> <ol> <li> <p>Write a manifest in a valid JSON format</p> </li> <li> <p>Write a configuration file</p> </li> </ol> <p>A manifest file indicates which component to load. If the manifest file does not exist, the server does not load the component associated with that file. During startup, the server reads the global manifest file from the installation directory. The global manifest file can contain the required information or point to a local manifest file located in the data directory. If you have multiple server instances that use different keyring components use a local manifest file in each data directory to load the correct keyring component for that instance.</p> <p>Warning</p> <p>Enable only one keyring plugin or one keyring component at a time for each server instance. Enabling multiple keyring plugins or keyring components or mixing keyring plugins or keyring components is not supported and may result in data loss.</p> <p>For more information, see Installing and Uninstalling Components.</p> <p>The following is an example of a global manifest file that does not use local manifests:</p> <pre><code>{\n \"read_local_manifest\": false,\n \"components\": \"file://component_keyring_kmip\"\n}\n</code></pre> <p>The following is an example of a global manifest file that points to a local manifest file:</p> <pre><code>{\n \"read_local_manifest\": true\n}\n</code></pre> <p>The following is an example of a local manifest file:</p> <pre><code>{\n \"components\": \"file://component_keyring_kmip\"\n}\n</code></pre> <p>The configuration settings are either in a global configuration file or a local configuration file. The settings are the same. </p> Example of a configuration file in JSON format <pre><code>{\n \"server_addr\": \"127.0.0.1\",\n \"server_port\": \"5696\",\n \"client_ca\": \"client_certificate.pem\",\n \"client_key\": \"client_key.pem\",\n \"server_ca\": \"root_certificate.pem\"\n}\n</code></pre> <p>For more information, see Keyring Component installation.</p> <p></p>"},{"location":"using-kmip.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"utility-user.html","title":"Utility user","text":"<p>Percona Server for MySQL has implemented ability to have a MySQL user who has system access to do administrative tasks but limited access to user schema. This feature is especially useful to those operating MySQL As A Service.</p> <p>This user has a mixed and special scope of abilities and protection:</p> <ul> <li> <p>Utility user does not appear in the mysql.user table and can not be modified by any other user, including root.</p> </li> <li> <p>Utility user does not appear in INFORMATION_SCHEMA.USER_STATISTICS, INFORMATION_SCHEMA.CLIENT_STATISTICS or THREAD_STATISTICS tables or in any performance_schema tables.</p> </li> <li> <p>Utility user\u2019s queries may appear in the general and slow logs.</p> </li> <li> <p>Utility user does not have the ability create, modify, delete or see any schemas or data not specified, except for information_schema.</p> </li> <li> <p>Utility user may modify all visible, non-read-only system variables (see expanded_option_modifiers functionality).</p> </li> <li> <p>Utility user may see, create, modify and delete other system users only if given access to the mysql schema.</p> </li> <li> <p>Regular users may be granted proxy rights to the utility user but attempts to impersonate the utility user fail. The utility user may not be granted proxy rights on any regular user.</p> </li> </ul> <p>For example, <code>GRANT PROXY ON utility_user TO regular_user;</code> does not fail, but any actual attempt to impersonate as the utility user fails.</p> <p><code>GRANT PROXY ON regular_user TO utility_user;</code> fails when utility_user is an exact match or is more specific than than the utility user specified.</p> <p>At server start, the server notes in the log output that the utility user exists and the schemas that the utility user can access.</p>"},{"location":"utility-user.html#system-variables","title":"System variables","text":"<p>In order to have the ability for a special type of MySQL user, which will have a very limited and special amount of control over the system and can not be see or modified by any other user including the root user, three new options have been added.</p>"},{"location":"utility-user.html#utility_user","title":"<code>utility_user</code>","text":"Option Description Command Line: Yes Config file utility_user=&lt;user@host&gt; Scope: Global Dynamic: No Data type String Default NULL <p>Specifies a MySQL user that will be added to the internal list of users and recognized as the utility user.</p> <p>Option utility_user specifies the user which the system  creates and recognizes as the utility user. The host in the utility user specification follows conventions described in the MySQL manual. For example, the conventions allow wildcards and IP masks. Anonymous user names are not permitted to be used for the utility user name.</p> <p>This user must not be an exact match to any other user that exists in the mysql.user table. If the server detects that the user specified with this option exactly matches any user within the mysql.user table on start up, the server reports an error and exits gracefully.</p> <p>If host name wildcards are used and a more specific user specification is identified on start up, the server reports a warning and continues.</p> Error message <pre><code>utility_user=frank@% and [frank@localhost](mailto:frank@localhost) exists within the mysql.user table.\n</code></pre> <p>If a client attempts to create a MySQL user that matches this user specification exactly or if host name wildcards are used for the utility user and the user being created has the same name and a more specific host, the creation attempt fails with an error.</p> Error message <pre><code>utility_user=frank@% and CREATE USER [\u2018frank@localhost](mailto:'frank@localhost)\u2019;\n</code></pre> <p>As a result of these requirements, it is strongly recommended that a very unique user name and reasonably specific host be used. </p> <p>Verify the script or tools test they are running within the correct user by executing <code>SELECT CURRENT_USER()</code> and comparing the result against the known utility user.</p>"},{"location":"utility-user.html#utility_user_password","title":"<code>utility_user_password</code>","text":"Option Description Command Line: Yes Config file utility_user_password=password Scope: Global Dynamic: No Data type String Default NULL <p>Specifies the password required for the utility user.</p> <p>Option utility_user_password specifies the password for the utility user and must be specified or the server exits with an error.</p> Utility user password <pre><code>utility_user_password=Passw0rD\n</code></pre>"},{"location":"utility-user.html#utility_user_schema_access","title":"<code>utility_user_schema_access</code>","text":"Option Description Command Line: Yes Config file utility_user_schema_access=schema,schema,schema Scope: Global Dynamic: No Data type String Default NULL <p>Specifies the schemas that the utility user has access to in a comma delimited list.</p> <p>Option utility_user_schema_access specifies the name(s) of the schema(s) that the utility user will have access to read write and modify. If a particular schema named here does not exist on start up it will be ignored. If a schema by the name of any of those listed in this option is created after the server is started, the utility user will have full access to it.</p> Utility user schema access <pre><code>utility_user_schema_access=schema1,schema2,schema3\n</code></pre>"},{"location":"utility-user.html#utility_user_privileges","title":"<code>utility_user_privileges</code>","text":"Option Description Command Line: Yes Config file utility_user_privileges=privilege1,privilege2,privilege3 Scope: Global Dynamic: No Data type String Default NULL <p>This variable can be used to specify a comma-separated list of extra access privileges to grant to the utility user. Supported values for the privileges list are: <code>SELECT, INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, GRANT, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE</code></p> <p>Option utility-user-privileges allows a comma-separated list of extra access privileges to grant to the utility user.</p> Utility user privileges <pre><code>utility-user-privileges =\u201dCREATE,DROP,LOCK TABLES\u201d;\n</code></pre>"},{"location":"utility-user.html#utility_user_dynamic_privileges","title":"<code>utility_user_dynamic_privileges</code>","text":"Option Description Command Line: Yes Config file utility_user_dynamic_privileges=privilege1,privilege2,privilege3 Scope: Global Dynamic: No Data type String Default NULL <p>This variable allows a comma-separated list of extra access dynamic privileges to grant to the utility user. The supported values for the dynamic privileges are:</p> <ul> <li> <p>APPLICATION_PASSWORD_ADMIN</p> </li> <li> <p>AUDIT_ADMIN</p> </li> <li> <p>BACKUP_ADMIN</p> </li> <li> <p>BINLOG_ADMIN</p> </li> <li> <p>BINLOG_ENCRYPTION_ADMIN</p> </li> <li> <p>CLONE_ADMIN</p> </li> <li> <p>CONNECTION_ADMIN</p> </li> <li> <p>ENCRYPTION_KEY_ADMIN</p> </li> <li> <p>FIREWALL_ADMIN</p> </li> <li> <p>FIREWALL_USER</p> </li> <li> <p>GROUP_REPLICATION_ADMIN</p> </li> <li> <p>INNODB_REDO_LOG_ARCHIVE</p> </li> <li> <p>NDB_STORED_USER</p> </li> <li> <p>PERSIST_RO_VARIABLES_ADMIN</p> </li> <li> <p>REPLICATION_APPLIER</p> </li> <li> <p>REPLICATION_SLAVE_ADMIN</p> </li> <li> <p>RESOURCE_GROUP_ADMIN</p> </li> <li> <p>RESOURCE_GROUP_USER</p> </li> <li> <p>ROLE_ADMIN</p> </li> <li> <p>SESSION_VARIABLES_ADMIN</p> </li> <li> <p>SET_USER_ID</p> </li> <li> <p>SHOW_ROUTINE</p> </li> <li> <p>SYSTEM_USER</p> </li> <li> <p>SYSTEM_VARIABLES_ADMIN</p> </li> <li> <p>TABLE_ENCRYPTION_ADMIN</p> </li> <li> <p>VERSION_TOKEN_ADMIN</p> </li> <li> <p>XA_RECOVER_ADMIN</p> </li> </ul> <p>Other dynamic privileges may be defined by plugins.</p> <p>Option utility_user_dynamic_privileges allows a comma-separated list of extra-access dynamic privileges to grant to the utility user.</p> Utility user dynamic privileges <pre><code>utility_user_dynamic_privileges =\u201dSYSTEM_USER,AUDIT_ADMIN\u201d;\n</code></pre> <p></p>"},{"location":"utility-user.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"uuid-versions.html","title":"UUID_VX component","text":"<p>A Universally Unique Identifier (UUID) is a 128-bit number used to identify information uniquely in computer systems. It is often represented as a 32-character hexadecimal string divided into five groups separated by hyphens.</p> Benefit Description Global Uniqueness UUIDs ensure that each identifier is unique across different databases and systems without needing a central authority to manage the IDs. This prevents ID conflicts when merging data from multiple sources. Decentralized Generation Since UUIDs can be generated independently by different systems, there is no need for coordination. This is particularly useful in distributed environments where systems might not have constant communication with each other. Scalability UUIDs support scalability in distributed databases. New records can be added without worrying about generating duplicate IDs, even when data is inserted concurrently across multiple nodes. Improved Data Merging When data from various sources is combined, UUIDs prevent conflicts, making the merging process simpler and more reliable. Security UUIDs, especially those generated randomly (like UUIDv4), are hard to predict, adding a layer of security when used as identifiers. <p>The following table describes the UUID versions:</p> UUID Version Description Version 1 (Time-based) - Generated using the current time and a node identifier (usually the MAC address).  - Ensures uniqueness over time and across nodes. Version 2 (DCE Security) - Similar to version 1 but includes additional information such as POSIX UID/GID.  - Often used in environments requiring enhanced security. Version 3 (Name-based, MD5 hash) - Generated from a namespace identifier and a name (string).  - Uses the MD5 hashing algorithm to ensure the UUID is derived from the namespace and name. Version 4 (Random) - Generated using random numbers.  - Offers high uniqueness and is easy to generate without requiring specific inputs. Version 5 (Name-based, SHA-1 hash) - Similar to version 3 but uses the SHA-1 hashing algorithm.  - Provides a stronger hash function than MD5. Version 6 (Time-ordered) - A reordered version of UUIDv1 for better indexing and storage efficiency.  - Combines timestamp and random or unique data. Version 7 (Unix Epoch Time) - Combines a high-precision timestamp with random data.  - Provides unique, time-ordered UUIDs that are ideal for database indexing. Version 8 (Custom) - Reserved for user-defined purposes and experimental uses.  - Allows custom formats and structures according to specific requirements. <p>UUID version 4 (UUIDv4) generates a unique identifier using random numbers. This randomness ensures a high level of uniqueness without needing a central authority to manage IDs. However, using UUIDv4 as a primary key in a distributed database is not recommended. The random nature of UUIDv4 leads to several issues:</p> Issue Description Inefficient Indexing UUIDv4 does not follow any order, causing inefficient indexing. Databases struggle to keep records organized, leading to slower query performance. Fragmentation The random distribution of UUIDv4 can cause data fragmentation, making database storage less efficient. Storage Space UUIDs are larger (128 bits) than traditional integer keys, consuming more storage space and memory. <p>For better performance and efficiency in a distributed database, consider using  UUIDv7, which incorporates timestamps for some order levels.</p> <p>UUID version 7 (UUIDv7) creates time-ordered identifiers by encoding a Unix timestamp with millisecond precision in the first 48 bits. It uses 6 bits to specify the UUID version and variant, while the remaining 74 bits are random. This time-ordering results in nearly sequential values, which helps improve index performance and locality in distributed systems.</p>"},{"location":"uuid-versions.html#install-the-uuid_vx-component","title":"Install the UUID_VX component","text":"<pre><code>mysql&gt; INSTALL COMPONENT 'file://component_uuid_vx_udf';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.03 sec) \n</code></pre>"},{"location":"uuid-versions.html#character-sets-available","title":"Character sets available","text":"<p>The following character sets are used in the component:</p> Character set Description ascii Used everywhere UUID strings are returned by functions or accepted as function arguments. utf8mb4 Used for string arguments in hash-based UUID generators, like <code>UUID_V3()</code> and <code>UUID_V5()</code> functions. binary Used for arguments in the <code>BIN_TO_UUID_VX()</code> function and for results from the <code>UUID_VX_TO_BIN()</code> function."},{"location":"uuid-versions.html#functions-available-in-uuid_vx","title":"Functions available in UUID_VX","text":"<p>The following functions are compatible with all UUID versions:</p> Function name Argument Description <code>BIN_TO_UUID_VX()</code> One string argument that must be a hexadecimal of exactly 32 characters (16 bytes) The function returns a UUID with binary data from the argument. It returns an error for all other inputs. <code>IS_MAX_UUID_VX()</code> One string argument that represents a UUID in standard or hexadecimal form. The function returns true if the argument is a valid UUID and is a MAX UUID. It returns false for all other inputs. If the argument is NULL, it returns NULL. If the argument cannot be parsed as a UUID, the function throws an error. <code>IS_NIL_UUID_VX()</code> One string argument representing a UUID in standard or hexadecimal form. The function returns true if the string is a NIL UUID. If the argument is NULL, it returns NULL. If the argument is not a valid UUID, it throws an error. <code>IS_UUID_VX()</code> One string argument that represents a UUID in either standard or hexadecimal form. The function returns true if the argument is a valid UUID. If the argument is NULL, it returns NULL. For any other input, it returns false. <code>MAX_UUID_VX()</code> No argument This function generates a MAX UUID, which has all 128 bits set to one (FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF). This function result is the opposite of the NIL UUID. <code>NIL_UUID_VX()</code> No argument. This function generates a NIL UUID, which has all 128 bits set to zero (00000000-0000-0000-0000-000000000000). <code>UUID_VX_TO_BIN()</code> One string argument, formatted as a UUID or in hexadecimal form The function converts the string arugment to its binary representation. <code>UUID_VX_VARIANT()</code> One string argument that represents a UUID in either standard or hexadecimal format. The function returns the UUID version (1-8) or an error if the argument is not a valid UUID or returns NULL if the input is NULL. <code>UUID_VX_VERSION()</code> One string representing a UUID in standard or hexadecimal form. The function returns version of UUID(1-8). The function throws an error if the argument is not a valid UUID in formatted or hexadecimal form or returns a NULL if the argument is NULL. If the argument is a valid UUID string but has an unknown value (outside of the 1-8 range) the function returns <code>-1</code>."},{"location":"uuid-versions.html#examples-of-functions-for-all-uuid-versions","title":"Examples of functions for all UUID versions","text":"<pre><code>mysql&gt; SELECT is_uuid_vx('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+----------------------------------------------------+\n| is_uuid_vx('01900bf6-0eb0-715a-80f4-636367e07777') |\n+----------------------------------------------------+\n|                                                  1 |\n+----------------------------------------------------+\n</code></pre> <pre><code>mysql&gt; SELECT uuid_vx_version('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+---------------------------------------------------------+\n| uuid_vx_version('01900bf6-0eb0-715a-80f4-636367e07777') |\n+---------------------------------------------------------+\n|                                                       7 |\n+---------------------------------------------------------+\n</code></pre> <pre><code> mysql&gt; SELECT uuid_vx_variant('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+---------------------------------------------------------+\n| uuid_vx_variant('01900bf6-0eb0-715a-80f4-636367e07777') |\n+---------------------------------------------------------+\n|                                                       1 |\n+---------------------------------------------------------+\n</code></pre>"},{"location":"uuid-versions.html#uuid-generator-functions","title":"UUID generator functions","text":"<p>The following functions generate specific UUID versions:</p> UUID Version Arguement Description <code>UUID_V1()</code> No argument Generates a version 1 UUID based on a timestamp. If possible, use UUID_V7() instead. <code>UUID_V3()</code> One or two arguments: the first argument is a string that is hashed with MD5 and used in the UUID; the second argument is optional and specifies a namespace (integer values: DNS: 0, URL: 1, OID: 2, X.500: 3; default is 1 or URL). Generates a version 3 UUID based on a name.  Note: MD5 is outdated and not secure. Use with caution and avoid exposing sensitive data. <code>UUID_V4()</code> No argument The function generates a version 4 UUID using random numbers and is similar to the built-in UUID() function. <code>UUID_V5()</code> One or two arguments: the first argument is a string that is hashed with SHA1 and used in the UUID; the second argument is optional and specifies a namespace (integer values: DNS: 0, URL: 1, OID: 2, X.500: 3; default is 1 or URL). Generates a version 5 UUID based on a name.  Note: SHA1 is better than MD5 but still not secure. Use with caution and avoid exposing sensitive data. <code>UUID_V6()</code> No argument Generates a version 6 UUID based on a timestamp. If possible, use UUID_V7() instead. <code>UUID_V7()</code> Can have either no argument or a one integer argument: the argument is the number of milliseconds to adjust the timestamp forward or backward (negative values). Generates a version 7 UUID based on a timestamp.  If there is no argument, no timestamp shift occurs. Timestamp shift can hide the actual creation time of the record. <p>The <code>UUID_v3()</code> function and <code>UUID_v5()</code> function do not validate the string argument, such as whether the URL is formatted correctly or the DNS name is correct. These functions generate a string hash and then add that hash to a UUID with the defined namespace. The user specifies the string.</p>"},{"location":"uuid-versions.html#uuid-generator-examples","title":"UUID generator examples","text":"<p>UUID version 1:</p> <pre><code>mysql&gt; SELECT uuid_v1();\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v1()                            |\n+--------------------------------------+\n| 14c22f93-2962-11ef-9078-c3abf1c446bb |\n+--------------------------------------+\n</code></pre> <p>UUID version 3 takes one argument and uses the default UUID namespace as \u201cURL\u201d.</p> <pre><code>mysql&gt; SELECT uuid_v3('http://example.com');\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v3('http://example.com')        |\n+--------------------------------------+\n| d632b50c-7913-3137-ae9a-2d93f56e70d5 |\n+--------------------------------------+\n</code></pre> <p>UUID version 3 takes one argument and the explicit UUID namespace is \u201cURL\u201d.</p> <pre><code>mysql&gt; SELECT uuid_v3('http://example.com', 1);\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v3('http://example.com')        |\n+--------------------------------------+\n| d632b50c-7913-3137-ae9a-2d93f56e70d5 |\n+--------------------------------------+\n</code></pre> <p>UUID version 3 takes one argument, with the explicit UUID namespace set to \u201cDNS\u201d.</p> <pre><code>mysql&gt; SELECT uuid_v3('example.com',0);\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v3('example.com',0)             |\n+--------------------------------------+\n| 9073926b-929f-31c2-abc9-fad77ae3e8eb |\n+--------------------------------------+\n</code></pre> <p>UUID version 4:</p> <pre><code>mysql&gt; SELECT uuid_v4();\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v4()                            |\n+--------------------------------------+\n| a408e4ad-9b98-4edb-a105-40f22648a928 |\n+--------------------------------------+\n</code></pre> <p>UUID version 5:</p> <pre><code>mysql&gt; SELECT uuid_v5(\"http://example.com\");\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v5(\"http://example.com\")        |\n+--------------------------------------+\n| 8c9ddcb0-8084-5a7f-a988-1095ab18b5df |\n+--------------------------------------+\n</code></pre> <p>UUID version 6:</p> <pre><code>mysql&gt; SELECT uuid_v6();\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v6()                            |\n+--------------------------------------+\n| 1ef29686-2168-64a7-b9a2-adb13f80f118 |\n+--------------------------------------+\n</code></pre> <p>UUID version 7 generation:</p> <pre><code>mysql&gt;SELECT uuid_v7();\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v7()                            |\n+--------------------------------------+\n| 019010f6-0426-70f0-80b0-b63decd3d7d1 |\n+--------------------------------------+\n1 row in set (0.00 sec)\n</code></pre> <p>UUID version 7 with timestamp offset in 84000 seconds in the future</p> <pre><code>mysql&gt; SELECT uuid_v7(84000000);\n</code></pre> Expected output <pre><code>+--------------------------------------+\n| uuid_v7(84000000)                    |\n+--------------------------------------+\n| 019015f8-c7c4-70b4-8043-fe241c2be36c |\n+--------------------------------------+\n</code></pre>"},{"location":"uuid-versions.html#time-based-functions","title":"Time-based functions","text":"<p>The following functions are used only with time-based UUIDs, specifically versions 1, 6, and 7.</p> Function name Argument Description UUID_VX_TO_TIMESTAMP() One string argument Returns a timestamp string like \u201c2024-05-29 18:04:14.201\u201d. If the argument is not parsable as UUID v.1,6,7, the function throws an error. The function always uses UTC time, regardless of system settings or time zone settings in MySQL. UUID_VX_TO_TIMESTAMP_TZ() One string argument Returns a timestamp string with the time zone like \u201cWed May 29 18:05:07 2024 GMT\u201d. If the argument is not parsable as UUID v.1,6,7, the function throws an error. The function always uses UTC time (GMT time zone), regardless of system settings or time zone settings in MySQL. UUID_VX_TO_UNIXTIME() One string argument Returns a number of milliseconds since the Epoch. If the argument is not parsable as UUID v.1,6,7, the function throws an error."},{"location":"uuid-versions.html#timestamp-based-function-examples","title":"Timestamp-based function examples","text":"<pre><code>mysql&gt; SELECT uuid_vx_to_timestamp('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+--------------------------------------------------------------+\n| uuid_vx_to_timestamp('01900bf6-0eb0-715a-80f4-636367e07777') |\n+--------------------------------------------------------------+\n| 2024-06-12 10:19:53.392                                      |\n+--------------------------------------------------------------+\n1 row in set (0.00 sec)\n</code></pre> <pre><code>mysql&gt; SELECT uuid_vx_to_timestamp_tz('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+-----------------------------------------------------------------+\n| uuid_vx_to_timestamp_tz('01900bf6-0eb0-715a-80f4-636367e07777') |\n+-----------------------------------------------------------------+\n| Wed Jun 12 10:19:53 2024 GMT                                    |\n+-----------------------------------------------------------------+\n</code></pre> <pre><code>mysql&gt; SELECT uuid_vx_to_unixtime('01900bf6-0eb0-715a-80f4-636367e07777');\n</code></pre> Expected output <pre><code>+-------------------------------------------------------------+\n| uuid_vx_to_unixtime('01900bf6-0eb0-715a-80f4-636367e07777') |\n+-------------------------------------------------------------+\n|                                               1718187593392 |\n+-------------------------------------------------------------+\n</code></pre>"},{"location":"uuid-versions.html#uninstall-the-uuid_vx-component","title":"Uninstall the UUID_VX component","text":"<pre><code>mysql&gt; UNINSTALL COMPONENT 'file://component_uuid_vx_udf';\n</code></pre> Expected output <pre><code>Query OK, 0 rows affected (0.03 sec)\n</code></pre>"},{"location":"uuid-versions.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"verify-encryption.html","title":"Verify the encryption for tables, tablespaces, and schemas","text":"<p>If a general tablespace contains tables, check the table information to see if the table is encrypted. When the general tablespace contains no tables, you may verify if the tablespace is encrypted or not.</p> <p>For single tablespaces, verify the ENCRYPTION option using INFORMATION_SCHEMA.TABLES and the CREATE OPTIONS settings.</p> <pre><code>mysql&gt; SELECT TABLE_SCHEMA, TABLE_NAME, CREATE_OPTIONS FROM\n       INFORMATION_SCHEMA.TABLES WHERE CREATE_OPTIONS LIKE '%ENCRYPTION%';\n</code></pre> Expected output <pre><code>+----------------------+-------------------+------------------------------+\n| TABLE_SCHEMA         | TABLE_NAME        | CREATE_OPTIONS               |\n+----------------------+-------------------+------------------------------+\n|sample                | t1                | ENCRYPTION=\"Y\"               |\n+----------------------+-------------------+------------------------------+\n</code></pre> <p>A <code>flag</code> field in the <code>INFORMATION_SCHEMA.INNODB_TABLESPACES</code> has bit number 13 set if the tablespace is encrypted. This bit can be checked with the <code>flag &amp; 8192</code> expression in the following way:</p> <pre><code>SELECT space, name, flag, (flag &amp; 8192) != 0 AS encrypted FROM\nINFORMATION_SCHEMA.INNODB_TABLESPACES WHERE name in ('foo', 'test/t2', 'bar',\n'noencrypt');\n</code></pre> <p>The encrypted table metadata is contained in the INFORMATION_SCHEMA.INNODB_TABLESPACES_ENCRYPTION table. You must have the <code>Process</code> privilege to view the table information.</p> <p>Note</p> <p>This table is in tech preview and may change in future releases.</p> <pre><code>   mysql&gt; DESCRIBE INNODB_TABLESPACES_ENCRYPTION;\n</code></pre> Expected output <pre><code>+-----------------------------+--------------------+-----+----+--------+------+\n| Field                       | Type               | Null| Key| Default| Extra|\n+-----------------------------+--------------------+-----+----+--------+------+\n| SPACE                       | int(11) unsigned   | NO  |    |        |      |\n| NAME                        | varchar(655)       | YES |    |        |      |\n| ENCRYPTION_SCHEME           | int(11) unsigned   | NO  |    |        |      |\n| KEYSERVER_REQUESTS          | int(11) unsigned   | NO  |    |        |      |\n| MIN_KEY_VERSION             | int(11) unsigned   | NO  |    |        |      |\n| CURRENT_KEY_VERSION         | int(11) unsigned   | NO  |    |        |      |\n| KEY_ROTATION_PAGE_NUMBER    | bigint(21) unsigned| YES |    |        |      |\n| KEY_ROTATION_MAX_PAGE_NUMBER| bigint(21) unsigned| YES |    |        |      |\n| CURRENT_KEY_ID              | int(11) unsigned   | NO  |    |        |      |\n| ROTATING_OR_FLUSHING        | int(1) unsigned    | NO  |    |        |      |\n+-----------------------------+--------------------+-----+----+--------+------+\n</code></pre> <p>To identify encryption-enabled schemas, query the INFORMATION_SCHEMA.SCHEMATA table:</p> <pre><code>mysql&gt; SELECT SCHEMA_NAME, DEFAULT_ENCRYPTION FROM\nINFORMATION_SCHEMA.SCHEMATA WHERE DEFAULT_ENCRYPTION='YES';\n</code></pre> Expected output <pre><code>+------------------------------+---------------------------------+\n| SCHEMA_NAME                  | DEFAULT_ENCRYPTION              |\n+------------------------------+---------------------------------+\n| samples                      | YES                             |\n+------------------------------+---------------------------------+\n</code></pre> <p>The <code>SHOW CREATE SCHEMA</code> statement returns the <code>DEFAULT ENCRYPTION</code> clause.</p> <p></p>"},{"location":"verify-encryption.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"views.html","title":"Views","text":"<p>A view is a virtual table generated from a SQL query. It allows users to simplify complex queries, hide sensitive data, and provide a customized view of the database without altering the underlying schema.</p>"},{"location":"views.html#advantages-of-using-views","title":"Advantages of Using Views","text":"Benefits Description Simplification Views simplify complex queries by encapsulating them into a single, reusable object. They provide a convenient way to abstract and hide the complexity of underlying tables. Security Views can enhance security by restricting access to sensitive data. Users can be granted access to views containing only the necessary columns, without direct access to the tables. Customization Views enable users to create customized perspectives of the data, presenting only the relevant information needed for specific tasks or reports. Performance Views can improve query performance by pre-computing and caching results, reducing the need to repeatedly execute complex queries."},{"location":"views.html#disadvantages-of-using-views","title":"Disadvantages of Using Views","text":"Disadvantages Description Complexity Views can introduce complexity to the database schema and query execution plan, making it harder to optimize and troubleshoot performance issues. Overhead Views may incur overhead in terms of storage and processing resources, particularly for materialized views or views involving joins and aggregation functions. Maintenance Views require maintenance to keep them synchronized with the underlying tables. Changes to the base tables may impact the results returned by the view. Limited Use Views have limitations in terms of updateability and support for certain SQL operations, such as ordering or grouping by columns not present in the underlying tables."},{"location":"views.html#create-view","title":"Create view","text":"<pre><code>mysql&gt; CREATE VIEW customer_orders AS\n    SELECT customers.name, orders.order_id, orders.total_amount\n    FROM customers\n    JOIN orders ON customers.customer_id = orders.customer_id;\n</code></pre> <pre><code>mysql&gt; CREATE VIEW recent_orders AS\n   SELECT *\n    FROM orders\n    WHERE order_date &gt;= CURDATE() - INTERVAL 30 DAY;\n</code></pre>"},{"location":"views.html#drop-view","title":"Drop view","text":"<pre><code>mysql&gt; DROP VIEW IF EXISTS customer_orders;\n</code></pre> <pre><code>mysql&gt; DROP VIEW IF EXISTS recent_orders;\n</code></pre>"},{"location":"views.html#database-management","title":"Database management","text":"<ul> <li>Database</li> <li>Modify Tables</li> <li>Isolation Levels</li> <li>Transaction Management</li> </ul>"},{"location":"views.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"xtradb-performance-improvements.html","title":"XtraDB performance improvements for I/O-bound highly-concurrent workloads","text":""},{"location":"xtradb-performance-improvements.html#priority-refill-for-the-buffer-pool-free-list","title":"Priority refill for the buffer pool free list","text":"<p>In highly-concurrent I/O-bound workloads the following situation may happen:</p> <ul> <li> <p>Buffer pool free lists are used faster than they are refilled by the LRU cleaner thread.</p> </li> <li> <p>Buffer pool free lists become empty and more and more query and utility (i.e., purge) threads stall, checking whether a buffer pool free list has became non-empty, sleeping, performing single-page LRU flushes.</p> </li> <li> <p>The number of buffer pool free list mutex waiters increases.</p> </li> <li> <p>When the LRU manager thread (or a single page LRU flush by a query thread) finally produces a free page, it is starved from putting it on the buffer pool free list as it must acquire the buffer pool free list mutex too. However, being one thread in up to hundreds, the chances of a prompt acquisition are low.</p> </li> </ul> <p>This is addressed by delegating all the LRU flushes to the to the LRU manager thread, never attempting to evict a page or perform a LRU single page flush by a query thread, and introducing a backoff algorithm to reduce buffer pool free list mutex pressure on empty buffer pool free lists. This is controlled through a new system variable innodb_empty_free_list_algorithm.</p>"},{"location":"xtradb-performance-improvements.html#innodb_empty_free_list_algorithm","title":"<code>innodb_empty_free_list_algorithm</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: legacy, backoff Default legacy <p>When <code>legacy</code> option is set, server will use the upstream algorithm and when the <code>backoff</code> is selected, Percona implementation will be used.</p>"},{"location":"xtradb-performance-improvements.html#multi-threaded-lru-flusher","title":"Multi-threaded LRU flusher","text":"<p>This feature has been removed in Percona Server for MySQL 8.3.0-1.</p> <p>Percona Server for MySQL features a true multi-threaded LRU flushing. In this scheme, each buffer pool instance has its own dedicated LRU manager thread that is tasked with performing LRU flushes and evictions to refill the free list of that buffer pool instance. Existing multi-threaded flusher no longer does any LRU flushing and is tasked with flush list flushing only.</p> <ul> <li> <p>All threads still synchronize on each coordinator thread iteration. If a particular flushing job is stuck on one of the worker threads, the rest will idle until the stuck one completes.</p> </li> <li> <p>The coordinator thread heuristics focus on flush list adaptive flushing without considering the state of free lists, which might be in need of urgent refill for a subset of buffer pool instances on a loaded server.</p> </li> <li> <p>LRU flushing is serialized with flush list flushing for each buffer pool instance, introducing the risk that the right flushing mode will not happen for a particular instance because it is being flushed in the other mode.</p> </li> </ul> <p>The following InnoDB metrics are no longer accounted, as their semantics do not make sense under the current LRU flushing design: <code>buffer_LRU_batch_flush_avg_time_slot</code>, <code>buffer_LRU_batch_flush_avg_pass</code>, <code>buffer_LRU_batch_flush_avg_time_thread</code>, <code>buffer_LRU_batch_flush_avg_time_est</code>.</p> <p>The need for InnoDB recovery thread writer threads is also removed, consequently all associated code is deleted.</p>"},{"location":"xtradb-performance-improvements.html#innodb_sched_priority_master","title":"<code>innodb_sched_priority_master</code>","text":"Option Description Command-line: Yes Config file: Yes Scope: Global Dynamic: Yes Data type: Boolean <p>This variable can be added to the configuration file.</p> <p></p>"},{"location":"xtradb-performance-improvements.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-download-rpm.html","title":"Install Percona Server for MySQL using downloaded RPM packages","text":"<p>Download the packages from Percona Product Downloads. If needed, Instructions for the Percona Product Download are available.</p> <p>The RPM builds for RHEL 8 and RHEL 9 contain ARM packages with the aarch64.rpm extension. This means that Percona Server for MySQL is available for users on ARM-based systems.</p> <p>The following example downloads Percona Server for MySQL 8.4.0-1 release <code>x86_64</code> packages for RHEL 8.</p> <ol> <li> <p>Use <code>wget</code> to download the tar file.</p> <pre><code>$ wget https://downloads.percona.com/downloads/Percona-Server-8.4/Percona-Server-8.4.0-1/binary/redhat/8/x86_64/Percona-Server-8.4.0-1-r238b3c02-el8-x86_64-bundle.tar\n</code></pre> </li> <li> <p>Unpack the bundle to get the packages: </p> <pre><code>$ tar xvf Percona-Server-8.4.0-1-r238b3c02-el8-x86_64-bundle.tar\n</code></pre> </li> <li> <p>To view a list of packages, run the following command:</p> <p><pre><code>$ ls *.rpm\n</code></pre> The output should look like the following:</p> Expected output <pre><code>percona-icu-data-files-8.4.0-1.1.el8.x86_64.rpm\npercona-mysql-router-8.4.0-1.1.el8.x86_64.rpm\npercona-mysql-router-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-client-8.4.0-1.1.el8.x86_64.rpm\npercona-server-client-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-debugsource-8.4.0-1.1.el8.x86_64.rpm\npercona-server-devel-8.4.0-1.1.el8.x86_64.rpm\npercona-server-rocksdb-8.4.0-1.1.el8.x86_64.rpm\npercona-server-rocksdb-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-server-8.4.0-1.1.el8.x86_64.rpm\npercona-server-server-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-shared-8.4.0-1.1.el8.x86_64.rpm\npercona-server-shared-compat-8.4.0-1.1.el8.x86_64.rpm\npercona-server-shared-debuginfo-8.4.0-1.1.el8.x86_64.rpm\npercona-server-test-8.4.0-1.1.el8.x86_64.rpm\npercona-server-test-debuginfo-8.4.0-1.1.el8.x86_64.rpm\n</code></pre> </li> <li> <p>Install <code>jemalloc</code> with the following command, if needed:</p> <pre><code>$ wget https://repo.percona.com/yum/release/8/RPMS/x86_64/jemalloc-3.6.0-1.el8.x86_64.rpm\n</code></pre> </li> <li> <p>An EL8-based RHEL distribution or derivatives package installation requires the mysql module to be disabled before installing the packages:</p> <pre><code>$ sudo yum module disable mysql\n</code></pre> </li> <li> <p>Install all the packages (for debugging, testing, etc.) with the following command:</p> <pre><code>$ sudo rpm -ivh *.rpm\n</code></pre> <p>Note</p> <p>When installing packages manually, you must make sure to resolve all dependencies and install any missing packages yourself.</p> </li> </ol> <p></p>"},{"location":"yum-download-rpm.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-files.html","title":"Files in the RPM package built for Percona Server for MySQL 8.4","text":"<p>Each of the Percona Server for MySQL RPM packages has a particular purpose.</p> Package Contains percona-server-server Server itself (the mysqld binary) percona-server-debuginfo Debug symbols for the server percona-server-client Command line client percona-server-devel Header files needed to compile software using the client library. percona-server-shared Client shared library. percona-server-shared-compat Shared libraries for software compiled against older versions of the client library. The following libraries are included in this package: libmysqlclient.so.12, libmysqlclient.so.14, libmysqlclient.so.15, libmysqlclient.so.16, and libmysqlclient.so.18.   This package is not included in downloads for Red Hat Enterprise Linux 9 and derivatives. percona-server-test Includes the test suite for Percona Server for MySQL. <p></p>"},{"location":"yum-files.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-repo.html","title":"Install from Percona Software repository","text":"<p>Ready-to-use packages are available from the Percona Server for MySQL software repositories and the download page. The Percona yum repository supports popular RPM-based operating systems. The easiest way to install the Percona RPM repository is to install an RPM that configures yum and installs the Percona GPG key.</p> <p>We gather Telemetry data in the Percona packages and Docker images.</p>"},{"location":"yum-repo.html#supported-platforms","title":"Supported platforms","text":"<p>Specific information on the supported platforms, products, and versions are described in Percona Software and Platform Lifecycle.</p>"},{"location":"yum-repo.html#red-hat-certified","title":"Red Hat Certified","text":"<p>Percona Server for MySQL is certified for Red Hat Enterprise Linux 8. This certification is based on common and secure best practices and successful interoperability with the operating system. Percona Server is listed in the Red Hat Ecosystem Catalog.</p>"},{"location":"yum-repo.html#arm-support","title":"ARM support","text":"<p>The RPM builds for RHEL 8 and RHEL 9 contain ARM packages with the <code>aarch64.rpm</code> extension. This means that Percona Server for MySQL is available for users on ARM-based systems.</p>"},{"location":"yum-repo.html#install","title":"Install","text":"<p>To install using the Percona Software repository, run the following commands either as a <code>root</code> user or, as in the example, using <code>sudo</code>.</p> <pre><code>```{.bash data-prompt=\"$\"}\n$ sudo yum install https://repo.percona.com/yum/percona-release-latest.noarch.rpm\n$ sudo percona-release enable-only ps-84-lts release\n$ sudo percona-release enable tools release\n$ sudo yum install percona-server-server\n```\n</code></pre>"},{"location":"yum-repo.html#available-storage-engines","title":"Available storage engines","text":"<p>Percona Server for MySQL 8.4 comes with the <code>MyRocks</code> storage engine. This storage engine is installed as a plugin. For information on how to install and configure MyRocks, refer to the Percona MyRocks Installation Guide.</p>"},{"location":"yum-repo.html#percona-yum-testing-repository","title":"Percona yum Testing repository","text":"<p>Percona offers pre-release builds from our testing repository. To subscribe to the testing repository, you enable the testing repository in <code>/etc/yum.repos.d/percona-release.repo</code>. To do so, set both <code>percona-testing-$basearch</code> and <code>percona-testing-noarch</code> to <code>enabled = 1</code> (Note that there are three sections in this file: release, testing, and experimental - in this case, it is the second section that requires updating).</p> <p></p>"},{"location":"yum-repo.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-run.html","title":"Run Percona Server for MySQL","text":"<p>Percona Server for MySQL stores the data files in <code>/var/lib/mysql/</code> by default. The configuration file used to manage Percona Server for MySQL is the <code>/etc/my.cnf</code>.</p> <p>The following commands start, provide the server status, stop the server, and restart the server.</p> <p>Note</p> <p>The RHEL distributions and derivatives come with systemd as the default system and service manager so you can invoke all of the commands with <code>sytemctl</code> instead of <code>service</code>. Currently, both options are supported.</p> <ol> <li> <p>Percona Server for MySQL is not started automatically on the RHEL distributions and derivatives after installation. Start the server with the following command:</p> <pre><code>$ sudo service mysql start\n</code></pre> </li> <li> <p>Review the service status with the following command:</p> <pre><code>$ sudo service mysql status\n</code></pre> </li> <li> <p>Stop the service with the following command:</p> <pre><code>$ sudo service mysql stop\n</code></pre> </li> <li> <p>Restart the service with the following command:</p> <pre><code>$ sudo service mysql restart\n</code></pre> </li> </ol>"},{"location":"yum-run.html#selinux-and-security-considerations","title":"SELinux and security considerations","text":"<p>For information on working with SELinux, see Working with SELinux.</p> <p>The RHEL 8 distributions and derivatives have added system-wide cryptographic policies component. This component allows the configuration of cryptographic subsystems.</p> <p></p>"},{"location":"yum-run.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"yum-uninstall.html","title":"Uninstall Percona Server for MySQL","text":"<p>To completely uninstall Percona Server for MySQL, remove all the installed packages and data files.</p> <ol> <li> <p>Stop the Percona Server for MySQL service:</p> <pre><code>$ sudo service mysql stop\n</code></pre> </li> <li> <p>Remove the packages:</p> <pre><code>$ sudo yum remove percona-server*\n</code></pre> </li> <li> <p>Remove the data and configuration files:</p> <p>Warning</p> <p>This step removes all the packages and deletes all the data files (databases, tables, logs, etc.). Take a backup before this operation in case you need the data.</p> <pre><code>$ rm -rf /var/lib/mysql\n$ rm -f /etc/my.cnf\n</code></pre> </li> </ol> <p></p>"},{"location":"yum-uninstall.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/8.4.0-1.html","title":"Percona Server for MySQL 8.4.0-1 (2024-08-28)","text":"<p>Get started with Quickstart Guide for Percona Server for MySQL.</p> <p>Percona Server for MySQL 8.4.0-1 includes all the features and bug fixes available in the MySQL 8.4 Community Edition in addition to enterprise-grade features developed by Percona.</p>"},{"location":"release-notes/8.4.0-1.html#release-highlights","title":"Release highlights","text":"<p>In MySQL 8.0, the release model changed to include new features in patch releases, allowing MySQL to introduce new features more frequently. However, this approach was complex for projects and applications needing only critical patches with minimal changes.</p> <p>MySQL then moved to a versioning model with two options: Innovation releases and Long-Term Support (LTS) releases. Both types are production-ready.</p> <p>Innovation releases offer access to the latest features, making them ideal for dynamic environments with strong automated testing and continuous integration.</p> <p>Changes were made to each Innovation release that are now included in the 8.4 (LTS) release. You should review the Innovation release notes for details.</p> <ul> <li> <p>Percona Server for MySQL 8.1.0-1 (2023-11-27)</p> </li> <li> <p>Percona Server for MySQL 8.2.0-1 (2024-02-05)</p> </li> <li> <p>Percona Server for MySQL 8.3.0-1 (2024-04-16)</p> </li> </ul> <p>LTS releases are more suitable for stable, established environments where minimal changes are needed. These releases include only essential fixes, reducing the risk of changes in the database software\u2019s behavior.</p> <p>This 8.4.0-1 release is the first 8.4 LTS series.</p> <p>Improvements and bug fixes introduced by Oracle for MySQL 8.4 and included in Percona Server for MySQL are the following:</p> <ul> <li> <p>The MySQL native password has been deprecated and is no longer loaded by default. However, it can be loaded if needed.</p> </li> <li> <p>The clone plugin allows cloning between different point releases within the same series. You only must match the major and minor version numbers for cloning.</p> </li> <li> <p>GTIDs (Global Transaction Identifiers) can now handle groups of transactions, which helps speed up processing.</p> </li> <li> <p><code>mysqldump</code> can now create output for older versions of MySQL.</p> </li> <li> <p>Automatic updates for histograms. When enabled, the histogram updates automatically whenever <code>ANALYZE TABLE</code> is run on the table. InnoDB\u2019s automatic recalculation of persistent statistics also updates the histogram when automatic updates are enabled.</p> </li> <li> <p>Adds a new privilege called FLUSH_PRIVILEGES. This privilege explicitly allows the use of FLUSH PRIVILEGES statements. Unlike the RELOAD privilege, FLUSH_PRIVILEGES only applies to FLUSH PRIVILEGES statements.</p> </li> <li> <p>The terms \u201cMASTER\u201d and \u201cSLAVE\u201d in replication commands are being replaced with \u201cSOURCE\u201d and \u201cREPLICA\u201d. This change is part of an ongoing effort to use more inclusive language.</p> </li> <li> <p>Removed the the <code>mysqlpump</code> utility.</p> </li> <li> <p>Removed the <code>mysql_upgrade</code> utility.</p> </li> <li> <p>The default values for specific InnoDB server system variables have changed. See What is new in MySQL 8.4 since 8.0 for details.</p> </li> </ul> <p>Find the complete list of bug fixes and changes in the MySQL 8.4 Release Notes.\u2019</p>"},{"location":"release-notes/8.4.0-1.html#new-features","title":"New features","text":"<ul> <li>PS-9233: Adds the UUID_VX component which provides a set of functions for generating and working with various versions of the Universally Unique Identifier (UUID).</li> </ul>"},{"location":"release-notes/8.4.0-1.html#improvements","title":"Improvements","text":"<ul> <li>PS-9302: Changed underlying internal data structure used by the binlog transaction dependency tracking in <code>WRITESET</code> mode (MySQL 8.4 removed the <code>COMMIT_ORDER</code> mode). Instead of <code>std::map</code> (an RB-tree) we now use <code>std::unordered_map</code> (a hash) which gives much better performance for lookup operations. This change showed an up to 17% Queries per second (QPS) increase in the <code>oltp_inlist_update</code> workload.</li> </ul>"},{"location":"release-notes/8.4.0-1.html#bug-fixes","title":"Bug fixes","text":"<ul> <li> <p>PS-9092: There were data inconsistencies during a high rate of page split/merge.</p> </li> <li> <p>PS-9121: MySQL exited when InnoDB failed to update a spatial index.</p> </li> <li> <p>PS-9151: Percona server 8.0 build failed on CentOS 7 with <code>-DWITH_SSL=openssl11</code>.</p> </li> <li> <p>PS-9219: While converting the charset collation in a table, MySQL converted the date and time data types columns in the <code>.ibd</code> file. However, the <code>collation_id</code> in the <code>.ibd</code> file did not align with that of the data dictionary.</p> </li> <li> <p>PS-9155: The server exited during the execution of the complicated query with 9 CTEs.</p> </li> <li> <p>PS-9235: Keyring vault failed to work with <code>binlog_rotate_encryption_master_key_at_startup</code>.</p> </li> </ul>"},{"location":"release-notes/8.4.0-1.html#deprecation","title":"Deprecation","text":"<ul> <li>PS-8963: The <code>SEQUENCE_TABLE()</code> function is deprecated and may be removed in a future release. We recommend that you use <code>PERCONA_SEQUENCE_TABLE()</code> instead. To maintain compatibility with existing third-party software, <code>SEQUENCE_TABLE</code> is no longer a reserved term and can be used as a regular identifier. Find more information in PERCONA_SEQUENCE_TABLE(n) function</li> </ul>"},{"location":"release-notes/8.4.0-1.html#packaging-notes","title":"Packaging notes","text":"<p>Percona Server for MySQL 8.4.0-1 is compatible with Ubuntu 24.04.</p>"},{"location":"release-notes/8.4.0-1.html#additional-resources","title":"Additional resources","text":"<ul> <li> <p>Install Percona Server for MySQL 8.4</p> </li> <li> <p>The Percona Server for MySQL GitHub repository</p> </li> <li> <p>Download product binaries, packages, and tarballs at Percona Software Downloads</p> </li> <li> <p>Contribute to the documentation</p> </li> <li> <p>For training, contact Percona Training - Start learning now</p> </li> </ul> <p></p>"},{"location":"release-notes/8.4.0-1.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"},{"location":"release-notes/release-notes-index.html","title":"Percona Server for MySQL 8.4 release notes index","text":"<ul> <li>Percona Server for MySQL 8.4.0-1 (2024-08-28)</li> </ul>"},{"location":"release-notes/release-notes-index.html#get-expert-help","title":"Get expert help","text":"<p>If you need assistance, visit the community forum for comprehensive and free database knowledge, or contact our Percona Database Experts for professional support and services.</p> <p> Community Forum  Get a Percona Expert</p>"}]}